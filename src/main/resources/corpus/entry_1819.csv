2015,End-to-end Learning of LDA by Mirror-Descent Back Propagation over a Deep Architecture,We develop a fully discriminative learning approach for supervised Latent Dirichlet Allocation (LDA) model using Back Propagation (i.e.  BP-sLDA)  which maximizes the posterior probability of the prediction variable given the input document. Different from traditional variational learning or Gibbs sampling approaches  the proposed learning method applies (i) the mirror descent algorithm for maximum a posterior inference and (ii) back propagation over a deep architecture together with stochastic gradient/mirror descent for model parameter estimation  leading to scalable and end-to-end discriminative learning of the model.  As a byproduct  we also apply this technique to develop a new learning method for the traditional unsupervised LDA model (i.e.  BP-LDA). Experimental results on three real-world regression and classification tasks show that the proposed methods significantly outperform the previous supervised topic models  neural networks  and is on par with deep neural networks.,End-to-end Learning of LDA by Mirror-Descent Back

Propagation over a Deep Architecture

Jianshu Chen⇤  Ji He†  Yelong Shen⇤  Lin Xiao⇤  Xiaodong He⇤  Jianfeng Gao⇤ 

Xinying Song⇤ and Li Deng⇤

⇤Microsoft Research  Redmond  WA 98052  USA 

{jianshuc yeshen lin.xiao xiaohe jfgao xinson deng}@microsoft.com
†Department of Electrical Engineering  University of Washington  Seattle  WA 98195  USA 

jvking@uw.edu

Abstract

We develop a fully discriminative learning approach for supervised Latent Dirich-
let Allocation (LDA) model using Back Propagation (i.e.  BP-sLDA)  which max-
imizes the posterior probability of the prediction variable given the input doc-
ument. Different from traditional variational learning or Gibbs sampling ap-
proaches  the proposed learning method applies (i) the mirror descent algorithm
for maximum a posterior inference and (ii) back propagation over a deep architec-
ture together with stochastic gradient/mirror descent for model parameter estima-
tion  leading to scalable and end-to-end discriminative learning of the model. As
a byproduct  we also apply this technique to develop a new learning method for
the traditional unsupervised LDA model (i.e.  BP-LDA). Experimental results on
three real-world regression and classiﬁcation tasks show that the proposed meth-
ods signiﬁcantly outperform the previous supervised topic models  neural net-
works  and is on par with deep neural networks.

1

Introduction

Latent Dirichlet Allocation (LDA) [5]  among various forms of topic models  is an important prob-
abilistic generative model for analyzing large collections of text corpora. In LDA  each document is
modeled as a collection of words  where each word is assumed to be generated from a certain topic
drawn from a topic distribution. The topic distribution can be viewed as a latent representation of
the document  which can be used as a feature for prediction purpose (e.g.  sentiment analysis). In
particular  the inferred topic distribution is fed into a separate classiﬁer or regression model (e.g. 
logistic regression or linear regression) to perform prediction. Such a separate learning structure
usually signiﬁcantly restricts the performance of the algorithm. For this purpose  various supervised
topic models have been proposed to model the documents jointly with the label information. In
[4]  variational methods was applied to learn a supervised LDA (sLDA) model by maximizing the
lower bound of the joint probability of the input data and the labels. The DiscLDA method devel-
oped in [15] learns the transformation matrix from the latent topic representation to the output in a
discriminative manner  while learning the topic to word distribution in a generative manner similar
to the standard LDA. In [26]  max margin supervised topic models are developed for classiﬁca-
tion and regression  which are trained by optimizing the sum of the variational bound for the log
marginal likelihood and an additional term that characterizes the prediction margin. These methods
successfully incorporate the information from both the input data and the labels  and showed better
performance in prediction compared to the vanilla LDA model.
One challenge in LDA is that the exact inference is intractable  i.e.  the posterior distribution of the
topics given the input document cannot be evaluated explicitly. For this reason  various approximate

1

↵

✓d

zd n wd n N

yd

D

k K 
U  

Figure 1: Graphical representation of the supervised LDA model. Shaded nodes are observables.

inference methods are proposed  such as variational learning [4  5  26] and Gibbs sampling [9  27] 
for computing the approximate posterior distribution of the topics. In this paper  we will show that 
although the full posterior probability of the topic distribution is difﬁcult  its maximum a posteriori
(MAP) inference  as a simpliﬁed problem  is a convex optimization problem when the Dirichlet pa-
rameter satisﬁes certain conditions  which can be solved efﬁciently by the mirror descent algorithm
(MDA) [2  18  21]. Indeed  Sontag and Roy [19] pointed out that the MAP inference problem of
LDA in this situation is polynomial-time and can be solved by an exponentiated gradient method 
which shares a same form as our mirror-descent algorithm with constant step-size. Nevertheless 
different from [19]  which studied the inference problem alone  our focus in this paper is to in-
tegrate back propagation with mirror-descent algorithm to perform fully discriminative training of
supervised topic models  as we proceed to explain below.
Among the aforementioned methods  one training objective of the supervised LDA model is to max-
imize the joint likelihood of the input and the output variables [4]. Another variant is to maximize
the sum of the log likelihood (or its variable bound) and a prediction margin [26  27]. Moreover 
the DiscLDA optimizes part of the model parameters by maximizing the marginal likelihood of the
input variables  and optimizes the other part of the model parameters by maximizing the condi-
tional likelihood. For this reason  DiscLDA is not a fully discriminative training of all the model
parameters. In this paper  we propose a fully discriminative training of all the model parameters by
maximizing the posterior probability of the output given the input document. We will show that the
discriminative training can be performed in a principled manner by naturally integrating the back-
propagation with the MDA-based exact MAP inference. To our best knowledge  this paper is the
ﬁrst work to perform a fully end-to-end discriminative training of supervised topic models. Dis-
criminative training of generative model is widely used and usually outperforms standard generative
training in prediction tasks [3  7  12  14  25]. As pointed out in [3]  discriminative training increases
the robustness against the mismatch between the generative model and the real data. Experimental
results on three real-world tasks also show the superior performance of discriminative training.
In addition to the aforementioned related studies on topic models [4  15  26  27]  there have been
another stream of work that applied empirical risk minimization to graphical models such as Markov
Random Field and nonnegative matrix factorization [10  20]. Speciﬁcally  in [20]  an approximate
inference algorithm  belief propagation  is used to compute the belief of the output variables  which
is further fed into a decoder to produce the prediction. The approximate inference and the decoder
are treated as an entire black-box decision rule  which is tuned jointly via back propagation. Our
work is different from the above studies in that we use an MAP inference based on optimization
theory to motivate the discriminative training from a principled probabilistic framework.

2 Smoothed Supervised LDA Model

We consider the smoothed supervised LDA model in Figure 1. Let K be the number of topics 
N be the number of words in each document  V be the vocabulary size  and D be the number of
documents in the corpus. The generative process of the model in Figure 1 can be described as:

1. For each document d  choose the topic proportions according to a Dirichlet distribution:
✓d ⇠ p(✓d|↵) = Dir(↵)  where ↵ is a K ⇥ 1 vector consisting of nonnegative components.
2. Draw each column k of a V ⇥ K matrix  independently from an exchangeable Dirichlet
distribution: k ⇠ Dir() (i.e.   ⇠ p(|))  where > 0 is the smoothing parameter.
3. To generate each word wd n:

2

(a) Choose a topic zd n ⇠ p(zd n|✓d) = Multinomial(✓d). 1
(b) Choose a word wd n ⇠ p(wd n|zd n  ) = Multinomial(zd n).

4. Choose the C ⇥ 1 response vector: yd ⇠ p(yd|✓  U   ).
(a) In regression  p(yd|✓d  U  ) = N (U✓ d  1)  where U is a C ⇥ K matrix consisting
(b) In multi-class classiﬁcation  p(yd|✓d  U  ) = MultinomialSoftmax(U✓ d)  where

the softmax function is deﬁned as Softmax(x)c =

of regression coefﬁcients.

exc

c0=1 exc0   c = 1  . . .   C.
PC

Therefore  the entire model can be described by the following joint probability

p(|)

DYd=1h p(yd|✓d  U  ) · p(✓d|↵) · p(wd 1:N|zd 1:N   ) · p(zd 1:N|✓d)
}

 p(yd ✓d wd 1:N  zd 1:N| U ↵ )

{z

|

i

(1)

where wd 1:N and zd 1:N denotes all the words and the associated topics  respectively  in the d-th
document. Note that the model in Figure 1 is slightly different from the one proposed in [4]  where
the response variable yd in Figure 1 is coupled with ✓d instead of zd 1:N as in [4]. Blei and Mcauliffe
also pointed out this choice as an alternative in [4]. This modiﬁcation will lead to a differentiable
end-to-end cost trainable by back propagation with superior prediction performance.
To develop a fully discriminative training method for the model parameters  and U  we follow the
argument in [3]  which states that the discriminative training is also equivalent to maximizing the
joint likelihood of a new model family with an additional set of parameters:

arg max
 U  ˜

p(|)p( ˜|)

p(yd|wd 1:N     U ↵  )

p(wd 1:N| ˜ ↵ )

(2)

DYd=1

DYd=1

where p(wd 1:N| ˜ ↵ ) is obtained by marginalizing p(yd ✓ d  wd 1:N   zd 1:N|  U ↵  ) in (1) and
replace  with ˜. The above problem (2) decouples into

arg max

arg max

 U h ln p(|) +
˜ h ln p( ˜|) +

DXd=1
DXd=1

ln p(yd|wd 1:N     U ↵  )i
ln p(wd 1:N| ˜ ↵ )i

(3)

(4)

which are the discriminative learning problem of supervised LDA (Eq. (3))  and the unsupervised
learning problem of LDA (Eq. (4))  respectively. We will show that both problems can be solved in
a uniﬁed manner using a new MAP inference and back propagation.

3 Maximum A Posterior (MAP) Inference

We ﬁrst consider the inference problem in the smoothed LDA model. For the supervised case  the
main objective is to infer yd given the words wd 1:N in each document d  i.e.  computing

p(yd|wd 1:N     U ↵  ) =Z✓d

p(yd|✓d  U  )p(✓d|wd 1:N    ↵ )d✓d

(5)

where the probability p(yd|✓d  U  ) is known (e.g.  multinomial or Gaussian for classiﬁcation and
regression problems — see Section 2). The main challenge is to evaluate p(✓d|wd 1:N    ↵ )  i.e. 
infer the topic proportion given each document  which is also the important inference problem in
the unsupervised LDA model. However  it is well known that the exact evaluation of the posterior
probability p(✓d|wd 1:N    ↵ ) is intractable [4  5  9  15  26  27]. For this reason  various approx-
imate inference methods  such as variational inference [4  5  15  26] and Gibbs sampling [9  27] 

1We will represent all the multinomial variables by a one-hot vector that has a single component equal to

one at the position determined by the multinomial variable and all other components being zero.

3

have been proposed to compute the approximate posterior probability. In this paper  we take an
alternative approach for inference; given each document d  we only seek a point (MAP) estimate
of ✓d  instead of its full (approximate) posterior probability. The major motivation is that  although
the full posterior probability of ✓d is difﬁcult  its MAP estimate  as a simpliﬁed problem  is more
tractable (and it is a convex problem under certain conditions). Furthermore  with the MAP estimate
of ✓d  we can infer the prediction variable yd according to the following approximation from (5):

p(yd|wd 1:N     U ↵  ) = E✓d|wd 1:N [p(yd|✓d  U  )] ⇡ p(yd|ˆ✓d|wd 1:N   U  )

(6)
where E✓d|wd 1:N denotes the conditional expectation with respect to ✓d given wd 1:N  and the ex-
pectation is sampled by the MAP estimate  ˆ✓d|wd 1:N   of ✓d given wd 1:N  deﬁned as

ˆ✓d|wd 1:N = arg max

✓d

p(✓d|wd 1:N    ↵  )

(7)

The approximation gets more precise when p(✓d|wd 1:N    ↵  ) becomes more concentrated
around ˆ✓d|wd 1;N . Experimental results on several real datasets (Section 5) show that the approx-
imation (6) provides excellent prediction performance.
Using the Bayesian rule p(✓d|wd 1:N    ↵ ) = p(✓d|↵)p(wd 1:N|✓d  )/p(wd 1:N| ↵ ) and the fact
that p(wd 1:N| ↵ ) is independent of ✓d  we obtain the equivalent form of (7) as
✓d2PK⇥ ln p(✓d|↵) + ln p(wd 1:N|✓d  )⇤
ˆ✓d|wd 1:N = arg max
where PK = {✓ 2 RK : ✓j  0 PK
j=1 ✓j = 1} denotes the (K  1)-dimensional probability
simplex  p(✓d|↵) is the Dirichlet distribution  and p(wd 1:N|✓d  ) can be computed by integrating
p(wd 1:N   zd 1:N|✓d  ) =QN
n=1 p(wd n|zd n  )p(zd n|✓d) over zd 1:N  which leads to (derived in
Section A of the supplementary material)

(8)

p(wd 1:N|✓d  ) =

VYv=1✓ KXj=1

✓d jvj◆xd v

= p(xd|✓d  )

(9)

where xd v denotes the term frequency of the v-th word (in vocabulary) inside the d-th document 
and xd denotes the V -dimensional bag-of-words (BoW) vector of the d-th document. Note that
p(wd 1:N|✓d  ) depends on wd 1:N only via the BoW vector xd  which is the sufﬁcient statistics.
Therefore  we use p(xd|✓d  ) and p(wd 1:N|✓d  ) interchangeably from now on. Substituting the
expression of Dirichlet distribution and (9) into (8)  we get

ˆ✓d|wd 1:N = arg max
= arg min

✓d2PK⇥xT
✓d2PK⇥  xT

d ln(✓d) + (↵  1)T ln ✓d⇤
d ln(✓d)  (↵  1)T ln ✓d⇤

(10)

where we dropped the terms independent of ✓d  and 1 denotes an all-one vector. Note that when
↵  1 (↵> 1)  the optimization problem (10) is (strictly) convex and is non-convex otherwise.
3.1 Mirror Descent Algorithm for MAP Inference

An efﬁcient approach to solving the constrained optimization problem (10) is the mirror descent
algorithm (MDA) with Bregman divergence chosen to be generalized Kullback-Leibler divergence
[2  18  21]. Speciﬁcally  let f (✓d) denote the cost function in (10)  then the MDA updates the MAP
estimate of ✓d iteratively according to:

✓d ` = arg min

✓d2PKf (✓d `1) + [r✓df (✓d `1)]T (✓d  ✓d `1) +

1
Td `

 (✓d ✓ d `1)

(11)

✓d ` denotes the estimate of ✓d ` at the `-th iteration  Td ` denotes the step-size of MDA  and (x  y)
is the Bregman divergence chosen to be (x  y) = xT ln(x/y)  1T x + 1T y. The argmin in (11)
can be solved in closed-form (see Section B of the supplementary material) as

✓d ` =

1

C✓ · ✓d `1  exp✓Td `T

✓d `1◆  ` = 1  . . .   L  ✓ d 0 =
↵  1

1

1
K

(12)

xd

✓d `1

+

4

Figure 2: Layered deep architecture for computing p(yd|wd 1:N     U ↵  )  where ()/() denotes
element-wise division   denotes Hadamard product  and exp() denotes element-wise exponential.
where C✓ is a normalization factor such that ✓d ` adds up to one   denotes Hadamard product  L is
the number of MDA iterations  and the divisions in (12) are element-wise operations. Note that the
recursion (12) naturally enforces each ✓d ` to be on the probability simplex. The MDA step-size Td `
can be either constant  i.e.  Td ` = T   or adaptive over iterations and samples  determined by line
search (see Section C of the supplementary material). The computation complexity in (12) is low
since most computations are sparse matrix operations. For example  although by itself ✓d `1 in
(12) is a dense matrix multiplication  we only need to evaluate the elements of ✓d `1 at the posi-
tions where the corresponding elements of xd are nonzero  because all other elements of xd/✓d `1
is known to be zero. Overall  the computation complexity in each iteration of (12) is O(nTok · K) 
where nTok denotes the number of unique tokens in the document. In practice  we only use a small
number of iterations  L  in (12) and use ✓d L to approximate ˆ✓d|wd 1:N so that (6) becomes

p(yd|wd 1:N     U ↵  ) ⇡ p(yd|✓d L  U  )

(13)
In summary  the inference of ✓d and yd can be implemented by the layered architecture in Figure 2 
where the top layer infers yd using (13) and the MDA layers infer ✓d iteratively using (12). Figure 2
also implies that the the MDA layers act as a feature extractor by generating the MAP estimate ✓d L
for the output layer. Our end-to-end learning strategy developed in the next section jointly learns the
model parameter U at the output layer and the model parameter  at the feature extractor layers to
maximize the posterior of the prediction variable given the input document.

4 Learning by Mirror-Descent Back Propagation

We now consider the supervised learning problem (3) and the unsupervised learning problem (4) 
respectively  using the developed MDA-based MAP inference. We ﬁrst consider the supervised
learning problem. With (13)  the discriminative learning problem (3) can be approximated by

which can be solved by stochastic mirror descent (SMD). Note that the cost function in (14) depends
on U explicitly through p(yd|✓d L  U  )  which can be computed directly from its deﬁnition in
Section 2. On the other hand  the cost function in (14) depends on  implicitly through ✓d L. From
Figure 2  we observe that ✓d L not only depends on  explicitly (as indicated in the MDA block on
the right-hand side of Figure 2) but also depends on  implicitly via ✓d L1  which in turn depends
on  both explicitly and implicitly (through ✓d L2) and so on. That is  the dependency of the
cost function on  is in a layered manner. Therefore  we devise a back propagation procedure to
efﬁciently compute its gradient with respect to  according to the mirror-descent graph in Figure
2  which back propagate the error signal through the MDA blocks at different layers. The gradient
formula and the implementation details of the learning algorithm can be found in Sections C–D in
the supplementary material.
For the unsupervised learning problem (4)  the gradient of ln p( ˜|) with respect to ˜ assumes the
same form as that of ln p(|). Moreover  it can be shown that the gradient of ln p(wd 1:N| ˜ ↵  )

5

 U" ln p(|) 

arg min

ln p(yd|✓d L  U  )#

DXd=1

(14)

Mirror Descent CellMirror Descent Cell…Normalization@ ln p(wd 1:N| ˜ ↵ )

@ ˜

= E✓d|xd⇢ @

@ ˜

ln p(xd|✓d  ˜) (a)

⇡

@
@ ˜

ln p(xd|✓d L  ˜)

(15)

with respect ˜ can be expressed as (see Section E of the supplementary material):

where p(xd|✓d  ˜) assumes the same form as (9) except  is replaced by ˜. The expectation is
evaluated with respect to the posterior probability p(✓d|wd 1:N   ˜ ↵ )  and is sampled by the MAP
estimate of ✓d in step (a). ✓d L is an approximation of ˆ✓d|wd 1:N computed via (12) and Figure 2.
5 Experiments

5.1 Description of Datasets and Baselines

We evaluated our proposed supervised learning (denoted as BP-sLDA) and unsupervised learning
(denoted as BP-LDA) methods on three real-world datasets. The ﬁrst dataset we use is a large-scale
dataset built on Amazon movie reviews (AMR) [16]. The data set consists of 7.9 million movie
reviews (1.48 billion words) from Amazon  written by 889 176 users  on a total of 253 059 movies.
For text preprocessing we removed punctuations and lowercasing capital letters. A vocabulary of
size 5 000 is built by selecting the most frequent words. (In another setup  we keep the full vocab-
ulary of 701K.) Same as [24]  we shifted the review scores so that they have zero mean. The task
is formulated as a regression problem  where we seek to predict the rating score using the text of
the review. Second  we consider a multi-domain sentiment (MultiSent) classiﬁcation task [6]  which
contains a total 342 104 reviews on 25 types of products  such as apparel  electronics  kitchen and
housewares. The task is formulated as a binary classiﬁcation problem to predict the polarity (posi-
tive or negative) of each review. Likewise  we preprocessed the text by removing punctuations and
lowercasing capital letters  and built a vocabulary of size 1 000 from the most frequent words. In ad-
dition  we also conducted a second binary text classiﬁcation experiment on a large-scale proprietary
dataset for business-centric applications (1.2M documents and vocabulary size of 128K).
The baseline algorithms we considered include Gibbs sampling (Gibbs-LDA) [17]  logistic/linear re-
gression on bag-of-words  supervised-LDA (sLDA) [4]  and MedLDA [26]  which are implemented
either in C++ or Java. And our proposed algorithms are implemented in C#.2 For BP-LDA and
Gibbs-LDA  we ﬁrst train the models in an unsupervised manner  and then generate per-document
topic proportion ✓d as their features in the inference steps  on top of which we train a linear (logistic)
regression model on the regression (classiﬁcation) tasks.

5.2 Prediction Performance

d  ¯yo

d)2)  where yo

1  (Pd(yo

d  yd)2)/(Pd(yo

We ﬁrst evaluate the prediction performance of our models and compare them with the traditional
(supervised) topic models. Since the training of the baseline topic models takes much longer time
than BP-sLDA and BP-LDA (see Figure 5)  we compare their performance on two smaller datasets 
namely a subset (79K documents) of AMR (randomly sampled from the 7.9 million reviews) and the
MultiSent dataset (342K documents)  which are all evaluated with 5-fold cross validation. For AMR
regression  we use the predictive R2 to measure the prediction performance  deﬁned as: pR2 =
d denotes the label of the d-th document in the
heldout (out-of-fold) set during the 5-fold cross validation  ¯yo
d in the heldout
set  and yd is the predicted value. The pR2 scores of different models with varying number of topics
are shown in Figure 3(a). Note that the BP-sLDA model outperforms the other baselines with large
margin. Moreover  the unsupervised BP-LDA model outperforms the unsupervised LDA model
trained by Gibbs sampling (Gibbs-LDA). Second  on the MultiSent binary classiﬁcation task  we
use the area-under-the-curve (AUC) of the operating curve of probability of correct positive versus
probability of false positive as our performance metric  which are shown in Figure 3(b). It also shows
that BP-sLDA outperforms other methods and that BP-LDA outperforms the Gibbs-LDA model.
Next  we compare our BP-sLDA model with other strong discriminative models (such as neural net-
works) by conducting two large-scale experiments: (i) regression task on AMR full dataset (7.9M
documents) and (ii) binary classiﬁcation task on the proprietary business-centric dataset (1.2M doc-
uments). For the large-scale AMR regression  we can see that pR2 improves signiﬁcantly compared

d is the mean of all yo

2A third-party code is available online at https://github.com/jvking/bp-lda.

6

0.5

0.4

2
R
p

0.3

0.2

0.1

0
 
0

 

BP−sLDA
Linear
MedLDA
sLDA
BP−LDA
Gibbs−LDA

95

90

85

80

75

70

65

)

%

(
 

C
U
A

BP−sLDA
Logistic regression
MedLDA
sLDA
BP−LDA
Gibbs−LDA

 

93

92

91

90

89

)

%

(
 

C
U
A

 

BP−sLDA
Logistic regression

20

40
80
Number of topics

60

100

120

60

 
0

20

40
80
Number of topics

60

100

120

88

 
0

20

40
80
Number of topics

60

100

120

(a) AMR regression task (79K)

(b) MultiSent classiﬁcation task

(c) MultiSent task (zoom in)

Figure 3: Prediction performance on AMR regression task (measured in pR2) and MultiSent classi-
ﬁcation task (measured in AUC). Higher score is better for both  with perfect value being one.

Table 1: pR2 (in percentage) on full AMR data (7.9M documents). The standard deviations in the
parentheses are obtained from 5-fold cross validation.

5

10

20

Number of topics
Linear Regression (voc5K)
Neural Network (voc5K)
BP-sLDA (↵ = 1.001  voc5K)
BP-sLDA (↵ = 0.5  voc5K)
BP-sLDA (↵ = 0.1  voc5K)
Linear Regression (voc701K)
BP-sLDA (↵=1.001 voc701K)

50

100

200

38.4 (0.1)

59.0 (0.1) 61.0 (0.1) 62.3 (0.4) 63.5 (0.7) 63.1 (0.8) 63.5 (0.4)
61.4 (0.1) 65.3 (0.3) 69.1 (0.2) 74.7 (0.3) 74.3 (2.4) 78.3 (1.1)
54.7 (0.1) 54.5 (1.2) 57.0 (0.2) 61.3 (0.3) 67.1 (0.1) 74.5 (0.2)
53.3 (2.8) 56.1 (0.1) 58.4 (0.1) 64.1 (0.1) 70.6 (0.3) 75.7 (0.2)

69.8 (0.2) 74.3 (0.3) 78.5 (0.2) 83.6 (0.6) 80.1 (0.9) 84.7 (2.8)

41.5 (0.2)

to the best results on the 79K dataset shown in Figure 3(a)  and also signiﬁcantly outperform the neu-
ral network models with same number of model parameters. Moreover  the best deep neural network
(200⇥ 200 in hidden layers) gives pR2 of 76.2%(±0.6%)  which is worse than 78.3% of BP-sLDA.
In addition  BP-sLDA also signiﬁcantly outperforms Gibbs-sLDA [27]  Spectral-sLDA [24]  and the
Hybrid method (Gibbs-sLDA initialized with Spectral-sLDA) [24]  whose pR2 scores (reported in
[24]) are between 10% and 20% for 5 ⇠ 10 topics (and deteriorate when further increasing the topic
number). The results therein are obtained under same setting as this paper. To further demonstrate
the superior performance of BP-sLDA on the large vocabulary scenario  we trained BP-sLDA on
full vocabulary (701K) AMR and show the results in Table 1  which are even better than the 5K
vocabulary case. Finally  for the binary text classiﬁcation task on the proprietary dataset  the AUCs
are given in Table 2  where BP-sLDA (200 topics) achieves 31% and 18% relative improvements
over logistic regression and neural network  respectively. Moreover  on this task  BP-sLDA is also
on par with the best DNN (a larger model consisting of 200⇥ 200 hidden units with dropout)  which
achieves an AUC of 93.60.

5.3 Analysis and Discussion

We now analyze the inﬂuence of different hyper parameters on the prediction performance. Note
from Figure 3(a) that  when we increase the number of topics  the pR2 score of BP-sLDA ﬁrst
improves and then slightly deteriorates after it goes beyond 20 topics. This is most likely to be
caused by overﬁtting on the small dataset (79K documents)  because the BP-sLDA models trained
on the full 7.9M dataset produce much higher pR2 scores (Table 1) than that on the 79K dataset
and keep improving as the model size (number of topics) increases. To understand the inﬂuence
of the mirror descent steps on the prediction performance  we plot in Figure 4(a) the pR2 scores
of BP-sLDA on the 7.9M AMR dataset for different values of mirror-descent steps L. When L
increases  for small models (K = 5 and K = 20)  the pR2 score remains the same  and  for a larger
model (K = 100)  the pR2 score ﬁrst improves and then remain the same. One explanation for
this phenomena is that larger K implies that the inference problem (10) becomes an optimization
problem of higher dimension  which requires more mirror descent iterations. Moreover  the mirror-
descent back propagation  as an end-to-end training of the prediction output  would compensate
the imperfection caused by the limited number of inference steps  which makes the performance
insensitive to L once it is large enough. In Figure 4(b)  we plot the percentage of the dominant

7

Table 2: AUC (in percentage) on the business-centric proprietary data (1.2M documents  128K vo-
cabulary). The standard deviations in the parentheses are obtained from ﬁve random initializations.

Number of topics
Logistic Regression
Neural Network
BP-sLDA

5

10

20

50
90.56 (0.00)

100

200

90.95 (0.07) 91.25 (0.05) 91.32 (0.23) 91.54 (0.11) 91.90 (0.05) 91.98 (0.05)
92.02 (0.02) 92.21 (0.03) 92.35 (0.07) 92.58 (0.03) 92.82 (0.07) 93.50 (0.06)

2
R
p

 

0.8
0.75
0.7
0.65
0.6
0.55
0.5
0.45
0.4
 
0
100
Number of mirror descent iterations (layers)
(a) Inﬂuence of MDA iterations L

5 topics
20 topics
100 topics

20

40

60

80

)

%

(
 
s
c
p
o

i

t
 
t

i

n
a
n
m
o
d

 
f

o

 

e
g
a

t

n
e
c
r
e
P

50

40

30

20

10

0
 
0

20

 

BP−sLDA (α=1.001)
BP−sLDA (α=0.5)
BP−sLDA (α=0.1)
Gibbs−LDA (α=0.5)
Gibbs−LDA (α=0.1)
BP−LDA (α=0.5)
BP−LDA (α=0.1)

40

Number of topics

60

80

100

d
o
o
h

i
l

e
k

i
l

−
g
o

l
 

d
r
o
w
−
r
e
p

 

e
v
i
t

a
g
e
N

12

10

8

6

4

2

0

 

BP−LDA (α=1.001)
BP−LDA (α=0.5)
BP−LDA (α=0.1)
Gibbs−LDA (α=0.5)
Gibbs−LDA (α=0.1)

 

5

10

Number of topics

20

(b) Sparsity of the topic distribution

(c) Per-word log-likelihoods

Figure 4: Analysis of the behaviors of BP-sLDA and BP-LDA models.

topics (which add up to 90% probability) on AMR  which shows that BP-sLDA learns sparse topic
distribution even when ↵ = 1.001 and obtains sparser topic distribution with smaller ↵ (i.e.  0.5 and
0.1). In Figure 4(c)  we evaluate the per-word log-likelihoods of the unsupervised models on AMR
dataset using the method in [23]. The per-word log-likelihood of BP-LDA with ↵ = 1.001 is worse
than the case of ↵ = 0.5 and ↵ = 0.1 for Gibbs-LDA  although its prediction performance is better.
This suggests the importance of the Dirichlet prior in text modeling [1  22] and a potential tradeoff
between the text modeling performance and the prediction performance.

5.4 Efﬁciency in Computation Time

To compare the efﬁciency of the algorithms  we
show the training time of different models on the
AMR dataset (79K and 7.9M) in Figure 5  which
shows that our algorithm scales well with respect
to increasing model size (number of topics) and in-
creasing number of data samples.

6 Conclusion

sLDA (79K)
BP−sLDA (79K)
MedLDA (79K)
BP−sLDA (7.9M)

 

103

102

101

100

s
r
u
o
h
 
n
i
 
e
m

i

i
t
 
g
n
n
a
r
T

i

10−1

60

40

20

10−2
 
0

Number of topics

We have developed novel learning approaches for
supervised LDA models  using MAP inference and
mirror-descent back propagation  which leads to an
end-to-end discriminative training. We evaluate the
prediction performance of the model on three real-
world regression and classiﬁcation tasks. The re-
sults show that the discriminative training signiﬁ-
cantly improves the performance of the supervised
LDA model relative to previous learning methods.
Future works include (i) exploring faster algorithms for the MAP inference (e.g.  accelerated mirror
descent)  (ii) developing semi-supervised learning of LDA using the framework from [3]  and (iii)
learning ↵ from data. Finally  also note that the layered architecture in Figure 2 could be viewed
as a deep feedforward neural network [11] with structures designed from the topic model in Figure
1. This opens up a new direction of combining the strength of both generative models and neu-
ral networks to develop new deep learning models that are scalable  interpretable and having high
prediction performance for text understanding and information retrieval [13].

Figure 5: Training time on the AMR dataset.
(Tested on Intel Xeon E5-2680 2.80GHz.)

100

80

8

References
[1] A. Asuncion  M. Welling  P. Smyth  and Y. W. Teh. On smoothing and inference for topic models. In

Proc. UAI  pages 27–34  2009.

[2] A. Beck and M. Teboulle. Mirror descent and nonlinear projected subgradient methods for convex opti-

mization. Operations Research Letters  31(3):167–175  2003.

[3] C. M. Bishop and J. Lasserre. Generative or discriminative? getting the best of both worlds. Bayesian

Statistics  8:3–24  2007.

[4] D. M. Blei and J. D. Mcauliffe. Supervised topic models. In Proc. NIPS  pages 121–128  2007.
[5] D. M. Blei  A. Y. Ng  and M. I. Jordan. Latent dirichlet allocation. JMLR  3:993–1022  2003.
[6] J. Blitzer  M. Dredze  and F. Pereira. Biographies  bollywood  boom-boxes and blenders: Domain adap-

tation for sentiment classiﬁcation. In Proc. ACL  volume 7  pages 440–447  2007.

[7] G. Bouchard and B. Triggs. The tradeoff between generative and discriminative classiﬁers.

COMPSTAT  pages 721–728  2004.

In Proc.

[8] J. Duchi  E. Hazan  and Y. Singer. Adaptive subgradient methods for online learning and stochastic

optimization. Journal of Machine Learning Research  12:2121–2159  Jul. 2011.

[9] T. L. Grifﬁths and M. Steyvers. Finding scientiﬁc topics. Proc. of the National Academy of Sciences 

pages 5228–5235  2004.

[10] J. R. Hershey  J. L. Roux  and F. Weninger. Deep unfolding: Model-based inspiration of novel deep

architectures. arXiv:1409.2574  2014.

[11] G. Hinton  L. Deng  D. Yu  G. E. Dahl  A. Mohamed  N. Jaitly  A. Senior  V. Vanhoucke  P. Nguyen 
T. N. Sainath  and B. Kingsbury. Deep neural networks for acoustic modeling in speech recognition: The
shared views of four research groups. IEEE Signal Process. Mag.  29(6):82–97  2012.

[12] A. Holub and P. Perona. A discriminative framework for modelling object classes. In Proc. IEEE CVPR 

volume 1  pages 664–671  2005.

[13] P.-S. Huang  X. He  J. Gao  L. Deng  A. Acero  and L. Heck. Learning deep structured semantic models

for web search using clickthrough data. In Proc. CIKM  pages 2333–2338  2013.

[14] S. Kapadia. Discriminative Training of Hidden Markov Models. PhD thesis  University of Cambridge 

1998.

[15] S. Lacoste-Julien  F. Sha  and M. I. Jordan. DiscLDA: Discriminative learning for dimensionality reduc-

tion and classiﬁcation. In Proc. NIPS  pages 897–904  2008.

[16] J. J. McAuley and J. Leskovec. From amateurs to connoisseurs: modeling the evolution of user expertise

through online reviews. In Proc. WWW  pages 897–908  2013.

[17] Andrew Kachites McCallum.
http://mallet.cs.umass.edu  2002.

MALLET: A Machine Learning for Language Toolkit.

[18] D. B. Nemirovsky. A. S.  Yudin. Problem Complexity and Method Efﬁciency in Optimization. Wiley 

New York  1983.

[19] D. Sontag and D. Roy. Complexity of inference in latent dirichlet allocation.

1008–1016  2011.

In Proc. NIPS  pages

[20] V. Stoyanov  A. Ropson  and J. Eisner. Empirical risk minimization of graphical model parameters given

approximate inference  decoding  and model structure. In Proc. AISTATS  pages 725–733  2011.

[21] P. Tseng. On accelerated proximal gradient methods for convex-concave optimization. SIAM Journal on

Optimization  2008.

[22] H. M. Wallach  D. M. Mimno  and A. McCallum. Rethinking LDA: Why priors matter. In Proc. NIPS 

pages 1973–1981  2009.

[23] H. M. Wallach  I. Murray  R. Salakhutdinov  and D. Mimno. Evaluation methods for topic models. In

Proc. ICML  pages 1105–1112  2009.

[24] Y. Wang and J. Zhu. Spectral methods for supervised topic models. In Proc. NIPS  pages 1511–1519 

2014.

[25] Oksana Yakhnenko  Adrian Silvescu  and Vasant Honavar. Discriminatively trained Markov model for

sequence classiﬁcation. In Proc. IEEE ICDM  2005.

[26] J. Zhu  A. Ahmed  and E. P. Xing. MedLDA: maximum margin supervised topic models. JMLR 

13(1):2237–2278  2012.

[27] J. Zhu  N. Chen  H. Perkins  and B. Zhang. Gibbs max-margin topic models with data augmentation.

JMLR  15(1):1073–1110  2014.

9

,Jianshu Chen
Ji He
Yelong Shen
Lin Xiao
Xiaodong He
Jianfeng Gao
Xinying Song
Li Deng