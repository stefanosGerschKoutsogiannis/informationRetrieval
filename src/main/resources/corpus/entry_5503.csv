2016,The Power of Adaptivity in Identifying Statistical Alternatives,This paper studies the trade-off between two different kinds of pure exploration: breadth versus depth. We focus on the most biased coin problem  asking how many total coin flips are required to identify a ``heavy'' coin from an infinite bag containing both ``heavy'' coins with mean $\theta_1 \in (0 1)$  and ``light" coins with mean $\theta_0 \in (0 \theta_1)$  where heavy coins are drawn from the bag with proportion $\alpha \in (0 1/2)$. When $\alpha \theta_0 \theta_1$ are unknown  the key difficulty of this problem lies in distinguishing whether the two kinds of coins have very similar means  or whether heavy coins are just extremely rare. While existing solutions to this problem require some prior knowledge of the parameters $\theta_0 \theta_1 \alpha$  we propose an adaptive algorithm that requires no such knowledge yet still obtains near-optimal sample complexity guarantees. In contrast  we provide a lower bound showing that non-adaptive strategies require at least quadratically more samples.  In characterizing this gap between adaptive and nonadaptive strategies   we make connections to anomaly detection and prove lower bounds on the sample complexity of differentiating between a single parametric distribution and a mixture of two such distributions.,The Power of Adaptivity in Identifying Statistical

Alternatives

Kevin Jamieson  Daniel Haas  Ben Recht

University of California  Berkeley

Berkeley  CA 94720

{kjamieson dhaas brecht}@eecs.berkeley.edu

Abstract

This paper studies the trade-off between two different kinds of pure exploration:
breadth versus depth. We focus on the most biased coin problem  asking how
many total coin ﬂips are required to identify a “heavy” coin from an inﬁnite bag
containing both “heavy” coins with mean ✓1 2 (0  1)  and “light" coins with
mean ✓0 2 (0 ✓ 1)  where heavy coins are drawn from the bag with proportion
↵ 2 (0  1/2). When ↵  ✓0 ✓ 1 are unknown  the key difﬁculty of this problem lies in
distinguishing whether the two kinds of coins have very similar means  or whether
heavy coins are just extremely rare. While existing solutions to this problem require
some prior knowledge of the parameters ✓0 ✓ 1 ↵   we propose an adaptive algorithm
that requires no such knowledge yet still obtains near-optimal sample complexity
guarantees. In contrast  we provide a lower bound showing that non-adaptive
strategies require at least quadratically more samples. In characterizing this gap
between adaptive and nonadaptive strategies  we make connections to anomaly
detection and prove lower bounds on the sample complexity of differentiating
between a single parametric distribution and a mixture of two such distributions.

Introduction

1
The trade-off between exploration and exploitation has been an ever-present trope in the online
learning literature. In contrast  this paper studies the trade-off between two different kinds of pure
exploration: breadth versus depth. Consider a bag that contains an inﬁnite number of two kinds
of biased coins: “heavy” coins with mean ✓1 2 (0  1) and “light” coins with mean ✓0 2 (0 ✓ 1).
When a player picks a coin from the bag  with probability ↵ the coin is “heavy” and with probability
(1  ↵) the coin is “light.” The player can ﬂip any coin she picks from the bag as many times as she
wants  and the goal is to identify a heavy coin using as few total ﬂips as possible. When ↵  ✓0 ✓ 1 are
unknown  the key difﬁculty of this problem lies in distinguishing whether the two kinds of coins have
very similar means  or whether heavy coins are just extremely rare. That is  how does one balance
ﬂipping an individual coin many times to better estimate its mean against considering many new coins
to maximize the probability of observing a heavy one. Previous work has only proposed solutions
that rely on some or full knowledge ↵  ✓0 ✓ 1  limiting their applicability. In this work we propose
the ﬁrst algorithm that requires no knowledge of ↵  ✓0 ✓ 1  is guaranteed to return a heavy coin with
probability at least 1    and ﬂips a total number of coins  in expectation  that nearly matches known
lower bounds. Moreover  our fully adaptive algorithm supports more general sub-Gaussian sources in
addition to just coins  and only ever has one “coin” outside the bag at a given time  a constraint of
practical importance to some applications.
In addition  we connect the most biased coin problem to anomaly detection and prove novel lower
bounds on the difﬁculty of detecting the presence of a mixture versus just a single component of
a known family of distributions (e.g. X ⇠ (1  ↵)g✓0 + ↵g✓1 versus X ⇠ g✓ for some ✓). We
show that in detecting the presence of a mixture distribution  there is a stark difference of difﬁculty

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

between when the underlying distribution parameters are known (e.g. ↵  ✓0 ✓ 1) and when they are
not. The most biased coin problem can be viewed as an online  adaptive mixture detection problem
where source distributions arrive one at a time that are either g✓0 with probability (1  ↵) or g✓1
with probability ↵ (e.g. null or anomolous) and the player adaptively chooses how many samples
to take from each distribution (to increase the signal-to-noise ratio) with the goal of identifying an
anomolous distribution f✓1 using as few total number of samples as possible. This work draws a
contrast between the power of an adaptive versus non-adaptive (e.g. taking the same number of
samples each time) approaches to this problem  speciﬁcally when ↵  ✓0 ✓ 1 are unknown.
1.1 Motivation and Related Work for the Most Biased Coin Problem
The most biased coin problem characterizes the inherent difﬁculty of real-world problems including
anomaly and intrusion detection and discovery of vacant frequencies in the radio spectrum. Our
interest in the problem stemmed from automated hiring of crowd workers: data labeling for machine
learning applications is often performed by humans  and recent work in the crowdsourcing literature
accelerates labeling by organizing workers into pools of labelers and paying them to wait for incoming
data [4  12]. Workers hired on marketplaces such as Amazon’s Mechanical Turk [16] vary widely in
skill  and identifying high-quality workers as quickly as possible is an important challenge. We can
model each worker’s performance (e.g. accuracy or speed) as a random variable so that selecting
a good worker is equivalent to identifying a worker with a high mean. Since we do not observe a
worker’s expected performance directly  we must give them tasks from which we estimate it (like
repeatedly ﬂipping a biased coin). Arlotto et al. [3] proposed a strategy with some guarantees for a
related problem but did not characterize the sample complexity of the problem  the focus of our work.
The most biased coin problem was ﬁrst proposed by Chandrasekaran and Karp [8]. In that work 
it was shown that if ↵  ✓0 ✓ 1 were known then there exists an algorithm based on the sequential
probability ratio test (SPRT) that is optimal in that it minimizes the expected number of total ﬂips to
ﬁnd a “heavy” coin whose posterior probability of being heavy is at least 1    and the expected
sample complexity of this algorithm was upper-bounded by

16

(✓1  ✓0)2✓ 1  ↵

↵

+ log✓ (1  ↵)(1  )

↵

◆◆ .

(1)

However  the practicality of the proposed algorithm is severely limited as it relies critically on
knowing ↵  ✓0  and ✓1 exactly. In addition  the algorithm returns to coins it has previously ﬂipped
and thus requires more than one coin to be outside the bag at a time  ruling out some applications.
Malloy et al. [15] addressed some of the shortcomings of [9] (a preprint of [8]) by considering both
an alternative SPRT procedure and a sequential thresholding procedure. Both of these proposed
algorithms only ever have one coin out of the bag at a time. However  the former requires knowledge
of all relevant parameters ↵  ✓0 ✓ 1  and the latter requires knowledge of ↵  ✓0. Moreover  these results
are only presented for the asymptotic case where  ! 0.
The most biased coin problem can be viewed through the lens of multi-armed bandits. In the
best-arm identiﬁcation problem  the player has access to K distributions (arms) such that if arm
i 2 [K] is sampled (pulled)  an iid random variable with mean µi is observed; the objective is to
identify the arm associated with the highest mean with probability at least 1   using as few pulls
as possible (see [14] for a short survey). In the inﬁnite armed bandit problem  the player is not
conﬁned to K arms but an inﬁnite reservoir of arms such that a draw from this reservoir results in
an arm with a mean µ drawn from some distribution; the objective is to identify the highest mean
possible after n total pulls for any n > 0 with probability 1   (see [7]). The most biased coin
problem is an instance of this latter game with the arm reservoir distribution of means µ deﬁned as
P(µ  ✓1  ✏) = ↵1✏0 + (1  ↵)1✏✓1✓0 for all ✏. Previous work has focused on an alternative
arm distribution reservoir that satisﬁes E✏  P(µ  µ⇤  ✏)  E0✏ for some µ⇤ 2 [0  1] where
E  E0 are constants and  is known [5  21  6  7]. Because neither arm distribution reservoir can be
written in terms of the other  neither work subsumes the other. Note that one can always apply an
algorithm designed for the inﬁnite armed bandit problem to any ﬁnite K-armed bandit problem by
deﬁning the arm reservoir as placing a uniform distribution over the K arms. This is appealing when
K is very large and one wishes to guarantee nontrivial performance when the number of pulls is
much less than K1. The most biased problem is a special case of the K-armed reservoir distribution
where one arm has mean ✓1 and K  1 arms have mean ✓0 with ↵ = 1
K .

1All algorithms for K-armed bandit problem known to these authors begins by sampling each arm once so

that until the number of pulls exceeds K  performance is no better than random selection.

2

Given that [8] and [15] are provably optimal algorithms for the most biased coin problem given
knowledge of ↵  ✓0 ✓ 1  it is natural to consider a procedure that ﬁrst estimates these unknown
parameters ﬁrst and then uses these estimates in the algorithms of [8] or [15]. Indeed  in the -
parameterized arm reservoir setting discussed above  this is exactly what Carpentier and Valko [7]

propose to do  suggesting a particular estimator for  given a lower boundb  . They show that
this estimator is sufﬁcient to obtain the same sample complexity result up to log factors as when 
was known. Sadly  through upper and lower bounds we show that for the most biased coin problem
this estimate-then-explore approach requires quadratically more ﬂips than our proposed algorithm
that adapts to these unknown parameters. Speciﬁcally  we show that when ✓1  ✓0 is sufﬁciently
small one cannot use a static estimation step to determine whether ↵ = 0 or ↵> 0 unless a number
of samples quadratic in the optimal sample complexity are taken.
Our contributions to the most biased coin problem include a novel algorithm that never has more
than one coin outside the bag at a time  has no knowledge of the distribution parameters  supports
distributions on [0  1] rather than just “coins ” and comes within log factors of the known information-
theoretic lower bound and Equation 1 which is achieved by an algorithm that knows the parameters.
See Table 1 for an overview of the upper and lower bounds proved in this work for this problem.
We believe that our algorithm is the ﬁrst solution to the most biased coin problem that does not
require prior knowledge of the problem parameters and that the same approach can be reworked to
solve more general instances of the inﬁnite-armed bandit problem  including the -parameterized
and K-armed reservoir cases described of above. Finally  if an algorithm is desired for arbitrary arm
reservoir distributions  this work rules out an estimate-then-explore approach.

1.2 Problem Statement
Let ✓ 2 ⇥ index a family of single-parameter probability density functions g✓ and ﬁx ✓0 ✓ 1 2 ⇥ 
↵ 2 [0  1/2]. For any ✓ 2 ⇥ assume that g✓ is known to the procedure. Note that in the most biased
coin problem  g✓ =Bernoulli(✓)  but in general it is arbitrary (e.g. N (✓  1)). Consider a sequence of iid
Bernoulli random variables ⇠i 2{ 0  1} for i = 1  2  . . . where each P(⇠i = 1) = 1 P(⇠i = 0) = ↵.
Let Xi j for j = 1  2  . . . be a sequence of random variables drawn from g✓1 if ⇠i = 1 and g✓0
otherwise  and let {{Xi j}Mi
i=1 represent the sampling history generated by a procedure for some
N 2 N and (M1  . . .   MN ) 2 NN. Any valid procedure behaves accordingly:
Algorithm 1 The most biased coin problem deﬁnition. Only the last distribution drawn may be
sampled or declared heavy  enforcing the rule that only one coin may be outside the bag at a time.
Initialize an empty history (N = 1  M = (0  0  . . . )).
Repeat until heavy distribution declared:

j=1}N

Choose one of

1. draw a sample from distribution N  MN MN + 1
2. draw a sample from the (N + 1)st distribution  MN +1 = 1  N N + 1
3. declare distribution N as heavy

Deﬁnition 1 We say a strategy for the most biased coin problem is -probably correct if for all
(↵  ✓0 ✓ 1) it identiﬁes a “heavy” g✓1 distribution with probability at least 1  .
Deﬁnition 2 (Strategies for the most biased coin problem) An estimate-then-explore strategy
is a strategy that  for any ﬁxed m 2 N  begins by sampling each successive coin exactly m times for
a number of coins that is at least the minimum necessary for any test to determine that ↵ 6= 0 with
probability at least 1    then optionally continues sampling with an arbitrary strategy that declares
a heavy coin. An adaptive strategy is any strategy that is not an estimate-then-explore strategy.

We study the estimate-then-explore strategy because there exist optimal algorithms [8  15] for the
most biased coin problem if ↵  ✓0 ✓ 1 are known  so it is natural to consider estimating these quantities
then using one of these algorithms. Note that the algorithm of [7] for the -parameterized inﬁnite
armed bandit problem discussed above can be considered an estimate-then-explore strategy since it
ﬁrst estimates  by sampling a ﬁxed number of samples from a set of arms  and then uses this estimate
to draw a ﬁxed number of arms and applies a UCB-style algorithm to these arms. A contribution of
this work is showing that such a strategy is infeasible for the most biased coin problem.

3

For all strategies that are -probably correct and follow the interface of Algorithm 1  our goal is
i=1 Mi] for any (↵  ✓0 ✓ 1) if N

to provide lower and upper bounds on the quantity E[T ] := E[PN

denotes the ﬁnal number of coins considered.

2 From Identifying Coins to Detecting Mixture Distributions
Addressing the most biased coin problem  [15] analyzes perhaps the most natural strategy: ﬁx an
m 2 N and ﬂip each successive coin exactly m times. The relevant questions are how large does m
have to be in order to guarantee correctness with probability 1    and for a given m how long must
one wait to declare a “heavy” coin? The authors partially answer these questions and we improve
upon them (see Section 3.2.1) which leads us to our study of the difﬁculty of detecting the presence of
a mixture distribution. As an example of the kind of lower bounds shown in this work  if we observe
a sequence of random variables X1  . . .   Xn  consider the following hypothesis test:

H0 : 8i X1  . . .   Xn ⇠N (✓   2)
H1 : 8i X1  . . .   Xn ⇠ (1  ↵)N (✓0  2) + ↵ N (✓1  2)

for some ✓ 2 R 

(P1)

which will henceforth be referred to as Problem P1 or just (P1). We can show that if ✓0 ✓ 1 ↵ are
known and ✓ = ✓0  then it is sufﬁcient to observe just max{1/↵ 
↵2(✓1✓0)2 log(1/)} samples to
determine the correct hypothesis with probability at least 1  . However  if ✓0 ✓ 1 ↵ are unknown
then it is necessary to observe at least max1/↵ 
↵(✓1✓0)22 log(1/) samples in expectation
whenever (✓1✓0)2

↵2(✓1✓0)2 log(1/)} otherwise (see Appendix C).

 1 and max{1/↵ 

2

2

2

2

2

Recognizing (✓1✓0)2
as the KL divergence between two Gaussians of H1  we observe startling
consequences for anomaly detection when the parameters of the underlying distributions are unknown:
if the anomalous distribution is well separated from the null distribution  then detecting an anomalous
component is only about as hard as observing just one anomalous sample (i.e. 1/↵) multiplied by
the inverse KL divergence between the null and anomalous distributions. However  when the two
distributions are not well separated then the necessary sample complexity explodes to this latter
quantity squared. In Section 4 we will investigate adaptive methods for dramatically decreasing this
sample complexity.
Our lower bounds are based on the detection of the presence of a mixture of two distributions of an
exponential family versus just a single distribution of the same family. There has been extensive
work in the estimation of mixture distributions [13  11] but this literature often assumes that the
mixture coefﬁcient ↵ is bounded away from 0 and 1 to ensure a sufﬁcient number of samples from
each distribution. In contrast  we highlight the regime when ↵ is arbitrarily small  as is the case in
statistical anomaly detection [10  20  2]. Property testing  e.g. unimodality  [1] is relevant but can
lack interpetability or strength in favor of generality. Considering the exponential family allowing us
to make interpretable statements about the relevant problem parameters in different regimes.
Preliminaries Let P and Q be two probability distributions with densities p and q  respectively. For
simplicity  assume p and q have the same support. Deﬁne the KL Divergence between P and Q

q(x)⌘ dp(x). Deﬁne the 2 Divergence between P and Q as 2(P  Q) =

as KL(P  Q) =R log⇣ p(x)
R⇣ p(x)
q(x)  1⌘2
Examples: If P = N (✓1  2) and Q = N (✓0  2) then KL(P  Q) = (✓1✓0)2
(✓1✓0)2

q⇤ = log2(P  Q) + 1  2(P  Q).
2  1. If P = Bernoulli(✓1) and Q = Bernoulli(✓0) then KL(P  Q) = ✓1 log( ✓1

dq(x) =R (p(x)q(x))2
KL(P  Q) = Ep⇥ log p

q⇤  logEp⇥ p

dx. Note that by Jensen’s inequality

22

and 2(P  Q) =
) + (1 
✓0(1✓0). All proofs appear in the

and 2(P  Q) = (✓1✓0)2

✓0(1✓0)[(✓1✓0)(2✓01)]+

(✓1✓0)2/2

(2)

e
✓1) log( 1✓1
1✓0
appendix.

) 

q(x)

✓0

3 Lower bounds
We present lower bounds on the sample complexity of -probably correct strategies for the most
biased coin problem that follow the interface of Algorithm 1. Lower bounds are stated for any

4

adaptive strategy in Section 3.1  non-adaptive strategies that may have knowledge of the parameters
but sample each distribution the same number of times in Section 3.2.1  and estimate-then-explore
strategies that do not have prior knowledge of the parameters in Section 3.2.2. Our lower bounds 
with the exception of the adaptive strategy  are based on the difﬁculty of detecting the presence of a
mixture distribution  and this reduction is explained in Section 3.2.

3.1 Adaptive strategies
The following theorem  reproduced from [15]  describes the sample complexity of any -probably
correct algorithm for the most biased coin identiﬁcation problem. Note that this lower bound holds
for any procedure even if it returns to previously seen distributions to draw additional samples and
even if it knows ↵  ✓0 ✓ 1.
Theorem 1 [15  Theorem 2] Fix  2 (0  1). Let T be the total number of samples taken of any
procedure that is -probably correct in identifying a heavy distribution. Then

E[T ]  c1 max⇢ 1  

↵

 

(1  )

↵KL(g✓0|g✓1)

whenever ↵  c2 where c1  c2 2 (0  1) are absolute constants.
The above theorem is directly applicable to the special case where g✓ is a Bernoulli distribution 
implying a lower bound of max 1

The upper bounds of our proposed procedures for the most biased coin problem presented later will
be compared to this benchmark.

 for the most biased coin problem.

↵   2 min{✓0(1✓0) ✓1(1✓1)}

↵(✓1✓0)2

3.2 The detection of a mixture distribution and the most biased coin problem
First observe that identifying a speciﬁc distribution i  N as heavy (i.e. ⇠i = 1) or determining that ↵
is strictly greater than 0  is at least as hard as detecting that any of the distributions up to distribution N
is heavy. Thus  a lower bound on the total expected number of samples of all considered distributions
for this strictly easier detection problem is also a lower bound for the estimate-then-explore strategy
for the most biased coin identiﬁcation problem.
The estimate-then-explore strategy ﬁxes an m 2 N prior to starting the game and then samples each
distribution exactly m times  i.e. Mi = m for all i  N for some N. To simplify notation let f✓
denote the distribution of the sufﬁcient statistics of these m samples. In general f✓ is a product
distribution  but when g✓ is a Bernoulli distribution  as in the biased coin problem  we can take f✓ to
be a Binomial distribution with parameters (m  ✓). Now our problem is more succinctly described as:

H0 : 8i Xi ⇠ f✓
H1 : 8i⇠ i ⇠ Bernoulli(↵) 

for some ✓ 2 e⇥ ✓ ⇥ 
8i Xi ⇠⇢f✓0

f✓1

if ⇠i = 0
if ⇠i = 1

(P2)

If ✓0 and ✓1 are close to each other  or if ↵ is very small  it can be very difﬁcult to decide between H0
and H1 even if ↵  ✓0 ✓ 1 are known a priori. Note that when the parameters are known  one can take

e⇥= {✓0}. However  when the parameters are unknown  one takese⇥=⇥ to prove a lower bound on

the sample complexity of the estimate-then-explore algorithm  which is tasked with deciding whether
or not samples are coming from a mixture of distributions or just a single distribution within the
family. That is  lower bounds on the sample complexity when the parameters are known and unknown
follow by analyzing a simple binary and composite hypothesis test  respectively. In what follows  for
any event A  let Pi(A) and Ei[A] denote probability and expectation of A under hypothesis Hi for
i 2{ 0  1} (the speciﬁc value of ✓ in H0 will be clear from context). The next claim is instrumental
in our ability to prove lower bounds on the difﬁculty of the hypothesis tests.
Claim 1 Any procedure that is -probably correct also satisﬁes P0(N < 1)   whenever ↵ = 0.
3.2.1 Sample complexity when parameters are known

⇥. Let N be the random number of distributions considered before stopping and declaring a

Theorem 2 Fix  2 (0  1). Consider the hypothesis test of Problem P2 for any ﬁxed ✓ 2 e⇥ ✓

5

↵  

log(1/)

hypothesis. If a procedure satisﬁes P0(N < 1)   and P1([N
2(P1|P0)o . In particular  ife⇥= {✓0} then
E1[N ]  maxn 1
↵22(f✓1|f✓0)o.

KL(P1|P0)o  maxn 1
E1[N ]  maxn 1  

↵   log(1/)

i=1{⇠i = 1})  1    then

The next corollary relates Theorem 2 to the most biased coin problem and is related to Malloy et al.
[15  Theorem 4] that considers the limit as ↵ ! 0 and assumes m is sufﬁciently large (speciﬁcally 
large enough for the Chernoff-Stein lemma to apply). In contrast  our result holds for all ﬁnite   ↵  m.
Corollary 1 Fix  2 (0  1). For any m 2 N consider a -probably correct strategy that ﬂips each
coin exactly m times. If Nm is the number of coins considered before declaring a coin as heavy then

log(1/)

↵

 

min
m2N

E[mNm] 

(1  ) log⇣ log(1/)

↵

↵

⌘

✓0(1  ✓0)
(✓1  ✓0)2 .

One can show the existence of such a strategy with a nearly matching upperbound when ↵  ✓0 ✓ 1 are
known (see Appendix B.1). Note that this is at least log(1/↵) larger than the sample complexity of
(1) that can be achieved by an adaptive algorithm when the parameters are known.
3.2.2 Sample complexity when parameters are unknown
If ↵  ✓0  and ✓1 are unknown  we cannot test f✓0 against the mixture (1  ↵)f✓0 + ↵f✓1. Instead  we
have the general composite test of any individual distribution against any mixture  which is at least as
hard as the hypothesis test of Problem P2 withe⇥= {✓} for some particular worst-case setting of ✓.

Without any speciﬁc form of f✓  it is difﬁcult to pick a worst case ✓ that will produce a tight bound.
Consequently  in this section we consider single parameter exponential families (deﬁned formally
below) to provide us with a class of distributions in which we can reason about different possible
values for ✓. Since exponential families include Bernoulli  Gaussian  exponential  and many other
distributions  the following theorem is general enough to be useful in a wide variety of settings. The
constant C referred to in the next theorem is an absolute constant under certain conditions that we
outline in the following remark and corollary  its explicit form is given in the proof.
Theorem 3 Suppose f✓ for ✓ 2 ⇥ ⇢ R is a single parameter exponential family so that f✓(x) =
h(x) exp(⌘(✓)x  b(⌘(✓))) for some scalar functions h  b  ⌘ where ⌘ is strictly increasing. Ife⇥=
{✓⇤} where ✓⇤ = ⌘1(1  ↵)⌘(✓0) + ↵⌘(✓1)and N is the stopping time of any procedure that
satisﬁes P0(N < 1)   and P1([N

i=1{⇠i = 1})  1    then
1
 )

E1[N ]  maxn 1

↵  

log(

2 ↵(1↵)(⌘(✓1)⌘(✓0))2)2o.

C( 1

where C is a constant that may depend on ↵  ✓0 ✓ 1.
The following remark and corollary apply Theorem 3 to the special cases of Gaussian mixture model
detection and the most biased coin problem  respectively.

2
2

Remark 1 When ↵  ✓0 ✓ 1 are unknown  any procedure has no knowledge ofe⇥ in Problem P2 and
consequently it cannot rule out ✓ = ✓⇤ for H0 where ✓⇤ is deﬁned in Theorem 3. If f✓ = N (✓   2)
for known   then whenever (✓1✓0)2
 1 the constant C in Theorem 3 is an absolute constant and
↵(✓1✓0)22 log(1/). Conversely  when ↵  ✓0 ✓ 1 are known  then we
consequently  E1[N ] =⌦
simply need to determine whether samples came from N (✓0  2) or (1 ↵)N (✓0  2) + ↵N (✓1  2) 
↵2(✓1✓0)2 log(1/)⌘ samples (see Appendix C).
and we show that it is sufﬁcient to take just O⇣
Corollary 2 Fix  2 [0  1] and assume ✓0 ✓ 1 are bounded sufﬁciently far from {0  1} such that
2(✓1  ✓0)  min{✓0(1  ✓0) ✓ 1(1  ✓1)}. For any m let Nm be the number of coins a -probably
correct estimate-then-explore strategy that ﬂips each coin m times in the exploration step. Then

2

mE[Nm] 

m  ✓ ⇤(1  ✓⇤)}

c0 min{ 1
⇣↵(1  ↵) (✓1✓0)2

✓⇤(1✓⇤)⌘2 log( 1

 ) whenever m 

✓⇤(1  ✓⇤)
(✓1  ✓0)2 .

where c0 is an absolute constant and ✓⇤ = ⌘1 ((1  ↵)⌘(✓0) + ↵⌘(✓1)) 2 [✓0 ✓ 1].

6

Remark 2 If ↵  ✓0 ✓ 1 are unknown  any estimate-then-explore strategy (or the strategy described in
Corollary 1) would be unable to choose an m that depended on these parameters  so we can treat it as
a constant. Thus  for the case when ✓0 and ✓1 are bounded away from {0  1} (e.g. ✓0 ✓ 1 2 [1/8  7/8]) 
the above corollary states that for any ﬁxed m  whenever ✓1  ✓0 is sufﬁciently small the number
↵(✓1✓0)22 log(1/).
of samples necessary for these strategies to identify a heavy coin scales like
This is striking example of the difference when parameters are known versus when they are not and
effectively rules out an estimate-then-explore strategy for practical purposes.

1

Setting

Upper Bound
log(1/(↵))

 

Fixed  known ↵  ✓0 ✓ 1

Adaptive  known ↵  ✓0 ✓ 1

↵✏2
↵ + log( 1
Est+Expl  unknown ↵  ✓0 ✓ 1 Unconsidered†

✏2 1

 )

1

Lower Bound
log(log(1/)/↵)

↵✏2

Thm. 7

[8  15]  Thm. 4

1
↵✏2

 1
↵✏22 log( 1

1
↵✏2

 )

Cor. 1

[15]

Cor. 2

[15]

Adaptive  unknown ↵  ✓0 ✓ 1

c log( 1

↵✏2 ) log(log( 1

↵✏2 )/)

↵✏2

Thm. 5

Table 1: Upper and lower bounds on the expected sample complexity of different -probably correct
strategies. Fixed refers to the strategy of Corollary 1. For this table  we assume min{✓0(1 
✓0) ✓ 1(1  ✓1)} is lower bounded by a constant (e.g. ✓0 ✓ 1 2 [1/8  7/8]) and ✏ = ✓1  ✓0 is
sufﬁciently small. Also note that the upperbounds apply to distributions supported on [0  1]  not
just coins. All results without bracketed citations were unknown prior to this work. † Due to our
discouraging lower bound for any estimate-then-explore strategy  it is inadvisable to propose an algorithm.

4 Near optimal adaptive algorithm
In this section we propose an algorithm that has no prior knowledge of the parameters ↵  ✓0 ✓ 1 yet
yields an upper bound that matches the lower bound of Theorem 1 up to logarithmic factors. We
assume that samples from heavy or light distributions are supported on [0  1]  and that drawn samples
are independent and unbiased estimators of the mean  i.e.  E[Xi j] = µi for µi 2{ ✓0 ✓ 1}. All
results can be easily extended to sub-Gaussian distributions. Consider Algorithm 2  an SPRT-like
procedure [18] for ﬁnding a heavy distribution given  and lower bounds on ↵ and ✏ = ✓1  ✓0. It
improves upon prior work by supporting arbitrary distributions on [0  1] and requires only bounds
↵  ✏.

Algorithm 2 Adaptive strategy for heavy distribution identiﬁcation with inputs ↵0 ✏ 0 
Given  2 (0  1/4) ↵ 0 2 (0  1/2) ✏ 0 2 (0  1).
Initialize n = d2 log(9)/↵0e  m = d64✏2
log(14n/)  k1 = 5  k2 = d8✏2
Draw k1 distributions and sample them each k2 times.

log(2k1/ min{/8  m1✏2

log(14n/)e  A = 8✏1

log(21) 
0 })e.

B = 8✏1
0

0

0

0

Estimateb✓0 = mini=1 ... k1bµi k2  ˆ =b✓0 + ✏0/2.

Repeat for i = 1  . . .   n:
Draw distribution i.
Repeat for j = 1  . . .   m:

Sample distribution i and observe Xi j.

IfPj
Else ifPj

break.

Output null.

k=1(Xi k  ˆ) > B:
Declare distribution i to be heavy and Output distribution i.

k=1(Xi k  ˆ) < A:

Theorem 4 If Algorithm 2 is run with  2 (0  1/4) ↵ 0 2 (0  1/2) ✏ 0 2 (0  1)  then the expected
number of total samples taken by the algorithm is no more than

c0↵ log(1/↵0) + c00 log 1


↵0✏2
0

7

(3)

for some absolute constants c0 c00  and all of the following hold: 1) with probability at least 1   
a light distribution is not returned  2) if ✏0  ✓1  ✓0 and ↵0  ↵  then with probability 4
5 a heavy
distribution is returned  and 3) the procedure takes no more than c log(1/(↵0))
total samples.

↵0✏2
0

The second claim of the theorem holds only with constant probability (versus with probability 1  )
since the probability of observing a heavy distribution among the n = d2 log(4)/↵0e distributions
only occurs with constant probability. One can show that if the outer loop of algorithm is allowed
to run indeﬁnitely (with m and n deﬁned as is)  ✏0 = ✓1  ✓0  ↵0 = ↵  andb✓0 = ✓0  then a heavy
coin is returned with probability at least 1   and the expected number of samples is bounded by
(3). If a tight lower bound is known on either ✏ = ✓1  ✓0 or ↵  there is only one parameter that is
unknown and the “doubling trick”  along with Theorem 4  can be used to identify a heavy coin with
just log(log(✏2)/)
Now consider Algorithm 3 that assumes no prior knowledge of ↵  ✓0 ✓ 1  the ﬁrst result for this setting
that we are aware of. We remark that while the placing of “landmarks” (↵k ✏ k) throughout the search
space as is done in Algorithm 3 appears elementary in hindsight  it is surprising that so few can cover
this two dimensional space since one has to balance the exploration of ↵ and ✏. We believe similar a
similar approach may be generalized for more generic inﬁnite armed bandit problems.

samples  respectively (see Appendix B.3).

and log(log(↵1)/)

↵✏2

↵✏2

Algorithm 3 Adaptive strategy for heavy distribution identiﬁcation with unknown parameters
Given > 0.
Initialize ` = 1  heavy distribution h = null.
Repeat until h is not null:

Set ` = 2`  ` = /(2`3)
Repeat for k = 0  . . .  ` :

 ✏ k =q 1

Set ↵k = 2k
`
Run Algorithm 2 with ↵0 = ↵k ✏ 0 = ✏k  = ` and Set h to its output.
If h is not null break

2↵k`

Set ` = ` + 1

Output h

Theorem 5 (Unknown ↵  ✓0 ✓ 1) Fix  2 (0  1). If Algorithm 3 is run with  then with probability
at least 1   a heavy distribution is returned and the expected number of total samples taken is
bounded by

↵✏2 )

log2( 1
↵✏2

c

for an absolute constant c.

(↵ log2( 1

✏2 ) + log(log2( 1

↵✏2 )) + log(1/))

5 Conclusion
While all prior works have required at least partial knowledge of ↵  ✓0 ✓ 1 to solve the most biased
coin problem  our algorithm requires no knowledge of these parameters yet obtain the near-optimal
sample complexity. In addition  we have proved lower bounds on the sample complexity of detecting
the presence of a mixture distribution when the parameters are known or unknown  with consequences
for any estimate-then-explore strategy  an approach previously proposed for an inﬁnite armed bandit
problem. Extending our adaptive algorithm to arbitrary arm reservoir distributions is of signiﬁcant
interest. We believe a successful algorithm in this vein could have a signiﬁcant impact on how
researchers think about sequential decision processes in both ﬁnite and uncountable action spaces.

Acknowledgments Kevin Jamieson is generously supported by ONR awards N00014-15-1-2620  and N00014-
13-1-0129. This research is supported in part by NSF CISE Expeditions Award CCF-1139158  DOE Award
SN10040 DE-SC0012463  and DARPA XData Award FA8750-12-2-0331  and gifts from Amazon Web Services 
Google  IBM  SAP  The Thomas and Stacey Siebel Foundation  Apple Inc.  Arimo  Blue Goji  Bosch  Cisco  Cray 
Cloudera  Ericsson  Facebook  Fujitsu  Guavus  HP  Huawei  Intel  Microsoft  Pivotal  Samsung  Schlumberger 
Splunk  State Farm and VMware.

8

References
[1] Jayadev Acharya  Constantinos Daskalakis  and Gautam C Kamath. Optimal testing for properties of

distributions. In Advances in Neural Information Processing Systems  pages 3577–3598  2015.

[2] Deepak Agarwal. Detecting anomalies in cross-classiﬁed streams: a bayesian approach. Knowledge and

Information Systems  11(1):29–44  2006.

[3] Alessandro Arlotto  Stephen E Chick  and Noah Gans. Optimal hiring and retention policies for heteroge-

neous workers who learn. Management Science  60(1):110–129  2013.

[4] Michael S Bernstein  Joel Brandt  Robert C Miller  and David R Karger. Crowds in two seconds: enabling

realtime crowd-powered interfaces. UIST  2011.

[5] Donald A. Berry  Robert W. Chen  Alan Zame  David C. Heath  and Larry A. Shepp. Bandit problems

with inﬁnitely many arms. Ann. Statist.  25(5):2103–2116  10 1997.

[6] Thomas Bonald and Alexandre Proutiere. Two-target algorithms for inﬁnite-armed bandits with bernoulli
rewards. In C.J.C. Burges  L. Bottou  M. Welling  Z. Ghahramani  and K.Q. Weinberger  editors  Advances
in Neural Information Processing Systems 26  pages 2184–2192. Curran Associates  Inc.  2013.

[7] Alexandra Carpentier and Michal Valko. Simple regret for inﬁnitely many armed bandits. arXiv preprint

arXiv:1505.04627  2015.

[8] Karthekeyan Chandrasekaran and Richard Karp. Finding a most biased coin with fewest ﬂips.

Proceedings of The 27th Conference on Learning Theory  pages 394–407  2014.

In

[9] Karthekeyan Chandrasekaran and Richard M. Karp. Finding the most biased coin with fewest ﬂips. CoRR 

abs/1202.3639  2012. URL http://arxiv.org/abs/1202.3639.

[10] Eleazar Eskin. Anomaly detection over noisy data using learned probability distributions. In Proceedings of
the Seventeenth International Conference on Machine Learning  ICML ’00  pages 255–262  San Francisco 
CA  USA  2000. Morgan Kaufmann Publishers Inc.

[11] Yoav Freund and Yishay Mansour. Estimating a mixture of two product distributions. In Proceedings of

the twelfth annual conference on Computational learning theory  pages 53–62. ACM  1999.

[12] Daniel Haas  Jiannan Wang  Eugene Wu  and Michael J. Franklin. Clamshell: Speeding up crowds for

low-latency data labeling. Proc. VLDB Endow.  9(4):372–383  December 2015. ISSN 2150-8097.

[13] Moritz Hardt and Eric Price. Sharp bounds for learning a mixture of two gaussians. ArXiv e-prints  1404 

2014.

[14] Kevin Jamieson and Robert Nowak. Best-arm identiﬁcation algorithms for multi-armed bandits in the

ﬁxed conﬁdence setting. In Information Sciences and Systems (CISS)  pages 1–6. IEEE  2014.

[15] Matthew L Malloy  Gongguo Tang  and Robert D Nowak. Quickest search for a rare distribution. In

Information Sciences and Systems (CISS)  pages 1–6. IEEE  2012.

[16] MTurk. Amazon Mechanical Turk. https://www.mturk.com/.
[17] David Pollard. Asymptopia. Manuscript in progress. Available at http://www. stat.yale.edu/⇠pollard 

2000.

[18] David Siegmund. Sequential analysis: tests and conﬁdence intervals. Springer Science & Business Media 

2013.

[19] Robert Spira. Calculation of the gamma function by stirling’s formula. mathematics of computation  pages

317–322  1971.

[20] Gautam Thatte  Urbashi Mitra  and John Heidemann. Parametric methods for anomaly detection in

aggregate trafﬁc. IEEE/ACM Trans. Netw.  19(2):512–525  April 2011. ISSN 1063-6692.

[21] Yizao Wang  Jean yves Audibert  and Rémi Munos. Algorithms for inﬁnitely many-armed bandits. In
D. Koller  D. Schuurmans  Y. Bengio  and L. Bottou  editors  Advances in Neural Information Processing
Systems 21  pages 1729–1736. Curran Associates  Inc.  2009.

9

,Kevin Jamieson
Daniel Haas
Benjamin Recht