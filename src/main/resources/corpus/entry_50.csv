2019,A Convex Relaxation Barrier to Tight Robustness Verification of Neural Networks,Verification of neural networks enables us to gauge their robustness against adversarial attacks. Verification algorithms fall into two categories: exact verifiers that run in exponential time and relaxed verifiers that are efficient but incomplete. In this paper  we unify all existing LP-relaxed verifiers  to the best of our knowledge  under a general convex relaxation framework. This framework works for neural networks with diverse architectures and nonlinearities and covers both primal and dual views of neural network verification. Next  we perform large-scale experiments  amounting to more than 22 CPU-years  to obtain exact solution to the convex-relaxed problem that is optimal within our framework for ReLU networks. We find the exact solution does not significantly improve upon the gap between PGD and existing relaxed verifiers for various networks trained normally or robustly on MNIST and CIFAR datasets. Our results suggest there is an inherent barrier to tight verification for the large class of methods captured by our framework. We discuss possible causes of this barrier and potential future directions for bypassing it.,A Convex Relaxation Barrier to Tight Robustness

Veriﬁcation of Neural Networks

Hadi Salman∗

Microsoft Research AI

hadi.salman@microsoft.com

Greg Yang

Microsoft Research AI

gregyang@microsoft.com

Huan Zhang

UCLA

huan@huan-zhang.com

Cho-Jui Hsieh

UCLA

chohsieh@cs.ucla.edu

Pengchuan Zhang

Microsoft Research AI

penzhan@microsoft.com

Abstract

Veriﬁcation of neural networks enables us to gauge their robustness against ad-
versarial attacks. Veriﬁcation algorithms fall into two categories: exact veriﬁers
that run in exponential time and relaxed veriﬁers that are efﬁcient but incom-
plete.
In this paper  we unify all existing LP-relaxed veriﬁers  to the best of
our knowledge  under a general convex relaxation framework. This framework
works for neural networks with diverse architectures and nonlinearities and covers
both primal and dual views of neural network veriﬁcation. Next  we perform
large-scale experiments  amounting to more than 22 CPU-years  to obtain exact
solution to the convex-relaxed problem that is optimal within our framework for
ReLU networks. We ﬁnd the exact solution does not signiﬁcantly improve upon
the gap between PGD and existing relaxed veriﬁers for various networks trained
normally or robustly on MNIST and CIFAR datasets. Our results suggest there
is an inherent barrier to tight veriﬁcation for the large class of methods captured
by our framework. We discuss possible causes of this barrier and potential fu-
ture directions for bypassing it. Our code and trained models are available at
http://github.com/Hadisalman/robust-verify-benchmark2.

Introduction

1
A classiﬁcation neural network f : Rn → RK (where fi(x) should be thought of as the ith logit) is
considered adversarially robust with respect to an input x and its neighborhood Sin(x) if

i∗ = arg max

j

x(cid:48)∈Sin(x) i(cid:54)=i∗ fi∗ (x) − fi(x(cid:48)) > 0  where

min

fj(x).

(1)

Many recent works have proposed robustness veriﬁcation methods by lower-bounding eq. (1); the
positivity of this lower bound proves the robustness w.r.t. Sin(x). A dominant approach thus far has
tried to relax eq. (1) into a convex optimization problem  from either the primal view [Zhang et al. 
2018  Gehr et al.  2018  Singh et al.  2018  Weng et al.  2018] or the dual view [Wong and Kolter 
2018  Dvijotham et al.  2018b  Wang et al.  2018b]. In our ﬁrst main contribution  we propose a
layer-wise convex relaxation framework that uniﬁes these works and reveals the relationships between
them (Fig. 1). We further show that the performance of methods within this framework is subject to a
theoretical limit: the performance of the optimal layer-wise convex relaxation.
This then begs the question: is the road to fast and accurate robustness veriﬁcation paved by just faster
and more accurate layer-wise convex relaxation that approaches the theoretical limit? In our second
main contribution  we answer this question in the negative. We perform extensive experiments

∗Work done as part of the Microsoft AI Residency Program.
2Please see http://arxiv.org/abs/1902.08722 for the full and most recent version of this paper.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: Relationship between existing relaxed algorithms and our framework. See Appendix D for
detailed discussions of each unlabeled arrow from the “Primal view” side.

with deep ReLU networks to compute the optimal layer-wise convex relaxation and compare with
the LP-relaxed dual formulation from Wong and Kolter [2018]  the PGD attack from Madry et al.
[2017]  and the mixed integer linear programming (MILP) exact veriﬁer from Tjeng et al. [2019].
Over different models  sizes  training methods  and datasets (MNIST and CIFAR-10)  we ﬁnd that (i)
in terms of lower bounding the minimum l∞ adversarial distortion3  the optimal layer-wise convex
relaxation only slightly improves the lower bound found by Wong and Kolter [2018]  especially when
compared with the upper bound provided by the PGD attack  which is consistently 1.5 to 5 times
larger; (ii) in terms of upper bounding the robust error  the optimal layer-wise convex relaxation does
not signiﬁcantly close the gap between the PGD lower bound (or MILP exact answer) and the upper
bound from Wong and Kolter [2018]. Therefore  there seems to be an inherent barrier blocking our
progress on this road of layer-wise convex relaxation  and we hope this work provokes much thought
in the community on how to bypass it.

2 Preliminaries and Related Work

Exact veriﬁers and NP-completeness. For ReLU networks (piece-wise linear networks in general) 
exact veriﬁers solve the robustness veriﬁcation problem (1) by typically employing MILP solvers
[Cheng et al.  2017  Lomuscio and Maganti  2017  Dutta et al.  2018  Fischetti and Jo  2017  Tjeng
et al.  2019  Xiao et al.  2019] or Satisﬁability Modulo Theories (SMT) solvers [Scheibler et al. 
2015  Katz et al.  2017  Carlini et al.  2017  Ehlers  2017]. However  due to the NP-completeness for
solving such a problem [Katz et al.  2017  Weng et al.  2018]  it can be really challenging to scale
these to large networks. It can take Reluplex [Katz et al.  2017] several hours to ﬁnd the minimum
distortion of an example for a ReLU network with 5 inputs  5 outputs  and 300 neurons. A recent
work by Tjeng et al. [2019] uses MILP to exactly verify medium-size networks  but the veriﬁcation
time is very sensitive to how a network is trained; for example  it is fast for networks trained using
the LP-relaxed dual formulation of Wong and Kolter [2018]  but much slower for normally trained
networks. A concurrent work by Xiao et al. [2019] trains networks with the objective of speeding up
the MILP veriﬁcation problem  but this compromises on the performance of the network.

Relaxed and efﬁcient veriﬁers. These veriﬁers solve a relaxed  but more computationally efﬁcient 
version of (1)  and have been proposed from different perspectives. From the primal view  one can
relax the nonlinearity in (1) into linear inequality constraints. This perspective has been previously
explored as in the framework of “abstract transformers” [Singh et al.  2018  2019a b  Gehr et al. 

3The radius of the largest l∞ ball in which no adversarial examples can be found.

2

DeepZ(Singh et al.  2018)DeepPoly(Singh et al.  2019)Neurify(Wang et al.  2018)Fast-Lin(Weng & Zhang et al.  2018)CROWN(Zhang & Weng et al.  2018)Optimal Convex Relaxation “Problem (C)” With Eq. (6) & (7)Abstract TransformersLinear Outer BoundsPrimal ViewDual ViewLagrangianDual (Dvijotham et al.  2018Qin et al.  2019)LP-Relaxed Dual(Wong & Kolter  2018)LegendTheorem 4.2Similar strengthWeaker / more relaxedNeural Network Verification“Problem (O)”Corollary 4.3Section 3Section 4GapConvex Relaxation Barrier2018  Mirman et al.  2018]  via linear outer bounds of activation functions [Zhang et al.  2018  Weng
et al.  2018  Wang et al.  2018a b]  or via interval bound propagation [Gowal et al.  2018  Mirman
et al.  2018]. From the dual view  one can study the dual of the relaxed problem [Wong and Kolter 
2018  Wong et al.  2018] or study the dual of the original nonconvex veriﬁcation problem [Dvijotham
et al.  2018b a  Qin et al.  2019]. In this paper  we unify both views in a common convex relaxation
framework for NN veriﬁcation  clarifying their relationships (as summarized in Fig. 1).
Raghunathan et al. [2018b] formulates the veriﬁcation of ReLU networks as a quadratic programming
problem and then relaxes and solves this problem with a semideﬁnite programming (SDP) solver.
While our framework does not cover this SDP relaxation  it is not clear to us how to extend the
SDP relaxed veriﬁer to general nonlinearities  for example max-pooling  which can be done in our
framework on the other hand. Other veriﬁers have been proposed to certify via an intermediary
step of bounding the local Lipschitz constant [Hein and Andriushchenko  2017  Weng et al.  2018 
Raghunathan et al.  2018a  Zhang et al.  2019]  and others have used randomized smoothing to certify
with high-probability [Lecuyer et al.  2018  Li et al.  2018  Cohen et al.  2019  Salman et al.  2019].
These are outside the scope of our framework.
Combining exact and relaxed veriﬁers  hybrid methods have shown some effectiveness [Bunel et al. 
2018  Singh et al.  2019b]. In fact  many exact veriﬁers also use relaxation as a subroutine to speed
things up  and hence can be viewed as hybrid methods as well. In this paper  we are not concerned
with such techniques but only focus on relaxed veriﬁers.

3 Convex Relaxation from the Primal View

In this paper  we assume that the neighborhood Sin(xnom) is a convex set. An
Problem setting.
example of this is Sin(xnom) = {x : (cid:107)x − xnom(cid:107)∞ ≤ }  which is the constraint on x in the (cid:96)∞
adversarial attack model. We also assume that f (x) is an L-layer feedforward NN. For notational
simplicity  we denote {0  1  . . .   L − 1} by [L] and {x(0)  x(1)  . . .   x(L−1)} by x[L]. We deﬁne f (x)
as 

z

and

x(l+1) = σ(l)(W(l)x(l) + b(l)) ∀l ∈ [L] 

f (x) := z(L) = W(L)x(L) + b(L) 

  x(0) := x ∈ Rn(0) is the input  W(l) ∈ Rn(l)

(2)
where x(l) ∈ Rn(l)  z(l) ∈ Rn(l)
z ×n(l) and b(l) ∈ Rn(l)
z → Rn(l+1) is a (nonlinear)
are the weight matrix and bias vector of the lth linear layer  and σ(l) : Rn(l)
activation function like (leaky-)ReLU  the sigmoid family (including sigmoid  arctan  hyperbolic
tangent  etc)  and the pooling family (MaxPool  AvgPool  etc). Our results can be easily extended to
networks with convolutional layers and skip connections as well  similar to what is done in Wong
et al. [2018]  as these can be seen as special forms of (2).
Consider the following optimization problem O(c  c0  L  z[L]  z[L]):

z

(x[L+1] z[L])∈D c(cid:62)x(L) + c0

min

s.t.

z(l) = W(l)x(l) + b(l)  l ∈ [L] 
x(l+1) = σ(l)(z(l))  l ∈ [L] 

(O)

domain D is

the

where
preactivations
{x(0)  x(1)  . . .   x(L)  z(0)  z(1)  . . .   z(L−1)} satisfying the bounds z(l) ≤ z(l) ≤ z(l) ∀l ∈ [L]  i.e. 

optimization

activations

and

the

set

of

D =(cid:8)(x[L+1]  z[L]) : x(0) ∈ Sin(xnom) 

z(l) ≤ z(l) ≤ z(l)  l ∈ [L](cid:9).

inom : − W(L)

(3)
  z[L] = −∞  and z[L] = ∞  then (O) is equivalent to
If c(cid:62) = W(L)
problem (1). However  when we have better information about valid bounds z[l] and z[l] of z[l]  we
can signiﬁcantly narrow down the optimization domain and  as will be detailed shortly  achieve tighter
solutions when we relax the nonlinearities. We denote the minimal value of O(c  c0  L  z[L]  z[L]) by
p∗(c  c0  L  z[L]  z[L])  or just p∗

O when no confusion arises.

i :   c0 = b(L)

inom − b(L)

i

Obtaining lower and upper bounds (z[L]  z[L]) by solving sub-problems. This can be done by
recursively solving (O) with speciﬁc choices of c and c0  which is a common technique used in many

3

Figure 2: Optimal convex relaxations for common nonlinearities. For tanh  the relaxation contains
two linear segments and parts of the tanh function. For ReLU and the step function  the optimal
relaxations are written as 3 and 4 linear constraints  respectively. For z = max(x  y)  the light orange
shadow indicates the pre-activation bounds for x and y  and the optimal convex relaxation is lower
bounded by the max function itself.

works [Wong and Kolter  2018  Dvijotham et al.  2018b]. For example  one can obtain z((cid:96))
  a lower
j
bound of z((cid:96))
  (cid:96)  z[(cid:96)]  z[(cid:96)]); this shows that one can estimate z(l) and z(l)
inductively in l. However  we may have millions of sub-problems to solve because practical networks
can have millions of neurons. Therefore  it is crucial to have efﬁcient algorithms to solve (O).

  by solving O(W((cid:96))

(cid:62)  b((cid:96))

j :

j

j

Convex relaxation in the primal space. Due to the nonlinear activation functions σ(l)  the feasible
set of (O) is nonconvex  which leads to the NP-completeness of the neural network veriﬁcation
problem [Katz et al.  2017  Weng et al.  2018]. One natural idea is to do convex relaxation of its
feasible set. Speciﬁcally  one can relax the nonconvex equality constraint x(l+1) = σ(l)(z(l)) to
convex inequality constraints  i.e. 

s.t.

(cid:62)

c

min

x(L) + c0

z(l) = W(l)x(l) + b(l)  σ(l)(z(l)) ≤ x(l+1) ≤ σ(l)(z(l)) ∀l ∈ [L] 

(C)
(x[L+1] z[L])∈D
where σ(l)(z) ( σ(l)(z)) is convex (concave) and satisﬁes σ(l)(z) ≤ σ(l)(z) ≤ σ(l)(z) for z(l) ≤ z ≤
C. Naturally  we have that SC is
z(l). We denote the feasible set of (C) by SC and its minimum by p∗
convex and p∗
O. For example  Ehlers [2017] proposed the following relaxations for the ReLU
function σReLU (z) = max(0  z) and MaxPool σM P (z) = maxk zk:
(cid:88)

σReLU (z) = max(0  z) 

z−z (z − z)  

σReLU (z) = z

C ≤ p∗

(4)

σM P (z) = max

k

(zk − zk) + max

zk 

k

zk ≥(cid:88)

k

σM P (z) =

k

(zk + zk) − max

zk.

k

(5)

The optimal layer-wise convex relaxation. As a special case  we consider the optimal layer-wise
convex relaxation  where

σopt(z) is the greatest convex function majored by σ 
σopt(z) is the smallest concave function majoring σ.

(6)

A precise deﬁnition can be found in (12) in Appendix B. In Fig. 2  we show the optimal convex
relaxation for several common activation functions. It is easy to see that (4) is the optimal convex
relaxation for ReLU  but (5) is not optimal for the MaxPool function. Under mild assumptions
(non-interactivity as deﬁned in deﬁnition B.2)  the optimal convex relaxation of a nonlinear layer
x = σ(z)  i.e.  its convex hull  is simply σopt(z) ≤ x ≤ σopt(z) (see proposition B.3). We denote the
corresponding optimal relaxed problem as Copt  with its objective p∗
We emphasize that by optimal  we mean the optimal convex relaxation of the single nonlinear
constraint x(l+1) = σ(l)(z(l)) (see Proposition (B.3)) instead of the optimal convex relaxation of the
nonconvex feasible set of the original problem (O). As such  techniques as in [Anderson et al.  2018 
Raghunathan et al.  2018b] are outside our framework; see appendix C for more discussions.

Copt.

Greedily solving the primal with linear bounds. As another special case  when there are exactly
one linear upper bound and one linear lower bound for each nonlinear layer in (C) as follows:

σ(l)(z(l)) := a(l)z(l) + b

(7)
the objective p∗
C can be greedily bounded in a layer-by-layer manner. We can derive one linear
upper and one linear lower bound of zL := cT xL + c0 with respect to z(L−1)  using the fact that

σ(l)(z(l)) := a(l)z(l) + b(l).

 

(l)

4

tanhtanhtanh-2-112-1.0-0.50.51.0relurelurelu-1.0-0.50.51.00.20.40.60.81.01.2stepstepstep-1.0-0.50.51.0-0.20.20.40.60.81.01.2z(L) = cT σ(L−1)(z(L−1)) + c0 and that σ(L−1)(z(L−1)) is linearly upper and lower bounded by
σ(L−1)(z(L−1)) and σ(L−1)(z(L−1)). Because a linear combination of linear bounds (coefﬁcients
are related to the entries in c) can be relaxed to a single linear bound  we can apply this technique
again and replace z(L−1) with its upper and lower bounds with respect to z(L−2)  obtaining the bound
for z(L) with respect to z(L−2). Applying this repeatedly eventually leads to linear lower and upper
bounds of z(L) with respect to the input x(0) ∈ Sin(xnom).
This perspective covers Fast-Lin [Weng et al.  2018]  DeepZ [Singh et al.  2018] and Neurify [Wang
et al.  2018b]  where the proposed linear lower bound has the same slope as the upper bound  i.e. 
a(l) = a(l). The resulting shape is referred to as a zonotope in Gehr et al. [2018] and Singh et al.
[2018]. In CROWN [Zhang et al.  2018] and DeepPoly [Singh et al.  2019a]  this restriction is lifted
and they can achieve better veriﬁcation results than Fast-Lin and DeepZ. Fig. 1 summarizes the
relationships between these algorithms. Importantly  each of these works has its own merits on
solving the veriﬁcation problem; our focus here is to give a uniﬁed view on how they perform convex
relaxation of the original veriﬁcation problem (O) in our framework. See Appendix D for more
discussions and other related algorithms.

4 Convex Relaxation from the Dual View

We now tackle the veriﬁcation problem from the dual view and connect it to the primal view.
Strong duality for the convex relaxed problem. As in Wong and Kolter [2018]  we introduce the
dual variables for (C) and write its Lagrangian dual as

gC(µ[L]  λ[L]  λ

[L]

) :=

(cid:62)
c

x(L) + c0 +

µ(l)(cid:62)

(z(l) − W(l)x(l) − b(l))

min

(x[L+1] z[L])∈D

− L−1(cid:88)

λ(l)(cid:62)

(x(l+1) − σ(l)(z(l))) +

(l)(cid:62)

λ

(x(l+1) − σ(l)(z(l))).

L−1(cid:88)
L−1(cid:88)

l=0

(8)

(9)

By weak duality [Boyd and Vandenberghe  2004] 

l=0

l=0

d∗
C :=

max

µ[L] λ[L]≥0 λ[L]≥0

gC(µ[L]  λ[L]  λ

[L]

) ≤ p∗
C 

but in fact we can show strong duality under mild conditions as well (note that the following result
cannot be obtained by trivially applying Slater’s condition; see appendix E and ﬁg. 4).
Theorem 4.1 (p∗
domain [z(l)  z(l)] for each l ∈ [L]. Then strong duality holds between (C) and (9).

C). Assume that both σ(l) and σ(l) have a ﬁnite Lipschitz constant in the

C = d∗

The optimal layer-wise dual relaxation. Theorem 4.1 shows that taking the dual of the layer-wise
convex relaxed problem (C) cannot do better than the original relaxation. To obtain a tighter dual
problem  one could directly study the Lagrangian dual of the original (O) 
L−1(cid:88)

gO(µ[L]  λ[L]) := minD c
(10)
where the min is taken over {(x[L+1]  z[L]) ∈ D}. This was ﬁrst proposed in Dvijotham et al. [2018b].
Note  again  by weak duality 

(z(l) − W(l)x(l) − b(l)) +

(x(l+1) − σ(l)(z(l))) 

x(L) + c0 +

L−1(cid:88)

µ(l)(cid:62)

λ(l)(cid:62)

l=0

l=0

(cid:62)

d∗
O := max
µ[L] λ[L]

gO(µ[L]  λ[L]) ≤ p∗
O 

(11)

O would seem to be strictly better than d∗

and d∗
Theorem 4.2 (d∗
and the optimal layer-wise relaxation σ(l)
provided by the dual of the optimal layer-wise convex-relaxed problem (9) and d∗
dual of the original problem (11) are the same.

Copt). Assume that the nonlinear layer σ(l) is non-interactive (deﬁnition B.2)
opt are deﬁned in (6). Then the lower bound d∗
Copt
O provided by the

C. Unfortunately  they turn out to be equivalent:

opt and σ(l)

O = d∗

5

The complete proof is in Appendix F 4. Theorem 4.2 combined with the strong duality result of
Theorem 4.1 implies that the primal relaxation (C) and the two kinds of dual relaxations  (9) and (11) 
are all blocked by the same barrier. As concrete examples:
O). Suppose that the nonlinear activation functions σ(l) for all l ∈ [L] are
Corollary 4.3 (p∗
(for example) among the following: ReLU  step  ELU  sigmoid  tanh  polynomials and max pooling
with disjoint windows. Assume that σ(l)
opt are deﬁned in (6)  respectively. Then we have that
the lower bound p∗
O provided by
the dual relaxation (11) are the same.

Copt provided by the primal optimal layer-wise relaxation (C) and d∗

Copt = d∗

opt and σ(l)

Greedily solving the dual with linear bounds. When the relaxed bounds σ and σ are linear as
deﬁned in (7)  the dual objective (9) can be lower bounded as below:

(cid:19)

− b(l)(cid:62)µ(l)

+ c0 −

sup

x∈Sin(xnom)

(cid:16)

W(0)(cid:62)µ(0)(cid:17)(cid:62)

x 

p∗
C = d∗

(cid:18)

b

(l)(cid:62)(cid:16)

λ(l)(cid:17)
C ≥ L−1(cid:88)
λ(L−1) = −c  µ(l) = a(l)(cid:16)

l=0

+

− b(l)(cid:62)(cid:16)
λ(l)(cid:17)

λ(l)(cid:17)
+ a(l)(cid:16)

−

λ(l)(cid:17)

where the dual variables (µ[L]  λ[L]) are determined by a backward propagation

+

λ(l−1) = W(l)(cid:62)µ(l) ∀l ∈ [L − 1] 

−  

We provide the derivation of this algorithm in Appendix G. It turns out that this algorithm can exactly
recover the algorithm proposed in Wong and Kolter [2018]  where

σ(l)(z(l)) := α(l)z(l) 

σ(l)(z(l)) := z(l)

z(l)−z(l) (z(l) − z(l)) 

and 0 ≤ α(l) ≤ 1 represents the slope of the lower bound. When α(l) = z(l)
z(l)−z(l)   the greedy
algorithm also recovers Fast-Lin [Weng et al.  2018]  which explains the arrow from Wong and Kolter
[2018] to Weng et al. [2018] in Fig. 1. When α(l) is chosen adaptively as in CROWN [Zhang et al. 
2018]  the greedy algorithm then recovers CROWN  which explains the arrow from Wong and Kolter
[2018] to Zhang et al. [2018] in Fig. 1. See Appendix D for more discussions on the relationship
between the primal and dual greedy solvers.

5 Optimal LP-relaxed Veriﬁcation

In the previous sections  we presented a framework that subsumes all existing layer-wise convex-
relaxed veriﬁcation algorithms except that of Raghunathan et al. [2018b]. For ReLU networks 
being piece-wise linear  these correspond exactly to the set of all existing LP-relaxed algorithms  as
discussed above. We showed the existence of a barrier  p∗
C  that limits all such algorithms. Is this just
theoretical babbling or is this barrier actually problematic in practice?
In the next section  we perform extensive experiments on deep ReLU networks  evaluating the tightest
convex relaxation afforded by our framework (denoted LP-ALL) against a greedy dual algorithm
(Algorithm 1 of Wong and Kolter [2018]  denoted LP-GREEDY) as well as another algorithm LP-
LAST  intermediate in speed and accuracy between them. Both LP-GREEDY and LP-LAST solve the
bounds z[L]  z[L] by setting the dual variables heuristically (see previous section)  but LP-GREEDY
solves the adversarial loss in the same manner while LP-LAST solves this ﬁnal LP exactly. We also
compare them with the opposite bounds provided by PGD attack [Madry et al.  2017]  as well as
exact results from MILP [Tjeng et al.  2019] 5.
For the rest of the main text  we are only concerned with ReLU networks  so (C) subject to (4) is in
fact an LP.

4Theorem 2 in Dvijotham et al. [2018b] is a special case of our Theorem 4.2  when applied to ReLU networks.
Our proof makes use of the Fenchel-Moreau theorem to deal with general nonlinearities  which is different from
that in Dvijotham et al. [2018b].

5Note that in practice (as in [Tjeng et al.  2019])  MILP has a time budget  and usually not every sample can
be veriﬁed within that budget  so that in the end we still obtain only lower and upper bounds given by samples
veriﬁed to be robust or nonrobust

6

5.1 LP-ALL Implementation Details

In order to exactly solve the tightest LP-relaxed veriﬁcation problem of a ReLU network  two steps
are required: (A) obtaining the tightest pre-activation upper and lower bounds of all the neurons in
the NN  excluding those in the last layer  then (B) solving the LP-relaxed veriﬁcation problem exactly
for the last layer of the NN.

Step A: Obtaining Pre-activation Bounds. This can be done by solving sub-problems of the
orginial relaxed problem (C) subject to (4). Given a NN with L0 layers  for each layer l0 ∈ [L0]  we
  for all neurons j ∈ [n(l0)]. We do this
obtain a lower (resp. upper) bound z(l0)
by setting

(resp. z(l0)

) of z(l0)

j

j

j

L ← l0 

c(cid:62) ← W(l0)

j :

(resp. c(cid:62) ← −W(l0)
j : ) 

c0 ← b(l0)

j

(resp. c0 ← −b(l0)

j

)

in (C) and computing the exact optimum. However  we need to solve an LP for each neuron  and
practical networks can have millions of them. We utilize the fact that in each layer l0  computing the
for each j ∈ [n(l0)] can proceed independently in parallel. Indeed  we design a
bounds z(l0)
scheduler to do so on a cluster with 1000 CPU-nodes. See Appendix J for details.

and z(l0)

j

j

Step B: Solving the LP-relaxed Problem for the Last Layer. After obtaining the pre-activation
bounds on all neurons in the network using step (A)  we solve the LP in (C) subject to (4) for all
j ∈ [n(L0)]\{jnom} obtained by setting

L ← L0 

c(cid:62) ← W(L0)

jnom : − W(L0)

j :

c0 ← b(L0)

jnom − b(L0)

j

 

again in (C) and computing the exact minimum. Here  jnom is the true label of the data point xnom at
which we are verifying the network. We can certify the network is robust around xnom iff the solutions
of all such LPs are positive  i.e. we cannot make the true class logit lower than any other logits.
Again  note that these LPs are also independent of each other  so we can solve them in parallel.
Given any xnom  LP-ALL follows steps (A) then (B) to produce a certiﬁcate whether the network is
robust around a given datapoint or not. LP-LAST on the other hand solves only step (B)  and instead
of doing (A)  it ﬁnds the preactivation bounds greedily as in Algorithm 1 of Wong and Kolter [2018].

6 Experiments

We conduct two experiments to assess the tightness of LP-ALL: 1) ﬁnding certiﬁed upper bounds
on the robust error of several NN classiﬁers  2) ﬁnding certiﬁed lower bounds on the minimum
adversarial distortion  using different algorithms. All experiments are conducted on MNIST and/or
CIFAR-10 datasets.

Architectures. We conduct experiments on a range of ReLU-activated feedforward networks.
MLP-A and MLP-B refer to multilayer perceptrons: MLP-A has 1 hidden layer with 500 neurons 
and MLP-B has 2 hidden layers with 100 neurons each. CNN-SMALL  CNN-WIDE-K  and CNN-
DEEP-K are the ConvNet architectures used in Wong et al. [2018]. Full details are in Appendix I.1.

Training Modes. We conduct experiments on networks trained with a regular cross-entropy (CE)
loss function and networks trained to be robust. These networks are identiﬁed by a preﬁx correspond-
ing to the method used to train them: LPD when the LP-relaxed dual formulation of Wong and Kolter
[2018] is used for robust training  ADV when adversarial examples generated using PGD are used for
robust training  as in Madry et al. [2017]  and NOR when the network is normally trained using the
CE loss function. Training details are in Appendix I.2.

Experimental Setup. We run experiments on a cluster with 1000 CPU-nodes. The total run time
amounts to more than 22 CPU-years. Appendix J provides additional details about the computational
resources and the scheduling scheme used  and Appendix K provides statistics of the veriﬁcation
time in these experiments.

7

Table 1: Certiﬁed bounds on the robust error on the test set of MNIST for normally and robustly
trained networks. The preﬁx of each network corresponds to the training method used: ADV for PGD
training [Madry et al.  2017]  NOR for normal CE loss training  and LPD when the LP-relaxed dual
formulation of Wong and Kolter [2018] is used for robust training.

NETWORK



ADV-MLP-B 0.03
ADV-MLP-B 0.05
ADV-MLP-B
0.1
ADV-MLP-A
0.1
NOR-MLP-B 0.02
NOR-MLP-B 0.03
NOR-MLP-B 0.05
LPD-MLP-B
0.1
0.2
LPD-MLP-B
0.3
LPD-MLP-B
LPD-MLP-B
0.4

TEST
ERROR

LOWER BOUND
MILP
LP-ALL
MILP
PGD
4.18%
4.17%
5.78% 10.04%
1.53%
1.62%
6.11% 11.38% 23.29%
6.06%
3.33% 15.86% 16.25% 34.37% 61.59%
4.18% 11.51% 14.36% 30.81% 60.14%
2.05% 10.06% 10.16% 13.48% 26.41%
2.05% 20.37% 20.43% 48.67% 65.70%
2.05% 53.37% 53.37% 94.04% 97.95%
4.09% 13.39% 14.45% 14.45% 17.24%
15.72% 33.85% 36.33% 36.33% 37.50%
39.22% 57.29% 59.85% 59.85% 60.17%
67.97% 81.85% 83.17% 83.17% 83.62%

UPPER BOUND

LP-GREEDY

13.40%
33.09%
71.34%
67.50%
35.11%
75.85%
99.39%
18.32%
41.67%
66.85%
87.89%

6.1 Certiﬁed Bounds on the Robust Error

Table 1 presents the clean test errors and (upper and lower) bounds on the true robust errors for a
range of classiﬁers trained with different procedures on MNIST. For both ADV- and LPD-trained
networks  the  in Table 1 denotes the l∞-norm bound used for training and robust testing; for
NORmally-trained networks   is only used for the latter.
Lower bounds on the robust error are calculated by ﬁnding adversarial examples for inputs that are
not robust. This is done by using PGD  a strong ﬁrst-order attack  or using MILP [Tjeng et al.  2019].
Upper bounds on the robust error are calculated by providing certiﬁcates of robustness for input that
is robust. This is done using MILP  the dual formulation (LP-GREEDY) presented by Wong and
Kolter [2018]  or our LP-ALL algorithm.
For the MILP results  we use the code accompanying the paper by Tjeng et al. [2019]. We run the
code in parallel on a cluster with 1000 CPU-nodes  and set the MILP solver’s time limit to 3600
seconds. Note that this time limit is reached for ADV and NOR  and therefore the upper and lower
bounds are separated by a gap that is especially large for some of the NORmally trained networks.
On the other hand  for LPD-trained networks  the MILP solver ﬁnishes within the time limit  and
thus the upper and lower bounds match.
Results. For all NORmally and ADV-trained networks  we see that the certiﬁed upper bounds using
LP-GREEDY and LP-ALL are very loose when we compare the gap between them to the lower
bounds found by PGD and MILP. As a sanity check  note that LP-ALL gives a tighter bound than
LP-GREEDY in each case  as one would expect. Yet this improvement is not signiﬁcant enough to
close the gap with the lower bounds.
This sanity check also passes for LPD-trained networks  where the LP-GREEDY-certiﬁed robust
error upper bound is  as expected  much closer to the true error (given by MILP here) than for other
networks. For  = 0.1  the improvement of LP-ALL-certiﬁed upper bound over LP-GREEDY is at
most modest  and the PGD lower bound is tighter to the true error. For large   the improvement is
much more signiﬁcant in relative terms  but the absolute improvement is only 4 − 7%. In this large 
regime  however  both the clean and robust errors are quite large  so the tightness of LP-ALL is less
useful.

6.2 Certiﬁed Bounds on the Minimum Adversarial Distortion 

We are interested in searching for the minimum adversarial distortion   which is the radius of the
largest l∞ ball in which no adversarial examples can be crafted. An upper bound on  is calculated
using PGD  and lower bounds are calculated using LP-GREEDY  LP-LAST  or our LP-ALL  all via
binary search. Since solving LP-ALL is expensive  we ﬁnd the -bounds only for ten samples of the
MNIST and CIFAR-10 datasets. In this experiment  both ADV- and LPD-networks are trained with
an l∞ maximum allowed perturbation of 0.1 and 8/255 on MNIST and CIFAR-10  respectively. See
Appendix L.1 for details. Fig. 3 and 8 in the Appendix show the median percentage gap (deﬁned in

8

Figure 3: The median percentage gap between the convex-relaxed algorithms (LP-ALL  LP-LAST 
and LP-GREEDY) and PGD estimates of the minimum adversarial distortion  on ten samples of
MNIST. The error bars correspond to 95% conﬁdence intervals. We highlight the 1.5× and 5× gaps
between the  value estimated by PGD  and those estimated by the LP-relaxed algorithms. For more
details  please refer to Table 2 in Appendix L.2.

Appendix L.2) between the convex-relaxed algorithms and PGD bounds of  for MNIST and CIFAR 
respectively. Details are reported in Tables 2 and 3 in Appendix L.2.
On MNIST  the results show that for all networks trained NORmally or via ADV  the certiﬁed lower
bounds on  are 1.5 to 5 times smaller than the upper bound found by PGD; for LPD trained networks 
below 1.5 times smaller. On CIFAR-10  the bounds are between 1.5 and 2 times smaller across all
models. The smaller gap for LPD is of course as expected following similar observations in prior
work [Wong and Kolter  2018  Tjeng et al.  2019]. Furthermore  the improvement of LP-ALL and
LP-LAST over LP-GREEDY is not signiﬁcant enough to close the gap with the PGD upper bound.
Note that similar results hold as well for randomly initialized networks (no training). To avoid clutter 
we report these in Appendix M.

7 Conclusions and Discussions

In this work  we ﬁrst presented a layer-wise convex relaxation framework that uniﬁes all previous
LP-relaxed veriﬁers  in both primal and dual spaces. Then we performed extensive experiments to
show that even the optimal convex relaxation for ReLU networks in this framework cannot obtain
tight bounds on the robust error in all cases we consider here. Thus any method will face a convex
relaxation barrier as soon as it can be described by our framework. We look at how to bypass this
barrier in Appendix A.
Note that different applications have different requirements for the tightness of the veriﬁcation  so
our barrier could be a problem for some but not for others. In so far as the ultimate goal of robustness
veriﬁcation is to construct a training method to lower certiﬁed error  this barrier is not necessarily
problematic — some such method could still produce networks for which convex relaxation as
described by our framework produces accurate robust error bounds. An example is the recent work
of Gowal et al. [2018] which shows that interval bound propagation  which often leads to loose
certiﬁcation bounds  can still be used for veriﬁed training  and is able to achieve state-of-the-art
veriﬁed accuracy when carefully tuned. However  without a doubt  in all cases  tighter estimates
should lead to better results  and we reveal a deﬁnitive ceiling on most current methods.

9

References
Ross Anderson  Joey Huchette  Christian Tjandraatmadja  and Juan Pablo Vielma. Strong convex
relaxations and mixed-integer programming formulations for trained neural networks. arXiv
preprint arXiv:1811.01988  2018.

Stephen Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press  2004.

Rudy R Bunel  Ilker Turkaslan  Philip Torr  Pushmeet Kohli  and Pawan K Mudigonda. A uniﬁed
view of piecewise linear neural network veriﬁcation. In Advances in Neural Information Processing
Systems  pages 4795–4804  2018.

Nicholas Carlini  Guy Katz  Clark Barrett  and David L Dill. Provably minimally-distorted adversarial

examples. arXiv preprint arXiv:1709.10207  2017.

Chih-Hong Cheng  Georg Nührenberg  and Harald Ruess. Maximum resilience of artiﬁcial neural
networks. In International Symposium on Automated Technology for Veriﬁcation and Analysis 
pages 251–268. Springer  2017.

Jeremy M Cohen  Elan Rosenfeld  and J Zico Kolter. Certiﬁed adversarial robustness via randomized

smoothing. arXiv preprint arXiv:1902.02918  2019.

Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex

optimization. Journal of Machine Learning Research  17(83):1–5  2016.

A. Domahidi  E. Chu  and S. Boyd. ECOS: An SOCP solver for embedded systems. In European

Control Conference (ECC)  pages 3071–3076  2013.

Souradeep Dutta  Susmit Jha  Sriram Sankaranarayanan  and Ashish Tiwari. Output range analysis
for deep feedforward neural networks. In NASA Formal Methods Symposium  pages 121–138.
Springer  2018.

Krishnamurthy Dvijotham  Sven Gowal  Robert Stanforth  Relja Arandjelovic  Brendan O’Donoghue 
Jonathan Uesato  and Pushmeet Kohli. Training veriﬁed learners with learned veriﬁers. arXiv
preprint arXiv:1805.10265  2018a.

Krishnamurthy Dvijotham  Robert Stanforth  Sven Gowal  Timothy Mann  and Pushmeet Kohli. A

dual approach to scalable veriﬁcation of deep networks. UAI  2018b.

Ruediger Ehlers. Formal veriﬁcation of piece-wise linear feed-forward neural networks. In In-
ternational Symposium on Automated Technology for Veriﬁcation and Analysis  pages 269–286.
Springer  2017.

Matteo Fischetti and Jason Jo. Deep neural networks as 0-1 mixed integer linear programs: A

feasibility study. arXiv preprint arXiv:1712.06174  2017.

Timon Gehr  Matthew Mirman  Dana Drachsler-Cohen  Petar Tsankov  Swarat Chaudhuri  and Martin
Vechev. AI 2: Safety and robustness certiﬁcation of neural networks with abstract interpretation.
In 2018 IEEE Symposium on Security and Privacy (SP)  2018.

Sven Gowal  Krishnamurthy Dvijotham  Robert Stanforth  Rudy Bunel  Chongli Qin  Jonathan
Uesato  Timothy Mann  and Pushmeet Kohli. On the effectiveness of interval bound propagation
for training veriﬁably robust models. arXiv preprint arXiv:1810.12715  2018.

Matthias Hein and Maksym Andriushchenko. Formal guarantees on the robustness of a classiﬁer
against adversarial manipulation. In Advances in Neural Information Processing Systems (NIPS) 
pages 2266–2276  2017.

Guy Katz  Clark Barrett  David L Dill  Kyle Julian  and Mykel J Kochenderfer. Reluplex: An efﬁcient
smt solver for verifying deep neural networks. In International Conference on Computer Aided
Veriﬁcation  pages 97–117. Springer  2017.

Mathias Lecuyer  Vaggelis Atlidakis  Roxana Geambasu  Daniel Hsu  and Suman Jana. Certiﬁed
robustness to adversarial examples with differential privacy. arXiv preprint arXiv:1802.03471 
2018.

10

Bai Li  Changyou Chen  Wenlin Wang  and Lawrence Carin. Second-order adversarial attack and

certiﬁable robustness. arXiv preprint arXiv:1809.03113  2018.

Alessio Lomuscio and Lalit Maganti. An approach to reachability analysis for feed-forward relu

neural networks. arXiv preprint arXiv:1706.07351  2017.

Aleksander Madry  Aleksandar Makelov  Ludwig Schmidt  Dimitris Tsipras  and Adrian Vladu.
Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv:1706.06083 
2017.

Matthew Mirman  Timon Gehr  and Martin Vechev. Differentiable abstract interpretation for provably
robust neural networks. In International Conference on Machine Learning  pages 3575–3583 
2018.

Chongli Qin  Krishnamurthy Dj Dvijotham  Brendan O’Donoghue  Rudy Bunel  Robert Stanforth 
Sven Gowal  Jonathan Uesato  Grzegorz Swirszcz  and Pushmeet Kohli. Veriﬁcation of non-linear
speciﬁcations for neural networks. ICLR  2019.

Aditi Raghunathan  Jacob Steinhardt  and Percy Liang. Certiﬁed defenses against adversar-
International Conference on Learning Representations (ICLR)  arXiv preprint

ial examples.
arXiv:1801.09344  2018a.

Aditi Raghunathan  Jacob Steinhardt  and Percy S Liang. Semideﬁnite relaxations for certifying
robustness to adversarial examples. In Advances in Neural Information Processing Systems  pages
10900–10910  2018b.

Ralph Tyrell Rockafellar. Convex analysis. Princeton university press  2015.

Hadi Salman  Jerry Li  Ilya Razenshteyn  Pengchuan Zhang  Huan Zhang  Sebastien Bubeck  and
Greg Yang. Provably robust deep learning via adversarially trained smoothed classiﬁers. In
Advances in Neural Information Processing Systems  pages 11289–11300  2019.

Karsten Scheibler  Leonore Winterer  Ralf Wimmer  and Bernd Becker. Towards veriﬁcation of

artiﬁcial neural networks. In MBMV  pages 30–40  2015.

Gagandeep Singh  Timon Gehr  Matthew Mirman  Markus Püschel  and Martin Vechev. Fast and
effective robustness certiﬁcation. In Advances in Neural Information Processing Systems  pages
10825–10836  2018.

Gagandeep Singh  Timon Gehr  Markus Püschel  and Martin Vechev. An abstract domain for
certifying neural networks. Proceedings of the ACM on Programming Languages  3(POPL):41 
2019a.

Gagandeep Singh  Timon Gehr  Markus Püschel  and Martin Vechev. Robustness certiﬁcation with

reﬁnement. ICLR  2019b.

Vincent Tjeng  Kai Y. Xiao  and Russ Tedrake. Evaluating robustness of neural networks with mixed
integer programming. In International Conference on Learning Representations  2019. URL
https://openreview.net/forum?id=HyGIdiRqtm.

Shiqi Wang  Yizheng Chen  Ahmed Abdou  and Suman Jana. Mixtrain: Scalable training of formally

robust neural networks. arXiv preprint arXiv:1811.02625  2018a.

Shiqi Wang  Kexin Pei  Justin Whitehouse  Junfeng Yang  and Suman Jana. Efﬁcient formal safety
In Advances in Neural Information Processing Systems  pages

analysis of neural networks.
6369–6379  2018b.

Tsui-Wei Weng  Huan Zhang  Hongge Chen  Zhao Song  Cho-Jui Hsieh  Duane Boning  Inderjit S
Dhillon  and Luca Daniel. Towards fast computation of certiﬁed robustness for ReLU networks. In
International Conference on Machine Learning  2018.

Eric Wong and Zico Kolter. Provable defenses against adversarial examples via the convex outer
adversarial polytope. In International Conference on Machine Learning (ICML)  pages 5283–5292 
2018.

11

Eric Wong  Frank Schmidt  Jan Hendrik Metzen  and J Zico Kolter. Scaling provable adversarial

defenses. Advances in Neural Information Processing Systems (NIPS)  2018.

Kai Y. Xiao  Vincent Tjeng  Nur Muhammad (Mahi) Shaﬁullah  and Aleksander Madry. Training for
faster adversarial robustness veriﬁcation via inducing reLU stability. In International Conference
on Learning Representations  2019. URL https://openreview.net/forum?id=BJfIVjAcKm.

Huan Zhang  Tsui-Wei Weng  Pin-Yu Chen  Cho-Jui Hsieh  and Luca Daniel. Efﬁcient neural network
robustness certiﬁcation with general activation functions. In Advances in Neural Information
Processing Systems (NIPS)  dec 2018.

Huan Zhang  Pengchuan Zhang  and Cho-Jui Hsieh. Recurjac: An efﬁcient recursive algorithm for
bounding jacobian matrix of neural networks and its applications. AAAI Conference on Artiﬁcial
Intelligence  2019.

12

,Hadi Salman
Greg Yang
Huan Zhang
Cho-Jui Hsieh
Pengchuan Zhang