2018,Online Reciprocal Recommendation with Theoretical Performance Guarantees,A reciprocal recommendation problem is one where the goal of learning is not just to predict a user's preference towards a passive item (e.g.  a book)  but to recommend the targeted user on one side another user from the other side such that a mutual interest between the two exists. The problem thus is sharply different from the more traditional items-to-users recommendation  since a good match requires meeting the preferences of both users. We initiate a rigorous theoretical investigation of the reciprocal recommendation task in a specific framework of sequential learning. We point out general limitations  formulate reasonable assumptions enabling effective learning and  under these assumptions  we design and analyze a computationally efficient algorithm that uncovers mutual likes at a pace comparable to those achieved by a clairvoyant algorithm knowing all user preferences in advance. Finally  we validate our algorithm against synthetic and real-world datasets  showing improved empirical performance over simple baselines.,Online Reciprocal Recommendation with Theoretical

Performance Guarantees

Fabio Vitale

Department of Computer Science

Sapienza University of Rome (Italy) & University of Lille (France) & INRIA Lille Nord Europe

Rome  Italy & Lille  France
fabio.vitale@inria.fr

Nikos Parotsidis

University of Rome Tor Vergata  Rome  Italy

nikos.parotsidis@uniroma2.it

Claudio Gentile

INRIA Lille & Google New York
Lille  France & New York  USA

cla.gentile@gmail.com

Abstract

A reciprocal recommendation problem is one where the goal of learning is not
just to predict a user’s preference towards a passive item (e.g.  a book)  but to
recommend the targeted user on one side another user from the other side such that
a mutual interest between the two exists. The problem thus is sharply different from
the more traditional items-to-users recommendation  since a good match requires
meeting the preferences at both sides. We initiate a rigorous theoretical investiga-
tion of the reciprocal recommendation task in a speciﬁc framework of sequential
learning. We point out general limitations  formulate reasonable assumptions
enabling effective learning and  under these assumptions  we design and analyze
a computationally efﬁcient algorithm that uncovers mutual likes at a pace com-
parable to that achieved by a clairvoyant algorithm knowing all user preferences
in advance. Finally  we validate our algorithm against synthetic and real-world
datasets  showing improved empirical performance over simple baselines.

Introduction

1
Recommendation Systems are at the core of many successful online businesses  from e-commerce  to
online streaming  to computational advertising  and beyond. These systems have extensively been
investigated by both academic and industrial researchers by following the standard paradigm of
items-to-users preference prediction/recommendation. In this standard paradigm  a targeted user
is presented with a list of items that s/he may prefer according to a preference proﬁle that the
system has learned based on both explicit user features (item data  demographic data  explicitly
declared preferences  etc.) and past user activity. In more recent years  due to their hugely increasing
interest in the online dating and the job recommendation domains  a special kind of recommendation
systems called Reciprocal Recommendation Systems (RRS) have gained big momentum. The
reciprocal recommendation problem is sharply different from the more traditional items-to-users
recommendation  since recommendations must satisfy both parties  i.e.  both parties can express their
likes and dislikes and a good match requires meeting the preferences of both. Examples of RRS
include  for instance: online recruitment systems (e.g.  LinkedIn)  1 where a job seeker searches for
jobs matching his/her preferences  say salary and expectations  and a recruiter who seeks suitable
candidates to fulﬁl the job requirements; heterosexual online dating systems (e.g.  Tinder)  2 where
people have the common goal of ﬁnding a partner of the opposite gender; roommate matching systems

1 https://www.linkedin.com/.
2 https://tinder.com.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

(e.g.  Badi)  3 used to connect people looking for a room to those looking for a roommate  online
mentoring systems  customer-to-customer marketplaces  etc.
From a Machine Learning perspective  the main challenge in a RRS is thus to learn reciprocated
preferences  since the goal of the system is not just to predict a user’s preference towards a passive
item (a book  a movie  etc)  but to recommend the targeted user on one side another user from the
other side such that a mutual interest exists. Importantly enough  the interaction the two involved
users have with the system is often staged and unsynced. Consider  for instance  a scenario where a
user  Geena  is recommended to another user  Bob. The recommendation is successful only if both
Geena and Bob mutually agree that the recommendation is good. In the ﬁrst stage  Bob logs into the
system and Geena gets recommended to him; this is like in a standard recommendation system: Bob
will give a feedback (say  positive) to the system regarding Geena. Geena may never know that she
has been recommended to Bob. In a subsequent stage  some time in the future  also Geena logs in. In
an attempt to ﬁnd a match  the system now recommends Bob to Geena. It is only when also Geena
responds positively that the reciprocal recommendation becomes successful.
The problem of reciprocal recommendation has so far being studied mainly in the Data Mining 
Recommendation Systems  and Social Network Analysis literature (e.g.  [7  1  16  15  11  19  23  3 
17  12  13])  with some interesting adaptations of standard collaborative ﬁltering approaches to user
feature similarity  but it has remained largely unexplored from a theoretical standpoint. Despite each
application domain has its own speciﬁcity 4 in this paper we abstract such details away  and focus on
the broad problem of building matches between the two parties in the reciprocal recommendation
In particular  we do not consider explicit user
problem based on behavioral information only.
preferences (e.g.  those evinced by user proﬁles)  but only the implicit ones  i.e.  those derived from
past user behavior. The explicit-vs-implicit user features is a standard dichotomy in Recommendation
System practice  and it is by now common knowledge that collaborative effects (aka  implicit features)
carry far more information about actual user preferences than explicit features  like  for instance 
demographic metadata[18]. Similar experimental ﬁndings are also reported in the context of RRS in
the online dating domain [2].
In this paper  we initiate a rigorous theoretical investigation of the reciprocal recommendation
problem  and we view it as a sequential learning problem where learning proceeds in a sequence
of rounds. At each round  a user from one of the two parties becomes active and  based on past
feedback  the learning algorithm (called matchmaker) is compelled to recommend one user from the
other party. The broad goal of the algorithm is to uncover as many mutual interests (called matches)
as possible  and to do so as quickly as possible. We formalize our learning model in Section 2.
After observing that  in the absence of structural assumptions about matches  learning is virtually
precluded (Section 3)  we come to consider a reasonable clusterability assumption on the preference
of users at both sides. Under these assumptions  we design and analyze a computationally efﬁcient
matchmaking algorithm that leverages the correlation across matches. We show that the number of
uncovered matches within T rounds is comparable (up to constant factors) to those achieved by an
optimal algorithm that knows beforehand all user preferences  provided T and the total number of
matches to be uncovered is not too small (Sections 3  and 4). Finally  in Section 5 we present a suite
of initial experiments  where we contrast (a version of) our algorithm to noncluster-based random
baselines on both synthetic and publicly available real-world benchmarks in the domain of online
dating. Our experiments serve the twofold purpose of validating our structural assumptions on user
preferences against real data  and showing the improved matchmaking performance of our algorithm 
as compared to simple noncluster-based baselines.

2 Preliminaries
We ﬁrst introduce our basic notation. We have a set of users V partitioned into two parties. Though a
number of alternative metaphores could be adopted here  for concreteness  we call the two parties B
(for “boys") and G (for “girls"). Throughout this paper  g  g(cid:48) and g(cid:48)(cid:48) will be used to denote generic
members of G  and b  b(cid:48)  and b(cid:48)(cid:48) to denote generic members of B. For simplicity  we assume the two
parties B and G have the same size n. A hidden ground truth about the mutual preferences of the
members of the two parties is encoded by a sign function σ : (B × G) ∪ (G × B) → {−1  +1}.

3 https://badiapp.com/en.
4 For instance  users in an online dating system have relevant visual features  and the system needs speciﬁc
care in removing popular user bias  i.e.  ensuring that popular users are not recommended more often than
unpopular ones.

2

Speciﬁcally  for a pairing (b  g) ∈ B × G  the assignment σ(b  g) = +1 means that boy b likes girl g 
and σ(b  g) = −1 means that boy b dislikes girl g. Likewise  given pairing (g  b) ∈ G × B  we have
σ(g  b) = +1 when girl g likes boy b  and σ(g  b) = −1 when girl g dislikes boy b. The ground truth
σ therefore deﬁnes a directed bipartite signed graph collectively denoted as ((cid:104)B  G(cid:105)  E  σ)  where
E  the set of directed edges in this graph  is simply (B × G) ∪ (G × B)  i.e.  the sef of all possible
2n2 directed egdes in this bipartite graph. A “+1" edge will sometimes be called a positive edge 
while a “-1" edge will be called a negative edge. Any pair of directed edges (g  b) ∈ G × B and
(b  g) ∈ B × G involving the same two subjects g and b is called a reciprocal pair of edges. We also
say that (g  b) is reciprocal to (b  g)  and vice versa. The pairing of signed edges (g  b) and (b  g) is
called a match if and only if σ(b  g) = σ(g  b) = +1. The total number of matches will often be
denoted by M. See Figure 1 for a pictorial illustration.

Figure 1: (a) The (complete and directed) bipartite
graph ((cid:104)B  G(cid:105)  E  σ) with n = |B| = |G| = 4 
edges are only sketched. (b) Representation of the
σ function through its two pieces σ : B × G →
{−1  +1} (B × G matrix on the left)  and σ : G ×
B → {−1  +1} (G × B matrix on the right). For
instance  in this graph  Boy 1 likes Girl 1 and Girl 3 
and dislikes Girl 2 and Girl 4  while Girl 3 likes Boy 1  and dislikes Boys 2  3  and 4. Out of the n2 = 16
pairs of reciprocal edges  this graph admits only M = 4 matches  which are denoted by green circles on both
matrices. For instance  the pairing of edges (1  3) and (3  1) are a match since Boy 1 likes Girl 3 and  at the
same time  Girl 3 likes Boy 1. (c) The associated (undirected and bipartite) matching graph M. We have  for
instance  degM(Girl 1) = 3  and degM(Boy 2) = 1.
Coarsely speaking  the goal of a learning algorithm A is to uncover in a sequential fashion as many
matches as possible as quickly as possible. More precisely  we are given a time horizon T ≤ n2  e.g. 
T = n

n  and at each round t = 1  . . .   T :

√

boy" that logs into the system);

(1B) A receives the id of a boy b chosen uniformly at random5 from B (b is meant to be the “next
(2B) A selects a girl g(cid:48) ∈ G to recommend to b;
(3B) b provides feedback to the learner  in that the sign σ(b  g(cid:48)) of the selected boy-to-girl edge is

revealed to A.

Within the same round t  the three steps described above are subsequently executed after switching
the roles of G and B (and will therefore be called Steps (1G)  (2G)  and (3G)). Hence  each round
t is made up of two halves  the ﬁrst half where a boy at random is logged into the system and the
learner A is compelled to select a girl  and the second half where a girl at random is logged in and A
has to select a boy. Thus at each round t  A observes the sign of the two directed edges (b  g(cid:48)) and
(g  b(cid:48))  where b ∈ B and g ∈ G are generated uniformly at random by the environment  and g(cid:48) and
b(cid:48) are the outcome of A’s recommendation effort. Notice that we assume the ground truth encoded
by σ is persistent and noiseless  so that whereas the same user (boy or girl) may recur several times
throughout the rounds due to their random generation  there is no point for the learner to request the
sign of the same edge twice at two different rounds. The goal of algorithm A is to maximize the
number of uncovered matches within the T rounds. The sign of the two reciprocal edges giving rise
to a match need not be selected by A in the same round; the round where the match is uncovered
is the time when the reciprocating edge is selected  e.g.  if in round t1 we observe σ(b  g(cid:48)) = −1 
σ(g  b(cid:48)) = +1  and in round t2 > t1 we observe σ(b(cid:48)  g) = +1  σ(g(cid:48)(cid:48)  b(cid:48)(cid:48)) = +1  we say that the
match involving b(cid:48) and g has been uncovered only in round t2. In fact  if A has uncovered a positive
edge g → b(cid:48) in (the second half of) round t1  the reciprocating positive edge (b(cid:48)  g) need not be
uncovered any time soon  since A has at the very least to wait until b(cid:48) will log into the system  an
event which on average will occur only n rounds later.
We call matching graph  and denote it by M  the bipartite and undirected graph having B ∪ G as
nodes  where (b  g) ∈ B × G is an edge in M if and only if b and g determine a match in the original
graph ((cid:104)B  G(cid:105)  E  σ). Given b ∈ B  we let NM(b) ⊆ G be the set of matching girls for b according
to σ  and degM(b) be the number of such girls. NM(g) and degM(g) are deﬁned symmetrically.
See again Figure 1 for an example.
The performance of algorithm A is measured by the number of matches found by A within the T
rounds. Speciﬁcally  if Mt(A) is the number of matches uncovered by A after t rounds of a given run 
5 Though different distributional assumptions could be made  for technical simplicity in this paper we decided

to focus on the uniform distribution only.

3

43214321 G x B → {-1 +1} B1 2 3 4 1 2 3 4 1 -1 -1 +1 +1+1 -1 -1 -1+1 +1 +1 +1 -1 -1 +1 +1+1 -1 +1 -1+1 -1 -1 -1+1 +1 +1 +1+1 -1 -1 -1G B x G → {-1 +1} σσ43214321BG(c)(a)(b)2431243t=1. Likewise  Er

we would like to obtain lower bounds on MT (A) that hold with high probability over the random
generation of boys and girls that log into the system as well as the internal randomization of A. To
this effect  we shall repeatedly use in our statements the acronym w.h.p to signify with probability
at least 1 − O( 1
n )  as n → ∞. It will also be convenient to denote by Et(A) the set of directed
edges selected by A during the ﬁrst t rounds  with E0(A) = ∅. A given run of A may therefore be
summarized by the sequence {Et(A)}T
t (A) will denote the set of reciprocal (not
necessarily matching) directed edges selected by A up to time t. Finally  Er will denote the set of all
|B| · |G| = n2 pairs of reciprocal (not necessarily matching) edges between B and G.
We will ﬁrst show (Section 3) that in the absence of further assumptions on the way the matches
are located  there is not much one can do but try and simulate a random sampler. In order to further
illustrate our model  the same section introduces a reference optimal behavior that assumes prior
knowledge of the whole sign fuction σ. This will be taken as a yardstick to be contrasted to the
performance of our algorithm SMILE (Section 4) that works under more speciﬁc  yet reasonable 
structural assumptions on σ.
3 General limitations and optimal behavior
We now show6 that in the absence of speciﬁc assumptions on σ  the best thing to do in order to
uncover matches is to reciprocate at random  no matter how big the number M of matches actually is.
Theorem 1 Given B and G such that |B| = |G| = n  and any integer m ≤ n2
2   there exists a
randomized strategy for generating σ such that M = m  and the expected number of matches

uncovered by any algorithm A operating on ((cid:104)B  G(cid:105)  E  σ) satisﬁes7 EMT (A) = O(cid:0) T

n2 M(cid:1) .

An algorithm matching the above upper bound is described next. We call this algorithm OOMM (Obliv-
ious Online Match Maker)  The main idea is to develop a strategy that is able to draw uniformly
at random as many pairs of reciprocal edges as possible from Er (recall that Er is the set of all
reciprocal edges between B and G). In particular  within the T rounds  OOMM will draw uniformly
at random Θ(T )-many such pairs. The pseudocode of OOMM is given next. For brevity  throughout
this paper an algorithm will be described only through Steps (2B) and (2G) – recall Section 2.

Algorithm 1: OOMM (Oblivious Online Match Maker)
(cid:46) INPUT : B and G
At each round t: (2B) Select g(cid:48) uniformly at random from G ;

(2G) Bg t ← {b(cid:48)(cid:48) ∈ B :

(b(cid:48)(cid:48)  g) ∈ Et(OOMM)  (g  b(cid:48)(cid:48)) (cid:54)∈ Et−1(OOMM)};

If Bg t (cid:54)= ∅ then select b(cid:48) uniformly at random from Bg t
else select b(cid:48) uniformly at random from B .

OOMM simply operates as follows. In Step (2B) of round t  the algorithm chooses a girl g(cid:48) uniformly
at random from the whole set G. OOMM maintains over time the set Bg t ⊆ B of all boys that so
far gave their feedback (either positive or negative) on g  but for whom the feedback from g is not
available yet. In Step (2G)  if Bg t is not empty  OOMM chooses a boy uniformly at random from
Bg t  otherwise it selects a boy uniformly at random from the whole set B.8
Note that  the way it is designed  the selection of g(cid:48) and b(cid:48) does not depend on the signs σ(b  g) or

σ(g  b) collected so far. The following theorem guarantees that EMT (OOMM) = Θ(cid:0) T
that EMT (OOMM) = Θ(cid:0) T

is as if we were able to directly sample in most of the T rounds pairs of reciprocal edges.
Theorem 2 Given any input graph ((cid:104)B  G(cid:105)  E  σ)  with |B| = |G| = n  if T − n = Ω(n) then
T (OOMM) is selected uniformly at random (with replacement) from Er  its size |Er
T (OOMM)| is
Er
such that E|Er
T (OOMM)| = Θ(T )  and the expected number of matches disclosed by OOMM is such

n2 M(cid:1)  which

n2 M(cid:1) .

We now describe an optimal behavior (called Omniscient Matchmaker) that assumes prior knowledge
of the whole edge sign assignment σ. This optimal behavior will be taken as a reference performance
for our algorithm of Section 4. This will also help to better clarify our learning model.

6 All proofs are provided in the appendix.
7 Recall that an upper bound on MT (A) is a negative result here  since we are aimed at making MT (A) as

large as possible.

8 A boy could be selected more than once while serving a girl g during the T rounds. The optimality of
OOMM (see Theorems 1 and 2) implies that this redundancy does not signiﬁcantly affect OOMM’s performance.

4

n

n2 M(cid:1) (this is how Theorem 1 is proven). On

algorithm can achieve is always upper bounded by O(cid:0) T

Deﬁnition 1 The Omniscient Matchmaker A∗ is an optimal strategy based on the prior knowledge
of the signs σ(b  g) and σ(g  b) for all b ∈ B and g ∈ G. Speciﬁcally  based on this information  A∗
maximizes the number of matches uncovered during T rounds over all n2T possible selections that
can be made in Steps (2B) and (2G). We denote this optimal number of matches by M∗
T = MT (A∗).
Observe that when the matching graph M is such that degM(u) > T
n for some user u ∈ B ∪ G  no
algorithm will be able to uncover all M matches in expectation  since Steps (1B) and (1G) of our
learning protocol entail that the expected number of times each user u logs into the system is equal to
n . In fact  this holds even for the Omniscient Matchmaker A∗  despite the prior knowledge of σ. For
T
instance  when M turns out to be a random bipartite graph9 the expected number of matches that any
T = Θ(M ) as n grows large  it is sufﬁcient that degM(u) ≤ T
the other hand  in order to have M∗
holds for all users u ∈ B ∪ G  even with such a random M. In order to avoid the pitfalls of M being
a random bipartite graph (and hence the negative result of Theorem 1)  we need to slightly depart
from our general model of Section 2  and make structural assumptions on the way matches can be
generated. The next section formulates such assumptions  and analyzes an algorithm that under these
assumptions is essentially optimal i.t.o. number of uncovered matches. The assumptions and the
algorithm itself are then validated against simple baselines on real-world data in the domain of online
dating (Section 5).
4 A model based on clusterability of received feedback
In a nutshell  our model is based on the extent to which it is possible to arrange the users in
(possibly) overlapping clusters by means of the feedbacks they may potentially receive from the
other party. In order to formally describe our model  it will be convenient to introduce the Boolean
preference matrices B  G ∈ {0  1}n×n. These two matrices collect in their rows the ground truth
contained in σ  separating the two parties B and G. Speciﬁcally  Bi j = 1
2 (1 + σ(bi  gj))  and
2 (1 + σ(gi  bj)) (these are essentially the matrices exempliﬁed in Figure 1(b) where the “−1”
Gi j = 1
signs therein are replaced by “0”). Then  we consider the n column vectors of B (resp. G) – i.e.  the
whole set of feedbacks that each g ∈ G (resp. b ∈ B) may receive from members of B (resp. G)
and  for a given radius ρ ≥ 0  the associated covering number of this set of Boolean vectors w.r.t.
Hamming distance. We recall that the covering number at radius ρ is the smallest number of balls of
radius ≤ ρ that are needed to cover the entire set of n vectors. The smaller ρ the higher the covering
number. If the covering number stays small despite a small ρ  then our n vectors can be clustered
into a small number of clusters each one having a small (Hamming) radius.
As we mentioned in Section 3  a reasonable model for this problem is one for which our learning task
can be solved in a nontrival manner  thereby speciﬁcally avoiding the pitfalls of M being a random
bipartite graph. It is therefore worth exploring what pairs of radii and covering numbers may be
associated with the two preference matrices G and B when M is indeed random bipartite. Assume
M = o(n2)  so as to avoid pathological cases. When M is random bipartite  one can show that we

may have ρ = Ω(cid:0) M
regime is when ρ = o(cid:0) M

(cid:1) even when the two covering numbers are both 1. Hence  the only interesting
(cid:1). Within this regime  our broad modeling assumption is that the resulting

n

covering numbers for G and B are o(n)  i.e.  less that linear in n when n grows large.
Related work. The approach of clustering users according to their description/preference similar-
ities while exploiting user feedback is similar in spirit to the two-sided clusterability assumptions
investigated  e.g.  in [1]  which is based on a mixture of explicit and implicit (collaborative ﬁltering-
like) user features. Yet  as far as we are aware  ours is the ﬁrst model that lends itself to a rigorous
theoretical quantiﬁcation of matchmaking performance (see Section 4.1). Moreover  in general in our
case the user set is not partitioned as in previous RRS models. Each user may in fact belong to more
than one cluster  which is apparently more natural for this problem.
The reader might also wonder whether the reciprocal recommendation task and associated modeling
assumptions share any similarity to the problem of (online) matrix completion/prediction. Recovering
a matrix from a sample of its entries has been widely analyzed by a number of authors with different
approaches  viewpoints  and assumptions  e.g.  in Statistics and Optimization (e.g.  [5  14])  in Online
Learning (e.g.  [20  21  22  9  8  6  10])  and beyond. In fact  one may wonder if the problem of
predicting the entries of matrices B and G may somehow be equivalent to the problem of disclosing
9 The matching graph M is a random bipartite graph if any edge (b  g) ∈ B × G is generated independently

n

with the same probability p ∈ [0  1].

5

matches between B and G. A closer look reveals that the two tasks are somewhat related  but
not quite equivalent  since in reciprocal recommendation the task is to search for matching "ones"
between the two binary matrices B and G by observing entries of the two matrices separately. In
addition  because we get to see at each round the sign of two pairings (b  g(cid:48)) and (g  b(cid:48))  where b and
g are drawn at random and b(cid:48) and g(cid:48) are selected by the matchmaker  our learning protocol is rather
half-stochastic and half-active  which makes the way we gather information about matrix entries
quite different from what is usually assumed in the available literature on matrix completion.
4.1 An efﬁcient algorithm
Under the above modeling assumptions  our goal is to design an efﬁcient matchmaker. We speciﬁcally
focus on the ability of our algorithm to disclose Θ(M ) matches  in the regime where also the optimal
number of matches M∗
T is Θ(M ). Recall from Section 3 that the latter assumption is needed so
as to make the uncovering of Θ(M ) matches possible within the T rounds. Our algorithm  called
SMILE (Sampling Matching Information Leaving out Exceptions) is described as Algorithm 2. The
algorithm depends on input parameter S ∈ [log n  n/ log n] and  after randomly shufﬂing both B and
G  operates in three phases: Phase 0 (described at the end)  Phase I  and Phase II.
Algorithm 2: SMILE (Sampling Matching Information Leaving out Exceptions)
(cid:46) INPUT : B and G; parameter S > 0.
Randomly shufﬂe sets B and G ;
Phase 0: Run OOMM to provide an estimate ˆM of M;
Phase I: (C F) ← Cluster Estimation((cid:104)B  G(cid:105)  S);
Phase II: User Matching((cid:104)B  G(cid:105)  (C F));

√

Due to space limitations  the actual pseudocode of Cluster Estimation() and User Matching() is
presented in the appendix. What follows is an an informal  yet precise  description of their functioning.
Phase I: Cluster Estimation. SMILE approximates the clustering over users by: i. asking  for each
cluster representative b ∈ B  Θ(n) feedbacks (i.e.  edge signs) selected at random from G (and
operating symmetrically for each representative g ∈ G)  ii. asking Θ(S)-many feedbacks for each
remaining user  where parameter S will be set later. In doing so  SMILE will be in a position to
estimate the clusters each user belongs to  that is  to estimate the matching graph M  the misprediction
per user being w.h.p of the order of (n log n)/S. The estimated M will then be used in Phase II.
A more detailed description of the Cluster Estimation procedure follows. For convenience  we focus
on clustering G (hence observing feedbacks from B to G)  the procedure operates in a completely
symmetric way on B. Let Fg be the set of all b ∈ B who provided feedback on g ∈ G so far. Assume
for the moment we have at our disposal a subset Gr ⊆ G containing one representative for each
cluster over B  and that for each g ∈ Gr we have already observed n/2 feedbacks provided by n/2
distinct members of B  selected uniformly at random from B. Also  let B(g  S) be a subset of B
obtained by sampling at random S(cid:48) = 2S + 4
S log n-many b from B. Then a Chernoff-Hoeffding
bound argument shows that for any g ∈ G\ Gr and any gr ∈ Gr we have w.h.p. |B(g  S)∩ Fgr| ≥ S.
We use the above to estimate the cluster each g ∈ G \ Gr belongs to. This task can be accomplished
by ﬁnding gr ∈ Gr who receives the same set of feedbacks as that of g  i.e.  who belongs to the
same cluster as gr. Yet  in the absence of the feedback provided by all b ∈ B to both g and gr  it is
not possible to obtain this information with certainty. The algorithm simply estimates g’s cluster by
exploiting Step (1B) of the protocol to ask for feedback on g from S(cid:48) = S(cid:48)(S) randomly selected
b ∈ B  which will be seen as forming the subset B(g  S). We shall therefore assign g to the cluster
represented by an arbitrary gr ∈ Gr such that s(b  g) = s(b  gr) for all b ∈ B(g  S) ∩ Fgr. We
proceed this way for all g ∈ G \ Gr.
We now remove the assumption on Gr. Although we initially do not have Gr  we can build through
a concentration argument an approximate version of Gr while asking for the feedback B(g  S) on
each unclustered g. The Cluster Estimation procedure does so by processing girls g sequentially  as
described next. Recall that G was randomly shufﬂed into an ordered sequence G = {g1  g2  . . .   gn}.
The algorithm maintains an index i over G that only moves forward  and collects feedback information
for gi. At any given round  Gr contains all cluster representatives found so far. Given b ∈ B that
needs to be served during round t (Step (1B))  we include b in Fgi. If |Fgi| becomes as big as S(cid:48) 
then we look for g ∈ Gr so as to estimate gi’s cluster. If we succeed  index i is incremented and
the algorithm will collect feedback for gi during the next rounds. If we do not succeed  gi will be
included in Gr  and the algorithm will continue to collect feedback on gi until |Fgi| < n
2 . When

6

|Fgi| ≥ n
2   index i is incremented  so as to consider the next member of G. Phase I terminates when
we have estimated the cluster of each b and g that are themselves not representative of any cluster.
Finally  when we have concluded with one of the two sides  but not with the other (e.g.  we are done
with G but not with B)  we continue with the unterminated side  while for the terminated one we can
select members (g ∈ G in this case) in Step 2 (Step (2B) in this case) arbitrarily.
Phase II: User matching. In phase II  we exploit the feedback collected in Phase I so as to match as
many pairs (b  g) as possible. For each user u ∈ B ∪ G selected in Step (1B) or Step (1G)  we pick
in step (2G) or (2B) a user u(cid:48) from the other side such that u(cid:48) belongs to an estimated cluster which is
among the set of clusters whose members are liked by u  and viceversa. When no such u(cid:48) exists  we
select u(cid:48) from the other side arbitrarily.
Phase 0: Estimating M. In the appendix we show that the optimal tuning of S is to set it as a
function of the number of hidden matches M  i.e. S := (n2 log n)/M. Since M is unknown  we run
a preliminary phase where we run OOMM (from Section 3) for a few rounds. Using Theorem 2 it is
not hard to show that the number T ˆM of rounds taken by this preliminary phase to ﬁnd an estimate

ˆM of M which is w.h.p. accurate up to a constant factor satisﬁes T ˆM = Θ(cid:0)(n2 log n)/M(cid:1).

In order to quantify the performance of SMILE  it will be convenient to refer to the deﬁnition of the
Boolean preference matrices B  G ∈ {0  1}n×n. For a given radius ρ ≥ 0  we denote by C G
ρ the
covering number of the n column vectors of B w.r.t. Hamming distance. In a similar fashion we
deﬁne C B
ρ . Moreover  let C G and C B be the total number of cluster representatives for girls and
boys  respectively  found by SMILE  i.e.  C G = |Gr| and C B = |Br| at the end of the T rounds.
The following theorem shows that when the optimal number of matches M∗
T is M  then so is also
MT (SMILE) up to a constant factor  provided M and T are not too small.
Theorem 3 Given any input graph ((cid:104)B  G(cid:105)  E  σ)  with |B| = |G| = n  such that M∗
as n grows large  then we have

T = M w.h.p.

(cid:110)
(cid:110)

(cid:16)
(cid:16)

ρ/2 + 3ρS(cid:48)(cid:17)
ρ/2 + 3ρS(cid:48)(cid:17)

(cid:111)
(cid:111)

 

.

  n

C G ≤ ¯C G def
C B ≤ ¯C B def

= min

minρ≥0

C G

Furthermore  when T and M are such that T = ω(cid:0)n( ¯C G + ¯C B + S(cid:48))(cid:1) and M = ω(cid:0) n2 log n

minρ≥0

= min

C B

  n

(cid:1)   then

S

we have w.h.p. MT (SMILE) = Θ(M ) .

Notice in the above theorem the role played by the upper bounds ¯C G and ¯C B. If the minimizing
ρ therein gives ¯C G = ¯C B = n  we have enough degrees of freedom for M to be generated as a
random bipartite graph. On the other hand  when ¯C G and ¯C B are signiﬁcantly smaller than n at the
minimizing ρ (which is what we expect to happen in practice) the resulting M will have a cluster
structure that cannot be compatible with a random bipartite graph. This entails that on both sides
of the bipartite graph  each subject receives from the other side a set of preferences that can be
collectively clustered into a relatively small number of clusters with small intercluster distance. Then
the number of rounds T that SMILE takes to achieve (up to a constant factor) the same number of
matches M∗
T as the Omniscient Matchmaker drops signiﬁcantly. In particular  when S in SMILE has
the form (n2 log n)/ ˆM  where ˆM is the value returned by Phase 0  we have the following result.
Corollary 1 Given any input graph ((cid:104)B  G(cid:105)  E  σ)  with |B| = |G| = n  such that M∗

as n grows large  with T and M satisfying T = ω(cid:0)n ( ¯C G + ¯C B) + (n3 log n)/M(cid:1)   where ¯C G and

T = M w.h.p.

¯C B are the upper bounds on CG and CB given in Theorem 3  then we have w.h.p. MT (SMILE) =
Θ(M ) .

In order to evaluate in detail the performance of SMILE  it is very interesting to show to what extent
the conditions bounding from below T in Theorem 3 are necessary. We have the following general
limitation  holding for any matchmaker A.
Theorem 4 Given B and G such that |B| = |G| = n  any integer m ∈ (n log n  n2 − n log n)   and
any algorithm A operating on ((cid:104)B  G(cid:105)  E  σ)  there exists a randomized strategy for generating σ such
0 −1 < M ≤ m  and the number of rounds T needed to achieve EMT (A) = Θ(M ) 
that m −
satisﬁes T = Ω(n (C G
log n(cid:1). To see this  observe that by deﬁnition we have ¯C G ≤ C G
Remark 1 One can verify that the time bound for SMILE established in Corollary 1 is nearly optimal
0 and

whenever M = ω(cid:0)n3/2√

0 ) + M )   as n → ∞.

0 + C B

0 +CB

CG

n

7

¯C B ≤ C B

0 . Now  if M = ω(cid:0)n3/2√

log n(cid:1)  then the additive term (n3 log n)/M becomes o(M ) and
the condition on T in Corollary 1 simply becomes T = ω(cid:0)n (C G
0 + M(cid:48))(cid:1)  where M(cid:48) = o(M ).
log n(cid:1)  the additive term (n3 log n)/M
We now explain why it is possible that  when M = ω(cid:0)n3/2√
in the bound T = ω(cid:0)n ( ¯C G + ¯C B) + (n3 log n)/M(cid:1) of Corollary 1 becomes o(M )  while the

This has to be contrasted to the lower bound on T contained in Theorem 4.

0 + C B

0 + C B

0 + C B

T = M. Let T ∗ be the number of rounds T necessary to satisfy w.h.p. M∗

ﬁrst term n ( ¯C G + ¯C B) can be upper bounded by n (C G
0 ). Since the lower bound T =
0 ) + M ) of Theorem 4 has a linear dependence on M  it might seem surprising that
Ω(n (C G
the larger M is the smaller becomes the second term in the bound of Corollary 1. However  it is
important to take into account that T in Corollary 1 must be large enough to also satisfy the condition
M∗
T = M. In Corollary 1 

both the conditions T ≥ T ∗ and T = ω(cid:0)n ( ¯C G + ¯C B) + (n3 log n)/M(cid:1) must simultaneously hold.
As a further insight  consider the following. We either have M = O(cid:0)n( ¯C G + ¯C B)(cid:1) or
M = ω(cid:0)n( ¯C G + ¯C B)(cid:1).
T = Ω(cid:0)n (C G
0 + ¯C G + ¯C B)(cid:1)  hence not directly depending on M. In the second case 
whenever M = ω(cid:0)n3/2√
log n(cid:1)  T ∗ is larger than n ( ¯C G + ¯C B) + (n3 log n)/M since  by deﬁ-

When M is large  the number of rounds needed to satisfy the former condition becomes much larger
than the one needed for the latter.

In the ﬁrst case  the lower bound in Theorem 4 clearly becomes

nition  we must have T ∗ = Ω(M )  while in this case n ( ¯C G + ¯C B) + (n3 log n)/M = o(M ). In
conclusion  if the number of rounds SMILE takes to uncover Θ(M ) matches equals the number of
rounds taken by the omniscient Matchmaker to uncover exactly M matches  then SMILE is optimal up
to a constant factor  because no algorithm can outperform the omniscient Matchmaker. This provides
a crucially important insight into the key factors allowing the additive term (n3 log n)/M to be equal
to o(M ) in Corollary 1  and is indeed one of the keystones in the proof of Theorem 3.

0 + C B

We conclude this section by emphasizing the fact that SMILE is indeed quite scalable. As proven
in the appendix  an implementation of SMILE exists that leverages a combined use of suitable
data-structures  leading to both time and space efﬁciency.
Theorem 5 Let ¯C G and ¯C B be the upper bounds on CG and CB given in Theorem 3. Then

the running time of SMILE is O(cid:0)T + n S (cid:0) ¯C G + ¯C B(cid:1)(cid:1)  the memory requirement is O(n ( ¯C G +
¯C B)). Furthermore  when T = ω(cid:0)n ( ¯C G + ¯C B) + (n3 log n)/M(cid:1)  as required by Corollary 1  the

amortized time per round is Θ(1) + o( ¯C G + ¯C B)  which is always sublinear in n.

5 Experiments
In this section  we evaluate the performance of (a variant of) our algorithm by empirically contrasting
it to simple baselines against artiﬁcial and real-world datasets from the online dating domain. The
comparison on real-world data also serves as a validation of our modeling assumptions.

#clusters within bounded radius

properties

CB
20
95
500
2000

|B|
1007
1526
2265

CG
23
100
480
2000

|G|
1286
2564
3939

S-20-23
S-95-100
S-500-480
S-2000-2000

RW-1007-1286
RW-1526-2564
RW-2265-3939

2 · n/ log n
Synthetic datasets (2000 boys and 2000 girls)
CG
23
100
480
2000

#matches
374K
377K
380K
382K

#likes
2.45M
2.46M
2.47M
2.47M

CB
20
95
500
2000

Real-world datasets

#likes
125K
227K
370K

#matches
13.9K
19.6K
25.0K

CB
53
37
42

CG
48
45
45

n/ log n

CB
20
95
500
2000

CB
177
138
145

CG
23
100
480
2000

CG
216
216
215

0.5 · n/ log n

CB
445
603
983
2000

CB
385
339
306

CG
429
624
950
2000

CG
508
601
622

Table 1: Relevant properties of our datasets. The last six columns present an approximation to the number of
clusters when we allow radius 2 · n/ log n  n/ log n  and 0.5 · n/ log n between users of the same cluster.

Datasets. The relevant properties of our datasets are given in Table 1. Each of our synthetic datasets
has |B| = |G| = 2000. We randomly partitioned B and G into CB and CG clusters  respectively.
Each boy likes all the girls of a cluster C with probability 0.2  and with probability 0.8 dislikes them.

8

We do the same for the preferences from girls to boy clusters. Finally  for each preference (either
positive or negative) we reverse its sign with probability 1/(2· log n) (in our case  n = 2000). Notice
that in Table 1  for all four datasets we generated  the number of likes is bigger than |B|·|G|/2. As for
real-world datasets  we used the one from [4]  which is also publicly available. This is a dataset from
a Czech dating website  where 220 970 users rate each other in a scale from 1 (worst) to 10 (best).
The gender of the users is not always available. To get two disjoint parties B and G  where each user
rates only users from the other party  we disregarded all users whose gender is not speciﬁed. As this
dataset is very sparse  we extracted dense subsets as follows. We considered as ”like" any rating > 2 
while all ratings  including the missing ones  are ”dislikes". Next  we iteratively removed the users
with the smallest number of ratings until we met some desired density level. Speciﬁcally  we executed
the above process until we obtained two sets B and G such that the number of likes between the two
parties is at least 2(min{|B| |G|})3/2 (resulting in dataset RW-1007-1286)  1.75(min{|B| |G|})3/2
(dataset RW-1526-2564)  or 1.5(min{|B| |G|})3/2 (dataset RW-2265-3939).
Random baselines. We included as baselines OOMM   from Section 3  and a random method that
asks a user for his/her feedback on another user (of opposite gender) picked uniformly at random.
We refer to this algorithm as UROMM.
Implementation of SMILE.
In the implementation of SMILE  we slightly deviated from the de-
scription in Section 4.1. One important modiﬁcation is that we interleaved Phase I and Phase II.
The high-level idea is to start exploiting immediately the clusters once some clusters are identiﬁed 
without waiting to learn all of them. Additionally  we gave higher priority to exploring the reciprocal
feedback of a discovered like  and we avoided doing so in the case of a dislike. Finally  whenever we
test whether two users belong in the same cluster  we allowed a radius of a (1/ log n) fraction of the
tested entries. The parameter S(cid:48) in SMILE has been set to S +
S log n  with S = (n2 log n)/ ˆM 
where ˆM is the estimate from Phase 0. We call the resulting algorithm I-SMILE (Improved SMILE).
Evaluation. To get a complete picture on the behavior of the algorithms for different time
horizons  we present for each algorithm the number of discovered matches as a function of
T ∈ {1  . . .   2|B||G|}. Figure 2 contains three representative cases. In all datasets we tested 
I-SMILE clearly outperforms UROMM and OOMM. Our experiments conﬁrm that SMILE (and there-
fore I-SMILE) quickly learns the underlying structure of the likes between users  and uses this structure
to reveal the matches between them. Moreover  the variant I-SMILE that we implemented allows
one not only to perform well on graphs with no underlying structure in the likes  but also to discover
matches during the exploration phase while learning the clusters.

√

Figure 2: Empirical comparison
of the three algorithms on datasets
S-95-100 (left)  RW-1007-1286
(middle)  RW-2265-3939 (right).
Each plot gives number of dis-
closed matches vs. time.

6 Conclusions and Ongoing Research
We have initiated a theoretical investigation of the problem of reciprocal recommendation in an ad
hoc model of sequential learning. Under suitable clusterability assumptions  we have introduced
an efﬁcient matchmaker called SMILE   and have proven its ability to uncover matches at a speed
comparable to the omniscient Matchmaker  so long as M and T are not too small (Theorem 3 and
Corollary 1). Our theoretical ﬁndings also include a computational complexity analysis (Theorem
5)  as well as limitations on the number of disclosable matches in both the general (Theorem 1) and
the cluster case (Theorem 4). We complemented our results with an initial set of experiments on
synthetic and real-world datasets in the online dating domain  showing encouraging evidence.
Current ongoing research includes: i. Introducing suitable noise models for the sign function σ. ii.
Generalizing our learning model to nonbinary feedback preferences. iii. Investigating algorithms
whose goal is to maximize the area under the curve “number of matches-vs-time"  i.e.  the criterion
t∈[T ] Mt(A)   rather than the one we analyzed in this paper; maximizing this criterion requires
interleaving the phases where we collect matches (exploration) and the phases where we do actually
disclose them (exploitation). iv. More experimental comparisons on different datasets against heuristic
approaches available in the literature. v. Incorporating in the protocol different frequencies for the
user logins.

(cid:80)

9

0100000200000300000400000UROMMOOMMI-SMILE#matches found#recommendations0400080001200016000UROMMOOMMI-SMILE#matches found#recommendations0500010000150002000025000UROMMOOMMI-SMILE#matches found#recommendationsAcknowledgements
We would like to thank the anonymous reviewers for their valuable comments and suggestions that
helped improving the presentation of this paper. Special thanks to Flavio Chierichetti and Marc
Tommasi for helpful discussions in early stages of our investigation. Fabio Vitale acknowledges
support from the ERC Starting Grant “DMAP 680153”  the Google Focused Award “ALL4AI”  and
grant “Dipartimenti di Eccellenza 2018-2022”  awarded to the Department of Computer Science of
Sapienza University.

References
[1] Joshua Akehurst  Irena Koprinska  Kalina Yacef  Luiz Augusto Pizzato  Judy Kay  and Tomasz
Rej. CCR - A content-collaborative reciprocal recommender for online dating. In IJCAI Int. Jt.
Conf. Artif. Intell.  pages 2199–2204  2011.

[2] Joshua Akehurst  Irena Koprinska  Kalina Yacef  Luiz Augusto Pizzato  Judy Kay  and Tomasz
Rej. Explicit and Implicit User Preferences in Online Dating. New Front. Appl. Data Min. 
pages 15–27  2012.

[3] Ammar Alanazi and Michael Bain. A Scalable People-to-People Hybrid Reciprocal Recom-
mender Using Hidden Markov Models. In 2nd Int. Work. Mach. Learn. Methods Recomm. Syst. 
2016.

[4] Lukas Brozovsky and Vaclav Petricek. Recommender system for online dating service. In

Proceedings of Znalosti 2007 Conference  Ostrava  2007. VSB.

[5] J. Emmanuel Candes and Terence Tao. The power of convex relaxation: Near-optimal matrix

completion. IEEE Transactions on Information Theory  56(5):2053–2080  2010.

[6] Paul Christiano. Online local learning via semideﬁnite programming. In Proceedings of the
Forty-sixth Annual ACM Symposium on Theory of Computing  STOC ’14  pages 468–474  2014.

[7] F. Diaz  D. Metzler  and S. Amer-Yahia. Relevance and ranking in online dating systems. In
33rd ACM conf. on Research and development in information retrieval  SIGIR’10  pages 66–73 
2010.

[8] C. Gentile  M. Herbster  and S. Pasteris. Online similarity prediction of networked data from
known and unknown graphs. In Proceedings of the 23rd Conference on Learning Theory (26th
COLT)  2013.

[9] E. Hazan  S. Kale  and S. Shalev-Shwartz. Near-optimal algorithms for online matrix prediction.

In Proceedings of the 25th Annual Conference on Learning Theory (COLT’12)  2012.

[10] M. Herbster  S. Pasteris  and M. Pontil. Mistake bounds for binary matrix completion. In NIPS

29  pages 3954–3962  2016.

[11] Wenxing Hong  Siting Zheng  Huan Wang  and Jianchao Shi. A job recommender system based

on user clustering. Journal of Computers  8(8):1960–1967  2013.

[12] A. Kleinerman  A. Rosenfeld  F. Ricci  and S. Kraus. Optimally balancing receiver and
recommended users’ importance in reciprocal recommender systems. In Proceedings of the
12th ACM Conference on Recommender Systems  2018.

[13] A. Kleinerman  A. Rosenfeld  and S. Kraus. Providing explanations for recommendations
in reciprocal environments. In Proceedings of the 12th ACM Conference on Recommender
Systems  2018.

[14] V. Koltchinskii  K. Lounici  and A. Tsybakov. Nuclear norm penalization and optimal rates for

noisy matrix completion. In arXiv:1011.6256v4  2016.

[15] J. Kunegis  G. Gröner  and T. Gottron. Online dating recommender systems: The split-complex
number approach. In 4th ACM RecSys workshop on Recommender systems and the social web 
2012.

10

[16] Lei Li and Tao Li. MEET: A Generalized Framework for Reciprocal Recommender Systems.

In Proc. 21st ACM Int. Conf. Inf. Knowl. Manag. (CIKM ’12)  pages 35–44  2012.

[17] Saket Maheshwary and Hemant Misra. Matching resumes to jobs via deep siamese network. In

Companion Proceedings of the The Web Conference 2018  WWW ’18  pages 87–88  2018.

[18] Istvan Pilaszy and Domonkos Tikk. Movies: Even a few ratings are more valuable than metadata.

In In Proceedings of the 3rd ACM Conference on Recommender Systems (RecSys)  2009.

[19] Luiz Augusto Pizzato  Tomasz Rej  Joshua Akehurst  Irena Koprinska  Kalina Yacef  and Judy
Kay. Recommending people to people: the nature of reciprocal recommenders with a case study
in online dating. User Model. User-adapt. Interact.  23(5):447–488  2013.

[20] S. Shalev-Shwartz  Y. Singer  and A. Ng. Online and batch learning of pseudo-metrics. In
Proceedings of the twenty-ﬁrst international conference on Machine learning  ICML 2004.
ACM  2004.

[21] K. Tsuda  G. Rätsch  and M. K. Warmuth. Matrix exponentiated gradient updates for on-line
learning and bregman projections. Journal of Machine Learning Research  6:995–1018  2005.

[22] M. K. Warmuth. Winnowing subspaces. In Proceedings of the 24th International Conference

on Machine Learning  pages 999–1006  2007.

[23] Peng Xia  Benyuan Liu  Yizhou Sun  and Cindy Chen. Reciprocal Recommendation System
for Online Dating. In Proc. 2015 IEEE/ACM Int. Conf. Adv. Soc. Networks Anal. Min. 2015 -
ASONAM ’15  pages 234–241. ACM Press  2015.

11

,Fabio Vitale
Nikos Parotsidis
Claudio Gentile
Andrei Barbu
David Mayo
Julian Alverio
William Luo
Christopher Wang
Dan Gutfreund
Josh Tenenbaum
Boris Katz