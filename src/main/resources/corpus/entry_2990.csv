2011,Learning Probabilistic Non-Linear Latent Variable Models for Tracking Complex Activities,A common approach for handling the complexity and inherent ambiguities of 3D human pose estimation is to use pose priors learned from  training data. Existing approaches however  are either too simplistic (linear)  too complex to learn  or  can only learn latent spaces from "simple data"  i.e.  single activities such as walking or running. In this paper  we present an efficient stochastic gradient descent algorithm that is able to learn probabilistic non-linear latent  spaces composed of multiple  activities. Furthermore  we derive an incremental algorithm for the online setting which can update the latent space without extensive relearning. We demonstrate the  effectiveness of our approach on the  task of monocular and multi-view tracking and show that our approach  outperforms the state-of-the-art.,Learning Probabilistic Non-Linear Latent Variable

Models for Tracking Complex Activities

Angela Yao∗
Raquel Urtasun
ETH Zurich
TTI Chicago
{yaoa  gall  vangool}@vision.ee.ethz.ch  rurtasun@ttic.edu

Luc Van Gool
ETH Zurich

Juergen Gall
ETH Zurich

Abstract

A common approach for handling the complexity and inherent ambiguities of 3D
human pose estimation is to use pose priors learned from training data. Exist-
ing approaches however  are either too simplistic (linear)  too complex to learn 
or can only learn latent spaces from “simple data”  i.e.  single activities such as
walking or running. In this paper  we present an efﬁcient stochastic gradient de-
scent algorithm that is able to learn probabilistic non-linear latent spaces com-
posed of multiple activities. Furthermore  we derive an incremental algorithm for
the online setting which can update the latent space without extensive relearning.
We demonstrate the effectiveness of our approach on the task of monocular and
multi-view tracking and show that our approach outperforms the state-of-the-art.

1

Introduction

Tracking human 3D articulated motions from video sequences is well known to be a challenging
machine vision problem. Estimating the human body’s 3D location and orientation of the joints
is notoriously difﬁcult because it is a high-dimensional problem and is riddled with ambiguities
coming from noise  monocular imagery and occlusions. To reduce the complexity of the task  it has
become very popular to use prior models of human pose and dynamics [20  25  27  28  8  13  22].
Linear models (e.g. PCA) are among the simplest priors [20  15  26]  though linearity also restricts a
model’s expressiveness and results in inaccuracies when learning complex motions. Priors generated
from non-linear dimensionality reduction techniques such as Isomap [23] and LLE [18] have also
been used for tracking [5  8]. These techniques try to preserve the local structure of the manifold
but tend to fail when manifold assumptions are violated  e.g.  in the presence of noise  or multiple
activities. Moreover  LLE and Isomap provide neither a probability distribution over the space of
possible poses nor a mapping from the latent space to the high dimensional space. While such a
distribution and or mapping can be learned post hoc  learning them separately from the latent space
typically results in suboptimal solutions.
Probabilistic latent variable models (e.g. probabilistic PCA)  have the advantage of taking uncer-
tainties into account when learning latent representations. Taylor et al. [22] introduced the use of
Conditional Restricted Boltzmann Machines (CRBM) and implicit mixtures of CRBM (imCRBM) 
which are composed of large collections of discrete latent variables. Unfortunately  learning this
type of model is a highly complex task. A more commonly used latent variable model is the Gaus-
sian Process Latent Variable Model (GPLVM) [9] which has been applied to animation [27] and
tracking [26  25  6  7]. While the GPLVM is very successful at modeling small training sets with
single activities  it often struggles to learn latent spaces from larger datasets  especially those with
multiple activities. The main reason is that the GPLVM is a non-parametric model; learning requires
∗This research was supported by the Swiss National Foundation NCCR project IM2  NSERC Canada and

NSF #1017626. Source code is available at www.vision.ee.ethz.ch/yaoa

1

Figure 1: Representative poses  data (Euclidean) distance matrices and learned latent spaces
from walking  jumping  exercise stretching and basketball signal sequences. GPLVM was initialized
using probabilistic PCA; while stochastic GPLVM was initialized randomly.

the optimization of a non-convex function  for which complexity grows with the number of training
samples. As such  having a good initialization is key for success [9]  though good initializations
are not always available [6]  especially with complex data. Additionally  GPLVM learning scales
cubicly with the number of training examples  and application to large datasets is computationally
intractable  making it necessary to use sparsiﬁcation techniques to approximate learning [17  10].
As a consequence  the GPLVM has been mainly applied to single activities  e.g.  walking or running.
More recent works have focused on handling multiple activities  most often with mixture mod-
els [14  12  13] or switching models [16  8  2]. However  coordinating the different components
of the mixture models requires special care to ensure that they are aligned in the latent space [19] 
thereby complicating the learning process. In addition  both mixture and switching models require a
discrete notion of activity which is not always available  e.g. dancing motions are not a discrete set.
Others have tried to couple discriminate action classiﬁers with action-speciﬁc models [1  5]  though
accuracy of such systems does not scale well with the number of actions.
A good prior model for tracking should be accurate  expressive enough to capture a wide range
of human poses  and easy and tractable for both learning and inference. Unfortunately  none of the
aforementioned approaches exhibit all of these properties. In this paper  we are interested in learning
a probabilistic model that fulﬁll all of these criteria. Towards this end  we propose a stochastic gra-
dient descent algorithm for the GPLVM which can learn latent spaces from random initializations.
We draw inspiration for our work from two main sources. The ﬁrst  [24]  approximates Gaussian
process regression for large training sets by doing online predictions based on local neighborhoods.
The second  [11]  maximizes the likelihood function for GPLVM by considering one dimension of
the gradient at a time in the context of collaborative ﬁltering. Based on these two works  we propose
a similar strategy to approximate the gradient computation within each step of the stochastic gra-
dient descent algorithm. Local estimation of the gradients allows our approach to efﬁciently learn
models from large and complex training sets while mitigating the problem of local minima. Further-
more  we propose an online algorithm that can effectively learn latent spaces incrementally without
extensive relearning. We demonstrate the effectiveness of our approach on the task of monocular
and multi-view tracking and show that our approach outperforms the state-of-the-art on the standard
benchmark HumanEva [21].

2

PCAGPLVMstochastic GPLVMDistance MatrixWalkingJumpingExerciseStretchingBasketballSignals2 Stochastic learning

We ﬁrst review the GPLVM  the basis of our work  and then introduce our optimization method for
learning with stochastic local updates. Finally  we derive an extension of the algorithm which can
be applied to the online setting.

2.1 GPLVM Review

The GPLVM assumes that the observed data has been generated by some unobserved latent random
variables. More formally  let Y = [y1 ···   yN ]T be the set of observations yi ∈ (cid:60)D  and X =
[x1 ···   xN ]T be the set of latent variables xi ∈ (cid:60)Q  with Q (cid:28) D. The GPLVM relates the latent
variables and the observations via the probabilistic mapping y(d) = f (x) + η  with η being i.i.d.
Gaussian noise  and y(d) the d-th coordinate of the observations. In particular  the GPLVM places a
Gaussian process prior over the mapping f such that marginalization of the mapping can be done in
closed form. The resulting conditional distribution becomes
− 1
2

tr(cid:0)K−1YYT(cid:1)(cid:19)

p (Y|X  β) =

exp

(1)

1

 

(cid:112)(2π)N·D|K|D
(cid:16)−(cid:107)x−x(cid:48)(cid:107)2

(cid:18)
(cid:17)

where K is the kernel matrix with elements Kij = k(xi  xj) and the kernel k has parameters β.
Here  we follow existing approaches [26  25] and use a a kernel compounded from an RBF  a bias 
and Gaussian noise  i.e.  k (x  x(cid:48)) = β1 exp
The GPLVM is usually learned by maximum likelihood estimation of the latent coordinates X and
the kernel hyperparameters β = {β1 ···   β4}. This is equivalent to minimizing the negative log
likelihood L:

+ β3 + δx x(cid:48)

β4

β2

.

tr(cid:0)K−1YYT(cid:1) .

(2)

L = − ln p (Y|X  β) = − DN
2

ln 2π − D
2

ln|K| − 1
2

Typically a gradient descent algorithm is used for the minimization. The gradient of L with respect
to X can be obtained via the chain rule  where

∂L
∂X

=

∂L
∂K

· ∂K
∂X

= −(cid:0)K−1YYT K−1 − DK−1(cid:1) · ∂K

.

(3)

∂X

Similarly  the gradient of L with respect to β can be found by substituting ∂K
∂β in Eq. (3)
(see [9] for the exact derivation). As N gets large  however  computing the gradients becomes com-
putationally expensive  because inverting K is of O(N 3)  with N the number of training examples.
More importantly  as the negative log likelihood L is highly non-convex  especially with respect to
X  standard gradient descent approaches tend to get stuck in local minima  and rely on having good
initializations for success.
We now demonstrate how a stochastic gradient descent approach can be used to reduce computa-
tional complexity as well as decrease the chances of getting trapped in local minima. In particular 
as shown in our experiments (Section 3)  we are able to obtain smooth and accurate manifolds (see
Fig. 1) from random initialization.

∂X with ∂K

2.2 Stochastic Gradient Descent

In standard gradient descent  all points are taken into account at the same time when computing
the gradient; stochastic gradient descent approaches  on the other hand  approximate the gradient at
each point individually. Typically  a loop goes over the points in a series or by randomly sampling
from the training set. Note that after iterating over all the points  the gradient is exact. As the
GPLVM is a non-parametric approach  the gradient computation at each point does not decompose 
making it necessary to invert K  an O(N 3) operation at every iteration. We propose  however  to
approximate the gradient computation within each step of the stochastic gradient descent algorithm.
Therefore  the gradient of L can be estimated locally for some neighborhood of points XR  centered
at a reference point xr  rather than over all of X. Eq. (3) can then be evaluated only for the points
within the neighborhood  i.e. 

3

Algorithm 1: Stochastic GPLVM
Randomly initialize X
Set β with an initial guess
for t = 1:T

randomly select xr
ﬁnd R neighbors around xr: XR = X ∈ R
Compute ∂L
∂XR
Update X and β:

and ∂L
∂βR

(see Eq. (3))

∆Xt = µX · ∆Xt−1 + ηX · ∂L
Xt ← Xt−1 + ∆Xt
∆βt = µβ · ∆βt−1 + ηβ · ∂L
∂βR
βt ← βt−1 + ∆βt

∂XR

end

Algorithm 2: Incremental stochastic GPLVM
for t = 1 : T1

Learn Xorig and βorig as per Algorithm 1.

end
Initialize Xincr using nearest neighbors.
Set β = βorig
Group data:

for t = T1 + 1 : T2

Y = [Yorig  Yincr]
X = [Xorig  Xincr]
randomly select xr ∈ Xincr
ﬁnd R neighbors around xr: XR = X ∈ R
Compute ∂Lincr
(see Eq. (6))
∂XR
Update X and β:

and ∂Lincr
∂βR

∆Xt = µX · ∆Xt−1 + ηX · ∂Lincr
Xt ← Xt−1 + ∆Xt
∆βt = µβ · ∆βt−1 + ηβ · ∂Lincr
∂βR
βt ← βt−1 + ∆βt

∂XR

end

Figure 2: Stochastic gradient descent and incremental learning for the GPLVM; µ(·) is a mo-
mentum parameter and η(·) is the learning rate. Note that R  µ  and η can also vary with t.

≈ −(cid:0)K−1

R YRYT

RK−1

R − DK−1

R

(cid:1) · ∂KR

∂XR

 

(4)

∂L
∂XR

where KR is the kernel matrix for XR and YR is the corresponding neighborhood data points.
We employ a random strategy for choosing the reference point xr. The neighborhood R can be
determined by any type of distance measure  such as Euclidean distance in the latent space and/or
data space  or temporal neighbors when working with time series. More critical than the speciﬁc
type of distance measure  however  is allowing sufﬁcient coverage of the latent space so that each
neighborhood is not restricted too locally. To keep the complexity low  it is beneﬁcial to sample
randomly from a larger set of neighbors (see supplementary material).
The use of stochastic gradient descent has several desirable traits that correct for the aforementioned
drawbacks of GPLVMs. First  computational complexity is greatly reduced  making it feasible to
learn latent spaces with much larger amounts of data. Secondly  estimating the gradients stochasti-
cally and locally improves robustness of the learning process against local minima  making it possi-
ble to have a random initialization. An algorithmic summary of stochastic gradient descent learning
for GPLVMs is given in Fig. 2.

2.3

Incremental Learning

In this section  we derive an incremental learning algorithm based on the stochastic gradient descent
approach of the previous section. In this setting  we have an initial model which we would like
to update as new data comes in on the ﬂy. More formally  let Yorig be the initial training data 
and Xorig and βorig be a model learned from Yorig using stochastic GPLVM. For every step in
the online learning  let Yincr be new data  which can be as little as a single point or an entire set
of training points. Let Y = [Yorig  Yincr] ∈ R(N +M )×D be the set of training points containing
both the already trained data Yorig  and the new incoming data Yincr  and let X=[Xorig  Xincr] ∈
R(N +M )×Q be the corresponding latent coordinates  where M is the number of newly added training
examples. Let ˆXorig be the estimate of the latent coordinates that has already been learned.
A possible strategy is to update only the incoming points; however  we would like to exploit the
new data for improving the estimate of the entire manifold  therefore we propose to learn the full
X. To prevent the already-learned manifold from diverging and also to speed up learning  we add a
regularizer to the log-likelihood to encourage original points to not deviate too far from their initial
estimate. To this end  we use the Frobenius norm of the deviation from the estimate ˆXorig. Learning

4

Figure 3: Within- and cross-subject 3D tracking errors for each type of activity sequence with
respect to amount of additive noise for different number of particles  where error bars represent the
standard deviation from repetitions runs.

is then done by minimizing the regularized negative log-likelihood
||X1:N : − ˆXorig||2
F .

Lincr = L + λ · 1
N

(5)

Here  X1:N : indicates the ﬁrst N rows of X  while λ is a weighting on the regularization term. The
gradient of L with respect to XR

.

(6)

1 can then be computed as
∂L
∂XR

·(cid:0)X1:N : − ˆXorig

+ λ · 2
N

(cid:1) ∂X1:N :

∂XR

∂Lincr
∂XR

=

We employ a stochastic gradient descent approach for our incremental learning  where the points are
sampled randomly from Xincr. Note that while xr is only sampled from Xincr in the subsequent
learning step  this does not exclude points in Xorig from being a part of the neighbourhood R 
and thus from being updated. We have chosen a nearest neighbor approach by comparing Yincr to
Yorig for estimating an initial Xincr  though other possibilities include performing a grid search in
the latent space and selecting locations with the highest global log-likelihood (Eq. (2)) or training a
regressor from Yorig to Xorig to be applied to Yincr. An algorithmic summary of the incremental
method is provided in Fig. 2.

2.4 Tracking Framework
During training  a latent variable model M is learned from YM   where YM are relative joint loca-
tions with respect to a root node. We designate the learned latent points as XM . During inference 
tracking is performed in the latent space using a particle ﬁlter. The corresponding pose is computed
by projecting back to the data space via the Gaussian process mapping learned in the GPLVM.

1 ∂Lincr
∂βR

= ∂L
∂βR

since the regularization term does not depend on βR.

5

WalkingError (mm)JumpingError (mm)Exercise StretchingError (mm)Basketball SignalError (mm)PCAGPLVMstochastic GPLVM120160200240751001251501530456060801001200.1%0%25 particles0.05% 0%0.05%0.1%150 particlesWithin-Subject150 particles 0%0.05%0.1%25 particles 0%0.05%0.1%22024026028016017519020545607590115130145160Cross-Subject(a) manifolds

(b) 3D tracking error

Figure 4: (a) Learned manifolds from regular GPLVM  stochastic GPLVM and incremental
stochastic GPLVM from an exercise stretching sequence  where blue  red  green indicate jumping
jacks  jogging and squats respectively and (b) the associated 3D tracking errors (mm)  where error
bars indicate standard deviation over repeated runs.

We model the state s at time t as st = (xt  gt  rt) where xt denotes position in the latent space 
while gt and rt are the global position and rotation of the root node. Particles are initialized in the
latent space by a nearest neighbor search between the observed 2D image pose in the ﬁrst frame of
the sequence and the projected 2D poses of YM . Particles are then propagated from frame to frame
using a ﬁrst-order Markov model

xi
t = xi

t−1 + ˙xi
t 

gi
t = gi

t−1 + ˙gi
t 

ri
t = ri

t−1 + ˙ri
t.

(7)

We approximate the derivative ˙xi with the difference between temporally sequential points of the
nearest neighbors in XM   while ˙gi and ˙ri are drawn from individual Gaussians with means and
standard deviations estimated from the training data. The tracked latent position ˆxt at time t is then
approximated as the mode over all particles in the latent space while ˆyt is estimated via the mean
Gaussian process estimate

(8)
with µM the mean of YM and k(ˆxt  XM ) the vector with elements k(ˆxt  xm) for all xm in XM .
Note that the computation of K−1 needs to be performed only once and can be stored.

ˆyt = µM + YT

M K−1k(ˆxt  XM ) 

3 Experimental Evaluation

We demonstrate the effectiveness of our model when applied to tracking in both monocular and
multi-view scenarios.
In all cases  the latent models were learned with µX = 0.8  µβ = 0.5 
ηX=10e-4  ηβ =10e-8; we annealed these parameters over the iterations. To further smooth the
learned models  we incorporate a Gaussian Process prior over the dynamics of the training data
in the latent space [27] for the GPLVM and the stochastic GPLVM. We refer the reader to the
supplementary material for a visualization of the learning process as well as the results.

3.1 Monocular Tracking

We compare in the monocular setting the use of PCA  regular GPLVM and our stochastic GPLVM
to learn latent spaces from motion capture sequences (from the CMU Motion Capture Database [3]).
We chose simple single-activity sequences  such as walking (3 subjects  18 sequences) and jumping
(2 subjects  8 sequences)  as well as complex multi-activity sequences  such as stretching exercises
(2 subjects  6 sequences) and basketball refereeing signals (7 subjects  13 sequences). The stretch-
ing exercise and basketball signal sequences were cut to each contain four types of activities. We
synthesized 2D data by projecting the mocap from 3D to 2D and then corrupting the location of each
joint with different levels of additive Gaussian noise. We then recover the 3D locations of each joint
from the noisy images by tracking with the particle ﬁlter described in the previous section.
Examples of learned latent spaces for each type of sequence (i.e.  walking  jumping  exercise  bas-
ketball) are shown in Fig. 1. We used a neighborhood of 60 points for the single activity sequences 
which have on average 250 training examples  and 100 points for the multiple activity sequences 

6

GPLVMstochastic GPLVMincrementalstochastic GPLVM0%0.05%0.1%50100150200250  GPLVMstochastic GPLVMincremental stochastic GPLVMFigure 5: Example poses from tracked results on HumanEva.

which have on average 800 training examples. For a sequence of 800 training examples  the stochas-
tic GPLVM takes only 27s to learn (neighborhood of 100 points  2500 iterations); in comparison 
the regular GPLVM takes 2560s for 312 iterations  while with FITC approximations [10] takes on
average 1700s (100 active points  2500 iterations)2. In general  as illustrated by Fig. 1  the mani-
folds learned with stochastic GPLVM have smoother trajectories than those learned from PCA and
GPLVM  with better separation between the activities in the multi-activity sequences.
We evaluate the effectiveness of the learned latent pose models for tracking by comparing the av-
erage tracking error per joint per frame between PCA  GPLVM and stochastic GPLVM in two sets
of experiments. In the ﬁrst  training and test sequences are performed by the same subject; in the
second  to test generalization properties of the different latent spaces  we train and test on different
subjects. We report results average over 10 sequences  each repeated over 10 different runs of the
tracker. We use importance sampling and weight each particle at time t proportionally to a likelihood
deﬁned by the reprojection error: wi
j t is the projected 2D
t (see Eq. (8)) and qj t is the observed 2D position of joint j  assuming
position of joint j in yi
that the camera projection and correspondences between joints are already known. α is a parameter
determining selectivity of the weight function (we use α = 5 · 10−5).
Fig. 3 depicts 3D tracking error as a function of the amount of Gaussian noise for different number of
particles employed in the particle ﬁlter for the within- and cross-subject experiments. As expected 
tracking error is lower within-subject than cross-subject for all types of latent models. For the simple
activities such as walking and jumping  GPLVM generally outperforms PCA  but for the complex
activities  it performs only comparably or worse than PCA (with the exception of cross-subject
basketball signals). Our stochastic GPLVM  on the other hand  consistently outperforms PCA and
matches or outperforms the regular GPLVM in all experimental conditions  with signiﬁcantly better
performance in the complex  multi-activity sequences. Additional experiments are provided in the
supplementary material.

j t − qj t(cid:107)2(cid:17)

t ∝ exp

t from xi

(cid:16)−α(cid:80)

j (cid:107)pi

  where pi

3.2 Online Tracking

We took two stretching exercise sequences with three different activities from the same subject and
apply the online learning algorithm (see Sec. 2.3)  setting λ = 2. We consider each activity as a new
batch of data  and learn the latent space on the ﬁrst sequence and then track on the second and vice
versa. We ﬁnd the online algorithm less accurate for tracking than the stochastic GPLVM learned
with all data. This is expected since the latent space is biased towards the initial set of activities.
We note  however  that the incremental stochastic GPLVM still outperforms the regular GPLVM  as
illustrated in Fig. 4(b). Examples of the learned manifolds are shown in Fig. 4(a).

3.3 Multi-view Tracking on HumanEva

We also evaluate our learning algorithm on the HumanEva benchmark [21] on the activities walking
and boxing. For all experiments  we use a particle ﬁlter as described in Sec. 2.4 with 25 particles as
well as an additional annealing component [4] of 15 layers. To maintain consistency with previous

2Note that none of the models have completed training. For timing purposes  we take here a ﬁxed number of
iterations for the stochastic method and the FITC approximation and the “equivalent” for the regular GPLVM 
i.e.  2500 iterations /8  where 8 comes from the fact that 8X more points are used in computing K.

7

C1  Frame 27C1  Frame 72C3   Frame 27C3  Frame 72S1  BoxingC1  Frame 30C1  Frame 60C3   Frame 30C3  Frame 60S3  WalkingTrain
S1

S1 2 3

S1 2 3

S2

S3

S1 2 3

Test
S1
S1
S2
S2
S3
S3

[28]
-

140.3

-

-

149.4

156.3

[13]
-
-

68.7 ± 24.7
69.6 ± 22.2

-

-

GPLVM
57.6 ± 11.6
64.3 ± 19.2
98.2 ± 15.8
155.9 ± 48.8
71.6 ± 10.0
123.8. ± 16.7

CRBM [22]
48.8 ± 3.7
55.4 ± 0.8
47.4 ± 2.9
99.1 ± 23.0
49.8 ± 2.2
70.9 ± 2.1

imCRBM [22]
58.6 ± 3.9
54.3 ± 0.5
67.0 ± 0.7
69.3 ± 3.3
51.4 ± 0.9
43.4 ± 4.1

Ours

44.0 ± 1.8
41.6 ± 0.8
54.4 ± 1.8
64.0 ± 2.9
45.4 ± 1.1
46.5 ± 1.4

Table 1: Comparison of 3D tracking errors (mm) on the entire walking validation sequence with
subject-speciﬁc models  where ± indicates standard deviation over runs  except for [13]  who reports
tracking results for 200 frames of the sequences  with standard deviation over frames.

Model

[16] as reported in [12]
[14] as reported in [12]

GPLVM

[12]

Ours

Best CRBM [22]

Tracking Error
569.90 ± 209.18
380.02 ± 74.97
121.44 ± 30.7
117.0 ± 5.5
75.4 ± 9.7
74.1 ± 3.3

Table 2: Comparison of 3D tracking errors (mm) on boxing validation sequence for S1  where ±
indicates standard deviation over runs. Our results are comparable to the state-of-the-art [22].

works  we use the images from the 3 color cameras and the simple silhouette and edge likelihoods
provided in the HumanEva baseline algorithm [21].
HumanEva-I Walking: As per [22  28  13]  we track the walking validation sequences of subjects S1 
S2  and S3. The latent variable models are learned on the training sequences  being either subject-
speciﬁc or with all three subjects combined. Subject-speciﬁc models have ∼1200-2000 training
examples each  for which we used a neighborhood of 60 points  while the combined model has
∼4000 training examples with a neighborhood of 150 points. 3D tracking errors averaged over the
15 joints as speciﬁed in [21] and over all frames in the full sequence are depicted in Table1. Sample
frames of the estimated poses are shown in Fig. 5. In four of the six training/test combinations  the
stochastic GPLVM model outperforms the state-of-the-art CRBM and imCRBM model from [22] 
while in the other two cases  our model is comparable. These results are remarkable  given that we
use only a simple ﬁrst-order Markov model for estimating dynamics  and our success can only be
attributed to the latent model’s accuracy in encoding the body poses from the training data.

HumanEva-I boxing: We also track the validation sequence of S1 for boxing to assess the ability of
the stochastic GPLVM for learning acyclic motions. 3D tracking errors are shown in Table 2 and are
compared with [14  13  22]. Our results are slightly better than state-of-the-art.

4 Conclusion and Future Work

In this paper  we try to learn a probabilistic prior model which is accurate yet expressive  and is
tractable for both learning and inference. Our proposed stochastic GPLVM fulﬁlls all these criteria
- it effectively learns latent spaces of complex multi-activity datasets in a computationally efﬁcient
manner. When applied to tracking  our model outperforms state-of-the-art on the HumanEva bench-
mark  despite the use of very few particles and only a simple ﬁrst-order Markov model for handling
dynamics. In addition  we have also derived a novel approach for learning latent spaces incremen-
tally. One of the great criticisms of current latent variable models is that they cannot handle new
training examples without relearning; given the sometimes cumbersome learning process  this is not
always feasible. Our incremental method can be easily applied to an online setting without exten-
sive relearning  which may have impact in applications such as robotics where domain adaptation
might be key for accurate prediction. In the future  we plan to further investigate the incorporation
of dynamics into the stochastic model  particularly for multiple activities.

8

References
[1] A. Baak  M. Mueller B. Rosenhahn  and H.-P. Seidel. Stabilizing motion tracking using retrieved motion

priors. In ICCV  2009.

[2] J. Chen  M. Kim  Y. Wang  and Q. Ji. Switching gaussian process dynamic models for simultaneous

composite motion tracking and recognition. In CVPR  2009.

[3] CMU Mocap Database. http://mocap.cs.cmu.edu/.
[4] J. Deutscher and I. Reid. Articulated body motion capture by stochastic search. IJCV  61(2)  2005.
[5] J. Gall  A. Yao  and L. Van Gool. 2d action recognition serves 3d human pose estimation. In ECCV  2010.
[6] A. Geiger  R. Urtasun  and T. Darrell. Rank priors for continuous non-linear dimensionality reduction. In

CVPR  2009.

[7] S. Hou  A. Galata  F. Caillette  N. Thacker  and P. Bromiley. Real-time body tracking using a gaussian

process latent variable model. ICCV  2007.

[8] T. Jaeggli  E. Koller-Meier  and L. Van Gool. Learning generative models for multi-activity body pose

estimation. IJCV  83(2):121–134  2009.

[9] N. Lawrence. Probabilistic non-linear principal component analysis with gaussian process latent variable

models. JMLR  6:1783–1816  2005.

[10] N. Lawrence. Learning for larger datasets with the gaussian process latent variable model. In AISTATS 

2007.

[11] N. Lawrence and R. Urtasun. Non-linear matrix factorization with gaussian processes. In ICML  2009.
[12] R. Li  T. Tian  and S. Sclaroff. Simultaneous learning of non-linear manifold and dynamical models for

high-dimensional time series. In ICCV  2007.

[13] R. Li  T.-P. Tian  S. Sclaroff  and M.-H. Yang. 3d human motion tracking with a coordinated mixture of

factor analyzers. IJCV  87:170–190  2010.

[14] R.S. Lin  C.B. Liu  M.H. Yang  N. Ahja  and S. Levinson. Learning nonlinear manifolds from time series.

In ECCV  2006.

[15] D. Ormoneit  C. Lemieux  and D. Fleet. Lattice particle ﬁlters. In UAI  2001.
[16] V. Pavlovic  J. Rehg  and J. Maccormick. Learning switching linear models of human motion. In NIPS 

pages 981–987  2000.

[17] J. Quinonero-Candela and C. Rasmussen. A unifying view of sparse approximate gaussian process re-

gression. JMLR  page 2005  2006.

[18] S. Roweis and L. Saul. Nonlinear Dimensionality Reduction by Locally Linear Embedding. Science 

290(5500):2323–2326  2000.

[19] S. Roweis  L. Saul  and G. Hinton. Global coordination of local linear models. In NIPS  2002.
[20] H. Sidenbladh  M. Black  and D. Fleet. Stochastic tracking of 3d human ﬁgures using 2d image motion.

In ECCV  2000.

[21] L. Sigal  A. Balan  and M. Black. Humaneva: Synchronized video and motion capture dataset and baseline

algorithm for evaluation of articulated human motion. IJCV  87(1-2):4–27  2010.

[22] G. Taylor  L. Sigal  D. Fleet  and G. Hinton. Dynamical binary latent variable models for 3d human pose

tracking supplementary material. In CVPR  2010.

[23] J. Tenenbaum  V. de Silva  and J. Langford. A Global Geometric Framework for Nonlinear Dimensional-

ity Reduction. Science  2000.

[24] R. Urtasun and T. Darrell. Sparse probabilistic regression for activity-independent human pose inference.

In CVPR  2008.

[25] R. Urtasun  D. Fleet  and P. Fua. 3d people tracking with gaussian process dynamical models. In CVPR 

2006.

[26] R. Urtasun  D. Fleet  A. Hertzman  and P. Fua. Priors for people tracking from small training sets. In

ICCV  2005.

[27] J. Wang  D. Fleet  and A. Hertzmann. Gaussian process dynamical models for human motion. PAMI 

30(2):283–298  2008.

[28] X. Xu and B. Li. Learning motion correlation for tracking articulated human body with a rao-

blackwellised particle ﬁlter. In ICCV  2007.

9

,Leonid Boytsov
Bilegsaikhan Naidan
Julien Mairal