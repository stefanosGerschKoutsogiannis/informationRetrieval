2018,A Model for Learned Bloom Filters and Optimizing by Sandwiching,Recent work has suggested enhancing Bloom filters by using a pre-filter  based on applying machine learning to determine a function that models the data set the Bloom filter is meant to represent.  Here we model such learned Bloom filters  with the following outcomes: (1) we clarify what guarantees can and cannot be associated with such a structure; (2) we show how to estimate what size the learning function must obtain in order to obtain improved performance;  (3) we provide a simple method  sandwiching  for optimizing learned Bloom filters;  and (4) we propose a design and analysis approach for a learned Bloomier filter  based on our modeling approach.,A Model for Learned Bloom Filters 

and Optimizing by Sandwiching

Michael Mitzenmacher

School of Engineering and Applied Sciences

Harvard University

michaelm@eecs.harvard.edu

Abstract

Recent work has suggested enhancing Bloom ﬁlters by using a pre-ﬁlter  based
on applying machine learning to determine a function that models the data set the
Bloom ﬁlter is meant to represent. Here we model such learned Bloom ﬁlters 
with the following outcomes: (1) we clarify what guarantees can and cannot be
associated with such a structure; (2) we show how to estimate what size the learning
function must obtain in order to obtain improved performance; (3) we provide a
simple method  sandwiching  for optimizing learned Bloom ﬁlters; and (4) we
propose a design and analysis approach for a learned Bloomier ﬁlter  based on our
modeling approach.

1

Introduction

An interesting recent paper  “The Case for Learned Index Structures” [7]  argues that standard index
structures and related structures  such as Bloom ﬁlters  could be improved by using machine learning
to develop what the authors dub learned index structures. However  this paper did not provide a
suitable mathematical model for judging the performance of such structures. Here we aim to provide
a more formal model for their variation of a Bloom ﬁlter  which they call a learned Bloom ﬁlter.
To describe our results  we ﬁrst somewhat informally describe the learned Bloom ﬁlter. Like a standard
Bloom ﬁlter  it provides a compressed representation of a set of keys K that allows membership
queries. (We may sometimes also refer to the keys as elements.) Given a key y  a learned Bloom
ﬁlter always returns yes if y is in K  so there will be no false negatives  and generally returns no if y
is not in K  but may provide false positives. What makes a learned Bloom ﬁlter interesting is that it
uses a function that can be obtained by “learning” the set K to help determine the appropriate answer;
the function acts as a pre-ﬁlter that provides a probabilistic estimate that a query key y is in K. This
learned function can be used to make an initial decision as to whether the key is in K  and a smaller
backup Bloom ﬁlter is used to prevent any false negatives.
Our more formal model provides interesting insights into learned Bloom ﬁlters  and how they might
be effective. In particular  here we: (1) clarify what guarantees can and cannot be associated with
such a structure; (2) show how to estimate what size the learning function must obtain in order to
obtain improved performance; (3) provide a simple method for optimizing learned Bloom ﬁlters; and
(4) demonstrate our approach may be useful for other similar structures.
We brieﬂy summarize the outcomes above. First  we explain how the types of guarantees offered by
learned Bloom ﬁlters differ signiﬁcantly from those of standard Bloom ﬁlters. We thereby clarify
what application-level assumptions are required for a learned Bloom ﬁlter to be effective. Second 
we provide formulae for modeling the false positive rate for a learned Bloom ﬁlter  allowing for an
estimate of how small the learned function needs to be in order to be effective. We then ﬁnd  perhaps
surprisingly  that a better structure uses a Bloom ﬁlter before as well as after the learned function.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

Because we optimize for two layers of Bloom ﬁlters surrounding the learned function  we refer to
this as a sandwiched learned Bloom ﬁlter. We show mathematically and intuitively why sandwiching
improves performance. We also discuss an approach to designing learned Bloomier ﬁlters  where a
Bloomier ﬁlter returns a value associated with a set element (instead of just returning whether the
element is in the set)  and show it can be modeled similarly.
While the contents of this paper may be seen as relatively simple  we feel it is important to provide
solid foundations in order for a wide community to understand the potential and pitfalls of data
structures using machine learning components. We therefore remark that the simplicity is purposeful 
and suggest it is desirable in this context. Finally  we note that this work incorporates and extends
analysis that appeared in two prior working notes [8  9].

2 Review: Bloom Filters

We start by reviewing standard Bloom ﬁlters and variants  following the framework provided by the
reference [2].

2.1 Deﬁnition of the Data Structure
A Bloom ﬁlter for representing a set S = {x1  x2  . . .   xn} of n elements corresponds to an array
of m bits  and uses k independent hash functions h1  . . .   hk with range {0  . . .   m − 1}. Here we
follow the typical assumption that these hash functions are perfect; that is  each hash function maps
each item in the universe independently and uniformly to a number in {0  . . .   m − 1}. Initially all
array bits are 0. For each element x ∈ S  the array bits hi(x) are set to 1 for 1 ≤ i ≤ k; it does not
matter if some bit is set to 1 multiple times. To check if an item y is in S  we check whether all hi(y)
are set to 1. If not  then clearly y is not a member of S. If all hi(y) are set to 1  we conclude that y is
in S  although this may be a false positive. A Bloom ﬁlter does not produce false negatives.
The primary standard theoretical guarantee associated with a Bloom ﬁlter is the following. Let y be
an element of the universe such that y /∈ S  where y is chosen independently of the hash functions
used to create the ﬁlter. Let ρ be the fraction of bits set to 1 after the elements are hashed. Then

Pr(y yields a false positive) = ρk.

For a bit in the Bloom ﬁlter to be 0  it has to not be the outcome of the kn hash values for the n items.
It follows that

(cid:18)

(cid:19)kn ≈ 1 − e−kn/m 

E[ρ] = 1 −

1 − 1
m

and that via standard techniques using concentration bounds (see  e.g.  [11])

Pr(|ρ − E[ρ]| ≥ γ) ≤ e−Θ(γ2m)

in the typical regime where m/n and k are constant. That is  ρ is  with high probability  very close to
its easily calculable expectation  and thus we know (up to very small random deviations) what the
probability is that an element y will be a false positive. Because of this tight concentration around the
expectation  it is usual to talk about the false positive probability of a Bloom ﬁlter; in particular  it is
generally referred to as though it is a constant depending on the ﬁlter parameters  even though it is a
random variable  because it is tightly concentrated around its expectation.
Moreover  given a set of distinct query elements Q = {y1  y2  . . .   yq} with Q ∩ S = ∅ chosen a
priori before the Bloom ﬁlter is instantiated  the fraction of false positives over these queries will
similarly be concentrated near ρk. Hence we may talk about the false positive rate of a Bloom ﬁlter
over queries  which (when the query elements are distinct) is essentially the same as the false positive
probability. (When the query elements are not distinct  the false positive rate may vary signiﬁcantly 
depending on on the distribution of the number of appearances of elements and which ones yield
false positives; we focus on the distinct item setting here.) In particular  the false positive rate is a
priori the same for any possible query set Q. Hence one approach to ﬁnding the false positive rate of
a Bloom ﬁlter empirically is simply to test a random set of query elements (that does not intersect S)
and ﬁnd the fraction of false positives. Indeed  it does not matter what set Q is chosen  as long as it is
chosen independently of the hash functions.

2

We emphasize that  as we discuss further below  the term false positive rate often has a different
meaning in the context of learning theory applications. Care must therefore be taken in understanding
how the term is being used.

2.2 Additional Bloom Filter Beneﬁts and Limitations

For completeness  we relate some of the other beneﬁts and limitations of Bloom ﬁlters. More details
can be found in [2].
We have assumed in the above analysis that the hash functions are fully random. As fully random
hash functions are not practically implementable  there are often questions relating to how well the
idealization above matches the real world for speciﬁc hash functions. In practice  however  the model
of fully random hash functions appears reasonable in many cases; see [5] for further discussion on
this point.
If an adversary has access to the hash functions used  or to the ﬁnal Bloom ﬁlter  it can ﬁnd elements
that lead to false positives. One must therefore ﬁnd other structures for adversarial situations. A
theoretical framework for such settings is developed in [12]. Variations of Bloom ﬁlters  which
adapt to false positives and prevent them in the future  are described in [1  10]; while not meant for
adversarial situations  they prevent repeated false positives with the same element.
One of the key advantages of a standard Bloom ﬁlter is that it is easy to insert an element (possibly
slightly changing the false positive probability)  although one cannot delete an element without
using a more complex structure  such as a counting Bloom ﬁlter. However  there are more recent
alternatives to the standard Bloom ﬁlter  such as the cuckoo ﬁlter [6]  which can achieve the same
or better space performance as a standard Bloom ﬁlter while allowing insertions and deletions. If
the Bloom ﬁlter does not need to insert or delete elements  a well-known alternative is to develop a
perfect hash function for the data set  and store a ﬁngerprint of each element in each corresponding
hash location (see  e.g.  [2] for further explanation); this approach reduces the space required by
approximately 30%.

3 Learned Bloom Filters

3.1 Deﬁnition of the Data Structure

We now consider the learned Bloom ﬁlter construction as described in [7]. We are given a set of
positive keys K that correspond to set to be held in the Bloom ﬁlter – that is  K corresponds to the set
S in the previous section. We are also given a set of negative keys U for training. We then train a
neural network with D = {(xi  yi = 1) | xi ∈ K} ∪ {(xi  yi = 0) | xi ∈ U}; that is  they suggest
using a neural network on this binary classiﬁcation task to produce a probability  based on minimizing
the log loss function

y log f (x) + (1 − y) log(1 − f (x)) 

(cid:88)

L =

(x y)∈D

where f is the learned model from the neural network. Then f (x) can be interpreted as a “probability”
estimate that x is a key from the set. Their suggested approach is to choose a threshold τ so that
if f (x) ≥ τ then the algorithm returns that x is in the set  and no otherwise. Since such a process
may provide false negatives for some keys in K that have f (x) < τ  a secondary structure – such
as a smaller standard Bloom ﬁlter holding the keys from K that have f (x) < τ – can be used to
check keys with f (x) < τ to ensure there are no false negatives  matching this feature of the standard
Bloom ﬁlter.
In essence  [7] suggests using a pre-ﬁlter ahead of the Bloom ﬁlter  where the pre-ﬁlter comes from a
neural network and estimates the probability a key is in the set  allowing the use of a smaller Bloom
ﬁlter than if one just used a Bloom ﬁlter alone. Performance improves if the size to represent the
learned function f and the size of the smaller backup ﬁlter for false negatives is smaller than the size
of a corresponding Bloom ﬁlter with the same false positive rate. Of course the pre-ﬁlter here need
not come from a neural network; any approach that would estimate the probability an input key is in
the set could be used.
This motivates the following formal deﬁnition:

3

Deﬁnition 1 A learned Bloom ﬁlter on a set of positive keys K and negative keys U is a function
f : U → [0  1] and threshold τ  where U is the universe of possible query keys  and an associated
standard Bloom ﬁlter B  referred to as a backup ﬁlter. The backup ﬁlter holds the set of keys
{z : z ∈ K  f (z) < τ}. For a query y  the learned Bloom ﬁlter returns that y ∈ K if f (y) ≥ τ  or if
f (y) < τ and the backup ﬁlter returns that y ∈ K. The learned Bloom ﬁlter returns y /∈ K otherwise.

3.2 Deﬁning the False Positive Probability

The question remains how to determine or derive the false positive probability for a learned Bloom
ﬁlter  and how to choose an appropriate threshold τ. The approach in [7] is to ﬁnd the false positive
rate over a test set. This approach is  as we have discussed  suitable for a standard Bloom ﬁlter 
where the false positive rate is guaranteed to be close to its expected value for any test set  with high
probability. However  this methodology requires additional assumptions in the learned Bloom ﬁlter
setting.
As an example  suppose the universe of elements is the range [0  1000000)  and the set K of keys to
store in our Bloom ﬁlter consists of a random subset of 500 elements from the range [1000  2000]  and
of 500 other random elements from outside this range. Our learning algorithm might determine that a
suitable function f yields that f (y) is large (say f (y) ≈ 1/2) for elements in the range [1000  2000]
and close to zero elsewhere  and then a suitable threshold might be τ = 0.4. The resulting false
positive rate depends substantially on what elements are queried. If Q consists of elements primarily
in the range [1000  2000]  the false positive rate will be quite high  while if Q is chosen uniformly at
random over the whole range  the false positive rate will be quite low. Unlike a standard Bloom ﬁlter 
the false positive rate is highly dependent on the query set  and is not well-deﬁned independently of
the queries.
Indeed  it seems plausible that in many situations  the query set Q might indeed be similar to the set
of keys K  so that f (y) for y ∈ Q might often be above naturally chosen thresholds. For example  in
security settings  one might expect that queries for objects under consideration (URLs  network ﬂow
features) would be similar to the set of keys stored in the ﬁlter. Unlike in the setting of a standard
Bloom ﬁlter  the false positive probability for a query y can depend on y  even before the function f
is instantiated.
It is worth noting  however  that the problem we point out here can possibly be a positive feature in
other settings; it might be that the false positive rate is remarkably low if the query set is suitable.
Again  one can consider the range example above where queries are uniform over the entire space;
the query set is very unlikely to hit the range where the learned function f yields an above threshold
value in that setting for a key outside of K. The data-dependent nature of the learned Bloom ﬁlter
may allow it to circumvent lower bounds for standard Bloom ﬁlter structures.
While the false positive probability for learned Bloom ﬁlters does not have the same properties as for
a standard Bloom ﬁlter  we can deﬁne the false positive rate of a learned Bloom ﬁlter with respect to
a given query distribution.
Deﬁnition 2 A false positive rate on a query distribution D over U − K for a learned Bloom ﬁlter
(f  τ  B) is given by

y∼D(f (y) ≥ τ ) + (1 − Pr

y∼D(f (y) ≥ τ ))F (B) 

Pr

where F (B) is the false positive rate of the backup ﬁlter B.

While technically F (B) is itself a random variable  the false positive rate is well concentrated around
its expectations  which depends only on the size of the ﬁlter |B| and the number of false negatives
from K that must be stored in the ﬁlter  which depends on f. Hence where the meaning is clear we
may consider the false positive rate for a learned Bloom ﬁlter with function f and threshold τ to be

y∼D(f (y) ≥ τ ) + (1 − Pr

y∼D(f (y) ≥ τ ))E[F (B)] 

Pr

where the expectation E[F (B)] is meant to over instantiations of the Bloom ﬁlter with given size |B|.
Given sufﬁcient data  we can determine an empirical false positive rate on a test set  and use that
to predict future behavior. Under the assumption that the test set has the same distribution as future

4

queries  standard Chernoff bounds provide that the empirical false positive rate will be close to the
false positive rate on future queries  as both will be concentrated around the expectation. In many
learning theory settings  this empirical false positive rate appears to be referred to as simply the false
positive rate; we emphasize that false positive rate  as we have explained above  typically means
something different in the Bloom ﬁlter literature.
Deﬁnition 3 The empirical false positive rate on a set T   where T ∩ K = ∅  for a learned Bloom
ﬁlter (f  τ  B) is the number of false positives from T divided by |T |.
Theorem 4 Consider a learned Bloom ﬁlter (f  τ  B)  a test set T   and a query set Q  where T and
Q are both determined from samples according to a distribution D. Let X be the empirical false
positive rate on T   and Y be the empirical false positive rate on Q. Then

Pr(|X − Y | ≥ ) ≤ e−Ω(2 min(|T | |Q|)).

Proof: Let α = Pry∼D(f (y) ≥ τ )  and β be false positive rate for the backup ﬁlter. We ﬁrst show
that for T and X that

Pr(|X − (α + (1 − α)β)| ≥ ) ≤ 2e−22|T |.

This follows from a direct Chernoff bound (e.g.  [11][Exercise 4.13])  since each sample chosen
according to D is a false positive with probability α + (1 − α)β. A similar bound holds for Q and Y .
We can therefore conclude

Pr(|X − Y | ≥ ) ≤ Pr(|X − (α + (1 − α)β)| ≥ /2)

+ Pr(|Y − (α + (1 − α)β)| ≥ /2)

≤ 2e−2|T |/2 + 2e−2|Q|/2 

giving the desired result.

Theorem 4 also informs us that it is reasonable to ﬁnd a suitable parameter τ  given f  by trying
a suitable ﬁnite discrete set of values for τ  and choosing the best size-accuracy tradeoff for the
application. By a union bound  all choices of τ will perform close to their expectation with high
probability.
While Theorem 4 requires the test set and query set to come from the same distribution D  the
negative examples U do not have to come from that distribution. Of course  if negative examples U
are drawn from D  it may yield a better learning outcome f.
If the test set and query set distribution do not match  because for example the types of queries
change after the original gathering of test data T   Theorem 4 offers limited guidance. Suppose T is
derived from samples from distribution D and Q from another distribution D(cid:48). If the two distributions
are close (say in L1 distance)  or  more speciﬁcally  if the changes do not signiﬁcantly change the
probability that a query y has f (y) ≥ τ  then the empirical false positive rate on the test set may still
be relatively accurate. However  in practice it may be hard to provide such guarantees on the nature
of future queries. This explains our previous statement that learned Bloom ﬁlters appear most useful
when the query stream can be modeled as coming from a ﬁxed distribution  which can be sampled
during the construction.
We can return to our previous example to understand these effects. Recall our set consists of
500 random elements from the range [1000  2000] and 500 other random elements from the range
[0  1000000). Our learned Bloom ﬁlter has f (y) ≥ τ for all y in [1000  2000] and f (y) < τ
otherwise. Our backup ﬁlter will therefore store 500 elements. If our test set is uniform over
[0  1000000) (excluding elements stored in the Bloom ﬁlter)  our false positive rate from elements
with too large an f value would be approximately 0.0002; one could choose a backup ﬁlter with
roughly the same false positive probability for a total empirical false positive probability of 0.0004.
If  however  our queries are uniform over a restricted range [0  100000)  then the false positive
probability would jump to 0.0022 for the learned Bloom ﬁlter  because the learned function would
yield more false positives over the smaller query range.

5

3.3 Additional Learned Bloom Filter Beneﬁts and Limitations
Learned Bloom ﬁlters can easily handle insertions into K by adding the key  if is does not already
yield a (false) positive  to the backup ﬁlter. Such changes have a larger effect on the false positive
probability than for a standard Bloom ﬁlter  since the backup ﬁlter is smaller. Keys cannot be deleted
naturally from a learned Bloom ﬁlter. A deleted key would simply become a false positive  which (if
needed) could possibly be handled by an additional structure.
As noted in [7]  it may be possible to re-learn a new function f if the data set changes substantially via
insertions and deletion of keys from K. Of course  besides the time needed to re-learn a new function
f  this requires storing the original set somewhere  which may not be necessary for alternative
schemes. Similarly  if the false positive probability proves higher than desired  one can re-learn a
new function f; again  doing so will require access to K  and maintaining a (larger) set U of negative
examples.

4 Size of the Learned Function

We now consider how to model the performance of the learned Bloom ﬁlter with the goal of
understanding how small the representation of the function f needs needs to be in order for the
learned Bloom ﬁlter to be more effective than a standard Bloom ﬁlter. 1
Our model is as follows. The function f associated with Deﬁnition 1 we treat as an oracle for the
keys K  where |K| = m  that works as follows. For keys not in K there is an associated false positive
probability Fp  and there are Fnm false negatives for keys in K. (The value Fn is like a false negative
probability  but given K this fraction is determined and known according to the oracle outcomes.) We
note the oracle representing the function f is meant to be general  so it could potentially represent
other sorts of ﬁlter structures as well. As we have described in Section 3.2  in the context of a learned
Bloom ﬁlter the false positive rate is necessarily tied to the query stream  and is therefore generally
an empirically determined quantity  but we take the value Fp here as a given. Here we show how
to optimize over a single oracle  although in practice we may possibly choose from oracles with
different values Fp and Fn  in which case we can optimize for each pair of values and choose the
best suited to the application.
We assume a total budget of bm bits for the backup ﬁlter  and |f| = ζ bits for the learned function. If
|K| = m  the backup Bloom ﬁlter only needs to hold mFn keys  and hence we take the number of
bits per stored key to be b/Fn. To model the false positive rate of a Bloom ﬁlter that uses j bits per
stored key  we assume the false positive rate falls as αj. This is the case for a standard Bloom ﬁlter
(where α ≈ 0.6185 when using the optimal number of hash functions  as described in the survey
[2])  as well as for a static Bloom ﬁlter built using a perfect hash function (where α = 1/2  again
described in [2]). The analysis can be modiﬁed to handle other functions for false positives in terms
of j in a straightforward manner. (For example  for a cuckoo ﬁlter [6]  a good approximation for the
false positive rate is cαj for suitable constants c and α.)
The false positive rate of a learned Bloom ﬁlter is Fp + (1 − Fp)αb/Fn . This is because  for y /∈ K  y
causes a false positive from the learned function f with probability Fp  or with remaining probability
(1 − Fp) it yields a false positive on the backup Bloom ﬁlter with probability αb/Fn.
A comparable Bloom ﬁlter using the same number of total bits  namely bm + ζ bits  would have
a false positive probability of αb+ζ/m. Thus we ﬁnd an improvement using a learned Bloom ﬁlter
whenever

Fp + (1 − Fp)αb/Fn ≤ αb+ζ/m 

which simpliﬁes to

ζ/m ≤ logα

(cid:16)

Fp + (1 − Fp)αb/Fn

(cid:17) − b 

where we have expressed the requirement in terms of a bound on ζ/m  the number of bits per key the
function f is allowed.

1We thank Alex Beutel for pointing out that our analysis in [9] could be used in this manner.

6

This expression is somewhat unwieldy  but it provides some insight into what sort of compression is
required for the learned function f  and how a practitioner can determine what is needed. First  one
can determine possible thresholds and the corresponding rate of false positive and false negatives
from the learned function. For example  the paper [7] considers situations where Fp ≈ 0.01  and
Fn ≈ 0.5; let us consider Fp = 0.01 and Fn = 0.5 for clarity. If we have a target goal of one byte
per item  a standard Bloom ﬁlter achieves a false positive probability of approximately 0.0214. If
our learned function uses 3 bits per item (or less)  then the learned Bloom ﬁlter can use 5m bits
for the backup Bloom ﬁlter  and achieve a false positive rate of approximately 0.0181. The learned
Bloom ﬁlter will therefore provide over a 10% reduction in false positives with the same or less space.
More generally  in practice one could determine or estimate different Fp and Fn values for different
thresholds and different learned functions of various sizes  and use these equations to determine if
better performance can be expected without in depth experiments.
Indeed  an interesting question raised by this analysis is how learned functions scale in terms of
typical data sets. In extreme situations  such as when the set K being considered is a range of
consecutive integers  it can be represented by just two integers  which does not grow with K. If 
in practice  as data sets grow larger the amount of information needed for a learned function f to
approximate key sets K grows sublinearly with |K|  learned Bloom ﬁlters may prove very effective.

5 Sandwiched Learned Bloom Filters

5.1 The Sandwich Structure

Given the formalization of the learned Bloom ﬁlter  it seems natural to ask whether this structure can
be improved. Here we show that a better structure is to use a Bloom ﬁlter before using the function f 
in order to remove most queries for keys not in K. We emphasize that this initial Bloom ﬁlter does
not declare that an input y is in K  but passes forward all matching keys to the learned function f 
and it returns y /∈ K when the Bloom ﬁlter shows the key is not in K. Then  as before  we use the
function f to attempt to remove false positives from the initial Bloom ﬁlter  and then use the backup
ﬁlter to allow back in keys from K that were false negatives for f. Because we have two layers of
Bloom ﬁlters surrounding the learned function f  we refer to this as a sandwiched learned Bloom
ﬁlter. The sandwiched learned Bloom ﬁlter is represented pictorially in Figure 1.
In hindsight  our result that sandwiching improves performance makes sense. The purpose of
the backup Bloom ﬁlter is to remove the false negatives arising from the learned function. If we
can arrange to remove more false positives up front  then the backup Bloom ﬁlter can be quite
porous  allowing most everything that reaches it through  and therefore can be quite small. Indeed 
surprisingly  our analysis shows that the backup ﬁlter should not grow beyond a ﬁxed size.

5.2 Analyzing Sandwiched Learned Bloom Filters

We model the sandwiched learned Bloom ﬁlter as follows. As before  the learned function f in the
middle of the sandwich we treat as an oracle for the keys K  where |K| = m. Also as before  for
keys not in K there is an associated false positive probability Fp  and there are Fnm false negatives
for keys in K.
We here assume a total budget of bm bits to be divided between an initial Bloom ﬁlter of b1m bits
and a backup Bloom ﬁlter of b2m bits. As before  we model the false positive rate of a Bloom ﬁlter
that uses j bits per stored key as αj for simplicity. The backup Bloom ﬁlter only needs to hold mFn
keys  and hence we take the number of bits per stored key to be b2/Fn. If we ﬁnd the best value of b2
is b  then no initial Bloom ﬁlter is needed  but otherwise  an initial Bloom ﬁlter is helpful.
The false positive rate of a sandwiched learned Bloom ﬁlter is then αb1(Fp + (1 − Fp)αb2/Fn ). To
see this  note that for y /∈ K  y ﬁrst has to pass through the initial Bloom ﬁlter  which occurs with
probability αb1. Then y either causes a false positive from the learned function f with probability
Fp  or with remaining probability (1 − Fp) it yields a false positive on the backup Bloom ﬁlter  with
probability αb2/Fn.

7

Figure 1: The left side shows the original learned Bloom ﬁlter. The right side shows the sandwiched
learned Bloom ﬁlter.

As α  Fp  Fn and b are all constants for the purpose of this analysis  we may optimize for b1 in the
equivalent expression

(1)

(2)

The derivative with respect to b1 is

Fp(ln α)αb1 + (1 − Fp)

This equals 0 when

(cid:16) 1

Fn

Fp
(1 − Fp)

− 1

Fpαb1 + (1 − Fp)αb/Fnαb1(1−1/Fn).

(cid:19)

1 − 1
Fn

(cid:18)
(cid:17) = α(b−b1)/Fn = αb2/Fn .

αb/Fn (ln α)αb1(1−1/Fn).

This further yields that the false positive rate is minimized when b2 = b∗

2  where

b∗
2 = Fn logα

(cid:16) 1

Fn

(cid:17) .

− 1

Fp
(1 − Fp)

This result may be somewhat surprising  as here we see that the optimal value b∗
2 is a constant 
independent of b. That is  the number of bits used for the backup ﬁlter is not a constant fraction
of the total budgeted number of bits bm  but a ﬁxed number of bits; if the number of budgeted bits
increases  one should simply increase the size of the initial Bloom ﬁlter as long as the backup ﬁlter is
appropriately sized.
In hindsight  returning to the expression for the false positive rate αb1 (Fp + (1− Fp)αb2/Fn ) provides
useful intuition. If we think of sequentially distributing the bm bits among the two Bloom ﬁlters  the
expression shows that bits assigned to the initial ﬁlter (the b1 bits) reduce false positives arising from
the learned function (the Fp term) as well as false positives arising subsequent to the learned function
(the (1 − Fp) term)  while the backup ﬁlter only reduces false positives arising subsequent to the
learned function. Initially we would provide bits to the backup ﬁlter to reduce the (1 − Fp) rate of
false positives subsequent to the learned function. Indeed  bits in the backup ﬁlter drive down this
(1 − Fp) term rapidly  because the backup ﬁlter holds fewer keys from the original set  leading to
the b2/Fn (instead of just a b2) in the exponent in the expression αb2/Fn. Once the false positives
coming through the backup Bloom ﬁlter reaches an appropriate level  which  by plugging in the
determined optimal value for b2  we ﬁnd is Fp/
  then the tradeoff changes. At that point
the gains from reducing the false positives by increasing the bits for the backup Bloom ﬁlter become
smaller than the gains obtained by increasing the bits for the initial Bloom ﬁlter.
Again  we can look at situations discussed in [7] for some insight. Suppose we have a learned function
f where Fn = 0.5 and Fp = 0.01. We consider α = 0.6185 (which corresponds to a standard Bloom
ﬁlter). We do not consider the size of f in the calculation below. Then the optimal value for b2 is

(cid:16) 1

− 1

(cid:17)

Fn

2 = (logα 1/99)/2 ≈ 6.
b∗

8

Learned	  Oracle	  Backup	  Filter	  Input	  Posi6ves	  Nega6ves	  Posi6ves	  Nega6ves	  Learned	  Oracle	  Backup	  Filter	  Posi6ves	  Posi6ves	  Nega6ves	  Posi6ves	  Nega6ves	  Ini6al	  Filter	  Input	  Nega6ves	  Depending on our Bloom ﬁlter budget parameter b  we obtain different levels of performance
improvement by using the initial Bloom ﬁlter. At b = 8 bits per key  the false positive rate drops from
approximately 0.010045 to 0.005012  over a factor of 2. At b = 10 bits per key  the false positive
rate drops from approximately 0.010066 to 0.001917  almost an order of magnitude.
We may also consider the implications for the oracle size. Again  if we let ζ represent the size of the
oracle in bits  then a corresponding Bloom ﬁlter would have a false positive probability of αb+ζ/m.
Hence we have an improvement whenever

αb1 (Fp + (1 − Fp)αb2/Fn) ≤ αb+ζ/m.

For b sufﬁciently large that b1 > 0  we can calculate the false positive probability of the opti-
mized sandwiched Bloom ﬁlter. Let b∗
1 be the
corresponding value for b1. First using the relationship from equation 1  we have a gain whenever

2 be the optimal value for b2 from equation 2 and b∗

Using b∗

1 = b − b∗

2 and equation 2 gives
Fp
1 − Fn

ζ/m ≤ logα

αb∗

1

Fp
1 − Fn

≤ αb+ζ/m.

− Fn logα

(cid:16) 1

Fn

Fp
(1 − Fp)

(cid:17) .

− 1

Again  this expression is somewhat unwieldy  but one useful difference from the analysis of the
original learned Bloom ﬁlter is that we see the improvement does not depend on the exact value of
b (as long b is large enough so that b1 > 0  and we use the optimal value for b2). For Fp = 0.01 
Fn = 0.5  and α = 0.6185  we ﬁnd a gain whenever ζ/m falls below approximately 3.36.
A possible further advantage of the sandwich approach is that it makes learned Bloom ﬁlters more
robust. As discussed previously  if the queries given to a learned Bloom ﬁlter do not come from the
same distribution as the queries from the test set used to estimate the learned Bloom ﬁlter’s false
positive probability  the actual false positive probability may be substantially larger than expected.
The use of an initial Bloom ﬁlter mitigates this problem  as this issue then only affects the smaller
number of keys that pass the initial Bloom ﬁlter.
We note that a potential disadvantage of the sandwich approach may be that it is more computationally
complex than a learned Bloom ﬁlter without sandwiching  requiring possibly more hashing and
memory accesses for the initial Bloom ﬁlter. The overall efﬁciency would be implementation
dependent  but this remains a possible issue for further research.

6 Learned Bloomier Filters

In the supplemental material  we consider learned Bloomier ﬁlters. Bloomier ﬁlters are a variation
of the Bloom ﬁlter idea where each key in the set K has an associated value. The Bloomier ﬁlter
returns the value for every key of K  and is supposed to return a null value for keys not in K  but in
this context there can be false positives where the return for a key outside of K is a non-null value
with some probability. We derive related formulae for the performance of learned Bloomier ﬁlters.

7 Conclusion

We have focused on providing a more formal analysis of the proposed learned Bloom ﬁlter. As part of
this  we have attempted to clarify a particular issue in the Bloom ﬁlter setting  namely the dependence
of what is referred to as the false positive rate in [7] on the query set  and how it might affect the
applications this approach is suited for. We have also found that our modeling laeds to a natural and
interesting optimization  based on sandwiching  and allows for generalizations to related structures 
such as Bloomier ﬁlters. Our discussion is meant to encourage users to take care to realize all of the
implications of the learned Bloom ﬁlter approach before adopting it. However  for sets that can be
accurately predicted by small learned functions  the learned Bloom ﬁlter may provide a novel means
of obtaining signiﬁcant performance improvements over standard Bloom ﬁlter variants.

9

Acknowledgments

The author thanks Suresh Venkatasubramanian for suggesting a closer look at [7]  and thanks the
authors of [7] for helpful discussions involving their work. This work was supported in part by NSF
grants CCF-1563710  CCF-1535795  CCF-1320231  and CNS-1228598. Part of this work was done
while visiting Microsoft Research New England.

References
[1] M. Bender  M. Farach-Colton  M. Goswami  R. Johnson  S. McCauley  and S. Singh. Bloom
Filters  Adaptivity  and the Dictionary Problem. https://arxiv.org/abs/1711.01616 
2017.

[2] A. Broder and M. Mitzenmacher. Network Applications of Bloom Filters: A Survey. Internet

Mathematics  1(4):485-509  2004.

[3] D. Charles and K. Chellapilla. Bloomier Filters: A Second Look. In Proceedings of the European

Symposium on Algorithms  pp. 259-270  2008.

[4] B. Chazelle  J. Kilian  R. Rubinfeld  and A. Tal. The Bloomier Filter: an Efﬁcient Data
Structure for Static Support Lookup Tables. In Proceedings of the Fifteenth Annual ACM-SIAM
Symposium on Discrete Algorithms  pp. 30-39  2004.

[5] K. Chung  M. Mitzenmacher  and S. Vadhan. Why Simple Hash Functions Work: Exploiting

the Entropy in a Data Stream. Theory of Computing  9(30):897-945  2013.

[6] B. Fan  D. Andersen  M. Kaminsky  and M. Mitzenmacher. Cuckoo Filter: Practically Better
than Bloom. In Proceedings of the 10th ACM International Conference on Emerging Networking
Experiments and Technologies  pp. 75-88  2014.

[7] T. Kraska  A. Beutel  E. H. Chi  J. Dean  and N. Polyzotis. The Case for Learned Index

Structures. https://arxiv.org/abs/1712.01208  2017.

[8] M. Mitzenmacher. A Model for Learned Bloom Filters and Related Structures. https://

arxiv.org/abs/1802.00884  2018.

[9] M. Mitzenmacher. Optimizing Learned Bloom Filters by Sandwiching. https://arxiv.org/

abs/1803.01474  2018.

[10] M. Mitzenmacher  S. Pontarelli  and P. Reviriego. Adaptive Cuckoo Filters. In Proceedings
of the Twentieth Workshop on Algorithm Engineering and Experiments (ALENEX)  pp. 36-47 
2018.

[11] M. Mitzenmacher and E. Upfal. Probability and Computing: Randomization and Probabilistic

Techniques in Algorithms and Data Analysis. Cambridge University Pres  2017.

[12] M. Naor and E. Yogev. Bloom Filters in Adversarial Environments. In Proceedings of the

Annual Cryptography Conference  pp. 565-584  2015.

10

,Michael Mitzenmacher