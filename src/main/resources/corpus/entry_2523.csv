2016,Hypothesis Testing in Unsupervised Domain Adaptation with Applications in Alzheimer's Disease,Consider samples from two different data sources $\{\mathbf{x_s^i}\} \sim P_{\rm source}$ and $\{\mathbf{x_t^i}\} \sim P_{\rm target}$. We only observe their transformed versions $h(\mathbf{x_s^i})$ and $g(\mathbf{x_t^i})$  for some known function class $h(\cdot)$ and $g(\cdot)$. Our goal is to perform a statistical test checking if $P_{\rm source}$ = $P_{\rm target}$ while removing the distortions induced by the transformations. This problem is closely related to concepts underlying numerous domain adaptation algorithms  and in our case  is motivated by the need to combine clinical and imaging based biomarkers from multiple sites and/or batches  where this problem is fairly common and an impediment in the conduct of analyses with much larger sample sizes. We develop a framework that addresses this problem using ideas from hypothesis testing on the transformed measurements  where in the distortions need to be estimated {\it in tandem} with the testing. We derive a simple algorithm and study its convergence and consistency properties in detail  and we also provide lower-bound strategies based on recent work in continuous optimization. On a dataset of individuals at risk for neurological disease  our results are competitive with alternative procedures that are twice as expensive and in some cases operationally infeasible to implement.,Hypothesis Testing in Unsupervised Domain

Adaptation with Applications in Alzheimer’s Disease

Hao Henry Zhou†
Sterling C. Johnson§ †

Sathya N. Ravi†

Grace Wahba†

§William S. Middleton Memorial VA Hospital

†University of Wisconsin–Madison

Vamsi K. Ithapu†
Vikas Singh†

Abstract

s) and g(xi

s} ∼ Psource and {xi

Consider samples from two different data sources {xi
t} ∼
Ptarget. We only observe their transformed versions h(xi
t)  for some
known function class h(·) and g(·). Our goal is to perform a statistical test checking
if Psource = Ptarget while removing the distortions induced by the transformations.
This problem is closely related to domain adaptation  and in our case  is motivated
by the need to combine clinical and imaging based biomarkers from multiple sites
and/or batches – a fairly common impediment in conducting analyses with much
larger sample sizes. We address this problem using ideas from hypothesis testing
on the transformed measurements  wherein the distortions need to be estimated in
tandem with the testing. We derive a simple algorithm and study its convergence
and consistency properties in detail  and provide lower-bound strategies based on
recent work in continuous optimization. On a dataset of individuals at risk for
Alzheimer’s disease  our framework is competitive with alternative procedures that
are twice as expensive and in some cases operationally infeasible to implement.

1

Introduction

A ﬁrst order requirement in many estimation tasks is that the training and testing samples are from
the same underlying distribution and the associated features are directly comparable. But in many
real world datasets  training/testing (or source/target) samples may come from different “domains”:
they may be variously represented and involve different marginal distributions [8  32]. “Domain
adaptation” (DA) algorithms [24  27] are often used to address such problems. For example  in
vision  not accounting for systematic source/target variations in images due to commodity versus
professional camera equipment yields poor accuracy for visual recognition; here  these schemes
can be used to match the source/target distributions or identify intermediate latent representations
[12  1  9]  often yielding superior performance [29  12  1  9]. Such success has lead to specialized
formulations  for instance  when target annotations are absent (unsupervised) [11  13] or minimally
available (semi-supervised) [7  22]. With a mapping to compensate for this domain shift  we know
that the normalized (or transformed) features are sufﬁciently invariant and reliable in practice.
In numerous DA applications  the interest is in seamlessly translating a classiﬁer across domains —
consequently  the model’s test/target predictive performance serves the intended goals. However  in
many areas of science  issues concerning the statistical power of the experiment  the sample sizes
needed to achieve this power and whether we can derive p-values for the estimated domain adaptation
model are equally  if not  more important. For instance  the differences in instrument calibration and
reagents in wet lab experiments are potential DA applications except that the downstream analysis may
involve little to no discrimination performance measures per se. Separately  in multi-site population
studies [17  18  21]  where due to operational reasons  recruitment and data acquisition is distributed
over multiple sites (even countries) — site-speciﬁc shifts in measurements and missing covariates
are common [17  18  21]. The need to harmonize such data requires some form of DA. While good

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

predictive performance is useful  the ability to perform hypothesis tests and obtain interpretable
statistical quantities remain central to the conduct of experiments or analyses across a majority of
scientiﬁc disciplines. We remark that constructs such as H∆H distance have been widely used to
analyze non-conservative DA and obtain probabilistic bounds on the performance of a classiﬁer from
certain hypotheses classes  but the statistical considerations identiﬁed above are not well studied and
do not follow straightforwardly from the learning theoretic results derived in [2  5].
A Motivating Example from Neuroscience. The social and ﬁnancial burden (of health-care) is
projected to grow considerably since elderly are the fastest growing populace [28  6]  and age is the
strongest risk factor for neurological disorders such as Alzheimer’s disease (AD). Although numerous
large scale projects study the aging brain to identify early biomarkers for various types of dementia 
when younger cohorts are analyzed (farther away from disease onset)  the effect sizes become worse.
This has led to multi-center research collaborations and clinical trials in an effort to increase sample
sizes. Despite the promise  combining data across sites pose signiﬁcant statistical challenges – for AD
in particular  the need for harmonization or standardization (i.e.  domain adaptation) was found to be
essential [20  34] in the analysis of multi-site Cerebrospinal ﬂuid (CSF) assays and brain volumetric
measurements. These analyses refer to the use of AD related pathological biomarkers (β-amyloid
peptide in CSF)  but there is variability in absolute concentrations due to CSF collection and storage
procedures [34]. Similar variability issues exist for amyloid and structural brain imaging studies 
and are impediments before multi-site data can be pooled and analyzed in totality. The temporary
solution emerging from [20] is to use an “normalization/anchor” cohort of individuals which will
then be validated using test/retest variation. The goal of this paper is to provide a rigorous statistical
framework for addressing these challenges that will make domain adaptation an analysis tool in
neuroimaging as well as other experimental areas.
This paper makes the following key contributions. a) On the formulation side  we generalize
existing models which assume an identical transformation applied to both the source/target domains
to compensate for the domain shift. Our proposal permits domain-speciﬁc transformations to align
both the marginal (and the conditional) data distributions; b) On the statistical side  we derive a
provably consistent hypothesis test to check whether the transformation model can indeed correct the
‘shift’  directly yielding p-values. We also show consistency of the model in that we can provably
estimate the actual transformation parameters in an asymptotic sense; c) We identify some interesting
links of our estimation with recent developments in continuous optimization and show how our model
permits an analysis based on obtaining successively tighter lower bounds; d) Finally  we present
experiments on an AD study showing how CSF data from different batches (source/target) can be
harmonized enabling the application of standard statistical analysis schemes.
2 Background

Consider the unsupervised domain adaptation setting where the inputs/features/covariates in the
source and target domains are denoted by xs and xt respectively. The source and target feature
spaces are related via some unknown mapping  which is recovered by applying some appropriate
transformations on the inputs. We denote these transformed inputs as ˜xs and ˜xt. Within this setting 
our goal is two-fold: ﬁrst  to estimate the source-to-target mapping  followed by performing some
statistical test about the ‘goodness’ of the estimate. Speciﬁcally  the problem is to ﬁrst estimate
suitable transformations h ∈ G  g ∈ G(cid:48)  parameterized by some λ and β respectively  such that the
transformed data ˜xs := h(xs  λ) and ˜xt := g(xt  β) have similar distributions. G and G(cid:48) restrict
the allowable mappings (e.g.  afﬁne) between source and target. Clearly the goodness of domain
adaptation depends on the nature and size of G  and the similarity measure used to compare the
distributions. The distance/similarity measure used in our model deﬁnes a statistic for comparing
distributions. Hence  using the estimated transformations  we then provide a hypothesis test for the
existence of λ and β such that P r(˜xs) = P r(˜xt)  and ﬁnally assign p-values for the signiﬁcance.
To setup this framework  we start with a statistic that measures the distance between two distributions.
As motivated in Section 1  we do not impose any parametric assumptions. Since we are interested in
the mismatch of P r(˜xs) and P r(˜xt)  we use maximum mean discrepancy (MMD) which measures
the mean distance between {xs} and {xt} in a Hilbert space induced by a characteristic kernel K 

m(cid:88)

i=1

= (cid:107) 1
m

K(xi

t ·) − 1
n

n(cid:88)

i=1

K(xi

s ·)(cid:107)H

(1)

(cid:32)

M M D(xs  xt) = sup
f∈F

(cid:33)

m(cid:88)

i=1

1
m

f (xi

s) − 1
n

n(cid:88)

i=1

f (xi
t)

2

where F = {f ∈ HK ||f||HK ≤ 1} and HK denotes the universal RKHS. The advantage of
MMD over other nonparametric distance measures is discussed in [30  15  16  31]. Speciﬁcally 
MMD statistic deﬁnes a metric  and whenever MMD is large  the samples are “likely” from different
distributions. The simplicity of MMD and the statistical and asymptotic guarantees it provides
[15  16]  largely drive our estimation and testing approach. In fact  our framework will operate on
‘transformed’ data ˜xs and ˜xt while estimating the appropriate transformations.

2.1 Related Work

The body of work on domain adaptation is fairly extensive  even when restricted to the unsupervised
version. Below  we describe algorithms that are more closely related to our work and identify
the similarities/differences. A common feature of many unsupervised methods is to match the
feature/covariate distributions between the source and the target domains  and broadly  these fall
into two different categories. The ﬁrst set of methods deal with feature distributions that may be
different but not due to the distortion of the inputs/features. Denoting the labels/outputs for the source
and target domains as ys and yt respectively  here we have  P r(ys|xs) ≈ P r(yt|xt) but P r(xs) (cid:54)=
P r(xt) – this is sampling bias. The ideas in [19  25  2  5] address this by ‘re-weighting’ the source
instances so as to minimize feature distribution differences between the source and the target. Such
re-weighting schemes do not necessarily correspond to transforming the source and target inputs 
and may simply scale or shift the appropriate loss functions. The central difference among these
approaches is the distance metric used to measure the discrepancy of the feature distributions.
The second set of methods correspond to the case where distributional differences are mainly caused
by feature distortion such as change in pose  lighting  blur and resolution in visual recognition.
Under this scenario  P r(ys|xs) (cid:54)= P r(yt|xt) but P r(˜xs) ≈ P r(˜xt) and the transformed conditional
distributions are close. [26  1  10  14  12] address this problem by learning the same feature trans-
formation on source and target domains to minimize the difference of P r(˜xs) and P r(˜xt) directly.
Our proposed model ﬁts better under this umbrella — where the distributional differences are mainly
caused by feature distortion due to site speciﬁc acquisition and other experimental issues. While
some methods are purely data-driven such as those using geodesic ﬂow [14  12]  backpropagation
[10]) and so on  other approaches estimate the transformation that minimizes distance metrics such
as the Maximum Mean Discrepancy (MMD) [26  1]. To our knowledge  no statistical consistency
results are known for any of the methods that fall in the second set.
Overview: The idea in [1] is perhaps the most closely related to our proposal  but with a few important
differences. First  we relax the condition that the same transformation must be applied to each
domain; instead  we permit domain-speciﬁc transformations. Second  we derive a provably consistent
hypothesis test to check whether the transformation model can indeed correct the shift. We then prove
that the model is consistent when it is correct. These theoretical results apply directly to [1]  which
turns out to be a special case of our framework. We ﬁnd that the extension of our results to [26] is
problematic since that method violates the requirement that the mean differences should be measured
in a valid Reproducing Kernel Hilbert space (RKHS).

3 Model

We ﬁrst present the objective function of our estimation problem and provide a simple algorithm
to compute the unknown parameters λ and β. Recall the deﬁnition of MMD from (1). Given the
kernel K and the source and target inputs xs and xt  we are interested in the MMD between the
“transformed” inputs ˜xs and ˜xt. We are only provided the class of the transformations; m and n
denote the sample sizes of source and target inputs. So our objective function is simply

min
λ∈Ωλ

min
β∈Ωβ

(cid:107)ExtK(g(xt  β) ·) − ExsK(h(xs  λ) ·)(cid:107)H

(2)
where λ ∈ Ωλ and β ∈ Ωβ are the constraint sets of the unknowns. Assume that the parameters are
bounded is reasonable (discussed in Section 4.3)  and their approximations can be easily computed
using certain data statistics. The empirical estimate of the above objective would simply be

K(h(xi

s  λ) ·)||H

(3)

m(cid:88)

i=1

min
λ∈Ωλ

min
β∈Ωβ

(cid:107) 1
m

n(cid:88)

i=1

K(g(xi

t  β) ·) − 1
n

3

Remarks: We note a few important observations about (3) to draw the contrast from (1). The power
of MMD lies in differentiating feature distributions  and the correction factor is entirely dependant
on the choice of the kernel class – a richer one does a better job. Instead  our objective in (3) is
showing that complex distortions can be corrected before applying the kernel in an intra-domain
manner (as we show in Section 4). From the perspective of the complexity of distortions  this strategy
may correspond to a larger hypotheses space compared to the classical MMD setup. This is clearly
beneﬁcial in settings where source and target are related by complex feature distortions.
It may be seen from the structure of the objective in (3) that designing an algorithm for any given
K and G may not be straightforward. We present the estimation procedure for certain widely-used
classes of K and G in Section 4.3. For the remainder of the section  where we present our testing
procedure and describe technical results  we will assume that we can solve the above objective and
the corresponding estimates are denoted by ˆλ and ˆβ.

3.1 Minimal MMD test statistic
Observe that the objective in (3) is based on the assumption that the transformations h(·) ∈ G and
g(·) ∈ G(cid:48) (G and G(cid:48) may be different if desired) are sufﬁcient in some sense for ‘correcting’ the
discrepancy between the source and target inputs. Hence  we need to specify a model checking
task on the recoverability of these transforms  while also concurrently checking the goodness of the
estimates of λ and β. This task will correspond to a hypothesis test where the two hypotheses being
compared are as follows.

H0 : There exists a λ and β such that P r(g(xt  β)) = P r(h(xs  λ)).
HA : There does not exist any such λ and β such that P r(g(xt  β)) = P r(h(xs  λ)).

Since the statistic for testing H0 here needs to measure the discrepancy of P r(g(xt  β)) and
P r(h(xs  λ))  one can simply use the objective from (3). Hence our test statistic is given by
the minimal MMD estimate for a given h ∈ G  g ∈ G(cid:48)  xs  xt and computed at the estimates ˆλ  ˆβ

(ˆλ  ˆβ) := arg min
λ∈Ωλ

min
β∈Ωβ

M(λ  β) := (cid:107) 1
m

K(g(xi

t  β) ·) − 1
n

K(h(xi

s  λ) ·)||H

(4)

m(cid:88)

i=1

n(cid:88)

i=1

We denote the population estimates of the parameters under the null and alternate hypothesis as
(λ0  β0) and (λA  βA). Recall that the MMD corresponds to a statistic  and it has been used for
testing the equality of distributions in earlier works [15]. It is straightforward to see that the true
minimal MMD M∗(λ0  β0) = 0 if and only if H0 is true. Observe that (4) is the empirical (and
hence biased) ‘approximation’ of the true minimal MMD statistic M∗(·) from the objective in (2).
This will be used while presenting our technical results (in Section 4) on the consistency and the
corresponding statistical power guaranteed by this minimal MMD statistic based testing.

Relationship to existing approaches. Hypothesis testing involves transforming the inputs before
comparing their distributions in some RKHS (while we solve for the transformation parameters).
The approach in [15  16] applies the kernel to the input data directly and asks whether or not the
distributions are the same based on the MMD measure. Our approach derives from the intuition
that allowing for the two-step procedure of transforming the inputs ﬁrst  followed by computing
their distance in some RKHS is ﬂexible  and in some sense is more general compared to directly
using MMD (or other distance measures) on the inputs. To see this  consider the simple example
where xs ∼ N (0  1) and xt = xs + 1. A simple application of MMD (from (1)) on the inputs xs
and xt directly will reject the null hypothesis (where the H0 states that the source and target are the
same distributions). Our algorithm allows for a transformation on the source/target and will correct
this discrepancy and accept H0. Further  our proposed model generalizes the approach taken in [1].
Speciﬁcally  their approach is a special case of (3) with h(xs) = WT xs  g(xt) = WT xt (λ and β
correspond to W here) with the constraint that W is orthogonal.
Summary: Overall  our estimation followed by testing procedure will be two-fold. Given xs and
xt  the kernel K and the function spaces G  G(cid:48)  we ﬁrst estimate the unknowns λ and β (described
in Section 4.3). The corresponding statistic M(ˆλ  ˆβ) at the estimates is then compared to a given
signiﬁcance threshold γ. Whenever M(ˆλ  ˆβ) > γ the null H0 is rejected. This rejection simply
indicates that G and/or G(cid:48) are not sufﬁcient in recovering the mismatch of source to target at

4

the Type I error of α. Clearly  the richness of these function classes is central to the power of
the testing procedure. We will further argue in Section 4 that even allowing h(·) and g(·) to be
linear transformations greatly enhances the ability to remove the distorted feature distributions and
reliably test their difference or equivalence. Also the test is non-parametric and handles missing
(systematic/noisy) features among the two distributions of interest (see appendix for more details).

4 Consistency

Building upon the two-fold estimating and testing procedure presented in the previous sections 
we provide several guarantees about the estimation consistency and the power of minimal MMD
based hypothesis testing  both in the asymptotic and ﬁnite sample regimes. The technical results
presented here are applicable for large classes of transformation functions G with fairly weak and
reasonable assumptions on K. Speciﬁcally we consider Holder-continuous h(·) and g(·) functions on
compact sets Ωλ and Ωβ. Like [15]  we have K to be a bounded non-negative characteristic kernel
i.e.  0 ≤ K(x  x(cid:48)) ≤ K ∀x  x(cid:48)  and we assume ∂K to be bounded in a neighborhood of 0. We note
that technical results for an even more general class of kernels are fairly involved and so in this paper
we restrict ourselves to radial basis kernels. Nevertheless  even under the above assumptions our null
hypothesis space is more general than the one considered in [15] because of the extra transformations
that we allow on the inputs. With these assumptions  and the Holder-continuity of h(xs ·) and
g(xt ·)  we assume

(A1)
(A2)

(cid:107)K(h(xs  λ1) ·) − K(h(xs  λ2) ·)(cid:107) ≤ Lhd(λ1  λ2)rh ∀xs; λ1  λ2 ∈ Ωλ
(cid:107)K(g(xt  β1) ·) − K(g(xt  β2) ·)(cid:107) ≤ Lgd(β1  β2)rg
∀xt; β1  β2 ∈ Ωβ

4.1 Estimation Consistency

Observe that the minimization of (3) assumes that the null is true i.e.  the parameter estimates
correspond to H0. Therefore  we discuss consistency in the context of existence of a unique set of
parameters (λ0  β0) that match the distributions of ˜xs and ˜xt perfectly. By inspecting the structure of
the objective in (2) and (3)  we see that the estimates will be asymptotically unbiased. Our ﬁrst set
of results summarized here provide consistency of the estimation whenever the assumptions (A1)
and (A2) hold. This consistency result follows from the convergence of objective. All the proofs are
included in the appendix.
Theorem 4.1 (MMD Convergence). Under H0  (cid:107)ExsK(h(xs  ˆλ) ·) − ExtK(g(xt  ˆβ) ·)(cid:107)H → 0
at the rate  max
Theorem 4.2 (Consistency). Under H0  the estimators ˆλ and ˆβ are consistent.
Remarks: Theorem 4.1 shows the convergence rate of MMD distance between the source and the
target after the transformations are applied. Recall that m and n are the sample sizes of source and
target respectively  and h(xs  ˆλ) and g(xt  ˆβ) are the recovered transformations.

√
log m√
m

(cid:16)√

log n√
n  

(cid:17)

.

4.2 Power of the Hypothesis Test

We now discuss the statistical power of minimal MMD based testing. The next set of results establish
that the testing setup from Section 3.1 is asymptotically consistent. Recall that M∗(·) denotes the
(unknown) expected statistic from (2) while M(·) is its empirical estimate from (4).
Theorem 4.3 (Hypothesis Testing). (a) Whenever H0 is true  with probability at least 1 − α 

0 ≤ M(ˆλ  ˆβ) ≤

2K(m + n) log α−1

mn

√
K√
2
n

+

+

√
K√
2
m

+

(cid:33)

√
K√
2
m
√
K√
m

−

(cid:32)

(cid:115)

4 +

C (g ) +

dλ
2rh

log n

(5)

(cid:33)

log m

(6)

dβ
2rg

(b) Whenever HA is true  with probability at least 1 −  
√
K√
2
n

2K(m + n) log −1

M(ˆλ  ˆβ) ≤ M∗

(λA  βA) +

mn

+

M(ˆλ  ˆβ) ≥ M∗

(λA  βA) −

(cid:114)

(cid:114)

√
K√
n

(cid:32)

(cid:114)

4 +

C (h ) +

5

where C (h ) = log(2|Ωλ|)+log −1 + dλ

rh

log Lh√
K

  and C (g ) = log(2|Ωβ|)+log −1 + dβ

rg

log Lg√
K

n   1√

√
log n√
n  

Remarks: We make a few comments about the theorem. Recall that the constant K is the kernel
bound  and Lh  Lg  rh and rg are deﬁned in (A1)(A2). dλ and dβ are the dimensions of λ and β
spaces respectively. Observe that whenever H0 is true  (5) shows that M(ˆλ  ˆβ) approaches 0 as
the sample size increases. Similarly  under HA the statistic converges to some positive (unknown)
value M∗(λA  βA). Following these observations  Theorem 4.3 basically implies that the statistical
power of our test (described in Section 3.1) increases to 1 as the sample size m  n increases. Except
constants  the upper bounds under both H0 and HA have a rate of max( 1√
m )  while the lower
√
log m√
bound under HA has the rate max(
m ). In the appendix we show that (see Lemma 4.5)
as m  n → ∞  the constants |Ωλ|  |Ωβ| converge to a small positive number  thus removing the
dependence of consistency on these constants.
The dependence on the sizes of search spaces Ωλ and Ωβ may nevertheless make the bounds for
HA loose. In practice  one can choose ‘good’ bound constraints based on some pre-processing on
the source and target inputs (e.g.  comparison of median and modes). The loss in power due to
overestimated Ωλ and Ωβ will be compensated by ‘large enough’ sample sizes. Observe that this
trade-off of sample size versus complexity of hypothesis space is fundamental in statistical testing
and is not speciﬁc to our model. We further investigate this trade-off for certain special cases of
transformations h(·) and g(·) that may be of interest in practice. For instance  consider the scenario
where one of the transformations is identity and the other one is linear in the unknowns. Speciﬁcally 
˜xt = xt and h0(xs  λ0) = φ(xs)T λ0 where φ(·) is some known transformation. Although restrictive 
this scenario is very common in medical data acquisition (refer to Section 1) where the source and
target inputs are assumed to have linear/afﬁne distortions. Within this setting  the assumptions for our
technical results will be satisﬁed whenever φ(xs) is bounded with high probability and with rh = 1
2.
We have the following result for this scenario (Var(·) denotes empirical variance).
Theorem 4.4 (Linear transformation). Under H0  identity g(·) with h = φ(xs)T λ  we have
k=1 Var(xt k) + }. For any   α > 0 and sufﬁciently
Ωλ := {λ;| 1
large sample size  a neighborhood of λ0 is contained in Ωλ with probability at least 1 − α.

s)T λ)(cid:107)2 ≤ 3(cid:80)p

(cid:80)n
i=1 (cid:107)xi

n

t − φ(xi

Observe that subscript k in xt k above denotes the kth dimensional feature of xt. The above result
implies that the search space for λ reduces to a quadratic constraint in the above described example
scenario. Clearly  this reﬁned search region would enhance the statistical power for the test even when
the sample sizes are small (which is almost always the case in population studies). Note that such
reﬁned sets may be computed using ‘extra’ information about the structure of the transformations
and/or input data statistics  there by allowing for better estimation and higher power. Lastly  we point
out that the ideas presented in [16] for a ﬁnite sample testing setting translate to our model as well
but we do not present explicit details in this work.

4.3 Optimization Lower Bounds

We see that it is valid to assume that the feasible set is compact and convex for our purposes
(Theorem 4.4). This immediately allows us to use algorithms that exploit feasible set compactness to
estimate model parameters  for instance  conditional gradient algorithms which have low per iteration
complexity [23]. Even though these algorithms offer practical beneﬁts  with non-convex objective 
it is nontrivial to analyze their theoretical/convergence aspects  and as was noted earlier in Section
3  except for simplistic G  G(cid:48) and K  the minimization in (3) might involve a non-convex objective.
We turn to some recent results which have shown that speciﬁc classes of non-convex problems or
NP-Hard problems can be solved to any desired accuracy using a sequence of convex optimization
problems [33]. This strategy is currently an active area of research and has already shown to provide
impressive performance in practice [3].
Very recently [4] showed that one such class of problems called signomial programming can be solved
using successive relative entropy relaxations. Interestingly  we show that for the widely-used class of
Gaussian kernels  our objective can be optimized using these ideas. For notational simplicity  we do
not transform the targets i.e  ˜xt = xt or g(·) is identity and only allow for linear transformations h(·).
Observe that  with respect to the estimation problem (refer to (3)) this is the same as transforming
both source and target inputs. When K is Gaussian  the objective in (3) with identity g(·) and linear

6

h(·) (λ corresponds to slope and intercept here) can be equivalently written as 

(cid:32)

n(cid:88)

n(cid:88)

i=1

j=1

:= min
λ∈Ωλ

(cid:88)

j

min
λ∈Ωλ

1
n2

K(h(xi

s  λ)  h(xj

s  λ)) − 2
mn

(cid:16)−(cid:16)

1
n2 exp

aT
j λλT ai)

m(cid:88)
n(cid:88)
(cid:17)(cid:17) −(cid:88)

j=1

i=1

i j

K(xi

t  h(xj

2

mn

exp

s  λ))

(cid:16)−(cid:16)

ijλ + c2(cid:17)(cid:17) (7)

bT
ijλλT bij + 2cbT

(cid:33)

(cid:17)

for appropriate aj  bij and c. Denoting γ = λλT   the above objective can be made linear in the
decision variables γ and λ thus putting it in the standard form of signomial optimization. The convex
relaxation of the quadratic equality constraint is γ − λλT (cid:23) 0  hence we seek to solve 

(cid:88)

j

n2 exp (tr(Ajγ)) −(cid:88)

1

i j

min
γ λ

(cid:16)

2

mn

exp

tr(Bijγ) + C T

ijλ + c

s.t. γ − λλT (cid:23) 0

(8)

Clearly the objective is exactly in the form that [4] solves  albeit we also have a convex constraint.
Nevertheless  using their procedure for the unconstrained signomial optimization we can write a
sequence of convex relaxations for this objective. This sequence is hierarchical  in the sense that  as
we go down the sequence  each problem gives tighter bounds to the original nonconvex objective [4].
For our applications  we see that since conﬁdence interval procedure (mentioned earlier) naturally
suggests a good initial point in addition  any generic (local) numerical optimization schemes like
trust region  gradient projection etc. can be used to solve (7) whereas the hierarchy of (8) can be used
in general when one does not have access to a good starting point.

5 Experiments

Design and Overall Goals. We performed evaluations on both synthetic data as well as data from
an AD study. (A) We ﬁrst evaluate the goodness of our estimation procedure and the power of the
minimal MMD based test when the source and target inputs are known transformations of samples
from different distribution families (e.g.  Normal  Laplace). Here  we seek to clearly identify the
inﬂuence of the sample size as well as the effect of the transformations on recoverability. (B) After
these checks  we then apply our proposed model for matching CSF protein levels of 600 subjects.
These biomarkers were collected in two different batches; it is known that the measures for the same
participant (across batches) have high variability [20]. In our data  fortunately  a subset of individuals
have both batch data (the “real” measurement must be similar in both batches) whereas a fraction
of individuals’ CSF is only available in one batch. If we ﬁnd a linear standardization between the

(a)

(d)

(b)

(e)

(c)

(f)

Figure 1: (a b) Acceptance Ratios  (c d) Estimation errors  (e f) Histograms of minimal MMD statistic.

7

Sample Size (Log2 scale)46810Acceptance Rate00.20.40.60.811.2Normal target vs. different sourcesNormal(0 1)Laplace(0 1)Exponential(1)Sample Size (Log2 scale)46810Acceptance Rate00.20.40.60.811.2Models linear in parametersa*x2+b*x+ca*log(|x|)+bSample Size (Log2 scale)24681012L1 Error00.20.40.60.811.2Estimation Errors normal vs. normalSlopeInterceptSample Size (Log2 scale)456789Quartic Mean of estimation error0.511.522.5Estimation error for 2D simulationModel 1  first rowModel 1  second rowModel 2  first rowModel 2  second rowmMMD value00.0050.010.0150.020.025histogram00.20.40.60.81Minimal MMD histogram (128 samples)Nor vs NorNor vs ExpNor vs LapmMMD value00.0050.010.015histogram00.20.40.60.81Minimal MMD histogram (1024 samples)Nor vs NorNor vs ExpNor vs Lapresults

on

synthetic

comes

from different

source

data where
families.

1
samples

summarizes
and

data.

Fig
are Normal

two batches it serves as a gold standard  against which we compare our algorithm which does not
use information about corresponding samples. Note that the standardization trick is unavailable in
multi-center studies; we use this data in this paper simply to make the description of our evaluation
design simpler which  for multi-site data pooling  must be addressed using secondary analyses.
Synthetic
our
the
targets
First  observe that our testing procedure efﬁciently rejects
H0 whenever the targets are not Normal (blue and black
curves in Fig. 1(a)). If the transformation class is beyond
linear (e.g.  log)  the null is efﬁciently rejected as samples
increase (see Fig. 1(b)). Beyond the testing power  Figs.
1(c d) shows the error in the actual estimates  which de-
crease as the sample size increases (with tighter conﬁdence
intervals). The appendix includes additional model details.
To get a better idea about the minimal MMD statistic  we
show its histogram (over multiple bootstrap simulations)
for different targets in Fig 1(e f). The green line here de-
notes the bootstrap signiﬁcance threshold (0.05). In Fig.
1(e f)  the red curve is always to the left of the threshold 
as desired. However  the samples are not enough to reject
the null the black and blue curves; and we will need larger
sample sizes (Fig. 1(f)). If needed  the minimal MMD value can be used to obtain a better threshold.
Overall  these plots show that the minimal MMD based estimation and testing setup robustly removes
the feature distortions and facilitates the statistical test.
AD study. Fig 2 shows the relative errors after correcting the feature distortions between the two
batches in the 12 CSF proteins. The bars correspond to simple linear “standardization” transformation
where we assume we have corresponding sample information (blue) and our minimal MMD based
domain adaptation procedure on sets S1 and S2 (S1: participants available in both batches  S2: all
participants). Our models perform as well as the gold standard (where some subjects have volunteered
CSF sampling for both batches). Speciﬁcally  the trends in Fig 2 indicate that our minimal MMD
based testing procedure is a powerful procedure for conducting analyses on such pooled datasets.
To further validate these observations  we used the ‘trans-
formed’ CSF data from the two batches (our algorithm and
gold standard) and performed a multiple regression to predict
Left and Right Hippocampal Volume (which are known to be
AD markers). Table 1 shows that the correlations (predicted
vs. actual) resulting from the minimal MMD corrected data
are comparable or offer improvements to the alternatives. We
point out that the best correlations are achieved when all the
data is used with minimal MMD (which the gold standard
cannot beneﬁt from). Any downstream prediction tasks we
wish to conduct are independent of the model presented here.

Table 1:
Performance of transformed
(our vs. gold standard) CSF on a regres-
sion task.
Model
None
Linear
M (S1)
M (S2)

Figure 2: Relative error in transformation
estimation between CSF batches.

0.46± 0.15
0.46± 0.15
0.48± 0.15
0.48± 0.15

Right

0.37±0.16
0.37±0.16
0.39± 0.15
0.40± 0.15

Left

6 Conclusions

We presented a framework for kernelized statistical testing on data from multiple sources when the
observed measurements/features have been systematically distorted/transformed. While there is a rich
body of work on kernel test statistics based on the maximum mean discrepancy and other measures 
the ﬂexibility to account for a given class of transformations offers improvements in statistical power.
We analyze the statistical properties of the estimation and demonstrate how such a formulation may
enable pooling datasets from multiple participating sites  and facilitate the conduct of neuroscience
studies with substantially higher sample sizes which may be otherwise infeasible.

Acknowledgments: This work is supported by NIH AG040396  NIH U54AI117924  NSF
DMS1308847  NSF CAREER 1252725  NSF CCF 1320755 and UW CPCP AI117924. The authors
are grateful for partial support from UW ADRC AG033514 and UW ICTR 1UL1RR025011. We
thank Marilyn S. Albert (Johns Hopkins) and Anne Fagan (Washington University at St. Louis) for
discussions at a preclinical Alzheimer’s disease meeting in 2015 (supported by Stay Sharp fund).

8

p1p2p3p4p5p6p7p8p9p10p11p12Relative Error00.050.10.150.20.25Relative error on comparsion to baselineLinear ModelMinimal MMD (S1)Minimal MMD (S2)References
[1] M Baktashmotlagh  M Harandi  B Lovell  and M Salzmann. Unsupervised domain adaptation by domain

invariant projection. In Proceedings of the IEEE ICCV  2013.

[2] S Ben-David  J Blitzer  K Crammer  et al. A theory of learning from different domains. Machine learning 

[3] B Chalise  Y Zhang  and M Amin. Successive convex approximation for system performance optimization

in a multiuser network with multiple mimo relays. In IEEE CAMSAP  2011.

[4] V Chandrasekaran and P Shah. Relative entropy relaxations for signomial optimization. arXiv:1409.7640 

2010.

2014.

[5] C Cortes and M Mohri. Domain adaptation in regression. In Algorithmic Learning Theory  2011.
[6] T Dall  P Gallo  R Chakrabarti  T West  A Semilla  and M Storm. An aging population and growing disease

burden will require alarge and specialized health care workforce by 2025. Health Affairs  2013.

[7] H Daumé III  A Kumar  and A Saha. Frustratingly easy semi-supervised domain adaptation. In Proceedings

of the 2010 Workshop on Domain Adaptation for Natural Language Processing  2010.

[8] P Dollár  C Wojek  B Schiele  and P Perona. Pedestrian detection: A benchmark. In CVPR  2009.
[9] B Fernando  A Habrard  M Sebban  and T Tuytelaars. Unsupervised visual domain adaptation using

subspace alignment. In Proceedings of the IEEE ICCV  2013.

[10] Y Ganin and V Lempitsky. Unsupervised domain adaptation by backpropagation. arXiv:1409.7495  2014.
[11] B Gong  K Grauman  and F Sha. Connecting the dots with landmarks: Discriminatively learning domain-

invariant features for unsupervised domain adaptation. In ICML  2013.

[12] B Gong  Y Shi  F Sha  and K Grauman. Geodesic ﬂow kernel for unsupervised domain adaptation. In

[13] Boqing Gong. Kernel Methods for Unsupervised Domain Adaptation. PhD thesis  Citeseer  2015.
[14] R Gopalan  R Li  and R Chellappa. Domain adaptation for object recognition: An unsupervised approach.

In Proceedings of the IEEE ICCV  2011.

[15] A Gretton  K Borgwardt  M Rasch  B Schölkopf  and A Smola. A kernel two-sample test. JMLR  2012.
[16] A Gretton  K Fukumizu  Z Harchaoui  and B Sriperumbudur. A fast  consistent kernel two-sample test. In

CVPR  2012.

NIPS  2009.

[17] Glioma Meta-analysis Trialists GMT Group. Chemotherapy in adult high-grade glioma: a systematic

review and meta-analysis of individual patient data from 12 randomised trials. The Lancet  2002.

[18] M Haase  R Bellomo  P Devarajan  P Schlattmann  et al. Accuracy of neutrophil gelatinase-associated
lipocalin (ngal) in diagnosis and prognosis in acute kidney injury: a systematic review and meta-analysis.
American Journal of Kidney Diseases  2009.

[19] J Huang  A Gretton  K Borgwardt  B Schölkopf  and A Smola. Correcting sample selection bias by

unlabeled data. In NIPS  2006.

[20] W Klunk  R Koeppe  J Price  T Benzinger  M Devous  et al. The centiloid project: standardizing quantitative

amyloid plaque estimation by pet. Alzheimer’s & Dementia  2015.

[21] W Klunk  R Koeppe  J Price  T Benzinger  et al. The centiloid project: standardizing quantitative amyloid

plaque estimation by pet. Alzheimer’s & Dementia  2015.

[22] A Kumar  A Saha  and H Daume. Co-regularization based semi-supervised domain adaptation. In NIPS 

[23] S Lacoste-Julien  M Jaggi  M Schmidt  and P Pletscher. Block-coordinate frank-wolfe optimization for

structural svms. arXiv:1207.4747  2012.

[24] Qi Li. Literature survey: domain adaptation algorithms for natural language processing. Department of CS

The Graduate Center  The City University of New York  2012.

[25] X Nguyen  M Wainwright  and M Jordan. Estimating divergence functionals and the likelihood ratio by

convex risk minimization. Information Theory  IEEE Transactions on  2010.

[26] S Pan  I Tsang  J Kwok  and Q Yang. Domain adaptation via transfer component analysis. Neural Networks 

[27] V Patel  R Gopalan  R Li  and R Chellappa. Visual domain adaptation: A survey of recent advances. Signal

IEEE Transactions on  2011.

Processing Magazine  IEEE  2015.

[28] B Plassman  K Langa  G Fisher  S Heeringa  et al. Prevalence of dementia in the united states: the aging 

demographics  and memory study. Neuroepidemiology  2007.

[29] K Saenko  B Kulis  M Fritz  and T Darrell. Adapting visual category models to new domains. In ECCV.

[30] D Sejdinovic  B Sriperumbudur  A Gretton  K Fukumizu  et al. Equivalence of distance-based and

rkhs-based statistics in hypothesis testing. The Annals of Statistics  2013.

[31] B Sriperumbudur  K Fukumizu  A Gretton  G Lanckriet  and B Schölkopf. Kernel choice and classiﬁability

for rkhs embeddings of probability distributions. In NIPS  2009.

[32] A Torralba and A Efros. Unbiased look at dataset bias. In CVPR  2011.
[33] L Tunçel. Polyhedral and semideﬁnite programming methods in combinatorial optimization. AMS  2010.
[34] H Vanderstichele  M Bibl  S Engelborghs  N Le Bastard  et al. Standardization of preanalytical aspects
of cerebrospinal ﬂuid biomarker testing for alzheimer’s disease diagnosis: a consensus paper from the
alzheimer’s biomarkers standardization initiative. Alzheimer’s & Dementia  2012.

2010.

2010.

9

,Mehrdad Farajtabar
Nan Du
Manuel Gomez Rodriguez
Isabel Valera
Hongyuan Zha
Le Song
Hao Zhou
Vamsi Ithapu
Sathya Narayanan Ravi
Vikas Singh
Grace Wahba
Sterling Johnson