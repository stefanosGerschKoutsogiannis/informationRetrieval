2019,Online Prediction of Switching Graph Labelings with Cluster Specialists,We address the problem of predicting the labeling of a graph in an online setting when the labeling is changing over time. We present an algorithm based on a specialist approach; we develop the machinery of cluster specialists which probabilistically exploits the cluster structure in the graph. Our algorithm has two variants  one of which surprisingly only requires O(log n) time on any trial t on an n-vertex graph  an exponential speed up over existing methods. We prove switching mistake-bound guarantees for both variants of our algorithm. Furthermore these mistake bounds smoothly vary with the magnitude of the change between successive labelings. We perform experiments on Chicago Divvy Bicycle Sharing data and show that our algorithms significantly outperform an existing algorithm (a kernelized Perceptron) as well as several natural benchmarks.,Online Prediction of Switching Graph Labelings with

Cluster Specialists

Mark Herbster

Department of Computer Science

University College London

London

United Kingdom

m.herbster@cs.ucl.ac.uk

j.robinson@cs.ucl.ac.uk

James Robinson

Department of Computer Science

University College London

London

United Kingdom

Abstract

We address the problem of predicting the labeling of a graph in an online setting
when the labeling is changing over time. We present an algorithm based on a
specialist [11] approach; we develop the machinery of cluster specialists which
probabilistically exploits the cluster structure in the graph. Our algorithm has
two variants  one of which surprisingly only requires O(log n) time on any trial
t on an n-vertex graph  an exponential speed up over existing methods. We
prove switching mistake-bound guarantees for both variants of our algorithm.
Furthermore these mistake bounds smoothly vary with the magnitude of the change
between successive labelings. We perform experiments on Chicago Divvy Bicycle
Sharing data and show that our algorithms signiﬁcantly outperform an existing
algorithm (a kernelized Perceptron) as well as several natural benchmarks.

1 Introduction

We study the problem of predicting graph labelings that evolve over time. Consider the following
game for predicting the labeling of a graph in the online setting. Nature presents a graph G; Nature
queries a vertex i1 2 V = {1  2  . . .   n}; the learner predicts the label of the vertex ˆy1 2 {1  1};
Nature presents a label y1; Nature queries a vertex i2; the learner predicts ˆy2; and so forth. The
learner’s goal is to minimize the total number of mistakes M = |{t : ˆyt 6= yt}|. If Nature is
strictly adversarial  the learner will incur a mistake on every trial  but if Nature is regular or
simple  there is hope that the learner may incur only a few mistakes. Thus  a central goal of
mistake-bounded online learning is to design algorithms whose total mistakes can be bounded relative
to the complexity of Nature’s labeling. This (non-switching) graph labeling problem has been
studied extensively in the online learning literature [16  15  7  34  17]. In this paper we generalize
the setting to allow the underlying labeling to change arbitrarily over time. The learner has no
knowledge of when a change in labeling will occur and therefore must be able to adapt quickly to
these changes.
Consider an example of services placed throughout a city  such as public bicycle sharing stations.
As the population uses these services the state of each station–such as the number of available
bikes–naturally evolves throughout the day  at times gradually and others abruptly  and we might
want to predict the state of any given station at any given time. Since the location of a given station
as well as the state of nearby stations will be relevant to this learning problem it is natural to use a
graph-based approach. Another setting might be a graph of major road junctions (vertices) connected
by roads (edges)  in which one wants to predict whether or not a junction is congested at any given
time. Trafﬁc congestion is naturally non-stationary and also exhibits both gradual and abrupt changes
to the structure of the labeling over time [24].

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

The structure of this paper is as follows. In Section 2 we discuss the background literature. In
Section 3 we present the SWITCHING CLUSTER SPECIALISTS algorithm (SCS)  a modiﬁcation of the
method of specialists [11] with the novel machinery of cluster specialists  a set of specialists that in a
rough sense correspond to clusters in the graph. We consider two distinct sets of specialists  Bn and
Fn  where Bn ⇢F n. With the smaller set of specialists the bound is only larger by factor of log n.
On the other hand  prediction is exponentially faster per trial  remarkably requiring only O(log n)
time to predict. In Section 4 we provide experiments on Chicago Divvy Bicycle Sharing data. In
Section 5 we provide some concluding remarks. All proofs are contained in the technical appendices.

1.1 Notation
We ﬁrst present common notation. Let G = (V  E) be an undirected  connected  n-vertex graph with
vertex set V = {1  2  . . .   n} and edge set E. Each vertex of this graph may be labeled with one of
two states {1  1} and thus a labeling of a graph may be denoted by a vector u 2 {1  1}n where ui
denotes the label of vertex i. The underlying assumption is that we are predicting vertex labels from
a sequence u1  . . .   uT 2 {1  1}n of graph labelings over T trials. The set K := {t 2{ 2  . . .   T} :
ut 6= ut1}[{ 1} contains the ﬁrst trial of each of the |K| “segments” of the prediction problem.
Each segment corresponds to a time period when the underlying labeling is unchanging. The cut-size
of a labeling u on a graph G is deﬁned as G(u) := |{(i  j) 2 E : ui 6= uj}|  i.e.  the number of
edges between vertices of disagreeing labels.
We let rG(i  j) denote the resistance distance (effective resistance) between vertices i and j when the
graph G is seen as a circuit where each edge has unit resistance (e.g.  [26]). The effective resistance
for an unweighted graph G can be written as
u2Rn P(p q)2E

(up  uq)2 : ui  uj = 1

rG(i  j) =

min

1

The resistance diameter of a graph is RG := max
i j2V
labeling u is r

G(u) := P(i j)2E:ui6=uj

rG(i  j). Let n = {µ 2 [0  1]n :Pn

probability simplex. For µ 2 n we deﬁne H(µ) := Pn
For µ  ! 2 n we deﬁne d(µ  !) =Pn
For a vector ! and a set of indices I let !(I) :=Pi2I !i. For any positive integer N we deﬁne
[N ] := {1  2  . . .   N} and for any predicate [PRED] := 1 if PRED is true and equals 0 otherwise.
2 Related Work

i=1 µi log2

µi
!i

rG(i  j). The resistance weighted cut-size of a
i=1 µi = 1} be the n-dimensional
to be the entropy of µ.
to be the relative entropy between µ and !.

i=1 µi log2

1
µi

The problem of predicting the labeling of a graph in the batch setting was introduced as a foundational
method for semi-supervised (transductive) learning. In this work  the graph was built using both the
unlabeled and labeled instances. The seminal work by [3] used a metric on the instance space and then
built a kNN or ✏-ball graph. The partial labeling was then extended to the complete graph by solving
a mincut-maxﬂow problem where opposing binary labels represented sources and sinks. In practice
this method suffered from very unbalanced cuts. Signiﬁcant practical and theoretical advances
were made by replacing the mincut/maxﬂow model with methods based on minimising a quadratic
form of the graph Laplacian. Inﬂuential early results include but are not limited to [39  2  38]. A
limitation of the graph Laplacian-based techniques is that these batch methods–depending on their
implementation–typically require ⇥(n2) to ⇥(n3) time to produce a single set of predictions.
Predicting the labeling of a graph in the online setting was introduced by [20]. The authors proved
bounds for a Perceptron-like algorithm with a kernel based on the graph Laplacian. Since this
work there has been a number of extensions and improvements in bounds including but not limited
to [16  6  15  18  17  32]. Common to all of these papers is that a dominant term in their mistake
bounds is the (resistance-weighted) cut-size.
From a simpliﬁed perspective  the methods for predicting the labeling of a graph (online) split into
two approaches. The ﬁrst approach works directly with the original graph and is usually based on a
graph Laplacian [20  15  17]; it provides bounds that utilize the additional connectivity of non-tree
graphs  which are particularly strong when the graph contains uniformly-labeled clusters of small

2

(resistance) diameter. The drawbacks of this approach are that the bounds are weaker on graphs with
large diameter  and that computation times are slower.
The second approach is to approximate the original graph with an appropriately selected tree or “line”
graph [16  7  6  34]. This enables faster computation times  and bounds that are better on graphs with
large diameters. These algorithms may be extended to non-tree graphs by ﬁrst selecting a spanning
tree uniformly at random [7] and then applying the algorithm to the sampled tree. This randomized
approach induces expected mistake bounds that also exploit the cluster structure in the graph (see
Section 2.2). Our algorithm takes this approach.

2.1 Switching Prediction
In this paper rather than predicting a single labeling of a graph we instead will predict a (switching)
sequence of labelings. Switching in the mistake- or regret-bound setting refers to the problem of
predicting an online sequence when the “best comparator” is changing over time. In the simplest of
switching models the set of comparators is structureless and we simply pay per switch. A prominent
early result in this model is [21] which introduced the ﬁxed-share update which will play a prominent
role in our main algorithm. Other prominent results in the structureless model include but are not
limited to [36  4  12  28  27  5]. A stronger model is to instead prove a bound that holds for any
arbitrary contiguous sequence of trials. Such a bound is called an adaptive-regret bound. This type
of bound automatically implies a bound on the structureless switching model. Adaptive-regret was
introduced in [13]1 other prominent results in this model include [1  5  9].
The structureless model may be generalized by introducing a divergence measure on the set of
comparators. Thus  whereas in the structureless model we pay for the number of switches  in the
structured model we instead pay in the sum of divergences between successive comparators. This
model was introduced in [22]; prominent results include [25  5].
In [12  23  13] meta-algorithms were introduced with regret bounds which convert any “black-box”
online learning algorithm into an adaptive algorithm. Such methods could be used as an approach
to predict switching graph labelings online  however these meta-algorithms introduce a factor of
In the online
O(log T ) to the per-trial time complexity of the base online learning algorithm.
switching setting we will aim for our fastest algorithm to have O(log n) time complexity per trial.
In [18] the authors also consider switching graph label prediction. However  their results are not
directly comparable to ours since they consider the combinatorially more challenging problem of
repeated switching within a small set of labelings contained in a larger set. That set-up was a problem
originally framed in the “experts” setting and posed as an open problem by [10] and solved in [4]. If
we apply the bound in [18] to the case where there is not repeated switching within a smaller set  then
their bound is uniformly and signiﬁcantly weaker than the bounds in this paper and the algorithm
is quite slow requiring ✓(n3) time per trial in a typical implementation. Also contained in [18] is
a baseline algorithm based on a kernel perceptron with a graph Laplacian kernel. The bound of
that algorithm has the signiﬁcant drawback in that it scales with respect to the “worst” labeling in
a sequence of labelings. However  it is simple to implement and we use it as a benchmark in our
experiments.

2.2 Random Spanning Trees and Linearization
Since we operate in the transductive setting where the entire unlabeled graph is presented to the
learner beforehand  this affords the learner the ability to perform any reconﬁguration to the graph
as a preprocessing step. The bounds of most existing algorithms for predicting a labeling on a graph
are usually expressed in terms of the cut-size of the graph under that labeling. A natural approach
then is to use a spanning tree of the original graph which can only reduce the cut-size of the labeling.
The effective resistance between vertices i and j  denoted rG(i  j)  is equal to the probability that
a spanning tree of G drawn uniformly at random (from the set of all spanning trees of G) includes
(i  j) 2 E as one of its n  1 edges (e.g.  [30]). As ﬁrst observed by [6]  by selecting a spanning tree
uniformly at random from the set of all possible spanning trees  mistake bounds expressed in terms of
the cut-size then become expected mistake bounds now in terms of the effective-resistance-weighted
G(u) and thus
cut-size of the graph. That is  if R is a random spanning tree of G then E[R(u)] = r

1However  see the analysis of WML in [29] for a precursory result.

3

2 . On the other hand r

G(u)  G(u). A random spanning tree can be sampled from a graph efﬁciently using a random
r
walk or similar methods (see e.g.  [37]).
To illustrate the power of this randomization consider the simpliﬁed example of a graph with two
cliques each of size n
2   where one clique is labeled uniformly with ‘+1’ and the other ‘-1’ with an
2 “cut” edges between the cliques. This dense graph exhibits two disjoint clusters
additional arbitrary n
and G(u) = n
G(u) = ⇥(1)  since between any two vertices in the opposing
2 edge disjoint paths of length  3 and thus the effective resistance between any
cliques there are n
pair of vertices is ⇥( 1
n ). Since bounds usually scale linearly with (resistance-weighted) cut-size  the
cut-size bound would be vacuous but the resistance-weighted cut-size bound would be small.
We will make use of this preprocessing step of sampling a uniform random spanning tree  as well
as a linearization of this tree to produce a (spine) line-graph  S. The linearization of G to S as
a preprocessing step was ﬁrst proposed by [16] and has since been applied in  e.g.  [7  31]. In
order to construct S  a random-spanning tree R is picked uniformly at random. A vertex of R is
then chosen and the graph is fully traversed using a depth-ﬁrst search generating an ordered list
VL =il1  . . .   il2m+1 of vertices in the order they were visited. Vertices in V may appear multiple
times in VL. A subsequence VL0 ✓ VL is then chosen such that each vertex in V appears only once.
The line graph S is then formed by connecting each vertex in VL0 to its immediate neighbors in
VL0 with an edge. We denote the edge set of S by ES and let t := (ut)  where the cut  is
with respect to the linear embedding S. Surprisingly  as stated in the lemma below  the cut on this
linearized graph is no more than twice the cut on the original graph.
Lemma 1 ([16]). Given a labeling u 2 {1  1}n on a graph G  for the mapping G!R!S
  as
above  we have S(u)  2R(u)  2G(u).
By combining the above observations we may reduce the problem of learning on a graph to that
of learning on a line graph. In particular  if we have an algorithm with a mistake bound of the
form M O (G(u)) this implies we then may give an expected mistake bound of the form
G(u)) by ﬁrst sampling a random spanning tree and then linearizing it as above. One
M O (r
caveat of this however depends on the whether Nature is oblivious or adaptive. If Nature is
oblivious we assume that learner’s predictions have no effect on the labels chosen by Nature (or
equivalently all labelings are chosen beforehand). Conversely if Nature is adaptive then Nature’s
labelings are assumed to be adversarially chosen in response to learner’s predictions. In this paper
we will only state the deterministic mistake bounds in terms of cut-size which will hold for oblivious
and adaptive adversaries  while the expected bounds in terms of resistance-weighted cut-sizes will
hold for an oblivious adversary.

3 Switching Specialists

In this section we present a new method based on the idea of specialists [11] from the prediction
with expert advice literature [29  35  8]. Although the achieved bounds are slightly worse than other
methods for predicting a single labeling of a graph  the derived advantage is that it is possible to
obtain “competitive” bounds with fast algorithms to predict a sequence of changing graph labelings.
Our inductive bias is to predict well when a labeling has a small (resistance-weighted) cut-size. The
complementary perspective implies that the labeling consists of a few uniformly labeled clusters.
This suggests the idea of maintaining a collection of basis functions where each such function is
specialized to predict a constant function on a given cluster of vertices. To accomplish this technically
we adapt the method of specialists [11  27]. A specialist is a prediction function " from an input space
to an extended output space with abstentions. So for us the input space is just V = [n]  the vertices
of a graph; and the extended output space is {1  1  ⇤} where {1  1} corresponds to predicted
labels of the vertices  but ‘⇤’ indicates that the specialist abstains from predicting. Thus a specialist
specializes its prediction to part of the input space and in our application the specialists correspond to
a collection of clusters which cover the graph  each cluster uniformly predicting 1 or 1.
In Algorithm 1 we give our switching specialists method. The algorithm maintains a weight vector
!t over the specialists in which the magnitudes may be interpreted as the current conﬁdence we have
in each of the specialists. The updates and their analyses are a combination of three standard methods:
i) Halving loss updates  ii) specialists updates and iii) (delayed) ﬁxed-share updates.

4

1  p 0  m 0

1  (1  ↵)mp"

|E|

!t " (1  ↵)mp" ˙!t1 " +
!t " "(it))

1  ˙!0 1
|E|

: Specialists set E
input
parameter : ↵ 2 [0  1]
initialize
: !1 1
|E|
for t = 1 to T do
receive it 2 V
set At := {" 2E : "(it) 6= ⇤}
foreach " 2A t do
predict ˆyt sign(P"2At
receive yt 2{ 1  1}
set Yt := {" 2E : "(it) = yt}
if ˆyt 6= yt then
˙!t " 8><>:

0
˙!t1 "
!t "

!t(At)
!t(Yt)

" 2A t \ ¯Yt
" 62 At
" 2Y t

foreach " 2A t do
p" m
m m + 1
˙!t ˙!t1

else

// delayed share update
(1)

// loss update

(2)

Algorithm 1: SWITCHING CLUSTER SPECIALISTS

The loss update (2) zeros the weight components of incorrectly predicting specialists  while the
non-predicting specialists are not updated at all. In (1) we give our delayed ﬁxed-share style update.
A standard ﬁxed share update may be written in the following form:

!t " = (1  ↵) ˙!t1 " +

↵
|E|

.

(3)

Although (3) superﬁcially appears different to (1)  in fact these two updates are exactly the same
in terms of predictions generated by the algorithm. This is because (1) caches updates until the
given specialist is again active. The purpose of this computationally is that if the active specialists
are  for example  logarithmic in size compared to the total specialist pool  we may then achieve an
exponential speedup over (3); which in fact we will exploit.
In the following theorem we will give our switching specialists bound. The dominant cost of switching
on trial t to t + 1 is given by the non-symmetric JE (µt  µt+1) := |{" 2E : µt " = 0  µt+1 " 6= 0}| 
i.e.  we pay only for each new specialist introduced but we do not pay for removing specialists.
Theorem 2. For a given specialist set E  let ME denote the number of mistakes made in predicting
the online sequence (i1  y1)  . . .   (iT   yT ) by Algorithm 1. Then 

ME 

1
⇡1

log |E| +

TXt=1

1
⇡t

log

1

1  ↵

+

|K|1Xi=1

JEµki  µki+1 log |E|

↵

 

(4)

for any sequence of consistent and well-formed comparators µ1  . . .   µT 2 |E| where K :=
{k1 = 1 < ··· < k|K|} :={t2 [T ] : µt 6= µt1}[{ 1}  and ⇡t := µt(Yt).
The bound in the above theorem depends crucially on the best sequence of consistent and well-
formed comparators µ1  . . .   µT . The consistency requirement implies that on every trial there is no
active incorrect specialist assigned “mass” (µt(At \ Yt) = 0). We may eliminate the consistency
requirement by “softening” the loss update (2). A comparator µ 2 |E| is well-formed if 8 v 2 V  
there exists a unique " 2E such that "(v) 6= ⇤ and µ" > 0  and furthermore there exists a ⇡ 2 (0  1]
such that 8" 2E : µ" 2{ 0 ⇡ }  i.e.  each specialist in the support of µ has the same mass ⇡ and
these specialists disjointly cover the input space (V ). At considerable complication to the form of the
bound the well-formedness requirement may be eliminated.
The above bound is “smooth” in that it scales with a gradual change in the comparator. In the next
section we describe the novel specialists sets that we’ve tailored to graph-label prediction so that a
small change in comparator corresponds to a small change in a graph labeling.

5

y (v) := y if l  v  r and "l r

3.1 Cluster Specialists
In order to construct the cluster specialists over a graph G = (V = [n]  E)  we ﬁrst construct a
line graph as described in Section 2.2. A cluster specialist is then deﬁned by "l r
y (·) which maps
V ! {1  1  ⇤} where "l r
y (v) := ⇤ otherwise. Hence cluster
specialist "l r
y (v) corresponds to a function that predicts the label y if vertex v lies between vertices l
and r and abstains otherwise. Recall that by sampling a random spanning tree the expected cut-size
of a labeling on the spine is no more than twice the resistance-weighted cut-size on G. Thus  given
a labeled graph with a small resistance-weighted cut-size with densely interconnected clusters and
modest intra-cluster connections  this implies a cut-bracketed linear segment on the spine will in
expectation roughly correspond to one of the original dense clusters. We will consider two basis sets
of cluster specialists.
Basis Fn: We ﬁrst introduce the complete basis set Fn := {"l r
: l  r 2 [n]  l  r; y 2 {1  1}}.
We say that a set of specialists Cu ✓E✓ 2{1 1 ⇤}n from basis E covers a labeling u 2 {1  1}n if
for all v 2 V = [n] and " 2C u that "(v) 2{ uv  ⇤} and if v 2 V then there exists " 2C u such that
"(v) = uv. The basis E is complete if every labeling u 2 {1  1}n is covered by some Cu ✓E . The
basis Fn is complete and in fact has the following approximation property: for any u 2 {1  1}n
there exists a covering set Cu ✓F n such that |Cu| = S(u) + 1. This follows directly as a line with
k  1 cuts is divided into k segments. We now illustrate the use of basis Fn to predict the labeling of
a graph. For simplicity we illustrate by considering the problem of predicting a single graph labeling
without switching. As there is no switch we will set ↵ := 0 and thus if the graph is labeled with
u 2 {1  1}n with cut-size S(u) then we will need S(u) + 1 specialists to predict the labeling
and thus the comparators may be post-hoc optimally determined so that µ = µ1 = ··· = µT and
there will be S(u) + 1 components of µ each with “weight”
= S(u) + 1 
since there will be only one specialist (with non-zero weight) active per trial. Since the cardinality
of Fn is n2 + n  by substituting into (4) we have that the number of mistakes will be bounded by
(S(u) + 1) log (n2 + n). Note for a single graph labeling on a spine this bound is not much worse
than the best known result [16  Theorem 4]. In terms of computation time however it is signiﬁcantly
slower than the algorithm in [16] requiring ⇥(n2) time to predict on a typical trial since on average
there are ⇥(n2) specialists active per trial.
Basis B1 n: We now introduce the basis Bn which has ⇥(n) specialists and only requires O(log n)
time per trial to predict with only a small increase in bound. The basis is deﬁned as

(S (u)+1)  thus 1

⇡1

y

1

Bp q :=({"p q
1 " p q
1 }
{"p q
1 " p q
1 }[B p b p+q

2 c [B b p+q

2 c+1 q

p = q 
p 6= q

n

2e for n > 2.

and is analogous to a binary tree. We have the following approximation property for Bn := B1 n 
Proposition 3. The basis Bn is complete. Furthermore  for any labeling u 2 {1  1}n there exists
a covering set Cu ✓B n such that |Cu| 2(S(u) + 1)dlog2
From a computational perspective the binary tree structure ensures that there are only ⇥(log n)
specialists active per trial  leading to an exponential speed-up in prediction. A similar set of specialists
were used for obtaining adaptive-regret bounds in [9  23] and data-compression in [33]. In those
works however the “binary tree” structure is over the time dimension (trial sequence) whereas in this
work the binary tree is over the space dimension (graph) and a ﬁxed-share update is used to obtain
adaptivity over the time dimension.2
In the corollary that follows we will exploit the fact that by making the algorithm conservative we
may reduce the usual log T term in the mistake bound induced by a ﬁxed-share update to log log T .
A conservative algorithm only updates the specialists’ weights on trials on which a mistake is made.
Furthermore the bound given in the following corollary is smooth as the cost per switch will be
measured with a Hamming-like divergence H on the “cut” edges between successive labelings 
deﬁned as

H(u  u0) := X(i j)2ES

[ [[ui 6= uj] _ [u0i 6= u0j]] ^ [[ui 6= u0i] _ [uj 6= u0j]] ] .

2An interesting open problem is to try to ﬁnd good bounds and time-complexity with sets of specialists over

both the time and space dimensions.

6

Observe that H(u  u0) is smaller than twice the hamming distance between u and u0 and is often
signiﬁcantly smaller. To achieve the bounds we will need the following proposition  which upper
bounds divergence J by H  a subtlety is that there are many distinct sets of specialists consistent
with a given comparator. For example  consider a uniform labeling on S. One may “cover” this
labeling with a single specialist or alternatively n specialists  one covering each vertex. For the sake
of simplicity in bounds we will always choose the smallest set of covering specialists. Thus we
introduce the following formal deﬁnitions of consistency and minimal-consistency.
Deﬁnition 4. A comparator µ 2 |E| is consistent with the labeling u 2 {1  1}n if µ is well-
formed and µ" > 0 implies that for all v 2 V that "(v) 2{ uv  ⇤}.
Deﬁnition 5. A comparator µ 2 |E| is minimal-consistent with the labeling u 2 {1  1}n if it
is consistent with u and the cardinality of its support set |{µ" : µ" > 0}| is the minimum of all
comparators consistent with u.
Proposition 6. For a linearized graph S  for comparators µ  µ0 2 |Fn| that are minimal-consistent
with u and u0 respectively 

JFn(µ  µ0)  min (2H(u  u0)  S(u0) + 1) .

A proof is given in Appendix C. In the following corollary we summarize the results of the SCS
algorithm using the basis sets Fn and Bn with an optimally-tuned switching parameter ↵.
Corollary 7. For a connected n-vertex graph G and with randomly sampled spine S  the number
of mistakes made in predicting the online sequence (i1  y1)  . . .   (iT   yT ) by the SCS algorithm with
optimally-tuned ↵ is upper bounded with basis Fn by

and with basis Bn by

O0@1 log n +
O0@0@1 log n +
|K|1Xi=1

H(uki  uki+1) (log n + log |K| + log log T )1A
|K|1Xi=1
H(uki  uki+1) (log n + log |K| + log log T )1A log n1A

for any sequence of labelings u1  . . .   uT 2 {1  1}n such that ut it = yt for all t 2 [T ].
Thus the bounds are equivalent up to a factor of log n although the computation times vary dramat-
ically. See Appendix D for a technical proof of these results  and details on the selection of the
switching parameter ↵.
On the lower bound side  tight upper and lower bounds were proven for graph label prediction when
the graph was a tree in [6]. We now give a sketch of a simple argument for a lower bound on the
number of mistakes made for predicting a switching sequence of labelings on S. We ﬁrst describe
how introducing and removing cuts can force mistakes in the simplest case.
Given a single graph-labeling problem on an unlabeled line graph S  an adversary may force ⇥(log n)
mistakes with a resultant cut-size (u) = 1. In the switching case if S is uniformly labelled
((u) = 0) and up to two cuts are introduced  then the learner can be forced to make O(log n)
mistakes. On the other hand if we have cut-size of (u0) = 2 an adversary when a “switch” occurs
can force a single mistake with the outcome that the cut-size (u00) 2{ 0  1  2}.
Now for a switching sequence of graph labelings  u1  . . .   uT   let (ut) ⌧ n for all t. For a
labeling u  S can be divided into (u) + 1 segments of length
(u)+1. Each segment can be made
independent of one another by ﬁxing the boundary vertices between segments. We therefore have
(u) )) mistakes for
(u) + 1 independent learning problems and an adversary can force ⇥(log ( n
every two cuts introduced and 1 mistake for every 2 cuts removed.
While the bounds in Corollary 7 reﬂect the smoothness of the sequence of labelings  we pay O(log n+
log |K| + log log T ) for every cut removed and introduced for basis set Fn  with an additional
logarithmic factor for basis Bn. There is therefore an interesting gap between these bounds and the
sketched lower bound  not least of which caused by the log log T term  which we conjecture should
be possible to remove.

n

7

Table 1: Mean error ± std over 25 iterations on a 404-vertex graph for all algorithms and benchmarks 
and for all ensemble sizes of SCS-F and SCS-B.

Algorithm

1

3

5

SCS-F
SCS-B
Kernel Perceptron
Local
Global
Temporal (Local)
Temporal (Global)

1947 ± 49
1438 ± 32
3326 ± 43
3411 ± 55
4240 ± 44
2733 ± 42
3989 ± 44

1597 ± 32
1198 ± 27

-
-
-
-
-

1475 ± 30
1127 ± 25

-
-
-
-
-

Ensemble Size

9

1364 ± 28
1079 ± 24

-
-
-
-
-

17

33

65

1293 ± 26
1050 ± 23

-
-
-
-
-

1247 ± 21
1032 ± 22

-
-
-
-
-

1218 ± 19
1021 ± 18

-
-
-
-
-

Note that we may avoid the issue of needing to optimally tune ↵ using the following method proposed
by [14] and by [28]. We use a time-varying parameter and on trial t we set ↵t = 1
t+1. We have the
following guarantee for this method  see Appendix E for a proof.
Proposition 8. For a connected n-vertex graph G and with randomly sampled spine S  the SCS
algorithm with bases Fn and Bn in predicting the online sequence (i1  y1)  . . .   (iT   yT ) now with
time-varying ↵ set equal to 1
t+1 on trial t achieves the same asymptotic mistake bounds as in
Corollary 7 with an optimally-tuned ↵  under the assumption that S(u1) P|K|1
JE(µki  µki+1).

i=1

4 Experiments

In this section we present results of experiments on real data. The City of Chicago currently contains
608 public bicycle stations for its “Divvy Bike” sharing system. Current and historical data is
available from the City of Chicago3 containing a variety of features for each station  including
latitude  longitude  number of docks  number of operational docks  and number of docks occupied.
The latest data on each station is published approximately every ten minutes.
We used a sample of 72 hours of data  consisting of three consecutive weekdays in April 2019. The
ﬁrst 24 hours of data were used for parameter selection  and the remaining 48 hours of data were used
for evaluating performance. On each ten-minute snapshot we took the percentage of empty docks of
each station. We created a binary labeling from this data by setting a threshold of 50%. Thus each
bicycle station is a vertex in our graph and the label of each vertex indicates whether that station is
‘mostly full’ or ‘mostly empty’. Due to this thresholding the labels of some ‘quieter’ stations were
observed not to switch  as the percentage of available docks rarely changed. These stations tended to
be on the ‘outskirts’  and thus we excluded these stations from our experiments  giving 404 vertices
in our graph.
Using the geodesic distance between each station’s latitude and longitudinal position a connected
graph was built using the union of a k-nearest neighbor graph (k = 3) and a minimum spanning
tree. For each instance of our algorithm the graph was then transformed in the manner described
in Section 2.2  by ﬁrst drawing a spanning tree uniformly at random and then linearizing using
depth-ﬁrst search.
As natural benchmarks for this setting we considered the following four methods. 1.) For all vertices
predict with the most frequently occurring label of the entire graph from the training data (“Global”).
2.) For each vertex predict with its most frequently occurring label from the training data (“Local”).
3.) For all vertices at any given time predict with the most frequently occurring label of the entire
graph at that time from the training data (“Temporal-Global”) 4.) For each vertex at any given time
predict with that vertex’s label observed at the same time in the training data (“Temporal-Local”). We
also compare our algorithms against a kernel Perceptron proposed by [18] for predicting switching
graph labelings (see Appendix F for details).
Following the experiments of [7] in which ensembles of random spanning trees were drawn and
aggregated by an unweighted majority vote  we tested the effect on performance of using ensem-
bles of instances of our algorithms  aggregated in the same fashion. We tested ensemble sizes in
{1  3  5  9  17  33  65}  using odd numbers to avoid ties.
For every ten-minute snapshot (labeling) we queried 30 vertices uniformly at random (with replace-
ment) in an online fashion  giving a sequence of 8640 trials over 48 hours. The average performance

3

https://data.cityofchicago.org/Transportation/Divvy-Bicycle-Stations-Historical/eq45-8inv

8

+

−

+

−

Figure 1: Left: Mean cumulative mistakes over 25 iterations for all algorithms and benchmarks over 48 hours
(8640 trials) on a 404-vertex graph. A comparison of the mean performance of SCS with bases Fn and Bn
(SCS-F and SCS-B respectively) using an ensemble of size 1 and 65 is shown. Right: An example of two binary
labelings taken from the morning and evening of the ﬁrst 24 hours of data. An ‘orange’ label implies that station
is < 50% full and a ‘black’ label implies that station is  50% full.
over 25 iterations is shown in Figure 1. There are several surprising observations to be made from
our results. Firstly  both SCS algorithms performed signiﬁcantly better than all benchmarks and
competing algorithms. Additionally basis Bn outperformed basis Fn by quite a large margin  despite
having the weaker bound and being exponentially faster. Finally we observed a signiﬁcant increase
in performance of both SCS algorithms by increasing the ensemble size (see Figure 1 and Table 1) 
additional details on these experiments and results of all ensemble sizes are given in Appendix G.
Interestingly when tuning ↵ we found basis Bn to be very robust  while Fn was very sensitive. This
observation combined with the logarithmic per-trial time complexity suggests that SCS with Bn has
promise to be a very practical algorithm.

5 Conclusion

Our primary result was an algorithm for predicting switching graph labelings with a per-trial prediction
time of O(log n) and a mistake bound that smoothly tracks changes to the graph labeling over time. In
the long version of this paper we plan to extend the analysis of the primary algorithm to the expected
regret setting by relaxing our simplifying assumption of the well-formed comparator sequence that is
minimal-consistent with the labeling sequence. From a technical perspective the open problem that
we found most intriguing is to eliminate the log log T term from our bounds. The natural approach to
this would be to replace the conservative ﬁxed-share update with a variable-share update [21]; in our
efforts however we found many technical problems with this approach. On both the more practical
and speculative side; we observe that the specialists sets Bn  and Fn were chosen to “prove bounds”.
In practice we can use any hierarchical graph clustering algorithm to produce a complete specialist
set and furthermore multiple such clusterings may be pooled. Such a pooled set of subgraph “motifs”
could be then be used for example in a multi-task setting (see for example  [27]).

Leaflet	(http://leafletjs.com)

References
[1] D. Adamskiy  W. M. Koolen  A. Chernov  and V. Vovk. A closer look at adaptive regret. In
Proceedings of the 23rd International Conference on Algorithmic Learning Theory  ALT’12 
pages 290–304  2012.

[2] M. Belkin and P. Niyogi. Semi-supervised learning on riemannian manifolds. Machine learning 

56(1-3):209–239  2004.

[3] A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. In
Proceedings of the Eighteenth International Conference on Machine Learning  ICML ’01  pages
19–26  2001.

9

Leaflet	(http://leafletjs.com)

[4] O. Bousquet and M. K. Warmuth. Tracking a small set of experts by mixing past posteriors.

Journal of Machine Learning Research  3(Nov):363–396  2002.

[5] N. Cesa-Bianchi  P. Gaillard  G. Lugosi  and G. Stoltz. Mirror descent meets ﬁxed share (and
feels no regret). In Proceedings of the 25th International Conference on Neural Information
Processing Systems - Volume 1  NIPS ’12  pages 980–988  2012.

[6] N. Cesa-Bianchi  C. Gentile  and F. Vitale. Fast and optimal prediction on a labeled tree. In
Proceedings of the 22nd Annual Conference on Learning Theory  pages 145–156. Omnipress 
2009.

[7] N. Cesa-Bianchi  C. Gentile  F. Vitale  and G. Zappella. Random spanning trees and the
prediction of weighted graphs. Journal of Machine Learning Research  14(1):1251–1284  2013.
[8] N. Cesa-Bianchi and G. Lugosi. Prediction  Learning  and Games. Cambridge University Press 

New York  NY  USA  2006.

[9] A. Daniely  A. Gonen  and S. Shalev-Shwartz. Strongly adaptive online learning. In Proceedings
of the 32nd International Conference on International Conference on Machine Learning -
Volume 37  ICML’15  pages 1405–1411  2015.

[10] Y. Freund. Private communication  2000. Also posted on http://www.learning-theory.org.
[11] Y. Freund  R. E. Schapire  Y. Singer  and M. K. Warmuth. Using and combining predictors
that specialize. In Proceedings of the Twenty-ninth Annual ACM Symposium on Theory of
Computing  STOC ’97  pages 334–343  1997.

[12] A. Gyorgy  T. Linder  and G. Lugosi. Efﬁcient tracking of large classes of experts. IEEE

Transactions on Information Theory  58(11):6709–6725  Nov 2012.

[13] E. Hazan and C. Seshadhri. Adaptive algorithms for online decision problems. Electronic

Colloquium on Computational Complexity (ECCC)  14(088)  2007.

[14] M. Herbster. Tracking the best expert II. Unpublished manuscript  1997.
[15] M. Herbster and G. Lever. Predicting the labelling of a graph via minimum $p$-seminorm

interpolation. In COLT 2009 - The 22nd Conference on Learning Theory  2009.

[16] M. Herbster  G. Lever  and M. Pontil. Online prediction on large diameter graphs. In Proceedings
of the 21st International Conference on Neural Information Processing Systems  NIPS ’08 
pages 649–656  2008.

[17] M. Herbster  S. Pasteris  and S. Ghosh. Online prediction at the limit of zero temperature. In
Proceedings of the 28th International Conference on Neural Information Processing Systems -
Volume 2  NIPS’15  pages 2935–2943  2015.

[18] M. Herbster  S. Pasteris  and M. Pontil. Predicting a switching sequence of graph labelings.

Journal of Machine Learning Research  16(1):2003–2022  2015.

[19] M. Herbster and M. Pontil. Prediction on a graph with a perceptron. In Proceedings of the 19th
International Conference on Neural Information Processing Systems  NIPS’06  pages 577–584 
2006.

[20] M. Herbster  M. Pontil  and L. Wainer. Online learning over graphs. In Proceedings of the 22nd

International Conference on Machine Learning  ICML ’05  pages 305–312  2005.

[21] M. Herbster and M. Warmuth. Tracking the best expert. Machine Learning  32(2):151–178 

1998.

[22] M. Herbster and M. K. Warmuth. Tracking the best linear predictor. Journal of Machine

Learning Research  1:281–309  2001.

[23] K. Jun  F. Orabona  S. Wright  and R. Willett. Improved strongly adaptive online learning using
coin betting. In Proceedings of the 20th International Conference on Artiﬁcial Intelligence and
Statistics  volume 54 of Proceedings of Machine Learning Research  pages 943–951. PMLR 
2017.

10

[24] B. S. Kerner. Experimental features of self-organization in trafﬁc ﬂow. Phys. Rev. Lett. 

81:3797–3800  1998.

[25] J. Kivinen  A. Smola  and R. Williamson. Online learning with kernels. Trans. Sig. Proc. 

52(8):2165–2176  2004.

[26] D. J. Klein and M. Randi´c. Resistance distance. Journal of mathematical chemistry  12(1):81–95 

1993.

[27] W. M. Koolen  D. Adamskiy  and M. K. Warmuth. Putting bayes to sleep. In Proceedings of the
25th International Conference on Neural Information Processing Systems - Volume 1  NIPS ’12 
pages 135–143  2012.

[28] W. M. Koolen and S. Rooij. Combining expert advice efﬁciently. In 21st Annual Conference on

Learning Theory - COLT 2008  pages 275–286  2008.

[29] N. Littlestone and M. K. Warmuth. The weighted majority algorithm.

Computation  108(2):212–261  1994.

Information and

[30] R. Lyons and Y. Peres. Probability on Trees and Networks. Cambridge University Press  New

York  NY  USA  1st edition  2017.

[31] O. H. M. Padilla  J. Sharpnack  J. G. Scott  and R. J. Tibshirani. The dfs fused lasso: Linear-time

denoising over general graphs. Journal of Machine Learning Research  18(1):1–36  2018.

[32] A. Rakhlin and K. Sridharan. Efﬁcient online multiclass prediction on graphs via surrogate
losses. In Proceedings of the 20th International Conference on Artiﬁcial Intelligence and
Statistics  AISTATS 2017  pages 1403–1411  2017.

[33] J. Veness  M. White  M. Bowling  and A. György. Partition tree weighting. In Data Compression

Conference  pages 321–330. IEEE  2013.

[34] F. Vitale  N. Cesa-Bianchi  C. Gentile  and G. Zappella. See the tree through the lines: The
shazoo algorithm. In Advances in Neural Information Processing Systems 23  pages 1584–1592 
2011.

[35] V. Vovk. Aggregating strategies. In Proceedings of the Third Annual Workshop on Computa-

tional Learning Theory  COLT ’90  pages 371–386  1990.

[36] V. Vovk. Derandomizing stochastic prediction strategies. Machine Learning  35(3):247–282 

1999.

[37] D. B. Wilson. Generating random spanning trees more quickly than the cover time.

In
Proceedings of the Twenty-eighth Annual ACM Symposium on Theory of Computing  STOC ’96 
pages 296–303  1996.

[38] D. Zhou  O. Bousquet  T. N. Lal  J. Weston  and B. Schölkopf. Learning with local and
global consistency. In Proceedings of the 16th International Conference on Neural Information
Processing Systems  NIPS ’03  pages 321–328  2003.

[39] X. Zhu  Z. Ghahramani  and J. D. Lafferty. Semi-supervised learning using gaussian ﬁelds and
harmonic functions. In Proceedings of the Twentieth International Conference on International
Conference on Machine Learning  ICML ’03  pages 912–919  2003.

11

,Mark Herbster
James Robinson