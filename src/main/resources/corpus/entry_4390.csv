2015,Predtron: A Family of Online Algorithms for General Prediction Problems,Modern prediction problems arising in multilabel learning and learning to rank pose unique challenges to the classical theory of supervised learning. These problems have large prediction and label spaces of a combinatorial nature and involve sophisticated loss functions. We offer a general framework to derive mistake driven online algorithms and associated loss bounds.  The key ingredients in our framework are a general loss function  a general vector space representation of predictions  and a notion of margin with respect to a general norm. Our general algorithm  Predtron  yields the perceptron algorithm and its variants when instantiated on classic problems such as binary classification  multiclass classification  ordinal regression  and multilabel classification.  For multilabel ranking and subset ranking  we derive novel algorithms  notions of margins  and loss bounds. A simulation study confirms the behavior predicted by our bounds and demonstrates the flexibility of the design choices in our framework.,Predtron: A Family of Online Algorithms for General

Prediction Problems

Prateek Jain

Microsoft Research  INDIA

prajain@microsoft.com

Nagarajan Natarajan

University of Texas at Austin  USA

naga86@cs.utexas.edu

Ambuj Tewari

University of Michigan  Ann Arbor  USA

tewaria@umich.edu

Abstract

Modern prediction problems arising in multilabel learning and learning to rank
pose unique challenges to the classical theory of supervised learning. These prob-
lems have large prediction and label spaces of a combinatorial nature and involve
sophisticated loss functions. We offer a general framework to derive mistake
driven online algorithms and associated loss bounds. The key ingredients in our
framework are a general loss function  a general vector space representation of
predictions  and a notion of margin with respect to a general norm. Our general
algorithm  Predtron  yields the perceptron algorithm and its variants when instan-
tiated on classic problems such as binary classiﬁcation  multiclass classiﬁcation 
ordinal regression  and multilabel classiﬁcation. For multilabel ranking and sub-
set ranking  we derive novel algorithms  notions of margins  and loss bounds. A
simulation study conﬁrms the behavior predicted by our bounds and demonstrates
the ﬂexibility of the design choices in our framework.

1

Introduction

Classical supervised learning problems  such as binary and multiclass classiﬁcation  share a number
of characteristics. The prediction space (the space in which the learner makes predictions) is often
the same as the label space (the space from which the learner receives supervision). Because di-
rectly learning discrete valued prediction functions is hard  one learns real-valued or vector-valued
functions. These functions generate continuous predictions that are converted into discrete ones
via simple mappings  e.g.  via the ‘sign’ function (binary classiﬁcation) or the ‘argmax’ function
(multiclass classiﬁcation). Also  the most commonly used loss function is simple  viz. the 0-1 loss.
In contrast  modern prediction problems  such as multilabel learning  multilabel ranking  and subset
ranking do not share these characteristics. In order to handle these problems  we need a more general
framework that offers more ﬂexibility. First  it should allow for the possibility of having different
label space and prediction space. Second  it should allow practitioners to use creative  new ways
to map continuous  vector-valued predictions to discrete ones. Third  it should permit the use of
general loss functions.
Extensions of the theory of classical supervised learning to modern predictions problems have be-
gun. For example  the work on calibration dimension [1] can be viewed as extending one aspect of
the theory  viz. that of calibrated surrogates and consistent algorithms based on convex optimiza-
tion. This paper deals with the extension of another interesting part of classical supervised learning:
mistake driven algorithms such as perceptron (resp. winnow) and their analyses in terms of `2 (resp.
`1) margins [2  Section 7.3].

1

We make a number of contributions. First  we provide a general framework (Section 2) whose
ingredients include an arbitrary loss function and an arbitrary representation of discrete predic-
tions in a continuous space. The framework is abstract enough to be of general applicability but
it offers enough mathematical structure so that we can derive a general online algorithm  Predtron
(Algorithm 1)  along with an associated loss bound (Theorem 1) under an abstract margin condi-
tion (Section 2.2). Second  we show that our framework uniﬁes several perception-like algorithms
for classical problems such as binary classiﬁcation  multiclass classiﬁcation  ordinal regression  and
multilabel classiﬁcation (Section 3). Even for these classical problems  we get some new results  for
example  when the loss function treats labels asymmetrically or when there exists a ‘reject’ option
in classiﬁcation. Third  we apply our framework to two modern prediction problems: subset rank-
ing (Section 4) and multilabel ranking (Section 5). In both of these problems  the prediction space
(rankings) is different from the supervision space (set of labels or vector of relevance scores). For
these two problems  we propose interesting  novel notions of correct prediction with a margin and
derive mistake bounds under a loss derived from NDCG  a ranking measure that pays more attention
to the performance at the top of a ranked list. Fourth  our techniques based on online convex opti-
mization (OCO) can effortlessly incorporate notions of margins w.r.t. non-Euclidean norms  such as
`1 norm  group norm  and trace norm. Such ﬂexibility is important in modern prediction problems
where the learned parameter can be a high dimensional vector or a large matrix with low group or
trace norm. Finally  we test our theory in a simulation study (Section 6) dealing with the subset
ranking problem showing how our framework can be adapted to a speciﬁc prediction problem. We
investigate different margin notions as we vary two key design choices in our abstract framework:
the map used to convert continuous predictions into discrete ones  and the choice of the norm used
in the deﬁnition of margin.

Related Work. Our general algorithm is related to the perceptron and online gradient descent al-
gorithms used in structured prediction [3  4]. But  to the best of knowledge  our emphasis on keeping
label and prediction spaces possibly distinct  our use of a general representation of predictions  and
our investigation of generalized notions of margins are all novel. The use of simplex coding in mul-
ticlass problems [5] inspired the use of maximum similarity/minimum distance decoding to obtain
discrete predictions from continuous ones. Our proofs use results about Online Gradient Descent
and Online Mirror Descent from the Online Convex Optimization literature [6].

2 Framework and Main Result

The key ingredients in classic supervised learning are an input space  an output space and a loss
function. In this paper  the input space X2 Rp will always be some subset of a ﬁnite dimensional
Euclidean space. Our algorithms maintain prediction functions as a linear combination of the seen
inputs. As a result  they easily kernelize and the theory extends  in a straightforward way to the case
when the input space is a  possibly inﬁnite dimensional  reproducing kernel Hilbert space (RKHS).

2.1 Labels  Prediction  and Scores

We will distinguish between the label space and the prediction space. The former is the space where
the training labels come from whereas the latter is the space where the learning algorithm has to
make predictions in. Both spaces will be assumed to be ﬁnite. Therefore  without any loss of
generality  we can identify the label space with [`] = {1  . . .  `} and the prediction space with [k]
where `  k are positive  but perhaps very large  integers. A given loss function L : [k] ⇥ [`] ! R+
maps a prediction  2 [k] and a label y 2 [`] to a non-negative loss L(  y). The loss L can
equivalently be thought of as a k ⇥ ` matrix with loss values as entries. Deﬁne the set of correct
predictions for a label y as ⌃y = {y 2 [k]
: L(y  y) = 0}. We assume that  for every label
y  the set ⌃y is non-empty. That is  every column of the loss matrix has a zero entry. Also  let
cL = minL( y)>0 L(  y) and CL = max y L(  y) be the minimum (non-zero) and maximum
entries in the loss matrix.
In an online setting  the learner will see a stream of examples (X⌧   Y⌧ ) 2X⇥ [`]. Learner will
predict scores using a linear predictor W 2 Rd⇥p. However  the predicted scores W X⌧ will be
in Rd  not in the prediction space [k]. So  we need a function pred : Rd ! [k] to convert scores
into actual predictions. We will assume that there is a unique representation rep() 2 Rd of each

2

prediction  such that k rep()k2 = 1 for all . Given this  a natural transformation of scores into
prediction is given by the following maximum similarity decoding:
hrep()  ti  

(1)

pred(t) 2 argmax
2[k]

where ties in the “argmax” can be broken arbitrarily. There are some nice consequences of the
deﬁnition of pred above. First  because k rep()k2 = 1  maximum similarity decoding is equivalent
to nearest neighbor decoding: pred(t) 2 argmin k rep()  tk2. Second  we have a homogeneity
property: pred(ct) = pred(t) if c > 0. Third  rep serves as an “inverse” of pred in the following
sense. We have  pred(rep()) =  for all . Moreover  rep(pred(t)) is more similar to t than the
representation of any other prediction :

8t 2 Rd  2 [k]  hrep(pred(t))  ti  hrep()  ti .

In view of these facts  we will use pred1() and rep() interchangeably. Using pred  the loss
function L can be extended to a function deﬁned on Rd ⇥ [k] as:

L(t  y) = L(pred(t)  y).

With a little abuse of notation  we will continue to denote this new function also by L.

2.2 Margins

We say that a score t is compatible with a label y if the set of ’s that achieve the maximum in the

deﬁnition (1) of pred is exactly ⌃y. That is  argmax2[k] ⌦pred1()  t↵ =⌃ y. Hence  for any
y 2 ⌃y  /2 ⌃y  we have⌦pred1(y)  t↵ >⌦pred1()  t↵. The notion of margin makes this

requirement stronger. We say that a score t has a margin > 0 on label y  iff t is compatible with
y and

8y 2 ⌃y  /2 ⌃y  ⌦pred1(y)  t↵ ⌦pred1()  t↵ + 

Note that margin scales with t: if t has margin  on y then ct has margin c on y for any positive c.
If we are using linear predictions t = W X  we say that W has margin  on (X  y) iff t = W X has
margin  on y. We say that W has margin  on a dataset (X1  y1)  . . .   (Xn  yn) iff W has margin 
on (X⌧   y⌧ ) for all ⌧ 2 [n]. Finally  a dataset (X1  y1)  . . .   (Xn  yn) is said to be linearly separable
with margin  if there is a unit norm1 W ? such that W ? has margin  on (X1  y1)  . . .   (Xn  yn).

2.3 Algorithm

Just like the classic perceptron algorithm  our generalized perceptron algorithm (Algorithm 1) is
mistake driven. That is  it only updates on round when a mistake  i.e.  a non-zero loss  is incurred.
On a mistake round  it makes a rank-one update of the form W⌧ +1 = W⌧  g⌧ · X>⌧ where g⌧ 2
Rd  X⌧ 2 Rp. Therefore  W⌧ always has a representation of the formPi giX>i . The prediction
on a fresh input X is given byPi gi hXi  Xi which means the algorithm  just like the original
perceptron  can be kernelized.
We will give a loss bound for the algorithm using tools from Online Convex Optimization (OCO).
Deﬁne the function  : Rd ⇥ [`] ! R as

(t  y) = max

2[k] L(  y) ⌦pred1(y)  pred1()  t↵

(2)

where y 2 ⌃y is an arbitrary member of ⌃y. For any y  (·  y) is a point-wise maximum of linear
functions and hence convex. Also   is non-negative: choose  = y to lower bound the maximum.
The inner product part vanishes and the loss L(y  y) vanishes too because y 2 ⌃y. Given the
deﬁnition of   Algorithm 1 can be described succinctly as follows. At round ⌧  if L(W⌧ X⌧   Y⌧ ) >
0  then W⌧ +1 = W⌧  ⌘rW (W X⌧   Y⌧ )  otherwise W⌧ +1 = W⌧ .

1Here  we mean that the Frobenius norm kW ?kF equals 1. Of course  the notion of margin can be gener-
alized to any norm including the entry-based `1 norm kWk1 and the spectrum-based `1 norm kWkS(1) (also
called the nuclear or trace norm). See Appendix B.2.

3

Algorithm 1 Predtron: Extension of the Perceptron Algorithm to General Prediction Problems
1: W1 0
2: for ⌧ = 1  2  . . . do
Receive X⌧ 2 Rp
3:
Predict ⌧ = pred(W⌧ X⌧ ) 2 [k]
4:
Receive label y⌧ 2 [`]
5:
if L(⌧   y⌧ ) > 0 then
6:
7:
(t  y) = (W⌧ X⌧   y⌧ )
˜⌧ = argmax2[k] L(  y) ⌦pred1(y)  pred1()  t↵ 2 [k]
8:
r⌧ = (pred1(˜⌧ )  pred1(y)) · X>⌧ 2 Rd⇥p
9:
10:
W⌧ +1 = W⌧  ⌘r⌧
11:
12:
W⌧ +1 = W⌧
end if
13:
14: end for

else

Theorem 1. Suppose the dataset (X1  y1)  . . .   (Xn  yn) is linearly separable with margin . Then
the sequence W⌧ generated by Algorithm 1 with ⌘ = cL/(4R2) satisﬁes the loss bound 

L(W⌧ X⌧   y⌧ ) 

4R2C2
L
cL2

nX⌧ =1

where kX⌧k2  R for all ⌧.
Note that the bound above assumes perfect linear separability. However  just the classic perceptron 
the bound will degrade gracefully when the best linear predictor does not have enough margin on
the data set.
The Predtron algorithm has some interesting variants  two of which we consider in the appendix. A
loss driven version  Predtron.LD  enjoys a loss bound that gets rid of the CL/cL factor in the bound
above. A version  Predtron.Link  that uses link functions to deal with margins deﬁned with respect
to non-Euclidean norms is also considered.

3 Relationship to Existing Results

It is useful to discuss a few concrete applications of the abstract framework introduced in the last
section. Several existing loss bounds can be readily derived by applying our bound for the general-
ized perceptron algorithm in Theorem 1. In some cases  our framework yields a different algorithm
than existing counterparts  yet admitting identical loss bounds  up to constants.

Binary Classiﬁcation. We begin with the classical perceptron algorithm for binary classiﬁcation
(i.e.  ` = 2) [7]: L0-1(  y) = 1 if  6= y or 0 otherwise. Letting rep() be +1 for the positive
class and 1 for the negative class  predictor vector W⌧ 2 R1⇥p  and thus pred(t) = sign(t) 
Algorithm 1 reduces to the original perceptron algorithm; Theorem 1 yields identical mistake bound
on a linearly separable dataset with margin  (if the classical margin is   ours works out to be
2)  i.e. Pn
2 . We can also easily incorporate asymmetric losses. Let
L↵(  y) = ↵y  if  6= y and 0 otherwise. We then have the following result.
Corollary 2. Consider the perceptron with weighted loss L↵. Assume ↵1  ↵2 without loss of
generality. Then the sequence W⌧ generated by Algorithm 1 satisﬁes the weighted mistake bound 

⌧ =1 L0-1(W⌧ X⌧   y⌧ )  R2

L↵(W⌧ X⌧   y⌧ ) 

4R2↵2
1
22 .
↵2

nX⌧ =1

We are not aware of such results for weighted loss. Previous work [8] studies perceptrons
with uneven margins  and the loss bound there only implies a bound on the unweighted loss:
In a technical note  R¨atsch and Kivinen [9] provide a mistake bound of the

⌧ =1 L0-1(t⌧   y⌧ ).

Pn

4

⌧ =1 L↵(W⌧ X⌧   y⌧ )  R2

42   but for the speciﬁc choice of weights ↵1 = a2

form (without proof):Pn
and ↵2 = (1  a)2 for any a 2 [0  1].
Another interesting extension is obtained by allowing the predictions to have a REJECT option. De-
ﬁne LREJ(REJECT  y) = y and LREJ(  y) = L0-1(  y) otherwise. Assume 1  1  2 > 0 with-
out loss of generality. Choosing the standard basis vectors in R2 to be rep() for the positive and the
negative classes  and rep(REJECT) = 1p2P2{1 2} rep()  we obtainPn
⌧ =1 LREJ(W⌧ X⌧   y⌧ ) 

(See Appendix C.1).

4R22
1
22
2

Multiclass Classiﬁcation. Each instance is assigned exactly one of m classes (i.e.  ` = m).
Extending binary classiﬁcation  we choose the standard basis vectors in Rm to be rep() for
the m classes. The learner predicts score t 2 Rm using the predictor W 2 Rm⇥p. So 
pred(t) = argmaxi ti. Let wj denote the jth row of W (corresponding to label j). The deﬁni-
tion of margin becomes:

which is identical to the multiclass margin studied earlier [10]. For the multiclass 0-1 loss L0-1  we
recover their bound  up to constants2. Moreover  our surrogate  for L0-1:

hwy  Xi  max

j6=y hwj  Xi  

(t  y) = max0  1 + max

6=y

t  ty 

matches the multiclass extension of the Hinge loss studied by [11]. Finally  note that it is straight-
forward to obtain loss bounds for multiclass perceptron with REJECT option by naturally extending
the deﬁnitions of rep and LREJ for the binary case.

Ordinal Regression. The goal is to assign ordinal classes (such as ratings) to a set of objects
{X1  X2  . . .} described by their features Xi 2 Rp.
In many cases  precise rating information
may not be available  but only their relative ranks; i.e.  the observations consist of object-rank pairs
(X⌧   y⌧ ) where y⌧ 2 [`]. Y is totally-ordered with “>” relation  which in turn induces a partial
ordering on the objects (Xj is preferred to Xj0 if yj > yj0  Xj and Xj0 are not comparable if
yj = yj0). For the ranking loss L(  y) = |  y|  the PRank perceptron algorithm [12] enjoys the
boundPn
⌧ =1 L(⌧⌧   y⌧ )  (`  1)(R2 + 1)/˜2  where ˜ is a certain rank margin. By a reduction
to multi-class classiﬁcation with ` classes  Algorithm 1 achieves the loss bound 4(`  1)2R2/2
(albeit  for a different margin ).

Multilabel Classiﬁcation. This setting generalizes multiclass classiﬁcation in that instances are
assigned subsets of m classes rather than unique classes  i.e.  ` = 2m. The loss function L of
interest may dictate the choice of rep and in turn pred. For example  consider the following subset
losses that treat labels as well as predictions as subsets: (i) Subset 0-1 loss: LIsErr(  y) = 1 if
 = y or 0 otherwise; (ii) Hamming loss: LHam(  y) = | [ y||  \ y|  and (ii) Error set
size: LErrSetSize(  y) = {(r  s) 2 y ⇥ ([m] \ y) : r 62   s 2 }. A natural choice of rep then
is the subset indicator vector in {+1 1}d  where d = m = log `  which can be expressed as
rep() = 1pmPj2 ej Pj62 ej (where ej’s are the standard basis vectors in Rm). The learner
predicts score t 2 Rm using a matrix W 2 Rm⇥p. Note that pred(t) = sign(t)  where sign is
applied component-wise. The number of predictions is 2m  but we show in Appendix C.2 that the
surrogate (2) and its gradient can be efﬁciently computed for all of the above losses.

4 Subset Ranking

In subset ranking [13]  the task is to learn to rank a number of documents in order of their relevance to
a query. We will assume  for simplicity  that the number of documents per query is constant that we
denote by m. The input space is a subset of Rm⇥p0 that we can identify with Rp for p = mp0. Each
row of an input matrix corresponds to a p0-dimensional feature vector derived jointly using the query
2Perceptron algorithm in [10] is based on a slightly different loss deﬁned as LErrSet(t  y) = 1 if |{r 6= y :
tr  ty}| > 0 or 0 otherwise (where t = W X). This loss upper bounds L0-1 (because of the way ties are
handled  there can be rounds when L0-1 is 0  but LErrSet is 1).

5

real valued function that is applied entry-wise to . The normalization Z =pPm

and one of the documents associated with it. The predictions  are all m! permutations of degree m.
The most natural (but by no means the only one) representation of permutations is to set rep() =
/Z where (i) is the position of the document i in the predicted ranking and the normalization
Z ensures that rep() is a unit vector. Note that the dimension d of this representation is equal to m.
The minus sign in this representation ensures that pred(t) outputs a permutation that corresponds to
sorting the entries of t in decreasing order  a common convention in existing work. A more general
representation is obtained by setting rep() = f ()/Z where f : R ! R is a strictly decreasing
i=1 f 2(i) ensures
that k rep()k2 = 1. To convert an input matrix X 2 Rp (p = mp0) into a score vector t 2 Rm 
it seems that we need to learn a matrix W 2 Rm⇥mp0. However  a natural permutation invariance
requirement (if the documents associated are presented in a permuted fashion  the output scores
should also get permuted in the same way) reduces the dimensionality of W to p0 (see  e.g.  [14] for
more details). Thus  given a vector w 2 Rp0 we get the score vector as t = Xw. The label space
consists of relevance score vectors y 2{ 0  1  . . .   Ymax}m where Ymax is typically between 1 and
4 (yielding 2 to 5 grades of relevance). Note that the prediction space (of size k = m!) is different
from the label space (of size ` = (Ymax + 1)m).
A variety of loss functions have been used in subset ranking. For multigraded relevance judgments 

log2(1+(i))/Z(y)
a very popular choice is NDCG which is deﬁned as N DCG(  y) = Pm
where Z(y) is a normalization constant ensuring NDCG stays bounded by 1. To convert it into a
loss we deﬁne LNDCG = 1  N DCG. Note that any permutation that sorts y in decreasing order
gets zero LNDCG. One might worry that the computation of the surrogate deﬁned in (2) and its
gradient might require an enumeration of m! permutations. The next lemma allays such a concern.
Lemma 3. When L = LNDCG and rep() is chosen as above  the computation of the surrogate (2) 
as well as its gradient  can be reduced to solving a linear assignment problem and hence can be
done in O(m3) time.

2y(i)1

i=1

We now give a result explaining what it means for a score vector t to have a margin  on y when we
use a representation of the form described above. Without loss of generality  we may assume that y
is sorted in decreasing order of relevance judgements.
Lemma 4. Suppose rep() = f ()/Z for a strictly decreasing function f : R ! R and Z =
pPm
i=1 f 2(i). Let y be a non-constant relevance judgement vector sorted in decreasing order.
Suppose i1 < i2  . . . < iN   N  1 are the positions where the relevance drops by a grade or more
(i.e.  y(ij) < y(ij  1)). Then t has a margin  on y iff t is compatible with y and  for j 2 [N ] 

tij1  tij +

Z

f (ij  1)  f (ij)
where we deﬁne i0 = 1  iN +1 = m + 1 to handle boundary cases.
Note that if we choose f (i) = i↵ ↵ > 1 then f (ij  1)  f (ij) = O(i↵1
) for large ij. In
that case  the margin condition above requires less separation between documents with different
relevance scores down the list (when viewed in decreasing order of relevance scores) than at the top
of the list. We end this section with a loss bound for LNDCG under a margin condition.
Corollary 5. Suppose L = LNDCG and rep() is as in Lemma 4. Then  assuming the dataset is
linearly separable with margin   the sequence generated by Algorithm 1 with line 9 replaced by

j

satisﬁes

r⌧ = X>⌧ (pred1(˜⌧ )  pred1(y)) 2 Rp0⇥1
nX⌧ =1

LNDCG(X⌧ w⌧   y⌧ ) 

2Ymax+3 · m2 log2

2

2(2m) · R2

where kX⌧kop  R.
Imagine a subset
Note that the result above uses the standard `2-norm based notion of margin.
ranking problem  where only a small number of features are relevant.
It is therefore natural to
consider a notion of margin where the weight vector that ranks everything perfectly has low group `1
norm  instead of low `2 norm. The `1 margin also appears in the analysis of AdaBoost [2  Deﬁnition

6

6.2]. We can use a special case of a more general algorithm given in the appendix (Appendix B.2 
Algorithm 3). Speciﬁcally  we replace line 10 with the step w⌧ +1 = (r )1 (r (w⌧ )  r⌧ )
where (w) = 1
r. We set r = log(p0)/(log(p0)  1). The mapping r and its inverse can
both be easily computed (see  e.g.  [6  p. 145]).
Corollary 6. Suppose L = LNDCG and rep() is as in Lemma 4. Then  assuming the dataset is
linearly separable with margin  by a unit `1 norm w? (kw?k1 = 1)  the sequence generated by
Algorithm 3 with chosen as above (and line 9 modiﬁed as in Corollary 5)  satisﬁes

2kwk2

LNDCG(X⌧ w⌧   y⌧ ) 

9 · 2Ymax+3 · m2 log2
2(2m) · R2 · log p0
2

nX⌧ =1

where maxj=1 ... po kX⌧ jk2  R and X⌧ j denotes the jth column of X⌧ .
5 Multilabel Ranking

As discussed in Section 3  in multilabel classiﬁcation  both prediction space and label space are
{0  1}m with sizes k = ` = 2m. In multilabel ranking  however  the learner has to output rankings
as predictions. So  as in the previous section  we have k = m! since the prediction  can be any
one of m! permutations of the labels. As before  we choose rep() = f ()/Z and hence d = m.
However  unlike the previous section  the input is no longer a matrix but a vector X 2 Rp. A
prediction t 2 Rd is obtained as W X where W 2 Rm⇥p. Note the contrast with the last section:
there  inputs are matrices and a weight vector is learned; here  inputs are vectors and a weight matrix
is learned. Since we output rankings  it is reasonable to use a loss that takes positions of labels into
account. We can use L = LNDCG. Algorithm 1 now immediately applies. Lemma 3 already showed
that is efﬁciently implementable. We have the following straightforward corollary.
Corollary 7. Suppose L = LNDCG and rep() is as in Lemma 4. Then  assuming the dataset is
linearly separable with margin   the sequence generated by Algorithm 1 satisﬁes

nX⌧ =1

LNDCG(X⌧ w⌧   y⌧ ) 

2Ymax+3 · m2 log2

2(2m) · R2

2

where kX⌧k2  R.
The bound above matches the corresponding bound  up to loss speciﬁc constants  for the multiclass
multilabel perceptron (MMP) algorithm studied by [15]. The deﬁnition of margin by [15] for MMP
is different from ours since their algorithms are designed speciﬁcally for multilabel ranking. Just like
them  we can also consider other losses  e.g.  precision at top K positions. Another perceptron style
algorithm for multilabel ranking adopts a pairwise approach of comparing two labels at a time [16].
However  no loss bounds are derived.
The result above uses the standard Frobenius norm based margin. Imagine a multilabel problem 
where only a small number of features are relevant across all labels. Then  it is natural to consider a
notion of margin where the matrix that ranks everything perfectly has low group (2  1) norm  instead
of low Frobenius norm  where kWk2 1 = Pp
j=1 kWjk2 (Wj denotes a column of W ). We again
use a special case of Algorithm 3 (Appendix B.2). Speciﬁcally  we replace line 10 with the step
W⌧ +1 = (r )1 (r (W⌧ )  r⌧ ) where (W ) = 1
2 r. Recall that the group (2  r)-norm is
the `r norm of the `2 norm of the columns of W . We set r = log(p)/(log(p)  1). The mapping
r and its inverse can both be easily computed (see  e.g.  [17  Eq. (2)]).
Corollary 8. Suppose L = LNDCG and rep() is as in Lemma 4. Then  assuming the dataset is
linearly separable with margin  by a unit group norm W ? (kW ?k2 1 = 1)  the sequence generated
by Algorithm 3 with chosen as above  satisﬁes

2kWk2

LNDCG(X⌧ w⌧   y⌧ ) 

9 · 2Ymax+3 · m2 log2
2(2m) · R2 · log p
2

nX⌧ =1
where kX⌧k1  R.

7

)

G
C
D
N
−
1
(
 
s
t

i

n
o
P

 
t
s
e
T
n
o

 

 
s
s
o
L

0
10

−5

10

−10

10

 

Subset Ranking (m=20  p
=30)
0

 

pred−1(σ(i))=1/i
pred−1(σ(i))=−i1.1
pred−1(σ(i))=−i2
20

40

60

(a)

No. of Training Points (n)

80

100

)

G
C
D
N
−
1
(
 
s
t

i

n
o
P

 
t
s
e
T
n
o

 

 
s
s
o
L

Subset Ranking (n=30  p
=30)
0

 

pred−1(σ(i))=1/i
pred−1(σ(i))=−i1.1
pred−1(σ(i))=−i2

0
10

−5

10

−10

10

 
15

No. of documents in each instance (m)

20

25

(b)

)

G
C
D
N
−
1
(
 
s
t

i

n
o
P

 
t
s
e
T
n
o

 

 
s
s
o
L

0.4

0.3

0.2

0.1

0

 

L
 vs L
 (s=50  n=50  m=20)
2
1

 

Predtron−L

Predtron−L

2

1

500

1000

2000
Data dimensionality (p
)
0

1500

2500

(c)

Figure 1: Subset Ranking: NDCG loss for different pred1 choices with varying n (Plot (a)) and m
(Plot (b)). As predicted by Lemmas 4 and 5  pred1(i) = i1.1 is more accurate than 1/i. (c):
L1 vs L2 margin. LNDCG for two different Predtron algorithms based on L1 and L2 margin. Data
is generated using L1 margin notion but with varying sparsity of the optimal scoring function w⇤.

6 Experiments

We now present simulation results to demonstrate the application of our proposed Predtron frame-
work to subset ranking. We also demonstrate that empirical results match the trend predicted by
our error bounds  hence hinting at tightness of our (upper) bounds. Due to lack of space  we focus
only on the subset ranking problem. Also  we would like to stress that we do not claim that the
basic version of Predtron itself (with ⌘ = 1) provides a state-of-the-art ranker. Instead  we wish to
demonstrate the applicability and ﬂexibility of our framework in a controlled setting.
We generated n data points X⌧ 2 Rm⇥p0 using a Gaussian distribution with independent rows. The
ith row of X⌧ represents a document and is sampled from a spherical Gaussian centered at µi. We
selected a w⇤ 2 Rp0 and also a set of thresholds [⇣1  . . .  ⇣ m+1] to generate relevance scores; we
set ⇣j = 1
j   82  j  m and ⇣1 = +1 and ⇣m+1 = 1. We set relevance score y⌧ (i) of the
ith document in the ⌧th document-set as: y⌧ (i) = m  j iff ⇣j+1  hX⌧ (i)  w⇤i  ⇣j. That is 
y⌧ (i) 2 [m  1].
We measure performance of a given method using the NDCG loss LNDCG deﬁned in Section 4.
Note that LNDCG is less sensitive to errors in predictions for the less relevant documents in the list.
On the other hand  our selection of thresholds ⇣i’s implies that the gap between scores of lower-
ranked documents is very small compared to the higher-ranked ones  and hence chances of making
mistakes lower down the list is higher.
Figure 1 (a) shows LNDCG (on a test set) for our Predtron algorithm (see Section 4) but with different
pred1 functions. For pred1((i)) = f2() = i1.1  f2(i1)f2(i) is monotonically increasing
with i. On the other hand  for pred1((i)) = f1() = 1/i  f1(i  1)  f1(i) is monotonically
decreasing with i. Lemma 4 shows that the mistake bound (in terms of LNDCG) of Predtron is better
when pred1 function is selected to be f2((i)) = i1.1 (as well as for f3((i)) = i2) instead of
f1((i)) = 1/i. Clearly  Figure 1 (a) empirically validates this mistake bound with LNDCG going
to almost 0 for f2 and f3 with just 60 training points  while f1 based Predtron has large loss even
with n = 100 training points.
Next  we ﬁx the number of training instances to be n = 30 and vary the number of documents m.
As the gap between ⇣i’s decreases for larger i  increasing m implies reducing the margin. Naturally 
Predtron with the above mentioned inverse functions has monotonically increasing loss (see Figure 1
(b)). However  f2 and f3 provide zero-loss solutions for larger m when compared to f1.
Finally  we conduct an experiment to show that by selecting appropriate notion of margin  Predtron
can obtain more accurate solutions. To this end  we generate data from [1  1]p0 and select a sparse
w⇤. Now  Predtron with `2-margin notion  i.e.  standard gradient descent has pp0 dependency in
the error bounds while the `1-margin (see Corollary 6) has only s log(p0) dependence. This error
dependency is also revealed by Figure 1 (c)  where increasing p0 with ﬁxed s leads to minor increase
in the loss for `1-based Predtron but leads to signiﬁcantly higher loss for `2-based Predtron.

Acknowledgments

A. Tewari acknowledges the support of NSF under grant IIS-1319810.

8

References
[1] Harish G. Ramaswamy and Shivani Agarwal. Classiﬁcation calibration dimension for general multiclass

losses. In Advances in Neural Information Processing Systems  pages 2078–2086  2012.

[2] Mehryar Mohri  Afshin Rostamizadeh  and Ameet Talwalkar. Foundations of machine learning. MIT

press  2012.

[3] Michael Collins. Discriminative training methods for hidden Markov models: Theory and experiments
with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural
language processing-Volume 10  pages 1–8  2002.

[4] Nathan D. Ratliff  J Andrew Bagnell  and Martin Zinkevich.

(Approximate) subgradient methods for
structured prediction. In International Conference on Artiﬁcial Intelligence and Statistics  pages 380–
387  2007.

[5] Youssef Mroueh  Tomaso Poggio  Lorenzo Rosasco  and Jean-Jeacques Slotine. Multiclass learning with

simplex coding. In Advances in Neural Information Processing Systems  pages 2789–2797  2012.

[6] Shai Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends in Ma-

chine Learning  4(2):107–194  2011.

[7] Albert B.J. Novikoff. On convergence proofs on perceptrons. In Proceedings of the Symposium on the

Mathematical Theory of Automata  volume 12  pages 615–622  1962.

[8] Yaoyong Li  Hugo Zaragoza  Ralf Herbrich  John Shawe-Taylor  and Jaz S. Kandola. The perceptron
algorithm with uneven margins. In Proceedings of the Nineteenth International Conference on Machine
Learning  pages 379–386  2002.

[9] Gunnar Ratsch and Jyrki Kivinen. Extended classiﬁcation with modiﬁed Perceptron  2002. Presented
at the NIPS 2002 Workshop: Beyond Classiﬁcation and Regression: Learning Rankings  Preferences 
Equality Predicates  and Other Structures; abstract available at http://www.cs.cornell.edu/
people/tj/ranklearn/raetsch_kivinen.pdf.

[10] Koby Crammer and Yoram Singer. Ultraconservative online algorithms for multiclass problems. The

Journal of Machine Learning Research  3:951–991  2003.

[11] Koby Crammer and Yoram Singer. On the algorithmic implementation of multiclass kernel-based vector

machines. The Journal of Machine Learning Research  2:265–292  2002.

[12] Koby Crammer and Yoram Singer. Pranking with ranking. Advances in Neural Information Procession

Systems  14:641–647  2002.

[13] David Cossock and Tong Zhang. Statistical analysis of bayes optimal subset ranking. IEEE Transactions

on Information Theory  54(11):5140–5154  2008.

[14] Ambuj Tewari and Sougata Chaudhuri. Generalization error bounds for learning to rank: Does the length
of document lists matter? In Proceedings of the 32nd International Conference on Machine Learning 
volume 37 of JMLR Workshop and Conference Proceedings  2015.

[15] Koby Crammer and Yoram Singer. A family of additive online algorithms for category ranking. The

Journal of Machine Learning Research  3:1025–1058  2003.

[16] Eneldo Loza Menc´ıa and Johannes Furnkranz. Pairwise learning of multilabel classiﬁcations with per-

ceptrons. In IEEE International Joint Conference on Neural Networks  pages 2899–2906  2008.

[17] Sham M. Kakade  Shai Shalev-Shwartz  and Ambuj Tewari. Regularization techniques for learning with

matrices. Journal of Machine Learning Research  13:1865–1890  2012.

9

,Jie Liu
David Page
Prateek Jain
Nagarajan Natarajan
Ambuj Tewari
Timothy Rubin
Oluwasanmi Koyejo
Michael Jones
Tal Yarkoni
Yu-Chia Chen
Marina Meila