2016,Data Poisoning Attacks on Factorization-Based Collaborative Filtering,Recommendation and collaborative filtering systems are important in modern information and e-commerce applications.  As these systems are becoming increasingly popular in industry  their outputs could affect business decision making  introducing incentives for an adversarial party to compromise the availability or integrity of such systems. We introduce a data poisoning attack on collaborative filtering systems.  We demonstrate how a powerful attacker with full knowledge of the learner can generate malicious data so as to maximize his/her malicious objectives  while at the same time mimicking normal user behaviors to avoid being detected. While the complete knowledge assumption seems extreme  it enables a robust assessment of the vulnerability of collaborative filtering schemes to highly motivated attacks. We present efficient solutions for two popular factorization-based collaborative filtering algorithms: the alternative minimization formulation and the nuclear norm minimization method. Finally  we test the effectiveness of our proposed algorithms on real-world data and discuss potential defensive strategies.,DataPoisoningAttacksonFactorization-BasedCollaborativeFilteringBoLi∗VanderbiltUniversitybo.li.2@vanderbilt.eduYiningWang∗CarnegieMellonUniversityynwang.yining@gmail.comAartiSinghCarnegieMellonUniversityaarti@cs.cmu.eduYevgeniyVorobeychikVanderbiltUniversityyevgeniy.vorobeychik@vanderbilt.eduAbstractRecommendationandcollaborativeﬁlteringsystemsareimportantinmoderninfor-mationande-commerceapplications.Asthesesystemsarebecomingincreasinglypopularintheindustry theiroutputscouldaffectbusinessdecisionmaking in-troducingincentivesforanadversarialpartytocompromisetheavailabilityorintegrityofsuchsystems.Weintroduceadatapoisoningattackoncollaborativeﬁlteringsystems.Wedemonstratehowapowerfulattackerwithfullknowledgeofthelearnercangeneratemaliciousdatasoastomaximizehis/hermaliciousobjectives whileatthesametimemimickingnormaluserbehaviortoavoidbeingdetected.Whilethecompleteknowledgeassumptionseemsextreme itenablesarobustassessmentofthevulnerabilityofcollaborativeﬁlteringschemestohighlymotivatedattacks.Wepresentefﬁcientsolutionsfortwopopularfactorization-basedcollaborativeﬁlteringalgorithms:thealternativeminimizationformulationandthenuclearnormminimizationmethod.Finally wetesttheeffectivenessofourproposedalgorithmsonreal-worlddataanddiscusspotentialdefensivestrategies.1IntroductionRecommendationsystemshaveemergedasacrucialfeatureofmanyelectroniccommercesystems.Inmachinelearningsuchproblemsareusuallyreferredtoascollaborativeﬁlteringormatrixcompletion wheretheknownusers’preferencesareabstractedintoanincompleteuser-by-itemmatrix andthegoalistocompletethematrixandsubsequentlymakenewitemrecommendationsforeachuser.Existingapproachesintheliteratureincludenearest-neighbormethods whereauser’s(item’s)preferenceisdeterminedbyotherusers(items)withsimilarproﬁles[1] andfactorization-basedmethodswheretheincompletepreferencematrixisassumedtobeapproximatelylow-rank[2 3].Asrecommendationsystemsplayaneverincreasingroleincurrentinformationande-commercesystems theyaresusceptibletoariskofbeingmaliciouslyattacked.Oneparticularformofattacksiscalleddatapoisoning inwhichamaliciouspartycreatesdummy(malicious)usersinarecom-mendationsystemwithcarefullychosenitempreferences(i.e. data)suchthattheeffectivenessorcredibilityofthesystemismaximallydegraded.Forexample anattackermightattempttomakerecommendationsthatareasdifferentaspossiblefromthosethatwouldotherwisebemadebytherecommendationsystem.Inanother moresubtle example theattackerisassociatedwiththeproducerofaspeciﬁcmovieorproduct whomaywishtoincreaseordecreasethepopularityofacertainitem.Inbothcases thecredibilityofarecommendationsystemisharmedbythemaliciousactivities whichcouldleadtosigniﬁcanteconomicloss.Duetotheopennatureofrecommendation∗Bothauthorscontributeequally30thConferenceonNeuralInformationProcessingSystems(NIPS2016) Barcelona Spain.systemsandtheirrelianceonuser-speciﬁedjudgmentsforbuildingproﬁles variousformsofattacksarepossibleandhavebeendiscussed suchastherandomattackandrandomproductpush/nukeattack[4 5].However theseattacksarenotformallyanalyzedandcannotbeoptimizedaccordingtospeciﬁccollaborativeﬁlteringalgorithms.Asitisnotdifﬁcultforattackerstodeterminethedefender’sﬁlteringalgorithmorevenitsparameterssettings(e.g. throughinsiderattacks) thiscanleadonetosigniﬁcantlyunder-estimatetheattacker’sabilityandresultinsubstantialloss.Wepresentasystematicapproachtocomputingnear-optimaldatapoisoningattacksforfactorization-basedcollaborativeﬁltering/recommendationmodels.WeassumeahighlymotivatedattackerwithknowledgeofboththelearningalgorithmsandparametersofthelearnerfollowingtheKerckhoffs’principletoensurereliablevulnerabilityanalysisintheworstcase.Wefocusontwomostpopularalgorithms:alternatingminimization[6]andnuclearnormminimization[3].Ourmaincontributionsareasfollows:•Comprehensivecharacterizationofattackerutilities:Wecharacterizeseveralattackerutilities whichincludeavailabilityattacks wherepredictionerrorisincreased andintegrityattacks whereitem-speciﬁcobjectivesareconsidered.Optimalattackstrategiesforallutilitiescanbecomputedunderauniﬁedoptimizationframework.•Novelgradientcomputations:Buildinguponexistinggradient-baseddatapoisoningframe-works[7 8 9] wedevelopnovelmethodsforgradientcomputationbasedonﬁrst-orderKKTconditionsfortwowidelyusedalgorithms:alternatingminimization[6]andnuclearnormminimization[2].Theresultingderivationsarehighlynon-trivial;inaddition toourknowledgethisworkistheﬁrsttogivesystematicdatapoisoningattacksforproblemsinvolvingnon-smoothnuclearnormtypeobjectives.•Mimickingnormaluserbehaviors:Fordatapoisoningattacks mostpriorworkfocusesonmaximizingattacker’sutility.Alessinvestigatedproblemishowtosynthesizemaliciousdatapointsthatarehardforadefendertodetect.InthispaperweprovideanoveltechniquebasedonstochasticgradientLangevindynamicsoptimization[10]toproducemalicioususersthatmimicnormaluserbehaviorsinordertoavoiddetection whileachievingattackobjectives.RelatedWork:Therehasbeenextensivepriorresearchconcerningthesecurityofmachinelearningalgorithms[11 12 13 14 15].Biggioetal.pioneeredtheresearchofoptimizingmaliciousdata-drivenattacksforkernel-basedlearningalgorithmssuchasSVM[16].Thekeyoptimizationtechniqueistoapproximatelycomputeimplicitgradientsofthesolutionofanoptimizationproblembasedonﬁrst-orderKKTconditions.Similartechniqueswerelatergeneralizedtooptimizedatapoisoningattacksforseveralotherimportantlearningalgorithms suchasLassoregression[7] topicmodeling[8] andautoregressivemodels[17].Thereadermayreferto[9]forageneralalgorithmicframeworkoftheabovementionedmethods.Intermsofcollaborativeﬁltering/matrixcompletion thereisanotherlineofestablishedresearchthatfocusesonrobustmatrixcompletion inwhichasmallportionofelementsorrowsintheunderlyinglow-rankmatrixisassumedtobearbitrarilyperturbed[18 19 20 21].Speciﬁcally thestabilityofalternatingminimizationsolutionswasanalyzedwithrespecttomaliciousdatamanipulationsin[22].However [22]assumesagloballyoptimalsolutionofalternatingminimizationcanbeobtained whichisrarelytrueinpractice.2PreliminariesWeﬁrstsetupthecollaborativeﬁltering/matrixcompletionproblemandgiveanoverviewofexistinglow-rankfactorizationbasedapproaches.LetM∈Rm×nbeadatamatrixconsistingofmrowsandncolumns.Mijfori∈[m]andj∈[n]wouldthencorrespondtotheratingtheithusergivesforthejthitem.WeuseΩ={(i j):Mijisobserved}todenoteallobservableentriesinMandassumethat|Ω|(cid:28)mn.WealsouseΩi⊆[n]andΩ0j⊆[m]forcolumns(rows)thatareobservableattheithrow(jthcolumn).Thegoalofcollaborativeﬁltering(alsoreferredtoasmatrixcompletioninthestatisticallearningliterature[2])isthentorecoverthecompletematrixMfromfewobservationsMΩ.Thematrixcompletionproblemisingeneralill-posedasitisimpossibletocompleteanarbitrarymatrixwithpartialobservations.Asaresult additionalassumptionsareimposedontheunderlyingdatamatrixM.OnestandardassumptionisthatMisveryclosetoanm×nrank-kmatrixwith2k(cid:28)min(m n).Undersuchassumptions thecompletematrixMcanberecoveredbysolvingthefollowingoptimizationproblem:minX∈Rm×nkRΩ(M−X)k2F s.t.rank(X)≤k (1)wherekAk2F=Pi jA2ijdenotesthesquaredFrobeniousnormofmatrixAand[RΩ(A)]ijequalsAijif(i j)∈Ωand0otherwise.Unfortunately thefeasiblesetinEq.(1)isnon-convex makingtheoptimimzationproblemdifﬁculttosolve.Therehasbeenanextensivepriorliteratureonap-proximatelysolvingEq.(1)and/oritssurrogatesthatleadtotwostandardapproaches:alternatingminimizationandnuclearnormminimization.Fortheﬁrstapproach oneconsidersthefollowingproblem:minU∈Rm×k V∈Rn×k(cid:8)kRΩ(M−UV>)k2F+2λUkUk2F+2λVkVk2F(cid:9).(2)Eq.(2)isequivalenttoEq.(1)whenλU=λV=0.InpracticepeopleusuallysetbothregularizationparametersλUandλVtobesmallpositiveconstantsinordertoavoidlargeentriesinthecompletedmatrixandalsoimproveconvergence.SinceEq.(2)isbi-convexinUandV analternatingminimizationprocedurecanbeapplied.Alternatively onesolvesanuclear-normminimizationproblemminX∈Rm×nkRΩ(M−X)k2F+2λkXk∗ (3)whereλ>0isaregularizationparameterandkXk∗=Prank(X)i=1|σi(X)|isthenuclearnormofX whichactsasaconvexsurrogateoftherankfunction.Eq.(3)isaconvexoptimizationfunctionandcanbesolvedusinganiterativesingularvaluethresholdingalgorithm[3].ItcanbeshownthatbothmethodsinEq.(2)and(3)provablyapproximatethetrueunderlyingdatamatrixMundercertainconditions[6 2].3TheAttackModelInthissectionwedescribethedatapoisoningattackmodelconsideredinthispaper.Foradatamatrixconsistingofmusersandnitems theattackeriscapableofaddingαmmalicioususerstothetrainingdatamatrix andeachmalicioususerisallowedtoreporthis/herpreferenceonatmostBitemswitheachpreferenceboundedintherange[−Λ Λ].Beforeproceedingtodescribetheattacker’sgoals weﬁrstintroducesomenotationtofacilitatepresentation.WeuseM∈Rm×ntodenotetheoriginaldatamatrixandfM∈Rm0×ntodenotethedatamatrixofallm0=αmmalicioususers.LeteΩbethesetofnon-zeroentriesinfMandeΩi⊆[n]beallitemsthattheithmalicioususerrated.Accordingtoourattackmodels |eΩi|≤Bforeveryi∈{1 ··· m0}andkfMkmax=max|fMij|≤Λ.LetΘλ(fM;M)betheoptimalsolutioncomputedjointlyontheoriginalandpoisoneddatamatrices(fM;M)usingregularizationparametersλ.Forexample Eq.(2)becomesΘλ(fM;M)=argminU eU VkRΩ(M−UV>)k2F+kR˜Ω(fM−eUV>)k2F+2λU(kUk2F+keUk2F)+2λVkVk2F(4)wheretheresultingΘconsistsoflow-ranklatentfactorsU eUfornormalandmalicioususersaswellasVforitems.Simiarly forthenuclearnormminimizationformulationinEq.(3) wehaveΘλ(fM;M)=argminX eXkRΩ(M−X)k2F+kR˜Ω(fM−eX)k2F+2λk(X;eX)k∗ (5)whereΘ=(X eX).LetcM(Θ)bethematrixestimatedfromlearntmodelΘ.Forexample forEq.(4)wehavecM(Θ)=UV>andforEq.(5)wehavecM(Θ)=X.ThegoaloftheattackeristoﬁndoptimalmalicioususersfM∗suchthatfM∗∈argmaxfM∈MR(cM(Θλ(fM;M)) M).(6)HereM={fM∈Rm0×n:|˜Ωi|≤B kfMkmax≤Λ}isthesetofallfeasiblepoisoningattacksdiscussedearlierinthissectionandR(cM M)denotestheattacker’sutilityfordivertingthecollabo-rativeﬁlteringalgorithmtopredictcMonanoriginaldatasetM withthehelpoffewmalicioususersfM.Belowwelistseveraltypicalattackerutilities:3Availabilityattacktheattackerwantstomaximizetheerrorofthecollaborativeﬁlteringsystem andeventuallyrenderthesystemuseless.SupposeMisthepredictionofthecollaborativeﬁlteringsystemwithoutdatapoisoningattacks.2TheutilityfunctionisthendeﬁnedasthetotalamountofperturbationofpredictionsbetweenMandcM(predictionsafterpoisoningattacks)onunseenentriesΩC:Rav(cM M)=kRΩC(cM−M)k2F.(7)Integrityattackinthismodeltheattackerwantstoboost(orreduce)thepopularityofa(subset)ofitems.SupposeJ0⊆[n]isthesubsetofitemstheattackerisinterestedinandw:J0→Risapre-speciﬁedweightvectorbytheattacker.TheutilityfunctionisRinJ0 w(cM M)=mXi=1Xj∈J0w(j)cMij.(8)Hybridattackahybridlossfunctioncanalsobedeﬁned:RhybridJ0 w µ(cM M)=µ1RavJ0 w(cM M)+µ2Rin(cM M) (9)whereµ=(µ1 µ2)arecoefﬁcientsthattradeofftheavailabilityandintegrityattackobjectives.Inaddition µ1couldbenegative whichmodelsthecasewhentheattackerwantstoleavea“lighttrace":theattackerwantstomakehisitemmorepopularwhilemakingtheotherrecommendationsofthesystemlessperturbedtoavoiddetection.4ComputingOptimalAttackStrategiesWedescribepracticalalgorithmstosolvetheoptimizationprobleminEq.(6)foroptimalattackstrategyfM∗thatmaximizestheattacker’sutility.WeﬁrstconsiderthealternatingminimizationformulationinEq.(4)andderiveaprojectedgradientascentmethodthatsolvesforthecorrespondingoptimalattackstrategy.SimilarderivationsarethenextendedtothenuclearnormminimizationformulationinEq.(5).Finally wediscusshowtodesignmalicioususersthatmimicnormaluserbehaviorinordertoavoiddetection.4.1AttackingAlternatingMinimizationWeusetheprojectedgradientascent(PGA)methodforsolvingtheoptimizationprobleminEq.(6)withrespecttothealternatingminimizationformulationinEq.(4):initerationtweupdatefM(t)asfollows:fM(t+1)=ProjM(cid:16)fM(t)+st·∇fMR(cM M)(cid:17) (10)whereProjM(·)istheprojectionoperatorontothefeasibleregionMandstisthestepsizeiniterationt.NotethattheestimatedmatrixcMdependsonthemodelΘλ(fM;M)learntonthejointdatamatrix whichfurtherdependsonthemalicioususersfM.SincetheconstraintsetMishighlynon-convex wegenerateBitemsuniformlyatrandomforeachmalicioususertorate.TheProjM(·)operatorthenreducestoprojectingeachmalicioususers’ratingvectorontoan‘∞ballofdiameterΛ whichcanbeeasilyevaluatedbytruncatingallentriesinfMatthelevelof±Λ.Wenextshowhowto(approximately)compute∇fMR(cM M).Thisischallengingbecauseoneoftheargumentsinthelossfunctioninvolvesanimplicitoptimizationproblem.Weﬁrstapplychainruletoarriveat∇fMR(cM M)=∇fMΘλ(fM;M)∇ΘR(cM M).(11)Thesecondgradient(withrespecttoΘ)iseasytoevaluate asalllossfunctionsmentionedintheprevioussectionaresmoothanddifferentiable.Detailedderivationof∇ΘR(cM M)isdeferredtoAppendixA.Ontheotherhand theﬁrstgradienttermtermismuchhardertoevaluatebecauseΘλ(·)isanoptimizationprocedure.Inspiredby[7 8 9] weexploittheKKTconditionsoftheoptimizationproblemΘλ(·)toapproximatelycompute∇fMΘλ(fM;M).Morespeciﬁcally theoptimalsolutionΘ=(U eU V)ofEq.(4)satisﬁesλUui=Xj∈Ωi(Mij−u>ivj)vj;2Notethatwhenthecollaborativeﬁlteringalgorithmanditsparametersareset MisafunctionofobservedentriesRΩ(M).4Algorithm1OptimizingfMviaPGA1:Input:Originalpartiallyobservedm×ndatamatrixM algorithmregularizationparameterλ attackbudgetparametersα BandΛ attacker’sutilityfunctionR stepsize{st}∞t=1.2:Initialization:randomfM(0)∈Mwithbothratingsandrateditemsuniformlysampledatrandom;t=0.3:whilefM(t)doesnotconvergedo4:ComputetheoptimalsolutionΘλ(fM(t);M).5:Computegradient∇fMR(cM M)usingEq.(10).6:Update:fM(t+1)=ProjM(fM(t)+st∇fMR).7:t←t+1.8:endwhile9:Output:m0×nmaliciousmatrixfM(t).λU˜ui=Xj∈eΩi(fMij−˜u>ivj)vj;λVvj=Xi∈Ω0j(Mij−u>ivj)ui+Xi∈eΩ0j(fMij−˜u>ivj)˜ui whereui ˜uiaretheithrows(ofdimensionk)inUoreUandvjisthejthrow(alsoofdimensionk)inV.Subsequently {ui ˜ui vj}canbeexpressedasfunctionsoftheoriginalandmaliciousdatamatricesMandfM.Usingthefactthat(a>x)a=(aa>)xandMdoesnotchangewithfM weobtain∂ui(fM)∂fMij=0;∂˜ui(fM)∂fMij=(cid:16)λUIk+Σ(i)U(cid:17)−1vj;∂vj(fM)∂fMij=(cid:16)λVIk+Σ(j)V(cid:17)−1ui.HereΣ(i)UandΣ(j)VaredeﬁnedasΣ(i)U=Xj∈Ωi∪eΩivjv>j Σ(j)V=Xi∈Ω0j∪eΩ0juiu>i.(12)AframeworkoftheproposedoptimizationalgorithmisdescribedinAlgorithm1.4.2AttackingNuclearNormMinimizationWeextendtheprojectedgradientascentalgorithminSec.4.1tocomputeoptimalattackstrategiesforthenuclearnormminimizationformulationinEq.(5).SincetheobjectiveinEq.(5)isconvex theglobaloptimalsolutionΘ=(X eX)canbeobtainedbyconventionalconvexoptimizationproceduressuchasproximalgradientdescent(a.k.a.singularvaluethresholding[3]fornuclearnormminimization).Inaddition theresultingestimation(X;eX)islowrankduetothenuclearnormpenalty[2].Suppose(X;eX)hasrankρ≤min(m n).WeuseΘ0=(U eU V Σ)asanalternativecharacterizationofthelearntmodelwithareducednumberofparameters.HereX=UΣV>andeX=eUΣV>aresingularvaluedecompositionsofXandeX;thatis U∈Rm×ρ eU∈Rm0×ρ V∈Rn×ρhaveorthornormalcolumnsandΣ=diag(σ1 ··· σρ)isanon-negativediagonalmatrix.Tocomputethegradient∇fMR(cM M) weagainapplythechainruletodecomposethegradientintotwoparts:∇fMR(cM M)=∇fMΘ0λ(fM;M)∇Θ0R(cM M).(13)SimilartoEq.(11) thesecondgradientterm∇Θ0R(cM M)isrelativelyeasiertoevaluate.ItsderivationdetailsaredeferredtotheAppendix.Intheremainderofthissectionweshallfocusonthecomputationoftheﬁrstgradientterm whichinvolvespartialderivativesofΘ0=(U eU V Σ)withrespecttomalicioususersfM.WebeginwiththeKKTconditionattheoptimalsolutionΘ0ofEq.(5).Unlikethealternatingminimizationformulation thenuclearnormfunctionk·k∗isnoteverywheredifferentiable.Asa5Algorithm2OptimizingfMviaSGLD1:Input:Originalpartiallyobservedm×ndatamatrixM algorithmregularizationparameterλ attackbudgetparametersα BandΛ attacker’sutilityfunctionR stepsize{st}∞t=1 tuningparameterβ numberofSGLDiterationsT.2:Priorsetup:computeξj=1mPmi=1Mijandσ2j=1mPmi=1(Mij−ξj)2foreveryj∈[n].3:Initialization:samplefM(0)ij∼N(ξj σ2j)fori∈[m0]andj∈[n].4:fort=0toTdo5:ComputetheoptimalsolutionΘλ(fM(t);M).6:Computegradient∇fMR(cM M)usingEq.(10).7:UpdatefM(t+1)accordingtoEq.(17).8:endfor9:Projection:ﬁndfM∗∈argminfM∈MkfM−fM(t)k2F.Detailsinthemaintext.10:Output:m0×nmaliciousmatrixfM∗.result theKKTconditionrelatesthesubdifferentialofthenuclearnormfunction∂k·k∗asRΩ ˜Ω(cid:16)[M;fM]−[X;eX](cid:17)∈λ∂k[X;eX]k∗.(14)Here[X;eX]istheconcatenated(m+m0)×nmatrixofXandeX.Thesubdifferentialofthenuclearnormfunction∂k·k∗isalsoknown[2]:∂kXk∗=nUV>+W:U>W=WV=0 kWk2≤1o whereX=UΣV>isthesingularvaluedecompositionofX.Suppose{ui} {˜ui}and{vj}arerowsofU eU VandW={wij}.Wecanthenre-formulatetheKKTconditionEq.(14)asfollows:∀(i j)∈Ω Mij=u>i(Σ+λIρ)vj+λwij;∀(i j)∈eΩ fMij=˜u>i(Σ+λIρ)vj+λ˜wij.Nowwederive∇fMΘ=∇fM(u ˜u v σ);thefullderivationisdeferredtotheextendedversion3.4.3MimicingNormalUserBehaviorsNormalusersgenerallydonotrateitemsuniformlyatrandom.Forexample somemoviesaresigniﬁcantlymorepopularthanothers.Asaresult malicioususersthatpickratedmoviesuniformlyatrandomcanbeeasilyidentiﬁedbyrunningat-testagainstaknowndatabaseconsistingofonlynormalusers asshowninSec.5.Toalleviatethisissue inthissectionweproposeanalternativeapproachtocomputedatapoisoningattackssuchthattheresultingmalicioususersfMmimicsnormalusersMtoavoidpotentialdetection whilestillachievingreasonablylargeutilityR(cM M)fortheattacker.WeuseaBayesianformulationtotakebothdatapoisoninganddetectionavoidanceobjectivesintoconsideration.Thepriordistributionp0(fM)capturesnormaluserbehaviorsandisdeﬁnedasamultivariatenormaldistributionp0(fM)=m0Yi=1nYj=1N(fMij;ξj σ2j) whereξjandσ2jaremeanandvarianceparametersfortheratingofthejthitemprovidedbynormalusers.InpracticebothparameterscanbeestimatedusingnormalusermatrixMasξj=1mPmi=1Mijandσ2=1mPmi=1(Mij−ξj)2.Ontheotherhand thelikelihoodp(M|fM)isdeﬁnedasp(M|fM)=1Zexp(cid:16)β·R(cM M)(cid:17) (15)whereR(cM M)=R(cM(Θλ(fM;M)) M)isoneoftheattackerutilityfunctionsdeﬁnedinSec.3 Zisanormalizationconstantandβ>0isatuningparameterthattradesoffattackperformanceand3http://arxiv.org/abs/1608.081826(a)(b)(c)(d)Figure1:RMSE/Averageratingsforalternatingminimizationwithdifferentpercentageofmaliciousproﬁles;(a)µ1=1 µ2=0 (b)µ1=1 µ2=−1 (c)µ1=0 µ2=1 (d)µ1=−1 µ2=1.detectionavoidance.AsmallβshiftstheposterioroffMtowarditsprior whichmakestheresultingattackstrategylesseffectivebuthardertodetect andviceversa.Givenbothpriorandlikelihoodfunctions aneffectivedetection-avoidingattackstrategyfMcanbeobtainedbysamplingfromitsposteriordistribution:p(fM|M)=p0(fM)p(M|fM)/p(M)∝exp−m0Xi=1nXj=1(fMij−ξj)22σ2j+βR(cM M).(16)PosteriorsamplingofEq.(16)isclearlyintractableduetotheimplicitandcomplicateddependencyoftheestimatedmatrixcMonthemaliciousdatafM thatis cM=cM(Θλ(fM;M))).Tocircumventthisproblem weapplyStochasticGradientLangevinDynamics(SGLD [10])toapproximatelysamplefMfromitsposteriordistributioninEq.(16).Morespecﬁcally theSGLDalgorithmiterativelycomputesasequenceofposteriorsamples{fM(t)}t≥0andiniterationtthenewsamplefM(t+1)iscomputedasfM(t+1)=fM(t)+st2(cid:16)∇fMlogp(fM|M)(cid:17)+εt (17)where{st}t≥0arestepsizesandεt∼N(0 stI)areindependentGaussiannoisesinjectedateachSGLDiteration.Thegradient∇fMlogp(fM|M)canbecomputedas∇fMlogp(fM|M)=−(fM−Ξ)Σ−1+β∇fMR(cM M) whereΣ=diag(σ21 ··· σ2n)andΞisanm0×nmatrixwithΞij=ξjfori∈[m0]andj∈[n].Theothergradient∇fMR(cM M)canbecomputedusingtheprocedureinSections4.1and4.2.Finally thesampledmaliciousmatrixfM(t)isprojectedbackontothefeasiblesetMbyselectingBitemsperuserwiththelargestabsoluteratingandtruncatingratingstothelevelof{±Λ}.Ahigh-leveldescriptionoftheproposedmethodisgiveninAlgorithm2.5ExperimentalResultsToevaluatetheeffectivenessofourproposedpoisoningattackstrategy weusethepubliclyavailableMovieLensdatasetwhichcontains20millionsratingsand465 000tagapplicationsappliedto27 000moviesby138 000users[23].Weshifttheratingrangeto[−2 2]forcomputationconvenience.Toavoidthe“cold-start”problem weconsideruserswhohaveratedatleast20movies.Twometricsareemployedtomeasuretherelativeperformanceofthesystemsbeforeandafterdatapoisoningattacks:rootmeansquareerror(RMSE)forthepredictedunseenentries4andaverageratingforspeciﬁcitems.Wethenanalyzethetradeoffbetweenattackperformanceanddetectionavoidance whichiscontroledbytheβparameterinEq.(15).Thisservesasaguideforhowβshouldbesetinlaterexperiments.Weuseapairedt-testtocomparethedistributionsofrateditemsbetweennormalandmalicioususers.Wepresentthetrendofp-valueagainstdifferentvaluesofβintheextendedversionofthepaper.Tostriveforagoodtradeoff wesetβ=0.6atwhichthep-valuestablizesaround0.7andthepoisoningattackperformanceisnotsigniﬁcantlysacriﬁced.WeemployattackmodelsspeciﬁedinEq.(9) wheretheutilityparametersµ1andµ2balancetwodifferentmaliciousgoals(availabilityandintegrity)anattackerwishestoachieve.Fortheintegrity4deﬁnedasRMSE=qP(i j)∈ΩC(Mij−cMij)2/|ΩC| whereMisthepredictionofmodeltrainedoncleandataRΩ(M)only(i.e. withoutdatapoisoningattacks).7(a)(b)(c)(d)Figure2:RMSE/Averageratingsfornuclearnormminimizationwithdifferentpercentageofmali-ciousproﬁles;(a)µ1=1 µ2=0 (b)µ1=1 µ2=−1 (c)µ1=0 µ2=1 (d)µ1=−1 µ2=1.utilityRinJ0 w theJ0setcontainsonlyoneitemj0selectedrandomlyfromallitemswhoseaveragepredictedratingsarearound0.8.Theweightwj0issetaswj0=2.Figure1(a)(b)plotstheRMSEafterdatapoisoningattacks.Whenµ1=1 µ2=0 theattackerisinterestedinincreasingtheRMSEofthecollaborativeﬁlteringsystemandhencereducingthesystem’savailability.Ontheotherhand whenµ1=1 µ2=−1theattackerwishestoincreaseRMSEwhileatthesametimekeepingtheratingofspeciﬁcitems(j0)aslowaspossibleforcertainmaliciouspurposes.Figure1(b)showsthatwhentheattackersconsidertobothobjectives(µ1=1 µ2=−1) theRMSEafterpoisoningisslightlylowerthanthatifonlyavailabilityistargeted(µ1=1 µ2=0).Inaddition theprojectedgradientascent(PGA)strategygeneratesthelargestRMSEscorecomparedwiththeothermethods.However PGArequiresmalicioususerstorateeachitemuniformlyatrandom whichmightexposethemaliciousproﬁlestoaninformeddefender.Morespeciﬁcally thepairedt-testonthosemaliciousproﬁlesproducedbyPGArejectsthenullhypothesisthattheitemsratedbytheattackerstrategiesarethesameasthoseobtainedfromnormalusers(p<0.05).Incontrast theSGLDmethodleadstoslightlyworseattackerutilitybutgeneratesmalicioususersthatarehardtodistinguishfromthenormalusers(forexample thepairedt-testleadstoinconclusivep-values(largerthan0.7)withβ=0.6.Finally bothPGAandSGLDresultinhigherattackerutilitycomparedtouniformattacks wherebothratingsandrateditemsaresampleduniformlyatrandomformaliciousproﬁles.ApartfromtheRMSEscores wealsoplotratingsofspeciﬁcitemsagainstpercentageofmaliciousproﬁlesinFigure1(c)(d).Weconsidertwoadditionalattackutilitysettings:µ1=0 µ2=1 inwhichtheattackerwishestopushtheratingsofsomeparticularitems(speciﬁedinwandJ0ofRin)ashighaspossible;andµ1=−1 µ2=1 wheretheattackeralsowantstoleavea“lighttrace"byreducingtheimpactontheentiresystemresultedfrommaliciousactivities.Itisclearthattargetedattackes(bothPGAandSGLD)areindeedmoreeffectiveatmanipulatingratingsofspeciﬁcitemsforintegrityattacks.WealsoplotRMSE/AverageratingsagainstmalicioususerpercentageinFigure2forthenuclearnormminimizationundersimilarsettingsbasedonasubsetof1000usersand1700movies(items) sinceitismorecomputationallyexpensivethanalternatingminimization.Ingeneral weobservesimilarbehaviorofbothRMSE/Averageratingsunderdifferentattackingmodelsµ1 µ2withalternatingminimization.6DiscussionandConcludingRemarksOurultimategoalforthepoisoningattackanalysisistodeveloppossibledefensivestrategiesbasedonthecarefulanalysisofadversarialbehaviors.Sincethepoisoningdataisoptimizedbasedontheattacker’smaliciousobjectives thecorrelationsamongfeatureswithinafeaturevectormaychangetoappeardifferentfromnormalinstances.Therefore trackinganddetectingdeviationsinthefeaturecorrelationsandotheraccuracymetricscanbeonepotentialdefense.Additionally defendercanalsoapplythecombinationalmodelsorsamplingstrategies suchasbagging toreducetheinﬂuenceofpoisoningattacks.AcknowledgmentsThisresearchwaspartiallysupportedbytheNSF(CNS-1238959 IIS-1526860) ONR(N00014-15-1-2621) ARO(W911NF-16-1-0069) AFRL(FA8750-14-2-0180) SandiaNationalLaboratories andSymantecLabsGraduateResearchFellowship.8References[1]JunWang ArjendeVires andMarcelReinders.Unifyinguser-basedanditem-basedcollaborativeﬁlteringapproachesbysimilarityfusion.InSIGIR 2006.[2]EmmanuelCandèsandBenRecht.Exactmatrixcompletionviaconvexoptimization.FoundationsofComputationalMathematics 9(6):717–772 2007.[3]Jian-FengCai EmmanuelCandès andZuoweiShen.Asingularvaluethresholdingalgorithmformatrixcompletion.SIAMJournalonOptimization 20(4):1956–1982 2010.[4]BamshadMobasher RobinBurke RunaBhaumik andChadWilliams.Effectiveattackmodelsforshillingitem-basedcollaborativeﬁlteringsystems.InProceedingsofthe2005WebKDDWorkshop heldinconjuctionwithACMSIGKDD’2005 2005.[5]MichaelPO’Mahony NeilJHurley andGuenoleCMSilvestre.Promotingrecommendations:Anattackoncollaborativeﬁltering.InDatabaseandExpertSystemsApplications pages494–503.Springer 2002.[6]PrateekJain PraneethNetrapalli andSujaySanghavi.Low-rankmatrixcompletionusingalternatingminimization.InSTOC 2013.[7]HuangXiao BattistaBiggio GavinBrown GiorgioFumera ClaudiaEckert andFabioRoli.Isfeatureselectionsecureagainsttrainingdatapoisoning.InICML 2015.[8]ShikeMeiandXiaojinZhu.Thesecurityoflatentdirichletallocation.InAISTATS 2015.[9]ShikeMeiandXiaojinZhu.Usingmachineteachingtoidentifyoptimaltraining-setattacksonmachinelearners.InAAAI 2015.[10]MaxWellingandYeeWTeh.Bayesianlearningviastochasticgradientlangevindynamics.InProceedingsofthe28thInternationalConferenceonMachineLearning(ICML-11) pages681–688 2011.[11]NileshDalvi PedroDomingos SumitSanghai DeepakVerma etal.Adversarialclassiﬁcation.InProceedingsofthetenthACMSIGKDDinternationalconferenceonKnowledgediscoveryanddatamining pages99–108.ACM 2004.[12]DanielLowdandChristopherMeek.Adversariallearning.InProceedingsoftheeleventhACMSIGKDDinternationalconferenceonKnowledgediscoveryindatamining pages641–647.ACM 2005.[13]BoLiandYevgeniyVorobeychik.Featurecross-substitutioninadversarialclassiﬁcation.InAdvancesinNeuralInformationProcessingSystems pages2087–2095 2014.[14]BoLiandYevgeniyVorobeychik.Scalableoptimizationofrandomizedoperationaldecisionsinadversarialclassiﬁcationsettings.InProceedingsoftheEighteenthInternationalConferenceonArtiﬁcialIntelligenceandStatistics pages599–607 2015.[15]MarcoBarreno BlaineNelson RussellSears AnthonyDJoseph andJDougTygar.Canmachinelearningbesecure?InProceedingsofthe2006ACMSymposiumonInformation computerandcommunicationssecurity pages16–25.ACM 2006.[16]BattistaBiggio BlaineNelson andPavelLaskov.Poisoningattacksagainstsupportvectormachines.InICML 2012.[17]ScottAlfeld XiaojinZhu andPaulBarford.Datapoisoningattacksagainstautoregressivemodels.InAAAI 2016.[18]OlgaKlopp KarimLounici andAlexandreTsybakov.Robustmatrixcompletion.arXiv:1412.8132 2014.[19]YudongChen HuanXu ConstantineCaramanis andSujaySanghavi.Robustmatrixcompletionandcorruptedcolumns.InICML 2011.[20]YudongChen AliJalali SujaySanghavi andConstantineCaramanis.Low-rankmatrixrecoveryfromerrorsanderasures.IEEETransactionsonInformationTheory 59(7):4324–4337 2013.[21]FeipingNie HuaWang XiaoCai HengHuang andChrisDing.Robustmatrixcompletionviajointschattenp-normandlp-normminimization.InICDM 2012.[22]Yu-XiangWangandHuanXu.Stabilityofmatrixfactorizationforcollaborativeﬁltering.InICML 2012.[23]ResearchGroupLens.www.grouplens.org.9,Jonas Mueller
Tommi Jaakkola
Bo Li
Yining Wang
Aarti Singh
Yevgeniy Vorobeychik