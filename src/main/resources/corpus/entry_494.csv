2019,An Accelerated Decentralized Stochastic Proximal Algorithm for Finite Sums,Modern large-scale finite-sum optimization relies on two key aspects: distribution and stochastic updates. For smooth and strongly convex problems  existing decentralized algorithms are slower than modern accelerated variance-reduced stochastic algorithms when run on a single machine  and are therefore not efficient. Centralized algorithms are fast  but their scaling is limited by global aggregation steps that result in communication bottlenecks. In this work  we propose an efficient \textbf{A}ccelerated \textbf{D}ecentralized stochastic algorithm for \textbf{F}inite \textbf{S}ums named ADFS  which uses local stochastic proximal updates and randomized pairwise communications between nodes. On $n$ machines  ADFS learns from $nm$ samples in the same time it takes optimal algorithms to learn from $m$ samples on one machine. This scaling holds until a critical network size is reached  which depends on communication delays  on the number of samples $m$  and on the network topology. We provide a theoretical analysis based on a novel augmented graph approach combined with a precise evaluation of synchronization times and an extension of the accelerated proximal coordinate gradient algorithm to arbitrary sampling. We illustrate the improvement of ADFS over state-of-the-art decentralized approaches with experiments.,An Accelerated Decentralized Stochastic Proximal

Algorithm for Finite Sums

Hadrien Hendrikx

INRIA - DIENS - PSL Research University

Francis Bach

INRIA - DIENS - PSL Research University

hadrien.hendrikx@inria.fr

francis.bach@inria.fr

Laurent Massouli´e

INRIA - DIENS - PSL Research University

laurent.massoulie@inria.fr

Abstract

Modern large-scale ﬁnite-sum optimization relies on two key aspects: distribu-
tion and stochastic updates. For smooth and strongly convex problems  existing
decentralized algorithms are slower than modern accelerated variance-reduced
stochastic algorithms when run on a single machine  and are therefore not efﬁcient.
Centralized algorithms are fast  but their scaling is limited by global aggrega-
tion steps that result in communication bottlenecks. In this work  we propose an
efﬁcient Accelerated Decentralized stochastic algorithm for Finite Sums named
ADFS  which uses local stochastic proximal updates and randomized pairwise
communications between nodes. On n machines  ADFS learns from nm samples
in the same time it takes optimal algorithms to learn from m samples on one ma-
chine. This scaling holds until a critical network size is reached  which depends on
communication delays  on the number of samples m  and on the network topology.
We provide a theoretical analysis based on a novel augmented graph approach
combined with a precise evaluation of synchronization times and an extension of
the accelerated proximal coordinate gradient algorithm to arbitrary sampling. We
illustrate the improvement of ADFS over state-of-the-art decentralized approaches
with experiments.

Introduction

1
The success of machine learning models is mainly due to their capacity to train on huge amounts of
data. Distributed systems can be used to process more data than one computer can store or to increase
the pace at which models are trained by splitting the work among many computing nodes. In this
work  we focus on problems of the form:

min
θ∈Rd

n�i=1

fi(θ)  where

fi(θ) =

fi j(θ) +

σi
2 �θ�2.

m�j=1

(1)

This is the typical �2-regularized empirical risk minimization problem with n computing nodes that
have m local training examples each. The function fi j represents the loss function for the j-th
training example of node i and is assumed to be convex and Li j-smooth [Nesterov  2013  Bubeck 
2015]. These problems are usually solved by ﬁrst-order methods  and the basic distributed algorithms
compute gradients in parallel over several machines [Nedic and Ozdaglar  2009]. Another way
to speed up training is to use stochastic algorithms [Bottou  2010  Defazio et al.  2014  Johnson
and Zhang  2013]  that take advantage of the ﬁnite sum structure of the problem to use cheaper
iterations while preserving fast convergence. This paper aims at bridging the gap between stochastic

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

SYNCHRONY

STOCHASTIC

TIME

nm + √nmκs

�
×
×
�
�

γ

γ

N/A

GLOBAL
LOCAL
GLOBAL
LOCAL

ALGORITHM
POINT-SAGA [DEFAZIO  2016]
MSDA [SCAMAN ET AL.  2017]
ESDACD [HENDRIKX ET AL.  2019]
DSBA [SHEN ET AL.  2018]
ADFS (THIS PAPER)

Table 1: Comparison of various state-of-the-art decentralized algorithms to reach accuracy ε in

√κb�m + τ√γ�
(m + τ )� κb
�m + κs + γ−1� (1 + τ )
m + √mκs + (1 + τ )� κs
regular graphs. Constant factors are omitted  as well as the log�ε−1� factor in the TIME column.

Reported runtime for Point-SAGA corresponds to running it on a single machine with nm samples.
To allow for direct comparison  we assume that computing a dual gradient of a function fi as required
by MSDA and ESDACD takes time m  although it is generally more expensive than to compute m
separate proximal operators of single fi j functions.
and decentralized algorithms when local functions are smooth and strongly convex. In the rest of
this paper  following Scaman et al. [2017]  we assume that nodes are linked by a communication
network and can only exchange messages with their neighbours. We further assume that each
communication takes time τ and that processing one sample  i.e.  computing the proximal operator
for a single function fi j  takes time 1. The proximal operator of a function fi j is deﬁned by
2η�v − x�2 + fi j(v). The condition number of the Laplacian matrix of
proxηfi j (x) = arg minv
the graph representing the communication network is denoted γ. This natural constant appears in the
running time of many decentralized algorithms and is for instance of order O(1) for the complete
graph and O(n−1) for the 2D grid. More generally  γ−1/2 is typically of the same order as the
diameter of the graph. Following notations from Xiao et al. [2019]  we deﬁne the batch and stochastic
condition numbers κb and κs (which are classical quantities in the analysis of ﬁnite sum optimization)
such that for all i  κb ≥ Mi/σi where Mi is the smoothness constant of the function fi and κs ≥ κi 
with κi = 1 +�m
j=1 Li j/σi the stochastic condition number of node i. Although κs is always
bigger than κb  it is generally of the same order of magnitude  leading to the practical superiority of
stochastic algorithms. The next paragraphs discuss the relevant state of the art for both distributed and
stochastic methods  and Table 1 sums up the speeds of the main decentralized algorithms available
to solve Problem (1). Although it is not a distributed algorithm  Point-SAGA [Defazio  2016]  an
optimal single-machine algorithm  is also presented for comparison.

1

Centralized gradient methods. A simple way to split work between nodes is to distribute gradient
computations and to aggregate them on a parameter server. Provided the network is fast enough  this
allows the system to learn from the datasets of n workers in the same time one worker would need to
learn from its own dataset. Yet  these approaches are very sensitive to stochastic delays  slow nodes 
and communication bottlenecks. Asynchronous methods may be used [Recht et al.  2011  Leblond
et al.  2017  Xiao et al.  2019] to address the ﬁrst two issues  but computing gradients on older (or
even inconsistent) versions of the parameter harms convergence [Chen et al.  2016]. Therefore  this
paper focuses on decentralized algorithms  which are generally less sensitive to communication
bottlenecks [Lian et al.  2017].

Decentralized gradient methods.
In their synchronous versions  decentralized algorithms alternate
rounds of computations (in which all nodes compute gradients with respect to their local data) and
communications  in which nodes exchange information with their direct neighbors [Duchi et al. 
2012  Shi et al.  2015  Nedic et al.  2017  Tang et al.  2018  He et al.  2018]. Communication steps
often consist in averaging gradients or parameters with neighbours  and can thus be abstracted as
multiplication by a so-called gossip matrix. MSDA [Scaman et al.  2017] is a batch decentralized
synchronous algorithm  and it is optimal with respect to the constants γ and κb  among batch
algorithms that can only perform these two operations. Instead of performing global synchronous
updates  some approaches inspired from gossip algorithms [Boyd et al.  2006] use randomized
pairwise communications [Nedic and Ozdaglar  2009  Johansson et al.  2009  Colin et al.  2016].
This for example allows fast nodes to perform more updates in order to beneﬁt from their increased
computing power. These randomized algorithms do not suffer from the usual worst-case analyses of
bounded-delay asynchronous algorithms  and can thus have fast rates because the step-size does not
need to be reduced in the presence of delays. For example  ESDACD [Hendrikx et al.  2019] achieves
the same optimal speed as MSDA when batch computations are faster than communications (τ > m).

2

However  both use gradients of the Fenchel conjugates of the full local functions  which are generally
much harder to get than regular gradients.

Stochastic algorithms for ﬁnite sums. All distributed methods presented earlier are batch methods
that rely on computing full gradient steps of each function fi. Stochastic methods perform updates
based on randomly chosen functions fi j. In the smooth and strongly convex setting  they can be
coupled with variance reduction [Schmidt et al.  2017  Shalev-Shwartz and Zhang  2013  Johnson and
Zhang  2013  Defazio et al.  2014] and acceleration  to achieve the m + √mκs optimal ﬁnite-sum
rate  which greatly improves over the m√κb batch optimum when the dataset is large. Examples
of such methods include Accelerated-SDCA [Shalev-Shwartz and Zhang  2014]  APCG [Lin et al. 
2015]  Point-SAGA [Defazio  2016] or Katyusha [Allen-Zhu  2017]

Decentralized stochastic methods.
In the smooth and strongly convex setting  DSA [Mokhtari and
Ribeiro  2016] and later DSBA [Shen et al.  2018] are two linearly converging stochastic decentralized
algorithms. DSBA uses the proximal operator of individual functions fi j to signiﬁcantly improve
over DSA in terms of rates. Yet  DSBA does not enjoy the √mκs accelerated rates and needs an
excellent network with very fast communications. Indeed  nodes need to communicate each time they
process a single sample  resulting in many communication steps. CHOCO-SGD [Koloskova et al. 
2019] is a simple decentralized stochastic algorithm with support for compressed communications.
Yet  it is not linearly convergent and it requires to communicate between each gradient step as
well. Therefore  to the best of our knowledge  there is no decentralized stochastic algorithm with
accelerated linear convergence rate or low communication complexity without sparsity assumptions
(i.e.  sparse features in linear supervised learning).

ADFS. The main contribution of this paper is a locally synchronous Accelerated Decentralized
stochastic algorithm for Finite Sums  named ADFS. It is very similar to APCG for empirical risk
minimization in the limit case n = 1 (single machine)  for which it gets the same m + √mκs rate.
Besides  this rate stays unchanged when the number of machines grows  meaning that ADFS can
process n times more data in the same amount of time on a network of size n. This scaling lasts as
long as (1+τ )√κsγ− 1
2 < m+√mκs. This means that ADFS is at least as fast as MSDA unless both
the network is extremely fast (communications are faster than evaluating a single proximal operator)
and the diameter of the graph is very large compared to the size of the local ﬁnite sums. Therefore 
ADFS outperforms MSDA and DSBA in most standard machine learning settings  combining optimal
network scaling with the efﬁcient distribution of optimal sequential ﬁnite-sum algorithms. Note
however that  similarly to DSBA and Point-SAGA  ADFS requires evaluating proxfi j   which requires
solving a local optimization problem. Yet  in the case of linear models such as logistic regression  it is
only a constant factor slower than computing ∇fi j  and it is especially much faster than computing
the gradient of the conjugate of the full dual functions ∇f∗i required by ESDACD and MSDA  which
were not designed for ﬁnite sums on each node in the ﬁrst place.
ADFS is based on three novel technical contributions: (i) a novel augmented graph approach which
yields the dual formulation of Section 2  (ii) an extension of the APCG algorithm to arbitrary sampling
that is applied to the dual problem in order to get the generic algorithm of Section 3  and (iii) the
analysis of local synchrony  which is performed in Section 4. Finally  Section 5 presents a relevant
choice of parameters leading to the rates shown in Table 1  and an experimental comparison is done
in Section 6. A Python implementation of ADFS is also provided in supplementary material.

2 Model and Derivations
We now specify our approach to solve the problem in Equation (1). The ﬁrst (classical) step consists
in considering that all nodes have a local parameter  but that all local parameters should be equal
because the goal is to have the global minimizer of the sum. Therefore  the problem writes:

min
θ∈Rn×d

n�i=1

fi(θ(i)) such that θ(i) = θ(j) if j ∈ N(i) 

(2)

where N(i) represents the neighbors of node i in the communication graph. Then  ESDACD and
MSDA are obtained by applying accelerated (coordinate) gradient descent to an appropriate dual
formulation of Problem (2). In the dual formulation  constraints become variables and so updating
a dual coordinate consists in performing an update along an edge of the network. In this work  we
consider a new virtual graph in order to get a stochastic algorithm for ﬁnite sums. The transformation

3

Figure 1: Illustration of the augmented graph for n = 3 and m = 3.

is sketched in Figure 1  and consists in replacing each node of the initial network by a star network.
The centers of the stars are connected by the actual communication network  and the center of the
star network replacing node i has the local function f comm
2 �x�2. The center of node i is
then connected with m nodes whose local functions are the functions fi j for j ∈ {1  ...  m}. If we
denote E the number of edges of the initial graph  then the augmented graph has n(1 + m) nodes
and E + nm edges.
Then  we consider one parameter vector θ(i j) for each function fi j and one vector θ(i) for each
function f comm
. Therefore  there is one parameter vector for each node in the augmented graph.
We impose the standard constraint that the parameter of each node must be equal to the parameters
of its neighbors  but neighbors are now taken in the augmented graph. This yields the following
minimization problem:

: x �→ σi

i

i

min

θ∈Rn(1+m)×d

n�i=1� m�j=1

fi j(θ(i j)) +

σi

2 �θ(i)�2�

(3)

such that θ(i) = θ(j) if j ∈ N(i)  and θ(i j) = θ(i) ∀j ∈ {1  ..  m}.

In the rest of the paper  we use letters k  � to refer to any nodes in the augmented graph  and letters
i  j to speciﬁcally refer to a communication node and one of its virtual nodes. More precisely  we
denote (k  �) the edge between the nodes k and � in the augmented graph. Note that k and � can be
virtual or communication nodes. We denote e(k) the unit vector of Rn(1+m) corresponding to node
k  and ek� the unit vector of RE+nm corresponding to edge (k  �). To clearly make the distinction
between node variables and edge variables  for any matrix on the set of nodes of the augmented graph
x ∈ Rn(1+m)×d we write that x(k) = xT e(k) for k ∈ {1  ...  n(1 + m)} (superscript notation) and for
any matrix on the set of edges of the augmented graph λ ∈ R(E+nm)×d we write that λk� = λT ek�
(subscript notation) for any edge (k  �). For node variables  we use the subscript notation with a
t to denote time  for instance in Algorithm 1. By a slight abuse of notations  we use indices (i  j)
instead of (k  �) when speciﬁcally refering to virtual edges (or virtual nodes) and denote λij instead
of λi (i j) the virtual edge between node i and node (i  j) in the augmented graph. The constraints
of Problem (3) can be rewritten AT θ = 0 in matrix form  where A ∈ Rn(1+m)×(nm+E) is such that
Aek� = µk�(e(k) − e(�)) for some µk� > 0. Then  the dual formulation of this problem writes:

max

λ∈R(nm+E)×d −

n�i=1� m�j=1

f∗i j�(Aλ)(i j)� +

1

2σi�(Aλ)(i)�2� 

(4)

where the parameter λ is the Lagrange multiplier associated with the constraints of Problem (3)—
more precisely  for an edge (k  �)  λk� ∈ Rd is the Lagrange multiplier associated with the constraint
µk�(e(k) − e(�))T θ = 0. At this point  the functions fi j are only assumed to be convex (and not
necessarily strongly convex) meaning that the functions f∗i j are potentially non-smooth. This problem
could be bypassed by transferring some of the quadratic penalty from the communication nodes to the
virtual nodes before going to the dual formulation. Yet  this approach fails when m is large because
the smoothness parameter of f∗i j would scale as m/σi at best  whereas a smoothness of order 1/σi

4

is required to match optimal ﬁnite-sum methods. A better option is to consider the f∗i j terms as
non-smooth and perform proximal updates on them. The rate of proximal gradient methods such
as APCG [Lin et al.  2015] does not depend on the strong convexity parameter of the non-smooth
functions f∗i j. Each f∗i j is (1/Li j)-strongly convex (because fi j was (Li j)-smooth)  so we can
rewrite the previous equation in order to transfer all the strong convexity to the communication node.
Noting that (Aλ)(i j) = −µijλij when node (i  j) is a virtual node associated with node i  we rewrite
the dual problem as:

min

λ∈R(E+nm)×d

qA(λ) +

n�i=1

m�j=1

˜f∗i j(λij) 

(5)

µ2
ij

Σe(i) = σi if i is a center node and e(i j)T

2Li j �x�2 and qA : x �→ Trace� 1

with ˜f∗i j : x �→ f∗i j(−µijx) −
diagonal matrix such that e(i)T
Σe(i j) = Li j if it is
the virtual node (i  j). Since dual variables are associated with edges  using coordinate descent
algorithms on dual formulations from a well-chosen augmented graph of constraints allows us to
handle both computations and communications in the same framework. Indeed  choosing a variable
corresponding to an actual edge of the network results in a communication along this edge  whereas
choosing a virtual edge results in a local computation step. Then  we balance the ratio between
communications and computations by adjusting the probability of picking a given kind of edges.

2 xT AT Σ−1Ax�  where Σ is the

3 The Algorithm: ADFS Iterations and Expected Error

In this section  we detail our new ADFS algorithm. In order to obtain it  we introduce a generalized
version of the APCG algorithm [Lin et al.  2015]  which we detail in Appendix A. More speciﬁcally 
this generalized version allows for arbitrary sampling of coordinates  which is required to use different
probabilities for communications and computations. It also includes corrections for functions that
are strongly convex on a subspace only  which is the case of our augmented dual problem since
the Laplacian of a graph is not full rank. Then we apply it to Problem (5) to get Algorithm 1. Due
to lack of space  we only present the smooth version of ADFS here  but a non-smooth version is
presented in Appendix B  along with the derivations required to obtain Algorithm 1 and Theorem 1.
We denote A† the pseudo inverse of A and Wk� ∈ Rn(1+m)×n(1+m) the matrix such that Wk� =
(e(k) − e(�))(e(k) − e(�))T for any edge (k  �). Note that variables xt  yt and vt from Algorithm 1 are
variables associated with the nodes of the augmented graph and are therefore matrices in Rn(1+m)×d
(one row for each node). They are obtained by multiplying the dual variables of the proximal
coordinate gradient algorithm applied to the dual problem of Equation (5) by A on the left. We denote
σA = λ+

min(AT Σ−1A) the smallest non-zero eigenvalue of the matrix AT Σ−1A.

Algorithm 1 ADFS(A  (σi)  (Li j)  (µk�)  (pk�)  ρ)

  Rk� = eT

k�A†Aek�

// Initialization

// Return primal parameter

5

k�
σApk�

min(AT Σ−1A)  ˜ηk� = ρµ2
1: σA = λ+
2: x0 = y0 = v0 = z0 = 0(n+nm)×d
3: for t = 0 to K − 1 do
4:
1+ρ (xt + ρvt)
5:
6:
7:
8:

yt = 1
Sample edge (k  �) with probability pk�
zt+1 = vt+1 = (1 − ρ)vt + ρyt − ˜ηk�Wk�Σ−1yt
if (k  �) is the virtual edge between node i and virtual node (i  j) then
t+1 = prox˜ηij ˜f∗i j�z(i j)
t+1�
t+1 − v(i j)
(vt+1 − (1 − ρ)vt − ρyt)

v(i j)
v(i)
t+1 = z(i)
end if
xt+1 = yt + ρRk�
pk�

t+1 + z(i j)

9:
10:
11:
12: end for
13: return θK = Σ−1vK

t+1

// Run for K iterations

// Edge sampled from the augmented graph
// Nodes k and � communicate yt

// Virtual node update using fi j
// Center node update

kk + Σ−1

can happen:

= (Σ−1

A a

 

(6)

k�

��

p2
k�
µ2
k�Rk�

i=1 fi(x) and θ�

A�2 + 2σ−1

min(AT Σ−1A)/µ2

minimizer of the dual function F ∗A = qA + ψ. Then θt as output by Algorithm 1 veriﬁes:

Theorem 1. We denote θ� the minimizer of the primal function F : x �→ �n
with C0 = λmax(AT Σ−2A)��A†Aθ�

λ+
min(AT Σ−1A)
if ρ2 ≤ min
Σ−1
kk + Σ−1
A))�.
A (F ∗A(0) − F ∗A(θ�

E��θt − θ��2� ≤ C0(1 − ρ)t 

�� ))  to the graph topology (Rk� = eT
k�) and to the sampling probabilities of the edges (p2

communication network writes L =�communication (k �) µ2

We discuss several aspects related to the implementation of Algorithm 1 below  and provide its Python
implementation in supplementary material.
Convergence rate. The parameter ρ controls the convergence rate of ADFS. It is deﬁned by the
minimum of the individual rates for each edge  which explicitly depend on parameters related to the
functions themselves (1/(Σ−1
k�A†Aek�)  to a mix of both
(λ+
k�). Note that these quantities
are very different depending on whether edges are virtual or not. For example  the parameters µk� for
communication edges are related to the communication matrix by the fact that the Laplacian of the
k�Wk�. In Section 5  we carefully choose
the parameters µk� and pk� based on the graph and the local functions to get the best convergence
speed. Note that once µk� and pk� are ﬁxed  the choice of the other parameters (such as Rk�  ρ  η and
σA) is ﬁxed as well (no extra tuning is required).
Obtaining Line 6. The form of the communication update (virtual or not) comes from the fact that
the update in direction (k  �) writes A∇k�qA(yt) = Aek�eT
Sparse updates. Although the updates of Algorithm 1 involve all nodes of the network  it is actually
possible to implement them efﬁciently so that only two nodes are actually involved in each update  as
described below. Indeed  Wk� is a very sparse matrix so�Wk�Σ−1yt�(k)
t ) =
−�Wk�Σ−1yt�(�) and�Wk�Σ−1yt�(h)
= 0 for h �= k  �. Therefore  only the following situations
1. Communication updates: If (k  �) is a communication edge  the update only requires
nodes k and � to exchange parameters and perform a weighted difference between them.

k�AΣ−1yt = µ2

k y(k)

t − Σ−1

� y(�)

k�Wk�Σ−1yt.

2. Local updates: If (k  �) is the virtual edge between node i and its j-th virtual node 

Note that the Laplacian of the communication graph is�k�
3. Convex combinations: If we choose h �= k  � then v(h)

parameters exchange of line 4 is local  and the proximal term involves function fi j only.
t+1 are obtained by convex
combinations of y(h)
so the update is cheap and local. Besides  nodes actually need
the value of their parameters only when they perform updates of type 1 or 2. Therefore  they
can simply store how many updates of this type they should have done and perform them all
at once before each communication or local update.

t+1 and y(h)

and v(h)

t

t

µ2
ij

Primal proximal step. Algorithm 1 uses proximal steps performed on ˜f∗i j : x → f∗i j(−µi jx) −
using only
2Li j �x�2 instead of fi j. Yet  it is possible to use Moreau identity to express proxη ˜f∗i j
the proximal operator of fi j  which can easily be evaluated for many objective functions. The exact
derivations are presented in Appendix B.3.
Linear case. For many standard machine learning problems  fi j(θ) = �(X T
i jθ) with Xi j ∈ Rd.
This implies that f∗i j(θ) = +∞ whenever θ /∈ Vec (Xi j). Therefore  the proximal steps on the
Fenchel conjugate only have support on Xi j  meaning that they are one-dimensional problems that
can be solved in constant time using for example the Newton method when no analytical solution is
available. Warm starts (initializing on the previous solution) can also be used for solving the local
problems even faster so that in the end  a one-dimensional proximal update is only a constant time
slower than a gradient update. Note that this also allows to store parameters vt and yt as scalar
coefﬁcients for virtual nodes  thus greatly reducing the memory footprint of ADFS.
Unbalanced local datasets. We assume that all local datasets are of ﬁxed size m in order to ease
reading. Yet  the impact of the value of m on Algorithm 1 is indirect  and unbalanced datasets can be
handled without any change. Yet  this may affect waiting time since nodes with large local datasets
will generally be more busy than nodes with smaller ones.

6

4 Distributed Execution and Synchronization Time
Theorem 1 gives bounds on the expected error after a given number of iterations. To assess the
actual speed of the algorithm  it is still required to know how long executing a given number of
iterations takes. This is easy with synchronous algorithms such as MSDA or DSBA  in which all
nodes iteratively perform local updates or communication rounds. In this case  executing ncomp
computing rounds and ncomm communication rounds simply takes time ncomp + τ ncomm. ADFS
relies on randomized pairwise communications  so it is necessary to sample a schedule  i.e.  a random
sequence of edges from the augmented graph  and evaluate how fast this schedule can be executed.
Note that the execution time crucially depends on how many edges can be updated in parallel  which
itself depends on the graph and on the random schedule sampled.

Figure 2: Illustration of parallel execution and local synchrony. Nodes from a toy graph execute
the schedule [(A  C)  (B  D)  (A  B)  (D)  (C  D)]  where (D) means that node D performs a local
update. Each node needs to execute its updates in the partial order deﬁned by the schedule. In
particular  node C has to perform update (A  C) and then update (C  D)  so it is idle between times
τ and τ + 1 because it needs to wait for node D to ﬁnish its local update before the communication
update (C  D) can start. We assume τ > 1 since the local update terminates before the communication
update (A  B). Contrary to synchronous algorithms  no global notion of rounds exist and some nodes
(such as node D) perform more updates than others.

Shared schedule. Even though they only actively take part in a small fraction of the updates  all
nodes need to execute the same schedule to correctly implement Algorithm 1. To generate this shared
schedule  all nodes are given a seed and the sampling probabilities of all edges. This allows them to
avoid deadlocks and to precisely know how many convex combinations to perform between vt and yt.
Execution time. The problem of bounding the probability that a random schedule of ﬁxed length
exceeds a given execution time can be cast in the framework of fork-join queuing networks with
blocking [Zeng et al.  2018]. In particular  queuing theory [Baccelli et al.  1992] tells us that the
average time per iteration exists for any ﬁxed probability distribution over a given augmented graph.
Unfortunately  existing quantitative results are not precise enough for our purpose so we generalize
the method introduced by Hendrikx et al. [2019] to get a ﬁner bound. While their result is valid when
the only possible operation is communicating with a neighbor  we extend it to the case in which nodes
can also perform local computations. For the rest of this paper  we denote pcomm the probability of
performing a communication update and pcomp the probability of performing a local update. They are
such that pcomp + pcomm = 1. We also deﬁne pmax
are in the communication network only. When all nodes have the same probability to participate in
an update  pmax
Theorem 2. Let T (t) be the time needed for the system to execute a schedule of size t  i.e.  t
iterations of Algorithm 1. If all nodes perform local computations with probability pcomp/n with
pcomp > pmax

comm = n maxk��∈N(k) pk�/2  where neighbors

comm = pcomm. Then  the following theorem holds (see proof in Appendix C):

comm or if τ > 1 then there exists C < 24 such that:

(7)

P� 1

t

T (t) ≤

C

n�pcomp + 2τ pmax

comm�� → 1 as t → ∞

Note that the constant C is a worst-case estimate and that it is much smaller for homogeneous
communication probabilities. This novel result states that the number of iterations that Algorithm 1
can perform per unit of time increases linearly with the size of the network. This is possible because
each iteration only involves two nodes so many iterations can be done in parallel. The assumption
pcomp > pcomm is responsible for the 1 + τ factor instead of τ in Table 1  which prevents ADFS from
beneﬁting from network acceleration when communications are cheap (τ < 1). Note that this is
an actual restriction of following a schedule  as detailed in Appendix C. Yet  network operations

7

generally suffer from communication protocols overhead whereas computing a single proximal
update often either has a closed-form solution or is a simple one-dimensional problem in the linear
case. Therefore  assuming τ > 1 is not very restrictive in the ﬁnite-sum setting.

5 Performances and Parameters Choice in the Homogeneous Setting
We now prove the time to convergence of ADFS presented in Table 1  and detail the conditions under
which it holds. Indeed  Section 3 presents ADFS in full generality but the different parameters have
to be chosen carefully to reach optimal speed. In particular  we have to choose the coefﬁcients µ
to make sure that the graph augmentation trick does not cause the smallest positive eigenvalue of
AT Σ−1A to shrink too much. Similarly  ρ is deﬁned in Equation (6) by a minimum over all edges of
a given quantity. This quantity heavily depends on whether the edge is an actual communication edge
or a virtual edge. One can trade pcomp for pcomm so that the minimum is the same for both kind of
edges  but Theorem 2 tells us that this is only possible as long as pcomp > pcomm.

1

1

)

i

ij = λ+

j=1(1 + Li jσ−1

i

)

min(L)n2/(µ2

j=1 Li j = κs for all nodes. For virtual edges  we choose µ2

Parameters choice. We deﬁne L = AcommAT
comm ∈ Rn×n the Laplacian of the communication
graph  with Acomm ∈ Rn×E such that Acommek� = µk�(e(k) − e(�)) for all edge (k  �) ∈ Ecomm 
the set of communication edges. Then  we deﬁne ˜γ = min(k �)∈Ecomm λ+
k�Rk�E2).
As shown in Appendix D.2  ˜γ ≈ γ for regular graphs such as the complete graph or the grid 
justifying the use of γ instead of ˜γ in Table 1. We assume for simplicity that σi = σ and that κi = 1 +
i �m
σ−1
min(L)Li j/(σκi) and pij =
2 /(nScomp) with Scomp = n−1�n
i=1�m
pcomp(1 + Li jσ−1
2 . This corresponds
to using a standard importance sampling scheme for selecting samples. For communications edges
(k  �) ∈ Ecomm  we choose uniform pk� = pcomm/E and µ2
Parameters tuning. The previous paragraph speciﬁes relevant choices of parameters µk� and
pk�. Therefore  ADFS can be run without manual tuning. Extra tuning (such as communication
probabilities) could be performed to adapt to speciﬁc heterogeneous situations. Yet  this should
be considered as an extra degree of freedom that other algorithms may not have access to rather
than an extra parameter to tune. For example  the choice of uniform communication probabilities
is automatically enforced by synchronous gossip-based algorithms such as MSDA or DSBA (all
edges are activated at each step). Note that choosing different values of µk� for communication
edges amounts to tuning the gossip matrix  which is generally considered as an input of the problem.
Our speciﬁc choice of µij for virtual edges allows to precisely bound the strong convexity of the
augmented problem σA  as shown in Appendix D.1.
Inﬂuence of the network topology. The topology of the network only impacts the convergence
rate through the constant ˜γ  which is almost equal to the eigengap of the Laplacian of the graph for
regular networks. This dependence is standard  as it can be seen in Table 1. The topology can also
inﬂuence the synchronization time since the presence of hubs generally increases waiting time.

k� = 1/2.

Theorem 3. If we choose pcomm = min�1/2 �1 + Scomp�˜γ/κs�−1�. Then  running Algorithm 1
for Kε = ρ−1 log(ε−1) iterations guarantees E��θKε − θ��2� ≤ C0ε  and takes time T (Kε)  with:

T (Kε) ≤

√2C�m + √mκs + √2�1 + 4τ�� κs

˜γ � log�1/ε�

with probability tending to 1 as ρ−1 log(ε−1) → ∞  with C0 and C as in Theorems 1 and 2.
Theorem 3 assumes that all communication probabilities and condition numbers are exactly equal
in order to ease reading. A more detailed version with rates for more heterogeneous settings can be
found in Appendix D. Note that while algorithms such as MSDA required to use polynomials of the
initial gossip matrix to model several consecutive communication steps  we can more directly tune
the amount of communication and computation steps simply by adjusting pcomp and pcomm.

6 Experiments
In this section  we illustrate the theoretical results by showing how ADFS compares with MSDA [Sca-
man et al.  2017]  ESDACD [Hendrikx et al.  2019]  Point-SAGA [Defazio  2016]  and DSBA [Shen
et al.  2018]. All algorithms (except for DSBA  for which we ﬁne-tuned the step-size) were run

8

(a) Higgs  n = 4 
m = 104  σ = 1

(b) Higgs  n = 100 

m = 104  σ = 1

(c) Covtype  n = 100 

m = 104  σ = 1

(d) RCV1  n = 100 
m = 103  σ = 10−4

Figure 3: Performances of various decentralized algorithms on the logistic regression task with
m = 104 points per node  regularization parameter σ = 1 and communication delays τ = 5 on 2D
grid networks of different sizes.

with out-of-the-box hyperparameters given by theory on data extracted from the standard Higgs 
Covtype and RCV1 datasets from LibSVM. The underlying graph is assumed to be a 2D grid network.
Experiments were run in a distributed manner on an actual computing cluster. Yet  plots are shown for
idealized times in order to abstract implementation details as well as ensure that reported timings were
not impacted by the cluster status or implementation details. All the details of the experimental setup
as well as a comparison with centralized algorithms can be found in Appendix E. An implementation
of ADFS is also available in supplementary material.
Figure 3a shows that  as predicted by theory  ADFS and Point-SAGA have similar rates on small
networks whereas all other algorithms are signiﬁcantly slower. Figures 3b  3c and 3d use a much
larger grid to evaluate how these algorithms scale. In this setting  Point-SAGA is the slowest algorithm
since it has 100 times less computing power available. MSDA performs quite well on the Covtype
dataset thanks to its very good network scaling (dependent on κb rather than κs). Yet  the m√κb
factor dominates on the Higgs dataset  making it signiﬁcantly slower. DSBA has to communicate after
each proximal step  thus having to wait for a time τ = 5 at each step. ESDACD does not perform
well either because m > τ and it has to perform as many batch computing steps as communication
steps. ADFS does not suffer from any of these drawbacks and therefore outperforms other approaches
by a large margin on these experiments. This illustrates the fact that ADFS combines the strengths
of accelerated stochastic algorithms  such as Point-SAGA  and fast decentralized algorithms  such
as MSDA. We see that DSBA initially outperforms ADFS on the RCV1 dataset. This may be due
to statistical reasons  since there is more overlap of the local datasets of the different nodes in this
experiment than in the others. Yet  we see that ADFS has a better rate in the steady state and quickly
catches up. Besides  we still used a value τ = 5 but a much higher value of τ would be more realistic
in this high dimensional setting since local computations are sparse whereas communications are
fully dimensional. We only compare DSBA and ADFS in this setting since the high-dimensionality
of the dataset made the computation of dual gradients expensive  and Point-SAGA is much slower
when using 100 nodes since it is a single-machine algorithm  as shown on the Higgs and Covtype
datasets.

7 Conclusion

In this paper  we provided a novel accelerated stochastic algorithm for decentralized optimization. To
the best of our knowledge  it is the ﬁrst decentralized algorithm that successfully leverages the ﬁnite-
sum structure of the objective functions to match the rates of the best known sequential algorithms
while having the network scaling of optimal batch algorithms. The analysis in this paper could be
extended to better handle heterogeneous settings  both in terms of hardware (computing times  delays)
and local functions (different regularities). Finally  ﬁnding a locally synchronous algorithm that can
take advantage of arbitrarily low communication delays (beyond the τ > 1 limit) to scale to large
graphs is still an open problem.

Acknowledgement

We acknowledge support from the European Research Council (grant SEQUOIA 724063).

9

References
Zeyuan Allen-Zhu. Katyusha: The ﬁrst direct acceleration of stochastic gradient methods.

Proceedings of Symposium on Theory of Computing  pages 1200–1205  2017.

In

Franc¸ois Baccelli  Guy Cohen  Geert Jan Olsder  and Jean-Pierre Quadrat. Synchronization and

Linearity: an Algebra for Discrete Event Systems. John Wiley & Sons Ltd  1992.

L´eon Bottou. Large-scale machine learning with stochastic gradient descent. In Proceedings of

COMPSTAT  pages 177–186. Springer  2010.

Stephen Boyd  Arpita Ghosh  Balaji Prabhakar  and Devavrat Shah. Randomized gossip algorithms.

IEEE Transactions on Information Theory  52(6):2508–2530  2006.

S´ebastien Bubeck. Convex optimization: Algorithms and complexity. Foundations and Trends R� in

Machine Learning  8(3-4):231–357  2015.

Jianmin Chen  Xinghao Pan  Rajat Monga  Samy Bengio  and Rafal Jozefowicz. Revisiting distributed

synchronous SGD. arXiv preprint arXiv:1604.00981  2016.

Igor Colin  Aur´elien Bellet  Joseph Salmon  and St´ephan Cl´emenc¸on. Gossip dual averaging for
decentralized optimization of pairwise functions. In Proceedings of the International Conference
on International Conference on Machine Learning-Volume 48  pages 1388–1396  2016.

Aaron Defazio. A simple practical accelerated method for ﬁnite sums. In Advances in Neural

Information Processing Systems  pages 676–684  2016.

Aaron Defazio  Francis Bach  and Simon Lacoste-Julien. SAGA: A fast incremental gradient method
with support for non-strongly convex composite objectives. In Advances in Neural Information
Processing Systems  pages 1646–1654  2014.

John C Duchi  Alekh Agarwal  and Martin J Wainwright. Dual averaging for distributed optimization:
Convergence analysis and network scaling. IEEE Transactions on Automatic Control  57(3):
592–606  2012.

Olivier Fercoq and Peter Richt´arik. Accelerated  parallel  and proximal coordinate descent. SIAM

Journal on Optimization  25(4):1997–2023  2015.

Lie He  An Bian  and Martin Jaggi. Cola: Decentralized linear learning. In Advances in Neural

Information Processing Systems  pages 4536–4546  2018.

Hadrien Hendrikx  Francis Bach  and Laurent Massouli´e. Accelerated decentralized optimization with
local updates for smooth and strongly convex objectives. In Artiﬁcial Intelligence and Statistics 
2019.

Bj¨orn Johansson  Maben Rabi  and Mikael Johansson. A randomized incremental subgradient
method for distributed optimization in networked systems. SIAM Journal on Optimization  20(3):
1157–1170  2009.

Rie Johnson and Tong Zhang. Accelerating stochastic gradient descent using predictive variance

reduction. In Advances in Neural Information Processing Systems  pages 315–323  2013.

Anastasia Koloskova  Sebastian U Stich  and Martin Jaggi. Decentralized stochastic optimization
and gossip algorithms with compressed communication. International Conference on Machine
Learning  2019.

R´emi Leblond  Fabian Pedregosa  and Simon Lacoste-Julien. ASAGA: Asynchronous parallel SAGA.

In Artiﬁcial Intelligence and Statistics  pages 46–54  2017.

Yin Tat Lee and Aaron Sidford. Efﬁcient accelerated coordinate descent methods and faster algorithms
for solving linear systems. In Annual Symposium on Foundations of Computer Science (FOCS) 
pages 147–156  2013.

Xiangru Lian  Ce Zhang  Huan Zhang  Cho-Jui Hsieh  Wei Zhang  and Ji Liu. Can decentralized
algorithms outperform centralized algorithms? a case study for decentralized parallel stochastic
gradient descent. In Advances in Neural Information Processing Systems  pages 5330–5340  2017.

10

Qihang Lin  Zhaosong Lu  and Lin Xiao. An accelerated proximal coordinate gradient method. In

Advances in Neural Information Processing Systems  pages 3059–3067  2014.

Qihang Lin  Zhaosong Lu  and Lin Xiao. An accelerated randomized proximal coordinate gra-
dient method and its application to regularized empirical risk minimization. SIAM Journal on
Optimization  25(4):2244–2273  2015.

Tao Lin  Sebastian U. Stich  and Martin Jaggi. Don’t use large mini-batches  use local SGD. arXiv

preprint arXiv:1808.07217  2018.

Aryan Mokhtari and Alejandro Ribeiro. DSA: Decentralized double stochastic averaging gradient

algorithm. Journal of Machine Learning Research  17(1):2165–2199  2016.

Angelia Nedic and Asuman Ozdaglar. Distributed subgradient methods for multi-agent optimization.

IEEE Transactions on Automatic Control  54(1):48–61  2009.

Angelia Nedic  Alex Olshevsky  and Wei Shi. Achieving geometric convergence for distributed
optimization over time-varying graphs. SIAM Journal on Optimization  27(4):2597–2633  2017.

Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Bourse  volume 87. Springer

Science & Business Media  2013.

Yurii Nesterov and Sebastian U. Stich. Efﬁciency of the accelerated coordinate descent method on

structured optimization problems. SIAM Journal on Optimization  27(1):110–123  2017.

Neal Parikh and Stephen Boyd. Proximal algorithms. Foundations and Trends R� in Optimization  1

(3):127–239  2014.

Kumar Kshitij Patel and Aymeric Dieuleveut. Communication trade-offs for synchronized distributed

SGD with large step size. arXiv preprint arXiv:1904.11325  2019.

Benjamin Recht  Christopher Re  Stephen Wright  and Feng Niu. Hogwild: A lock-free approach to
parallelizing stochastic gradient descent. In Advances in Neural Information Processing Systems 
pages 693–701  2011.

Kevin Scaman  Francis Bach  S´ebastien Bubeck  Yin Tat Lee  and Laurent Massouli´e. Optimal
algorithms for smooth and strongly convex distributed optimization in networks. In International
Conference on Machine Learning  pages 3027–3036  2017.

Mark Schmidt  Nicolas Le Roux  and Francis Bach. Minimizing ﬁnite sums with the stochastic

average gradient. Mathematical Programming  162(1-2):83–112  2017.

Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized loss

minimization. Journal of Machine Learning Research  14(Feb):567–599  2013.

Shai Shalev-Shwartz and Tong Zhang. Accelerated proximal stochastic dual coordinate ascent for
regularized loss minimization. In International Conference on Machine Learning  pages 64–72 
2014.

Zebang Shen  Aryan Mokhtari  Tengfei Zhou  Peilin Zhao  and Hui Qian. Towards more efﬁcient
stochastic decentralized learning: Faster convergence and sparse communication. In International
Conference on Machine Learning  pages 4631–4640  2018.

Wei Shi  Qing Ling  Gang Wu  and Wotao Yin. Extra: An exact ﬁrst-order algorithm for decentralized

consensus optimization. SIAM Journal on Optimization  25(2):944–966  2015.

Hanlin Tang  Xiangru Lian  Ming Yan  Ce Zhang  and Ji Liu. D2: Decentralized training over
decentralized data. In International Conference on Machine Learning  pages 4855–4863  2018.

Lin Xiao  Adams Wei Yu  Qihang Lin  and Weizhu Chen. DSCOVR: Randomized primal-dual block
coordinate algorithms for asynchronous distributed optimization. Journal of Machine Learning
Research  20(43):1–58  2019.

Yun Zeng  Augustin Chaintreau  Don Towsley  and Cathy H Xia. Throughput scalability analysis of

fork-join queueing networks. Operations Research  66(6):1728–1743  2018.

11

,Remi Lam
Karen Willcox
David Wolpert
Hadrien Hendrikx
Francis Bach
Laurent Massoulié