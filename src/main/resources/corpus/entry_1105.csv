2016,Consistent Estimation of Functions of Data Missing Non-Monotonically and Not at Random,Missing records are a perennial problem in analysis of complex data of all types  when the target of inference is some function of the full data law.   In simple cases  where data is missing at random or completely at random (Rubin  1976)  well-known adjustments exist that result in consistent estimators of target quantities.  Assumptions underlying these estimators are generally not realistic in practical missing data problems.  Unfortunately  consistent estimators in more complex cases where data is missing not at random  and where no ordering on variables induces monotonicity of missingness status are not known in general  with some notable exceptions (Robins  1997)  (Tchetgen Tchetgen et al  2016)  (Sadinle and Reiter  2016).  In this paper  we propose a general class of consistent estimators for cases where data is missing not at random  and missingness status is non-monotonic.  Our estimators  which are generalized inverse probability weighting estimators  make no assumptions on the underlying full data law  but instead place independence restrictions  and certain other fairly mild assumptions  on the distribution of missingness status conditional on the data.  The assumptions we place on the distribution of missingness status conditional on the data  can be viewed as a version of a conditional Markov random field (MRF) corresponding to a chain graph.  Assumptions embedded in our model permit identification from the observed data law  and admit a natural fitting procedure based on the pseudo likelihood approach of (Besag  1975).  We illustrate our approach with a simple simulation study  and an analysis of risk of premature birth in women in Botswana exposed to highly active anti-retroviral therapy.,Consistent Estimation of Functions of Data Missing

Non-Monotonically and Not at Random

Ilya Shpitser

Department of Computer Science

Johns Hopkins University
ilyas@cs.jhu.edu

Abstract

Missing records are a perennial problem in analysis of complex data of all types 
when the target of inference is some function of the full data law. In simple cases 
where data is missing at random or completely at random [15]  well-known ad-
justments exist that result in consistent estimators of target quantities.
Assumptions underlying these estimators are generally not realistic in practical
missing data problems. Unfortunately  consistent estimators in more complex
cases where data is missing not at random  and where no ordering on variables
induces monotonicity of missingness status are not known in general  with some
notable exceptions [13  18  16].
In this paper  we propose a general class of consistent estimators for cases where
data is missing not at random  and missingness status is non-monotonic. Our es-
timators  which are generalized inverse probability weighting estimators  make
no assumptions on the underlying full data law  but instead place independence
restrictions  and certain other fairly mild assumptions  on the distribution of miss-
ingness status conditional on the data.
The assumptions we place on the distribution of missingness status conditional on
the data can be viewed as a version of a conditional Markov random ﬁeld (MRF)
corresponding to a chain graph. Assumptions embedded in our model permit
identiﬁcation from the observed data law  and admit a natural ﬁtting procedure
based on the pseudo likelihood approach of [2]. We illustrate our approach with
a simple simulation study  and an analysis of risk of premature birth in women in
Botswana exposed to highly active anti-retroviral therapy.

1

Introduction

Practical data sets generally have missing or corrupted entries. A classical missing data problem is
to ﬁnd a way to make valid inferences about the full data law. In other words  the goal is to exploit
assumptions on the mechanism which is responsible for missingness or corruption of data records
to transform the problem into another where missingness or corruption were not present at all.
In simple cases  where missingness status is assumed to be missing completely at random (deter-
mined by an independent coin ﬂip)  or at random (determined by a coin ﬂip independent conditional
on observed data records)  adjustments exist which result in consistent estimators of many functions
of the full data law. Unfortunately  these cases are difﬁcult to justify in practice. Often  data records
are missing intermittently and in complex patterns that do not conform to above assumptions. For
instance  in longitudinal observational studies in medicine  patients may elect to not show up at a
particular time point  for reasons having to do with their (by deﬁnition missing) health status at that
time point  and then later return for followup.

1

In this situation  missingness is not determined by a coin ﬂip independent of missing data conditional
on the observed data (data is missing not at random)  and missingness status of a patient is not
monotonic under any natural ordering. In this setting  deriving consistent estimators of even simple
functions of the full data law is a challenging problem [13  18  16].
In this paper we propose a new class of consistent generalized inverse probability weighting (IPW)
estimators for settings where data is missing non-monotonically and not at random. Like other IPW
estimators  ours makes no modeling assumptions on the full data law  and only models the joint
missingness status of all variables  conditional on those variables. This model can be viewed as
a conditional Markov random ﬁeld (MRF) with independence assumptions akin to those made in
factors of a chain graph model [6]. The assumptions encoded in our model permit identiﬁcation of
the full data law  and allow estimation based on the pseudo likelihood approach of [2].
Our paper is organized as follows. We discuss relevant preliminaries on graphical models in Section
2. We ﬁx additional notation and discuss some prior work on missing data in Section 3. We introduce
our missingness model  and identiﬁcation results based on it in Section 4  and discuss estimation in
Section 5. We illustrate the use of our model with a simple simulation study in Section 6  and give
a data analysis application in Section 7. Finally  we illustrate the difference between our model and
a seemingly similar non-identiﬁed model via a parameter counting argument in Section 8  and give
our conclusions in Section 9.

2 Chain Graph Models

We brieﬂy review statistical chain graph models. A simple mixed graph is a graph where every
vertex pair is connected by at most one edge  and there are two types of possible edges: directed and
undirected. Chain graphs are mixed graphs with the property that for every edge cycle in the graph 
there is no way to assign an orientation to undirected edges in any cycle to form a directed cycle [6].
For a graph G with a vertex set V  and any subset A ⊆ V  deﬁne the induced subgraph GA to be
a graph with the vertex set A and all edges in G between elements in A. Given a graph G  deﬁne
the augmented or moral graph Ga to be an undirected graph obtained from adding a new undirected
edge between any unconnected vertices W1  W2 if a path of the form W1 → ◦ − ◦ . . . ◦ −◦ ← W2
exists in G (note the path may only contain a single intermediate vertex)  and then replacing all
directed edges in G by undirected edges.
A clique in an undirected graph is a set of vertices where any pair of vertices are neighbors. A
maximal clique is a clique such that no superset of it forms a clique. Given an undirected graph G 
denote the set of maximal cliques in G by C(G). A block in a simple mixed graph G is any connected
component formed by undirected edges in a graph obtained from G dropping all directed edges.
Given a simple mixed graph G  denote the set of blocks in G by B(G).
A chain graph model is deﬁned by the following factorization

(cid:89)

p(V) =

where for each B 

p(B | paG(B)) =

p(B | paG(B)) 
(cid:89)

B∈B(G)

1

Z(paG(B))

C∈C((GB∪paG (B))a)

(1)

(2)

φC(C) 

and φC(C) are called potential functions and map value conﬁgurations of variables in C to real
numbers  which are meant to denote an “afﬁnity” of the model towards that particular value conﬁg-
uration. The chain graph factorization implies Markov properties  described in detail in [6].

3 Preliminaries  and Prior Work on Missing Data
We will consider data sets on random variables L ≡ L1  . . . Lk  drawn from a full data law p(L).
Associated with each random variable Li is a binary missingness indicator Ri  where Li is observed
if and only if Ri = 1. Deﬁne a vector (lj  rj) ≡ (lj
k) to be the jth realization of

1  . . . rj

1  . . . lj

k  rj

2

i | rj = 1} ⊆ lj. In missing data settings  for every j  we only get to
p(L  R). Deﬁne (l∗)j ≡ {lj
observe the vector of values ((l∗)j  rj)  and we wish to make inferences using the true realizations
(lj  rj) from the underlying law. Doing this entails building a bridge between the observed and the
underlying realizations  and this bridge is provided by assumptions made on p(L  R).
If we can assume that for any i  p(Ri | L) = p(Ri)  in other words  every missing value is de-
termined by an independent biased coin ﬂip  then data is said to be missing completely at random
(MCAR) [15]. In this simple setting  it is known that any estimator for complete data remains con-
sistent if applied to just the complete cases. A more complex assumption  known as missing at
random (MAR) [15]  states that for every i  p(Ri | L) = p(Ri | L∗). In other words  every missing
value is determined by a biased coin ﬂip that is independent of missing data values conditional on
the observed data values. In this setting  a variety of adjustments lead to consistent estimators.
The most interesting patterns of missingness  and the most relevant in practice  are those that do
not obey either of the above two assumptions  in which case data is said to be missing not at ran-
dom (MNAR). Conventional wisdom in MNAR settings is that without strong parametric modeling
assumptions  many functions of the full data law are not identiﬁed from the observed data law.
Nevertheless  a series of recent papers [8  7  17]  which represented missing data mechanisms as
graphical models  and exploited techniques developed in causal inference  have shown that the full
data law may be non-parametrically identiﬁed under MNAR.
In this approach  the full data law is assumed to factorize with respect to a directed acyclic graph
(DAG) [11]. Assumptions implied by this factorization are then used to derive functions of p(L)
in terms of p(R  L∗). We illustrate the approach using Fig. 1 (a) (b) and (c). Here nodes in green
are assumed to be completely observed. In Fig. 1 (a)  the Markov factorization is p(R2  L1  L2) =
p(R2 | L1)p(L2 | L1)p(L1). It is easy to verify using d-separation [11] in this DAG that p(R2 |
L1  L2) = p(R2 | L1). Since L1 is always observed  this setting is MAR  and we get the following
p(L1  L2) = p(L2|L1)p(L1) = p(L2|L1  R2 = 1)p(L1) = p(R2 = 1  L∗)/p(R2 = 1|L1)  where
the last expression is a functional of p(R  L∗)  and so the full data law p(L) is non-parametrically
identiﬁed from the observed data law p(R  L∗).
The ratio form of the identifying functional suggests the following simple IPW estimator for E[L2] 
known as the Horvitz-Thompson estimator [4]. We estimate p(R2 | L1) either directly if L1 is
discrete and low dimensional  or using maximum likelihood ﬁtting of a model for p(R2 | L1; β) 
for instance a logistic regression model. We then average observed values of L2  but compensate for
the fact that observed and missing values of L2 systematically differ using the inverse of the ﬁtted
2 /p(R2 =
1 | ln
1 ; ˆβ). Under our missingness model  this estimator is clearly unbiased. Under a number of
additional fairly mild conditions  this estimator is also consistent.
A more complicated graph  shown in Fig. 1 (b)  implies the following factorization

probability of the case being observed  conditional on L1  or ˆE[L2] = N−1(cid:80)

p(L1  L2  R1  R2) = p(R1 | L2)p(R2 | L1)p(L1 | L2)p(L2).

(3)
Using d-separation in this DAG  we see that in cases where any values are missing  neither MCAR
nor MAR assumptions hold under this model. Thus  in this example  data is MNAR. However  the
conditional independence constraints implied by the factorization (3) imply the following

n:rn=1 Ln

p(L1  L2) =

p(R1 = 1 | L∗

p(R1 = 1  R2 = 1  L∗)
2  R2 = 1) · p(R2 = 1 | L∗

.

1  R1 = 1)

As before  all terms on the right hand side are functions of p(R  L∗)  and so p(L) is non-
parametrically identiﬁed from p(R  L∗). This example was discussed in [8].
The form of the identifying functional suggests a simple generalization of the IPW estimator from
the previous example for E[L2]. As before  we ﬁt models p(R1 | L∗
1; β2) by
MLE. We take the empirical average of the observed values of L2  but reweigh them by the inverses
of both of the estimated probabilities  using complete cases only:

2; β1) and p(R2 | L∗

(cid:88)

1
N

n:rn

1 =rn

2 =1

2 ·
ln

1

p(r1 = 1 | ln

2 ; ˆβ1) · p(r1 = 1 | ln

1 ; ˆβ2)

.

This estimator is also consistent  with the proof a simple generalization of that for Horvitz-
Thompson. More generally  it has been shown in [8] that in DAGs where no R variable has a

3

L1

L2

L2

L1

L2

L3

L1

L1

L2

L3

L1

L2

L3

L1

L2

L3

R2

R1 R2

R1

(a)

(b)

L4

(c)

R2

R3 R2 R1

R3 R2 R1

R3 R2 R1

(d)

(e)

(f )

(a) A graphical model for MAR data. (b) (c) Graphical model for MNAR data where
Figure 1:
(e)
identiﬁcation of the full data law is possible.
A missingness model seemingly similar to (d)  where the full data law is not identiﬁed.
(f) An
undirected graph representing an independence model Markov equivalent to the independence model
represented by a chain graph in (d).

(d) The no self-censoring model for k = 3.

child  and the edge Li → Ri does not exist for any i  we get:
p(L∗  R = 1)

(cid:81)

p(L) =

p(Ri | paG(Ri)  R{i|Li∈paG (Ri)} = 1)

.

Ri

This identifying functional implies consistent IPW estimators can be derived that are similar to
estimators in the above examples.
The difﬁculty with this result is that it assumes missingness indicators are disconnected. This as-
sumption means we cannot model persistent dropout or loss to followup (where Ri = 0 at one time
point implies Ri = 0 at all following time points)  or complex patterns of non-monotone missing
data (where data is missing intermittently  but missingness also exhibits complex dependence struc-
ture). This kind of dependence is represented by connecting R variables in the graph. Unfortunately 
this often leads to non-identiﬁcation – the functional of the full data law not being a function of the
observed data law. For instance  if we add an edge R1 → R2 to Fig. 1 (b)  it is known that p(L1  L2)
is not identiﬁed from p(R  L∗). Intuition for this is presented in Section 8.
A classical approach to missingness with connected R variables assumes sequential ignorability 
and monotone missingness (where there exists an ordering on variables such that every unit that’s
missing earlier in the ordering remains missing later in the ordering) [12]. However  this approach
does not easily generalize to data missing in non-monotone patterns and not at random.
Nevertheless  if a sufﬁcient number of edges are missing in the graph  identiﬁcation sometimes
is possible even if R variables are dependent  and monotonicity and MAR do not hold. In par-
ticular  techniques from causal inference have been using to derive complex identiﬁcation results
in this setting [7  17]. For instance  it has been shown that in Fig. 1 (c)  p(L1  L2  L3  L4) =
p(L∗ R=1)
qL4 (L1|R2 R1=1)qL4 (R2) and
qL4 (R1  R2  L1  L2  L3) = p(L1  L2  R1  R2 | L3  L4)p(L3). See [17] for details. Unfortunately 
it is often difﬁcult to give a practical missing data setting which exhibits the particular pattern of
missing edges that permits identiﬁcation. In addition  a full characterization of identiﬁability of
functionals of the full data law under MNAR is an open problem. In the next sections  we generalize
the graphical model approach to missing data from DAGs to a particular type of chain graph. Our
model is able to encode fairly general settings where data is missing non-monotonically and not at
random  while also permitting identiﬁcation of the full data law under fairly mild assumptions.

  where ˜p1 = qL4 (R1 = 1 | L2  R2 = 1)  ˜p2 = qL4 (L1|R2=1 R1=1)qL4 (R2=1)

˜p1· ˜p2

(cid:80)

R2

4 The No Self-Censoring Missingness Model

Having given the necessary preliminaries  we are ready to deﬁne our missingness model for data
missing non-monotonically and not at random. Our desiderata for such a model are as follows.
First  in order for our model to be useful in as wide a variety of missing data settings as possible 
we want to avoid imposing any assumptions on the underlying full data law. Second  since we wish
to consider arbitrary non-monotonic missingness patterns  we want to allow arbitrary relationships
between missingness indicators. Finally  since we wish to allow data to be missing not at random 
we want to allow as much dependence of missingness indicators on the underlying data  even if
missing  as possible.

4

However  a completely unrestricted relationship between underlying variables and missingness in-
dicators can easily lead to non-identiﬁcation. For instance in any graph where the edge Li → Ri
exists  the marginal distribution p(Li) is not in general a function of the observed data law. Thus  we
do not allow variables to drive their own missingness status  and thus edges of the form Li → Ri.
However  we allow a variable to inﬂuence its own missingness status indirectly.
Surprisingly  the restrictions given so far essentially characterize independences deﬁning our pro-
posed model. Consider the following chain graph on vertices L1  . . . Lk  R1  . . . Rk. The vertices
L1  . . .   Lk form a complete DAG  meaning that the full data law p(L1  . . .   Lk) has no restrictions.
The vertices R1  . . . Rk form a k-clique  meaning arbitrary dependence structure between R vari-
ables is allowed. In addition  for every i  paG(Ri) ≡ L \ {Li}  which restricts a variable Li from
directly causing its own missingness status Ri. The resulting graph is always a chain graph. An
example (for k = 3) is shown in Fig. 1 (c). The factorizations (1) and (2) for chain graphs of this
form imply a particular set of independence constraints.
Lemma 1 Let G be a chain graph with vertex set R ∪ L  where B(G) = {R {L1}  . . .{Lk}}  and
for every i  paG(Li) = {L1  . . . Li−1}  paG(Ri) = L \ {Li}. Then for every i  and every p(L  R)
that factorizes according to G  the only conditional independences implied by this factorization on
p(L  R) are (∀i) (Ri ⊥⊥ Li | R \ {Ri}  L \ {Li}). 1

(cid:3)

Proof: This follows by the global Markov property results for chain graphs  found in [6].
This set of independences in p(R  L) can be represented not only by a chain graph  but also by
an undirected graph where every pair vertices except Ri and Li (for every i) are connected. Such a
graph  interpreted as a Markov random ﬁeld  would imply the same set of conditional independences
as those in Lemma 1. An example of such a graph for k = 3 is shown in Fig. 1 (f). The reason we
emphasize viewing the model using chain graphs is because the only independence restrictions we
place are on the conditional distribution p(R | L); these restrictions resemble those found in factors
of (1)  and not in classical conditional Markov random ﬁelds  where every variable in R would
depend on every variable in L. We call the missingness model with this independence structure the
no self-censoring model  due to the fact that no variable Li is allowed to directly censor itself via
setting Ri to 0. We now show that under relatively benign assumptions  we can identify the full data
law p(L) in this model.
Lemma 2 If p(R = 1 | L) is identiﬁed from the observed data distribution p(L∗  R = 1)  then
p(L) is identiﬁed from p(L∗  R = 1) via p(L∗  R = 1)/p(R = 1 | L).
Proof: Trivially follows by the chain rule of probability  and the fact that L = L∗ if R = 1.
To obtain identiﬁcation  we use a form of the log conditional pseudo-likelihood (LCPL) function 
ﬁrst considered (in joint form) in [2]. Deﬁne  for any parameterization p(R | L; α)  where |R| = k 

(cid:3)

log PL(α) =

log p(Ri = rj

i | Rj \ {Rj

i} = rj  Lj; α).

k(cid:88)

(cid:88)

i=1

j:Lj\{Lj

i}⊆(L∗)j

In subsequent discussion we will assume that if p1(R | L; α0) (cid:54)= p2(R | L; α) then α0 (cid:54)= α.
Lemma 3 Under the no self-censoring model  in the limit of inﬁnite data sampled from p(R  L) 
where only L∗  R is observed  log PL(α) is maximized at the true parameter values α0.

Proof: The proof follows that for the standard pseudo-likelihood in [9]. The difference between the
LCPL functions evaluated at α0 and α can be expressed as a sum of conditional relative entropies 
which is always non-negative. The fact that every term in the LCPL function is a function of the
(cid:3)
observed data follows by Lemma 1.
We will restrict attention to function classes which satisfy standard assumptions needed to derive
consistent estimators [10]  namely compactness of the parameter space  dominance  and (twice)
differentiability with respect to α  which implies continuity.

1A ⊥⊥ B | C is notation found in [3]  meaning A is independent of B given C.

5

 (cid:88)

R†⊆P(R)\{∅}



Corollary 1 Under the no self-censoring model of missingness  and assumptions above  the estima-
tor of α maximizing the LCPL function is weakly consistent.

Proof: Follows by Lemma 3  and the argument in [9] via equation (9)  Lemma 1 and Theorem 1. (cid:3)

5 Estimation
Since all variables in R are binary  and our model for p(R | L) is a type of conditional MRF  a
log-linear parameterization is natural. We thus adapt the following class of parameterizations:

p(R = r | L = l) =

1

Z(l)

exp

rR† · fR†(lL\L†; αR†)

(4)

where L† ≡ {Li | Ri ∈ R†}  P(R) is the powerset of R  and for every R†  fR† is a function
parameterized by αR†  mapping values of L\ L† to an |R†|-way interaction. Let α ≡ {αR† | R† ⊆
P(R) \ {∅}}. We now show our class of parameterizations gives the right independence structure.
Lemma 4 For an arbitrary p(L)  and a conditional distribution p(R | L) parameterized as in (4) 
the set of independences in Lemma 1 hold in the joint distribution p(L  R) = p(R | L)p(L).
Proof: For any Ri ∈ R  and values r  l  such that rRi = 1 

(cid:110)(cid:80)
(cid:110)(cid:80)

(cid:111)
Ri∈R†⊆P(R)\{∅} rR† · fR†(lL\L†; αR†)
Ri∈R†⊆P(R)\{∅} rR† · fR†(lL\L†; αR†)

(cid:111) .

exp

1 + exp

p(rRi | rR\{Ri}  lL) =

(cid:3)
By deﬁnition of fR†  this functional is not a function of Li  which gives our result.
As expected with a log-linear conditional MRF  the distribution p(Ri | R \ {Ri}  L) resembles the
logistic regression model. Under twice differentiability of fR†  ﬁrst and second derivatives of the
LCPL function have a straightforward derivation  which we omit in the interests of space. Just as
with the logistic model  the estimating equations cannot be solved in closed form  but iterative algo-
rithms are straightforward to construct. For sufﬁciently simple fR†  the Newton-Raphson algorithm
may be employed. Note that every conditional model for Ri is ﬁt only using rows where L \ {Li}
are observed. Thus  the ﬁtting procedure fails in datasets with few enough samples that for some
Ri  no such rows exist. We leave extensions of our model that deal with this issue to future work.
Finally  we use our ﬁtted model p(R | L; ˆα)  as a joint IPW for estimating functions of p(L). For
instance  if L1  . . . Lk−1 represents intermediate outcomes  and Lk the ﬁnal outcome of a longitu-
dinal study with intermittent MNAR dropout represented by our model  and we are interested in the
expected ﬁnal outcome  E[Lk]  we would extend IPW estimators discussed in Section 3 as follows:
k /p(R = 1 | ln; ˆα). Estimation of more complex functionals of p(L)
proceeds similarly  though it may employ marginal structural models if L is high-dimensional. Con-
sistency of these estimators follows  under the usual assumptions  by standard arguments for IPW
estimators  and Corollary 1.

ˆE[Lk] = N−1(cid:80)

n:rn=1 ln

6 A Simple Simulation Study

(cid:80)

To verify our results  we implemented our estimator for a simple model in the class of param-
eterizations (4) that satisfy the assumptions needed for deriving the true parameter by maximiz-
ing the LCPL function. Fig. 2 shows our results. For the purposes of illustration  we chose
the model in Fig. 1 (d) with functions fR† deﬁned as follows. For every edge (Li  Rj) in the
graph  deﬁne a parameter wij  and a parameter w∅. Deﬁne every function fR† to be of the form
i:Li∈L\L† j:Rj∈R† wijLi(1). The values of L1  L2  L3 were drawn from a multivariate normal
distribution with parameters µ = (1  1  1)  Σ = I + 1. We generated a series of datasets with sample
size 100 to 1000  and compared differences between the true means E[Li(1)] and the unadjusted
(complete case) MLE estimate of E[Li(1)] (blue)  and IPW adjusted estimate of E[Li(1)] (red)  for
i = 1  2  3. The true difference is  of course  0. Conﬁdence intervals at the 95% level were comput-
ing using case resampling bootstrap (50 iterations). The conﬁdence intervals generally overlapped

6

(a)

(b)

(c)

Figure 2:
(a) (b) (c) Results of estimating E[L1(1)]  E[L2(1)] and E[L3(1)]  respectively  from a
model in Fig. 1 (d). Y axis is parameter value  and X axis is sample size. Conﬁdence intervals are
reported using case resampling bootstrap at 95% level. Conﬁdence interval size does not necessarily
shrink with sample size – a known issue with IPW estimators.

0  while complete case analysis did not. We noted that conﬁdence intervals did not always shrink
with increased sample size – a known difﬁculty with IPW estimators.
Aside from the usual difﬁculties with IPW estimators  which are known to suffer from high variance 
our estimator only reweighs observed cases  which may in general be a small fraction of the overall
dataset as k grows (in our simulations only 50-60% of cases were complete). Furthermore  esti-
mating weights by maximizing pseudo-likelihood is known to be less efﬁcient than by maximizing
likelihood  since all variability of variables in the conditioning sets is ignored.

7 Analysis Application

To illustrate the performance of our model in a practical setting where data is missing not at random 
we report an analysis of a survey dataset for HIV-infected women in Botswana  also analyzed in [18].
The goal is to estimate an association between maternal exposure to highly active anti-retroviral
therapy (HAART) during pregnancy and a premature birth outcome among HIV-infected women
in Botswana. The overall data consisted of 33148 obstetrical records from 6 cites in Botswana.
Here we restricted to a subset of HIV positive women (n = 9711). We considered four features: the
outcome (preterm delivery)  with 6.7% values missing  and two risk factors – whether the CD4 count
(a measure of immune system health) was lower than 200 cells per µL (53.1% missing)  and whether
HAART was continued from before pregnancy (69.0% missing). We also included hypertension – a
common comorbidity of HIV (6.5% missing). In this dataset missing at random is not a reasonable
assumption  and what’s more missingness patterns are not monotonic.
We used a no-self censoring model with fR†(.) of the same form as in section 6. The results
are shown in Fig. 3  which contain the complete case analysis (CC)  the no self-censoring model
(NSCM)  and a version of the discrete choice model in [18] (DCM). We reported the odds ratios
(ORs) with a 95% conﬁdence interval  obtained by bootstrap. Note that CC and DCM conﬁdence
intervals for the OR overlap 1  indicating a weak or non-existent effect. The conﬁdence interval for
the NSCM indicates a somewhat non-intuitive inverse relationship for low CD4 count and premature
birth  which we believe may be due to assumptions of the NSCM not being met with a limited set
of four variables we considered. In fact  the dataset was sufﬁciently noisy that an expected positive
relationship was not found by any method.

8 Parameter Counting

Parameter counting may be used to give an intuition for why p(L) is identiﬁed under the no
self-censoring model  but not under a very similar missingness model where undirected edges
between R variables are replaced by directed edges under some ordering (see Fig. 1 (d) and

7

−0.20.00.20.42505007501000EstimatedObservedTrueL1 Mean with Sample Size−0.20.00.20.42505007501000EstimatedObservedTrueL2 Mean with Sample Size−0.250.000.250.502505007501000EstimatedObservedTrueL3 Mean with Sample SizeLow CD4 Count

CC

0.782 (0.531  1.135)
NSCM 0.651 (0.414  0.889)
DCM 1.020 (0.742  1.397)

Cont HAART

1.142 (0.810  1.620)
1.032 (0.670  1.394)
1.158 (0.869  1.560)

Figure 3: Analyses of the HIV pregnancy Botswana dataset. CC: complete case analysis  NSCM:
the no self-censoring model with a linear parameterization  DCM: a member of the discrete choice
model family described in [18].

R†⊆P(R)\{∅}

(cid:0) k|R†|

R†∈P(R)\{∅}

(e) for an example for k = 3.) Assume |L| = k  where L variables are discrete with d lev-
els. Then the observed data law may be parameterized by 2k − 1 parameters for p(R)  and by
dk−|R†|−1 parameters for each p(L∗ | R† = 1  R \ R† = 0)  where R† (cid:54)= ∅  for a total of

(cid:1)(d|R†| − 1) = (d + 1)k − 1. The no-censoring model needs
(cid:0) k|R†|
2k − 1 +(cid:80)
(cid:1)dk−|R†| for p(R | L)  yielding a total of
dk − 1 parameters for p(L)  and(cid:80)
dk−1 parameters for p(L)  and(cid:80)k

dk − 1 + (d + 1)k − dk = (d + 1)k − 1  which means the model is just-identiﬁed  and imposes no
restrictions on the observed data law under our assumptions on L. However  the DAG model needs
i=1(dk−1·2i−1) for p(R | L)  for a total of dk−1+dk−1·(2k−1).

The following Lemma implies the DAG version of the no self-censoring model is not identiﬁed.
Lemma 5 dk−1 · (2k − 1) > (d + 1)k − dk for k ≥ 2  d ≥ 2.

Proof: For k = 2  we have 3d > 2d + 1  which holds for any d > 1. If our result holds for k  then
2k > (d + 1)k/dk−1 − d + 1. Then the inequality holds for k + 1  since 2 > (d + 1)/d for d > 1. (cid:3)
Just identiﬁcation under the independence structure given in Lemma 1 was used in [16] (indepen-
dently of this paper) to derive a parameterization of the model that uses the observed data law. This
paper  by contrast  only models the missingness process represented by p(R | L)  and does not
model the observed data law p(L∗) at all.

9 Conclusions

In this paper  we have presented a graphical missingness model based on chain graphs for data
missing non-monotonically and not at random. Speciﬁcally  our model places no restrictions on the
underlying full data law  and on the dependence structure of missingness indicators  and allows a
high degree of interdependence between the underlying unobserved variables and missingness indi-
cators. Nevertheless  under our model  and fairly mild assumptions  the full data law is identiﬁed.
Our estimator is an inverse probability weighting estimator with the weights being joint probabilities
of the data being observed  conditional on all variables. The weights are ﬁtted by maximizing the
log conditional pseudo likelihood function  ﬁrst derived in joint form in [2].
We view our work as an alternative to existing and newly developed methods for MNAR data
[13  18  16]  and an attempt to bridge the gap between the existing rich missing data literature
on identiﬁcation and estimation strategies for MAR data (see [14] for further references)  and newer
work which gave an increasingly sophisticated set of identiﬁcation conditions for MNAR data using
missingness graphs [8  7  17]. The drawbacks of existing MAR methods is that most missingness
patterns of practical interest are not MAR  the drawbacks of the missingness graph literature is that
it has not yet considered estimation  and used assumptions on missingness that  while MNAR  are
difﬁcult to justify in practice (for example Fig. 1 (c) implies a complicated identifying functional
under MNAR  but places a marginal independence restriction (L1 ⊥⊥ L2) on the full data law).
Our work remedies both of these shortcomings. On the one hand  we assume a very general  and
thus easier to justify in practice  missingness model for MNAR data. On the other  we don’t just
consider an identiﬁcation problem for our model  but give a class of IPW estimators for functions
of the observed data law. Addressing statistical and computational challenges posed by our class of
estimators  and making them practical for analysis of high dimensional MNAR data is our next step.

8

References
[1] Heejung Bang and James M. Robins. Doubly robust estimation in missing data and causal inference

models. Biometrics  61:962–972  2005.

[2] Julian Besag. Statistical analysis of lattice data. The Statistician  24(3):179–195  1975.
[3] A. Philip Dawid. Conditional independence in statistical theory. Journal of the Royal Statistical Society 

41:1–31  1979.

[4] D. G. Horvitz and D. J. Thompson. A generalization of sampling without replacement from a ﬁnite

universe. Journal of the American Statistical Association  47:663–685  1952.

[5] J. Lafferty  A. McCallum  and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting
In Proceedings of the Eighteenth International Conference on Machine

and labeling sequence data.
Learning (ICML-01)  pages 282 – 289. Morgan Kaufmann  2001.

[6] Steffan L. Lauritzen. Graphical Models. Oxford  U.K.: Clarendon  1996.
[7] Karthika Mohan and Judea Pearl. Graphical models for recovering probabilistic and causal queries from
missing data. In Z. Ghahramani  M. Welling  C. Cortes  N.D. Lawrence  and K.Q. Weinberger  editors 
Advances in Neural Information Processing Systems 27  pages 1520–1528. Curran Associates  Inc.  2014.
[8] Karthika Mohan  Judea Pearl  and Jin Tian. Graphical models for inference with missing data. In C.J.C.
Burges  L. Bottou  M. Welling  Z. Ghahramani  and K.Q. Weinberger  editors  Advances in Neural Infor-
mation Processing Systems 26  pages 1277–1285. Curran Associates  Inc.  2013.

[9] A. Mozeika  O. Dikmen  and J. Piili. Consistent inference of a general model using the pseudolikelihood

method. Physical Review E: Statistical  Nonlinear  and Soft Matter Physics.  90  2014.

[10] Whitney Newey and Daniel McFadden. Chapter 35: Large sample estimation and hypothesis testing. In

Handbook of Econometrics  Vol.4  pages 2111–2245. Elsevier Science  1994.

[11] Judea Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan and Kaufmann  San Mateo  1988.
[12] James M. Robins. A new approach to causal inference in mortality studies with sustained exposure
periods – application to control of the healthy worker survivor effect. Mathematical Modeling  7:1393–
1512  1986.

[13] James M. Robins. Non-response models for the analysis of non-monotone non-ignorable missing data.

Statistics in Medicine  16:21–37  1997.

[14] James M. Robins and Mark van der Laan. Uniﬁed Methods for Censored Longitudinal Data and Causal-

ity. Springer-Verlag New York  Inc.  2003.

[15] D. B. Rubin. Causal inference and missing data (with discussion). Biometrika  63:581–592  1976.
[16] Mauricio Sadinle and Jerome P. Reiter. Itemwise conditionally independent nonresponse modeling for

incomplete multivariate data. https://arxiv.org/abs/1609.00656  2016. Working paper.

[17] Ilya Shpitser  Karthika Mohan  and Judea Pearl. Missing data as a causal and probabilistic problem.
In Proceedings of the Thirty First Conference on Uncertainty in Artiﬁcial Intelligence (UAI-15)  pages
802–811. AUAI Press  2015.

[18] Eric J. Tchetgen Tchetgen  Linbo Wang  and BaoLuo Sun. Discrete choice models for nonmonotone
nonignorable missing data: Identiﬁcation and inference. https://arxiv.org/abs/1607.02631 
2016. Working paper.

9

,Ilya Shpitser
Marco Ciccone
Marco Gallieri
Jonathan Masci
Christian Osendorfer
Faustino Gomez