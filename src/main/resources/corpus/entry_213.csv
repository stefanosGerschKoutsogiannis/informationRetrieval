2009,A Sparse Non-Parametric Approach for Single Channel Separation of Known Sounds,In this paper we present an algorithm for separating mixed sounds from  a monophonic recording. Our approach makes use of training data which  allows us to learn representations of the types of sounds that compose the  mixture. In contrast to popular methods that attempt to extract com-  pact generalizable models for each sound from training data  we employ  the training data itself as a representation of the sources in the mixture.  We show that mixtures of known sounds can be described as sparse com-  binations of the training data itself  and in doing so produce signiﬁcantly  better separation results as compared to similar systems based on compact  statistical models.,A Sparse Non-Parametric Approach for Single

Channel Separation of Known Sounds

Paris Smaragdis
Adobe Systems Inc.
paris@adobe.com

Madhusudana Shashanka

Bhiksha Raj

Mars Inc.

Carnegie Mellon University

shashanka@alum.bu.edu

bhiksha@cs.cmu.edu

Abstract

In this paper we present an algorithm for separating mixed sounds from
a monophonic recording. Our approach makes use of training data which
allows us to learn representations of the types of sounds that compose the
mixture.
In contrast to popular methods that attempt to extract com-
pact generalizable models for each sound from training data  we employ
the training data itself as a representation of the sources in the mixture.
We show that mixtures of known sounds can be described as sparse com-
binations of the training data itself  and in doing so produce signiﬁcantly
better separation results as compared to similar systems based on compact
statistical models.

Keywords: Example-Based Representation  Signal Separation  Sparse Models.

1 Introduction

This paper deals with the problem of single-channel signal separation – separating out sig-
nals from individual sources in a mixed recording. As of recently  a popular statistical
approach has been to obtain compact characterizations of individual sources and employ
them to identify and extract their counterpart components from mixture signals. Statisti-
cal characterizations may include codebooks [1]  Gaussian mixture densities [2]  HMMs [3] 
independent components [4  5]  sparse dictionaries [6]  non-negative decompositions [7–9]
and latent variable models [10  11]. All of these methods attempt to derive a generalizable
model that captures the salient characteristics of each source. Separation is achieved by
abstracting components from the mixed signal that conform to the statistical characteriza-
tions of the individual sources. The key here is the speciﬁc statistical model employed – the
more eﬀectively it captures the speciﬁc characteristics of the signal sources  the better the
separation that may be achieved.

In this paper we argue that  given any suﬃciently large collection of data from a source 
the best possible characterization of any data is  quite simply  the data themselves. This
has been the basis of several example-based characterizations of a data source  such as
nearest-neighbor  K-nearest neighbor  Parzen-window based models of source distributions
etc. Here  we use the same idea to develop a monaural source-separation algorithm that
directly uses samples from the training data to represent the sources in a mixture. Using
this approach we sidestep the need for a model training step  and we can rely on a very
ﬂexible reconstruction process  especially as compared with previously used statistical mod-
els. Identifying the proper samples from the training data that best approximate a sample
of the mixture is of course a hard combinatorial problem  which can be computationally
demanding. We therefore formulate this as a sparse approximation problem and proceed
to solve it with an eﬃcient algorithm. We additionally show that this approach results in

1

source estimates which are guaranteed to lie on the source manifold  as opposed to trained-
basis approaches which can produce arbitrary outputs that will not necessarily be plausible
source estimates.

Experimental evaluations show that this approach results in separated signals that exhibit
signiﬁcantly higher performance metrics as compared to conceptually similar techniques
which are based on various types of combinations of generalizable bases representing the
sources.

2 Proposed Method

In this section we cover the underlying statistical model we will use  introduce some of the
complications that one might encounter when using it and ﬁnally we propose an algorithm
that resolves these issues.

2.1 The Basic Model

Given a magnitude spectrogram of a single source  each spectral frame is modeled as a
histogram of repeated draws from a multinomial distribution over the frequency bins. At
a given time frame t  consider a random process characterized by the probability Pt(f ) of
drawing frequency f in a given draw. The distribution Pt(f ) is unknown but what one
can observe instead is the result of multiple draws from the process  that is the observed
spectral vector. The model assumes that Pt(f ) is comprised of bases indexed by a latent
variable z. The latent factors are represented by P (f |z). The probability of picking the
z-th distribution in the t-th time frame can be represented by Pt(z). We use this model to
learn the source-speciﬁc bases given by Pt(f |z) as done in [10  11]. At this point this model
is conceptually very similar to the non-negative factorization models in [8  9].

Now let the matrix VF ×T of entries vf t represent the magnitude spectrogram of the mixture
sound and vt represent time frame t (the t-th column vector of matrix V). Each mixture
spectral frame is again modeled as a histogram of repeated draws  from the multinomial
distributions corresponding to every source. The model for each mixture frame includes an
additional latent variable s representing each source  and is given by

Pt(f ) = X
s

Pt(s) X
z∈{zs}

Ps(f |z)Pt(z|s) 

(1)

where Pt(f ) is the probability of observing frequency f in time frame t in the mixture
spectrogram  Ps(f |z) is the probability of frequency f in the z-th learned basis vector from
source s  Pt(z|s) is the probability of observing the z-th basis vector of source s at time t 
{zs} represents the set of values the latent variable z can take for source s  and Pt(s) is the
probability of observing source s at time t.

We can assume that for each source in the mixture we have an already trained model in the
form of basis vectors Ps(f |z). These bases will represent a dictionary of spectra that best
describe each source. Armed with this knowledge we can decompose a new mixture of these
known sources in terms of the contributions of the dictionaries for each source. To do so we
can use the EM algorithm to estimate Pt(z|s) and Pt(s):

Pt(s  z|f ) =

Pt(s)Pt(z|s)Ps(f |z)

Ps Pt(s) Pz∈{zs} Ps(f |z)Pt(z|s)

Pt(z|s) = Pf vf tPt(s  z|f )
Pf z vf tPt(s  z|f )

Pt(s) = Pf vf t Pz∈{zs} Pt(s  z|f )
Pf vf t Ps Pz∈{zs} Pt(s  z|f )

(2)

(3)

(4)

The reconstruction of the contribution of source s in the mixture can then be computed as

ˆv(s)
f t =

Pt(s) Pz∈{zs} Ps(f |z)Pt(z|s)

Ps Pt(s) Pz∈{zs} Ps(f |z)Pt(z|s)

vf t

2

 

Source A
Source B
Mixture
Convex Hull A
Convex Hull B
Simplex

 

Figure 1: Illustration of the basic model. The triangles denote the position of basis functions
for two source classes. The square is an instance of a mixture of the two sources. The mixture
point is not within the convex hull which covers either source  but it is within the convex
hull deﬁned by all the bases combined.

These reconstructions will approximate the magnitude spectrogram of each source in the
mixture. Once we obtain these reconstructions we can use them to modulate the original
phase spectrogram of the mixture and obtain the time-series representation of the sources.

Let us now pursue a brief pictorial understanding of this algorithm  which will help us
introduce the concepts in the next section. Each basis vector and the mixture input will lie
in a F − 1 dimensional simplex (due to the fact that these quantities are normalized to sum
to unity). Each source’s basis set will deﬁne a convex hull within which any point can be
approximated using these bases. Assuming that the training data is accurate  all potential
inputs from that source should lie in that area. The union of all the source bases will deﬁne
a larger space in which a mixture input will be inside. Any mixture point can then be
approximated as a weighted sum of multiple bases from both sources. For visualization of
these concepts for F = 3  see ﬁgure 1.

2.2 Using Training Data Directly as a Dictionary

In this paper  we would like to explain the mixture frame from the training spectral frames
instead of using a smaller set of learned bases. There are two rationales behind this decision.
The ﬁrst is that the resulting large dictionary provides a better description of the sources 
as opposed to the less expressive learned-basis models. As we show later on  this holds even
for learned-basis models with dictionaries as large as the proposed method’s. The secondary
rationale behind this operation is based on the observation that the points deﬁned by the
convex hull of a source’s model  do not necessarily all fall on that source’s manifold. To
visualize this problem consider the plots in ﬁgure 2.
In both of these plots the sources
exhibit a clear structure. In the left plot both sources appear in a circular pattern  and
in the right plot in a spiral form. As shown in [12]  learning a set of bases that explains
these sources results in deﬁning a convex hull that surrounds the training data. Under this
model potential source estimates can now lie anywhere inside these hulls. Using trained-
basis models  if we decompose the mixture points in these ﬁgures we obtain two source
estimates which do not lie in the same manifold as the original sources. Although the input
was adequately approximated  there is no guarantee that the extracted sources are indeed
appropriate outcomes for their sound class.

In order to address this problem and to also provide a richer dictionary for the source
reconstructions  we will make direct use of the training data in order to explain the mixture 
and bypass the basis representation as an abstraction. To do so we will use each frame of the
spectrograms of the training sequences as the bases Ps(f |z). More speciﬁcally  let W(s)
F ×T (s)
be the training spectrogram from source s and let w(s)
represent the time frame t from the
spectrogram. In this case  the latent variable z for source s takes T (s) values  and the z-th
basis function will be given by the (normalized) z-th column vector of W(s).

t

3

 

Source A
Source B
Mixture
Convex Hull A
Convex Hull B
Estimate for A
Estimate for B
Approximation
of mixture

 

Source A
Source B
Mixture
Convex Hull A
Convex Hull B
Estimate for A
Estimate for B
Approximation
of mixture

 

 

Figure 2: Two examples where the separation process using trained bases provides poor
source estimates. In both plots the training data for each source are denoted by △ and ▽ 
and the mixture sample by (cid:3). The learned bases of each source are the vertices of the two
dashed convex hulls that enclose each class. The source estimates and the approximation
of the mixture are denoted by ×  + and (cid:13). In the left case the two sources lie on two
overlapping circular areas  the source estimates however lie outside these areas. On the
right  the two sources form two intertwined spirals. The recovered sources lie very closely
on the competing source’s area  thereby providing a highly inappropriate decomposition.
Although the mixture was well approximated in both cases  the estimated sources were
poor representations of their classes.

With the above model we would ideally want to use one dictionary element per source at
any point in time. Doing so will ensure that the outputs would lie on the source manifold 
and also oﬀset any issues of potential overcompleteness. One way to ensure this is to
perform a reconstruction such that we only use one element of each source at any time 
much akin to a nearest-neighbor model  albeit in an additive setting. This kind of search
can be computationally very demanding so we instead treat this as a sparse approximation
problem. The intuition is that at any given point in time  the mixture frame is explained
by very few active elements from the training data. In other words  we need the mixture
weight distributions and the speaker priors to be sparse at every time instant.

We use the concept of entropic prior introduced in [13] to enforce sparsity. Given a proba-
bility distribution θ  entropic prior is deﬁned as

Pe(θ) = e−H(θ)

(5)

where H(θ) = − Pi θi log θi is the entropy of the distribution. A sparse representation  by
deﬁnition  has few “active” elements which means that the representation has low entropy.
Hence  imposing this prior during maximum a posteriori estimation is a way to minimize
entropy during estimation which will result in a sparse θ distribution. We would like to
minimize the entropies of both the speaker dependent mixture weight distributions (given
by Pt(z|s)) and the source priors (given by Pt(s)) at every frame. In other words  we want
to minimize H(z|s) and H(s) at every time frame. However  we know from information
theory that

H(z  s) = H(z|s) + H(s).

Thus  reducing the entropy of the joint distribution Pt(z  s) is equivalent to reducing the
conditional entropy of the source dependent mixture weights and the entropy of the source
priors.

Since the dictionary is already known and is given by the normalized spectral frames from
source training spectrograms  the parameter to be estimated is given by Pt(z  s). The model 
written in terms of this parameter  is given by

Pt(f ) = X
s

X
z∈{zs}

Ps(f |z)Pt(z  s).

where we have modiﬁed equation (1) by representing Pt(s)Pt(z|s) as Pt(z  s). We use the
Expectation-Maximization algorithm to derive the update equations. Let all parameters
to be estimated be represented by Λ. We impose an entropic prior distribution on Pt(z  s)

4

 

Source A
Source B
Mixture
Estimate for A
Estimate for B
Approximation
of mixture

 
Source A
Source B
Mixture
Estimate for A
Estimate for B
Approximation
of mixture

 

 

Figure 3: Using a sparse reconstruction on the data in ﬁgure 2. Note how in contrast to that
ﬁgure the source estimates are now identiﬁed as training data points  and are thus plausible
solutions. The approximation of the mixture is the nearest point of the line connecting the
two source estimates  to the actual mixture input. Note that the proper solution is the one
that results in such a line that is as close as possible to the mixture point  and not one that
is deﬁned by two training points close to the mixture.

given by

log P (Λ) = β X
t

X
s

X
z∈{zs}

Pt(z  s) log Pt(z  s) 

where β is a parameter indicating the extent of sparsity desired. The E-step is given by

Pt(z  s|f ) =

Pt(z  s)Ps(f |z)

Ps Pz∈{zs} Pt(z  s)Ps(f |z)

and the M-step by

ωt

Pt(z  s)

+ β + β log Pt(z  s) + λt = 0

(6)

where we have let ω represent Pf vf tPt(s  z|f ) and λt is the Lagrange multiplier. The
above M-step equation is a system of simultaneous transcendental equations for Pt(z  s).
Brand [13] proposes a method to solve such problems using the Lambert W function [14].
It can be shown that Pt(z  s) can be estimated as

ˆPt(z  s) =

−ω/β

W(−ωe1+λt/β/β)

.

(7)

Equations (6) (7) form a set of ﬁxed point iterations that typically converge in 2-5 iterations
[13].

Once Pt(z  s) is estimated  the reconstruction of source s can be computed as

f t = Pz∈{zs} Ps(f |z)Pt(z  s)
ˆv(s)
Ps Pz∈{zs} Ps(f |z)Pt(z  s)

vf t

Now let us consider how this problem resolves the issues presented in ﬁgure 2. In ﬁgure 3
we show the results obtained using this approach on the same data. The sparsity parameter
β as set to 0.1. In both plots we see that the source reconstructions lie on a training point 
thereby being a plausible source estimate. The approximation of the mixture is not as exact
as before  since now it has to lie on the line connecting the two active source elements.
This is not however an issue of concern since in practice the approximation is always good
enough  and the guarantee of a plausible source estimate is more valuable than the exact
approximation of the mixture.

Alternative means to strive towards similar results would be to make use of priors such as
in [15  16]. In these approaches the priors are imposed on the mixture weights and thus
are not as eﬀective for this particular task since they still suﬀer from the symptoms of
learned-basis models. This was veriﬁed through cursory simulations  which also revealed an
additional computational complexity penalty against such models.

5

e
d
u

t
i
l

p
m
A

x
e
d
n

l

i
 
s
e
p
m
a
s
 

i

g
n
n
a
r
T

i

5
0
−5

10
5
0
−5

5
10
15
20
25

5
10
15
20
25

Input source 1

Input source 2

Training sample weights 1

25

Training sample weights 2

25

20

20

5

5

10

10

15

Time frame index

15

Time frame index

Figure 4: An oracle case where we ﬁt training data from two speakers  on the mixture
of that data. The top plots show the input waveforms  and the bottom plots shows the
estimated weights multiplied with the source priors. As expected the weights exhibit two
diagonal traces which imply that the algorithm we used has ﬁt the data appropriately.

3 Experimental Results

In this section we present the results of experiments done with real speech data. All of these
experiments we performed on data from the TIMIT speech database on 0dB male/female
mixtures. The sources were sampled as 16 kHz  we used 64 ms windows for the spectrogram
computation  and an overlap of 32 ms. Before the FFT computation  the input was tapered
using a square-root Hann window. The training data was around 25 sec worth of speech for
each speaker  and the testing mixture was about 3 sec long. We evaluated the separation
performance using the metrics provided in [17]. These metrics include the Signal to Inter-
ference Ratio (SIR)  the Signal to Distortion Ratio (SDR)  and the Signal to Artifacts Ratio
(SAR). The ﬁrst is a measure of how well we suppress the interfering speaker  whereas the
other two provide us with a sense of how much the extracted source is corrupted due to the
separation process. All of these are measured in dB and the higher they are the better the
performance is deemed to be.

In the following sections we ﬁrst present some “oracle tests” that validate that indeed
this algorithm is performing as expected  and we then proceed to more realistic testing.
Finally  we show the performance impact of pruning the training data in order to speed up
computation time.

3.1 Oracle tests

In order to verify that this approach works we go through a few oracle experiments. In these
tests we include the actual solutions as training data and we make sure that the answers are
exactly what we would expect to ﬁnd. The ﬁrst experiment we perform is on a mixture for
which the training data includes its isolated constituent sentences. In this experiment we
would expect to see two dictionary components active at each point in time  one from each
speaker’s dictionary  and both of these progressing through the component index linearly
through time. As shown in ﬁgure 4  we observe exactly that behavior. This test provides a
sanity check which veriﬁes that given an answer this algorithm can properly identify it.

A more comprehensive oracle test is shown in ﬁgure 5.
In this experiment  the training
data were again the same as the testing data. We averaged the results from 10 runs using
diﬀerent combinations of speakers  varying sparsity parameters and number of bases. The
sparsity parameter β was checked for various values from 0 to 0.8  and we used trained-basis
models with 5  10  20  40  80  160 and 320 bases  as well as the proposed scenario where
all the training data is used as a dictionary. The primary observation from this experiment
is that the more bases we use the better the results get. We also see that increasing the
sparsity parameter we see a modest improvement in most cases.

6

Signal to Distortion Ratio

Signal to Interference Ratio

Signal to Artifacts Ratio

10

5

0

20

10

0

10

5

0

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

Figure 5: Average separation performance metrics for oracle cases  as dependent on the
choice of diﬀerent number of elements in the speaker’s dictionary  and diﬀerent choices of
the entropic prior parameter β. The left plot shows the SDR  the middle plot the SIR  and
the right plot the SAR  all in dB. The basis row labeled as “Train” is the case where we use
all the training data as a basis set.

Signal to Distortion Ratio

Signal to Interference Ratio

Signal to Artifacts Ratio

10

5

0

20

10

0

10

5

0

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

0.8

0.5

0.3

0.2

0.1
0.01

β

Train

320

160

20

10

80

40

Bases

0

5

Figure 6: Average separation performance metrics for real-world cases  as dependent on the
choice of diﬀerent number of elements in the speaker’s dictionary  and diﬀerent choices of
the entropic prior parameter β. The left plot shows the SDR  the middle plot the SIR  and
the right plot the SAR  all in dB. Sparsely using all of the training data clearly outperforms
low-rank models by a signiﬁcant margin on all metrics.

3.2 Results on Realistic Situations

Let us now consider the more realistic case where the mixture data is diﬀerent from the
training set. In the following simulation we repeat the previous experiment  but in this case
there are no common elements between the training and testing data. The input mixture
has to be reconstructed using approximate samples. The results are now very diﬀerent in
nature. We do not obtain such high numbers in performance as in the oracle case  but
we also see a stronger trend in favor of sparsity and the use of all the training data as a
dictionary. The results are shown in ﬁgure 6. We can clearly see that in all metrics using all
the training data signiﬁcantly outperforms trained-basis models. More importantly  we see
that this is not because we have a larger dictionary. For trained-bases we see a performance
peak at around 80 bases  but then we observe a deterioration in performance as we use a
larger dictionary. Using the actual training data results in a signiﬁcant boost though. Due
to the high dimensionality of the data the eﬀect of sparsity is a little more subtle  but we still
see a helpful boost especially for the SIR which is the most important of the performance
measures. We see some decrease in the SAR  which is expected since the reconstructions are
made using elements that look like the remaining data  and are not made to approximate
the actual input mixture. This does not mean that the extracted sources are distorted and
of poor quality  but rather that they don’t match the original inputs exactly. The use of
sparsity ensures that the output is a plausible speech signal devoid of artifacts like distortion
and musical noise. The eﬀects of sparsity alone in the proposed case are shown separately
in ﬁgure 7.

7

B
d

15

10

5

0

 

SDR

SIR

0   

0.01

SAR

0.1 

0.2 

Sparsity parameter β

0.3 

0.5 

0.8 

 

Figure 7: A slice of the results in ﬁgure 6 in which we only show the case where we use
all the training data as adictionary. The horizontal axis represents various values for the
sparsity parameter β.

B
d

15

10

5

0

 

SDR

0%

SIR

SAR

20%

40%

60%

70%

80%

90%

95%

Percentage of discarded training frames

 

Figure 8: Eﬀect of discarding low energy training frames. The horizontal axis denotes the
percentage of training frames that have been discarded. These are averaged results using a
sparsity parameter β = 0.1.

The unfortunate side eﬀect of the proposed method is that we need to use a dictionary
which can be substantially larger than otherwise. In order to address this concern we show
that the size of the training data can be easily pruned down to a size comparable to trained-
basis models and still outperform them. Since sound signals  especially speech  tend to have
a considerable amount of short-term pauses and regions of silence  we can use an energy
threshold to in order to select the loudest frames of the training spectrogram as bases. In
ﬁgure 8 we show how the separation performance metrics are inﬂuenced as we increasingly
remove bases which lie under various energy percentiles. It is clear that even after discarding
up to at least 70% of the lowest energy training frames the performance is still approximately
the same. After that we see some degradation since we start discarding signiﬁcant parts of
the training data. Regardless this scheme outperforms trained-basis models of equivalent
size. For the 80% percentile case  a trained-basis model of the same size dictionary results
in roughly half the values in all performance metrics  a very signiﬁcant handicap for the
same amount of computational and memory requirements.

The experiments in this paper were all conducted in MATLAB on an average modern desk-
top machine. Overall computations for a single mixture took roughly 4 sec when not using
the sparsity prior  14 sec when using the sparsity prior (primarily due to slow computation
of Lambert’s function)  and dropped down to 5 sec when using the 30% highest energy
frames from the training data.

4 Conclusion

In this paper we present a new approach to solving the monophonic source separation
problem. The contributions of this paper lies primarily in the choice of using all the training
data as opposed to a trained-basis model. In order to do so we present a sparse learning
algorithm which can eﬃciently solve this problem  and also guarantees that the returned
source estimates are plausible given the training data. We provide experiments that show
how this approach is inﬂuenced by the use of varying sparsity constraints and training data
selection. Finally we demonstrate how this approach can generate signiﬁcantly superior
results as compared to trained-basis methods.

8

References

[1] S. T. Roweis  One microphone source separation  in Advances in Neural Information

Processing Systems  2001.

[2] Reddy  A.M. and B. Raj. Soft Mask Methods for Single-Channel Speaker Separation  in
IEEE Transactions of Audio  Speech  and Language Processing  Volume: 15  Issue: 6 
Aug 2007.

[3] T. Kristjansson  J. Hershey  P. Olsen  S. Rennie  and R. Gopinath  Super-human multi-
talker speech recognition: The IBM 2006 speech separation challenge system  in Interna-
tional Conference on Spoken Language Processing (INTERSPEECH)  2006  pp. 97–100 
Kluwer Academic Publishers  ch. 20  pp. 295304.

[4] Casey  M.A.  and A. Westner. Separation of mixed audio sources by independent sub-
space analysis  in Proceedings of the International Conference of Computer Music  2000.
[5] Jang  G.-J.  T.-W. Lee. A Maximum Likelihood Approach to Single-channel Source

Separation  in Journal of Machine Learning Research 4 (2003) pp. 1365–1392.

[6] Pearlmutter  B.  M. Zibulevsky  Blind Source Separation by Sparse Decomposition in a

Signal Dictionary  in Neural Computation 13  pp. 863–882. 2001.

[7] L. Benaroya  L. M. Donagh  F. Bimbot  and R. Gribonval  Non negative sparse repre-
sentation for wiener based source separation with a single sensor  in Acoustics  Speech 
and Signal Processing  IEEE International Conference on  2003  pp. 613–616.

[8] M. N. Schmidt and R. K. Olsson  Single-channel speech separation using sparse non-
negative matrix factorization  in International Conference on Spoken Language Process-
ing (INTERSPEECH)  2006.

[9] T. Virtanen  Sound source separation using sparse coding with temporal continuity

objective  in International Computer Music Conference  ICMC  2003.

[10] Smaragdis  P. Raj  B. and Shashanka  M.V. 2007. Supervised and Semi-Supervised Sep-
aration of Sounds from Single-Channel Mixtures. In proceedings of ICA 2007. London 
UK. September 2007.

[11] Raj  B.; Smaragdis  P. 2005. Latent Variable Decomposition of Spectrograms for single
channel speaker separation. In Proceedings of the IEEE Workshop on Applications of
Signal Processing to Audio and Acoustics  New Paltz  NY  October  2005.

[12] Shashanka  M.V.  B. Raj  P. Smaragdis  2007. Sparse Overcomplete Latent Variable
Decoposition of Counts Data. In Neural Information Processing Systems (NIPS)  Van-
couver  BC  Canada. December 2007.

[13] Brand  M.E. Pattern Discovery via Entropy Minimization. In Uncertainty 99  AIS-

TATS99 1999.

[14] Corless  R.M.  G.H. Gonnet  D.E.G. Hare  D.J. Jeﬀrey  and D.E. Knuth. On the Lam-

bert W Function. Advances in Computational Mathematics 1996.

[15] Bouguila N. and D. Ziou. Using unsupervised learning of a ﬁnite Dirichlet mixture
model to improve pattern recognition applications  Pattern Recognition Letters  Volume
26  Issue 12  September 2005.

[16] Hinneburg  A.  Gabriel  H.-H. and Gohr  A. Bayesian Folding-In with Dirichlet Kernels

for PLSI  in Seventh IEEE International Conference on Data Mining  Oct. 2007

[17] F´evotte  C.  R. Gribonval and E. Vincent. 2005. BSS EVAL Toolbox User Guide  IRISA

Technical Report 1706  Rennes  France  April 2005.

9

,Chongxuan Li
Jun Zhu
Tianlin Shi
Bo Zhang
Fuhai Chen
Rongrong Ji
Jiayi Ji
Xiaoshuai Sun
Baochang Zhang
Xuri Ge
Yongjian Wu
Feiyue Huang
Yan Wang