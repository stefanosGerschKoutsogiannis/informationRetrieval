2011,Collective Graphical Models,There are many settings in which we wish to fit a model of the behavior of individuals but where our data consist only of aggregate information (counts or low-dimensional contingency tables).  This paper introduces Collective Graphical Models---a framework for modeling and probabilistic inference that operates directly on the sufficient statistics of the individual model.  We derive a highly-efficient Gibbs sampling algorithm for sampling from the posterior distribution of the sufficient statistics conditioned on noisy aggregate observations  prove its correctness  and demonstrate its effectiveness experimentally.,Collective Graphical Models

Daniel Sheldon

Oregon State University

sheldon@eecs.oregonstate.edu

Thomas G. Dietterich
Oregon State University

tgd@eecs.oregonstate.edu

Abstract

There are many settings in which we wish to ﬁt a model of the behavior of in-
dividuals but where our data consist only of aggregate information (counts or
low-dimensional contingency tables). This paper introduces Collective Graphi-
cal Models—a framework for modeling and probabilistic inference that operates
directly on the sufﬁcient statistics of the individual model. We derive a highly-
efﬁcient Gibbs sampling algorithm for sampling from the posterior distribution
of the sufﬁcient statistics conditioned on noisy aggregate observations  prove its
correctness  and demonstrate its effectiveness experimentally.

1

Introduction

In ﬁelds such as ecology  marketing  and the social sciences  data about identiﬁable individuals is
rarely available  either because of privacy issues or because of the difﬁculty of tracking individuals
over time. Far more readily available are aggregated data in the form of counts or low-dimensional
contingency tables. Despite the fact that only aggregated data are available  researchers often seek
to build models and test hypotheses about individual behavior. One way to build a model connecting
individual-level behavior to aggregate data is to explicitly model each individual in the population 
together with the aggregation mechanism that yields the observed data.
However  with large populations it is infeasible to reason about each individual. Luckily  for many
purposes it is also unnecessary. To ﬁt a probabilistic model of individual behavior  we only need
the sufﬁcient statistics of that model. This paper introduces a formalism in which one starts with a
graphical model describing the behavior of individuals  and then derives a new graphical model —
the Collective Graphical Model (CGM) — on the sufﬁcient statistics of a population drawn from
that model. Remarkably  the CGM has a structure similar to that of the original model.
This paper is devoted to the problem of inference in CGMs  where the goal is to calculate conditional
probabilities over the sufﬁcient statistics given partial observations made at the population level. We
consider both an exact observation model where subtables of the sufﬁcient statistics are observed
directly  and a noisy observation model where these counts are corrupted. A primary application is
learning: for example  computing the expected value of the sufﬁcient statistics comprises the “E”
step of an EM algorithm for learning the individual model from aggregate data.
Main concepts. The ideas behind CGMs are best illustrated by an example. Figure 1(a) shows the
graphical model plate notation for the bird migration model from [1  2]  in which birds transition
stochastically among a discrete set of locations (say  grid cells on a map) according to a Markov
chain (the individual model). The variable X m
t denotes the location of the mth bird at time t  and
birds are independent and identically distributed. This model gives an explicit way to reason about
the interplay between individual-level behavior (inside the plate) and aggregate data. Suppose  for
example  that very accurate surveys reveal the number of birds nt(i) in each location i at each time
t  and these numbers are collected into a single vector nt for each time step. Then  for example  one
can compute the likelihood of the survey data given parameters of the individual model by summing
out the individual variables. However  this is highly impractical: if our map has L grid cells  then
the variable elimination algorithm run on this model would instantiate tabular potentials of size LM .

1

(a)

(b)

(c)

(d)

(e)

Figure 1: Collective graphical model of bird migation:
(a) replicates of individual model connected to
population-level observations  (b) CGM after marginalizing away individuals  (c) trellis graph on locations
{i  j} for T = 3  M = 10; numbers on edges indicate ﬂow amounts  (d) a degree-one cycle; ﬂows remain
non-negative for δ ∈ {−3  . . .   1}  (e) a degree-two cycle; ﬂows remain non-negative for δ ∈ {−2  . . .   1}.

(cid:1) = O(M L2−1) possible values for the table

L2−1

Figure 1(b) shows the CGM for this model  which we obtain by analytically marginalizing away the
individual variables to get a new model on their sufﬁcient statistics  which are the tables nt t+1 with
entries nt t+1(i  j) equaling the number of birds that ﬂy from i to j from time t to t + 1. A much
better inference approach would be to conduct variable elimination or message passing directly in
the CGM. However  this would still instantiate potentials that are much too big for realistic problems

due to the huge state space: e.g.  there are(cid:0)M +L2−1

nt t+1.
Instead  we will perform approximate inference using MCMC. Here  we are faced with yet another
challenge: the CGM has hard constraints encoded into its distribution  and our MCMC moves must
preserve these constraints yet still connect the state space. To understand this  observe that the
hidden variables in this example comprise a ﬂow of M units through the trellis graph of the Markov
chain  with the interpretation that nt t+1(i  j) birds “ﬂow” along edge (i  j) at time t (see Figure
1(c) and [1]). The constraints are that (1) ﬂow is conserved at each trellis node  and (2) the number
of birds that enter location i at time t equals the observed number nt(i). (In the case of noisy or
partial observations  the latter constraint may not be present.)
How can we design a set of moves that connect any two M-unit ﬂows while preserving these con-
straints? The answer is to make moves that send ﬂow around cycles. Cycles of the form illustrated
in Figure 1(d) preserve ﬂow conservation but change the amount of ﬂow through some trellis nodes.
Cycles of the form in Figure 1(e) preserve both constraints. One can show by graph-theoretic argu-
ments that moves of these two general classes are enough to connect any two ﬂows.
This gives us the skeleton of an ergodic MCMC sampler: starting with a feasible ﬂow  select cycles
from these two classes uniformly at random and propose moves that send δ units of ﬂow around
the cycle. There is one unassuming but crucially important ﬁnal question: how to select δ? The
following is a form of Gibbs sampler: from all values that preserve non-negativity  select δ with
probability proportional to that of the new ﬂow. Such moves are always accepted. Remarkably 
even though δ may take on as many as M different values  the resulting distribution over δ has an
extremely tractable form — either binomial or hypergeometric — and thus it is possible to select δ
in constant time  so we can make very large moves in time independent of the population size.
Contributions. This paper formally develops these concepts in a way that generalizes the construc-
tion of Figure 1 to allow arbitrary graphical models inside the plate  and a more general observation
model that includes both noisy observations and observations involving multiple variables. We de-
velop an efﬁcient Gibbs sampler to conduct inference in CGMs that builds on existing work for con-
ducting exact tests in contingency tables and makes several novel technical contributions. Foremost
is the analysis of the distribution over the move size δ  which we show to be a discrete univariate
distribution that generalizes both the binomial and hypergeometric distributions. In particular  we
prove that it is always log-concave [3]  so it can be sampled in constant expected running time. We

2

Xm1Xm2m=1:MXmT···n1n2nTn1n2nTn1 2nT−1 Tn2 3n3......ijij3115ij2215t=1t=2t=3ijijijt=1t=2t=315253+δ1−δ2+δ1−δijij3+δ1−δ1−δ5+δt=1t=2ij2215t=3show empirically that resulting inference algorithm runs in time that is independent of the population
size  and is dramatically faster than alternate approaches.
Related Work. The bird migration model of [1  2] is a special case of CGMs where the individual
model is a Markov chain and observations are made for single variables only. That work considered
only maximum a posteriori (MAP) inference; the method of this paper could be used for learning in
that application. Sampling methods for exact tests in contingency tables (e.g. [4]) generate tables
with the same sufﬁcient statistics as an observed table. Our work differs in that our observations
are not sufﬁcient  and we are sampling the sufﬁcient statistics instead of the complete contingency
table. Diaconis and Sturmfels [5] broadly introduced the concept of Markov bases  which are sets
of moves that connect the state space when sampling from conditional distributions by MCMC. We
construct a Markov basis in Section 3.1 based on work of Dobra [6]. Lauritzen [7] discusses the
problem of exact tests in nested decomposable models  a setup that is similar to ours. Inference
in CGMs can be viewed as a form of lifted inference [8–12]. The counting arguments used to de-
rive the CGM distribution (see below) are similar to the operations of counting elimination [9] and
counting conversion [10] used in exact lifted inference algorithms for ﬁrst-order probabilistic mod-
els. However  those algorithms do not replicate the CGM construction when applied to a ﬁrst-order
representation of the underlying population model. For example  when applied to the bird migration
model  the C-FOVE algorithm of Milch et al. [10] cannot introduce contingency tables over pairs
of variables (Xt  Xt+1) as required to represent the sufﬁcient statistics; it can only introduce his-
tograms over single variables Xt. Apsel and Brafman [13] have recently taken a step in this direction
by introducing a lifting operation to construct the Cartesian product of two ﬁrst-order formulas. In
the applications we are considering  exact inference (even when lifted) is intractable.

2 Problem Setup

Let (X1  X2  . . .   X|V |) be a set of discrete random variables indexed by the ﬁnite set V   where Xv
takes values in the set Xv. Let x = (x1  . . .   x|V |) denote a joint setting for these variables from the
set X = X1 × . . . × X|V |. For our individual model  we consider graphical models of the form:

Y

C∈C

p(x) =

1
Z

φC(xC).

(1)

has entries n(i) = PM

Here  C is the set of cliques of the independence graph  the functions φC : XC → R+ are potentials 
and Z is a normalization constant. For A ⊂ V   we use the notation xA to indicate the sub-vector
of variables with indices belonging to A  and use similar notation for the corresponding domain
XA. We also assume that p(x) > 0 for all x ∈ X   which is required for our sampler to be ergodic.
Models that fail this restriction can be modiﬁed by adding a small positive amount to each potential.
A collection A is a set of subsets of V . For collections A and B  deﬁne A (cid:22) B to mean that
each A ∈ A is contained in some B ∈ B. A collection A is decomposable if there is a junction tree
T = (A E(T )) on vertex set A [7]. Any collection A can be extended to a decomposable collection
B such that A (cid:22) B; this corresponds to adding ﬁll-in edges to a graphical model.
Consider a sample {x(1)  . . .   x(M )} from the graphical model. A contingency table n = (n(i))i∈X
m=1 I{x(m) = i} that count the number of times each element i ∈ X ap-
pears in the sample. We use index variables such as i  j ∈ X (instead of x ∈ X ) to refer to
cells of the contingency table  where i = (i1  . . .   iV ) is a vector of indices and iA is the sub-
vector corresponding to A ⊆ V . Let tbl(A) denote the set of all valid contingency tables on the
domain XA. A valid table is indexed by elements iA ∈ XA and has non-negative integer entries.
For a full table n ∈ tbl(V ) and A ⊆ V   let the marginal table n ↓ A ∈ tbl(A) be deﬁned as
n(iA  iB). When A = ∅  deﬁne n ↓ A to be
the scalar M  the grand total of the table. Write nA (cid:22) nB to mean that nA is a marginal table of
nB (i.e.  A ⊆ B and nA = nB ↓ A)
Our observation model is as follows. We assume that a sample {x(1)  . . .   x(M )} is drawn from the
individual model  resulting in a complete  but unobserved  contingency table nV . We then observe
the marginal tables nD = nV ↓ D for each set D in a collection of observed margins D  which
we require to be decomposable. Write this overall collection of tables as nD = {nD}D∈D. We
consider noisy observations in Section 3.3.

(n ↓ A)(iA) =PM

iB∈XV \A

A = iA} =P

m=1 I{x(m)

3

Building the CGM. In a discrete graphical model  the sufﬁcient statistics are the contingency tables
nC = {nC}C∈C over cliques. Our approach relies on the ability to derive a tractable probabilistic
model for these statistics by marginalizing out the sample. If C is decomposable  this is possible  so
let us assume that C has a junction tree TC (if not  ﬁll-in edges must be added to the original model).
Let µC be the table of marginal probabilities for clique C (i.e. µC(iC) = Pr(XC = iC)). Let S
be the collection of separators of TC (with repetition if the same set appears as a separator multiple
times) and let nS and µS be the tables of counts and marginal probabilities for the separator S ∈ S.
The distribution of nC was ﬁrst derived by Sundberg [14]:

!−1

µS(iS)nS (iS )

nS(iS)!

 

(2)

 Y

Y

C∈C

iC∈XC

p(nC) = M!

! Y

Y

S∈S

iS∈XS

µC(iC)nC (iC )

nC(iC)!

which can be understood as a product of multinomial distributions corresponding to a sampling
scheme for nC (details omitted). It is this distribution that we call the collective graphical model;
the parameters are the marginal probabilities of the individual model. To understand the conditional
distribution given the observations  let us further assume that D (cid:22) C (if not  add additional ﬁll-
in edges for variables that co-occur within D)  so that each observed table is determined by some
clique table. Write nD (cid:22) nC to express the condition that the tables nC produce observations nD:
formally  this means that D (cid:22) C and that D ⊆ C implies that nD (cid:22) nC. Let I{·} be an indicator
variable. Then

p(nC | nD) ∝ p(nC  nD) = p(nC)I{nD (cid:22) nC}.

(3)
In general  the number of contingency tables over small sets of variables leads to huge state spaces
that prohibit exact inference schemes using (2) and (3). Thus  our approach is based on Gibbs
sampling. However  there are two constraints that signiﬁcanlty complicate sampling. First  the
clique tables must match the observations (i.e.  nD (cid:22) nC). Second  implicit in (2) is the constraint
that the tables nC must be consistent in the sense that they are the sufﬁcient statistics of some sample 
otherwise p(nC) = 0.
Deﬁnition 1. Refer to the set of contingency tables nA = {nA}A∈A as a conﬁguration. A conﬁgu-
ration is (globally) consistent if there exists nV ∈ tbl(V ) such that nA = nV ↓ A for all A ∈ A.
Consistency requires  for example  that any two tables must agree on their common marginal  which
yields the ﬂow conservation constraints in the bird migration model. Table entries must be carefully
updated in concert to maintain these constraints. A full discussion follows.

Inference

3
Our goal is to develop a sampler for p(nC | nD) given the observed tables nD. We assume that the
CGM speciﬁed in Equations (1) and (2) satisﬁes D (cid:22) C  and that the conﬁguration nD is consistent.
Initialization. The ﬁrst step is to construct a valid initial value for nC  which must be a globally
consistent conﬁguration satisfying nD (cid:22) nC. Doing so without instantiating huge intermediate
tables requires a careful sequence of operations on the two junction trees TC and TD. We state one
key theorem  but defer the full algorithm  which is lengthy and technical  to the supplement.
Theorem 1. Let A be a decomposable collection with junction tree TA. Say that the conﬁguration
nA is locally consistent if it agrees on edges of TA  i.e.  if nA ↓ S = nB ↓ S for all (A  B) ∈ E(TA)
with S = A ∩ B. If nA is locally consistent  then it is also globally consistent.
In the bird migration example  Theorem 1 guarantees that preserving ﬂow conservation is enough to
maintain consistency. It is structurally equivalent to the “junction tree theorem” (e.g.  [15]) which
asserts that marginal probability tables {µA}A∈A that are locally consistent are realizable as the
marginals of some joint distribution p(x). Like that result  Theorem 1 also has a constructive proof 
which is the foundation for our initialization algorithm. However  the integrality requirements of
contingency tables necessitate a different style of construction.

3.1 Markov Basis

The ﬁrst key challenge in designing the MCMC sampler is constructing a set of moves that preserve
the constraints mentioned above  yet still connect any two points in the support of the distribution.
Such a set of moves is called a Markov basis [5].

4

Deﬁnition 2. A set of moves M is a Markov basis for the set F if  for any two conﬁgurations
‘=1 z‘  and (ii)

n  n0 ∈ F  there is a sequence of moves z1  . . .   zL ∈ M such that: (i) n0 = n +PL
n +PL0

‘=1 z‘ ∈ F for all L0 = 1  . . .   L − 1.

In our problem  the set we wish to connect is the support of p(nC | nD). Our positivity assumption
on p(x) implies that any consistent conﬁguration nC has positive probability  and thus the support
of p(nC | nD) is exactly the set of consistent conﬁgurations that match the observations:

FnD = {nC : nC is consistent and nD (cid:22) nC}

It is useful at this point to think of the conﬁguration nC as a vector obtained by sorting the table
entries in any consistent fashion (e.g.  lexicographically ﬁrst by C ∈ C and then by iC ∈ XC). A
move can be expressed as n0
C = nC + z where z is an integer-valued vector of the same dimension
as nC that may have negative entries.

let A be decomposable and let nA be consistent withSA = V   so that each variable is part of an

The Dobra Markov basis for complete tables. Dobra [6] showed how to construct a Markov
basis for moves in a complete contingency table given a decomposable set of margins. Speciﬁcally 
observed margin. Deﬁne F∗
nA = {nV ∈ tbl(V ) : nA (cid:22) nV }. Dobra gave a Markov basis for F∗
consisting of only degree-two moves:
Deﬁnition 3. Let (A  S  B) be a partition of V . A degree-two move z has two positive entries and
two negative entries:

nA

z(i  j  k) = 1  z(i  j  k0) = −1  z(i0  j  k) = −1  z(i0  j  k0) = 1 

(4)
where i 6= i0 ∈ XA  j ∈ XS k 6= k0 ∈ XB. Let Md=2(A  S  B) be the set of all degree-two moves
generated from this partition.

k

k0
i + −
i0 − +

A is a Markov basis for F∗
nA.

Theorem 2 (Dobra [6]). Let A be decomposable withSA = V . Let M∗

These are extensions of the well-known “swap moves” for two-dimensional con-
tingency tables (e.g. [5]) to the subtable n(·  j ·)  and they can be visualized as
shown at right. In this arrangement  it is clear that any such move preserves the
marginal table nA (row sums) and the marginal table nB (column sums); in other
words  z ↓ A = 0 and z ↓ B = 0. Moreover  because j is ﬁxed  it is straightfor-
ward to see that z ↓ A ∪ S = 0 and z ↓ B ∪ S = 0. The cycle in Figure 1(e) is a degree-two move
on the table n1 2  with A = {X1}  S = ∅  C = {X2}.
A be the union of the sets of
degree-two moves Md=2(A  S  B) where S is a separator of TA and (A  S  B) is the corresponding
decomposition of V . Then M∗
Adaptation of Dobra basis to FnD. We now adapt the Dobra basis to our setting. Consider a
complete table n ∈ tbl(V ) and the conﬁguration nC = {n ↓ C}C∈C. Because marginalization is a
linear operation  there is a linear operator A such that nC = AnV . Moreover  FnA is the image of
F∗
nA under A. Thus  the image of the Dobra basis under A is a Markov basis for FnA.
A be a Markov basis for F∗
Lemma 1. Let M∗
A} is a Markov basis
for FnA. We call MA the projected Dobra basis.
Proof. Let nC  n0
n0
C = An0
that n0
have that n0

nA such that nC = AnV and
V to nV   meaning
‘=1 z‘. By appliyng the linear operator A to both sides of this equation  we
Az‘ =

Az‘. Furthermore  each intermediate conﬁguration nC +PL0

C ∈ FnA. By consistency  there exist nV   n0
V . There is a sequence of moves z1  . . .   zL ∈ M∗

V = nV +PL
C = nC +PL

nA. Then MA = {Az : z ∈ M∗

V ∈ F∗
A leading from n0

A(nV +PL0

‘=1 z‘) ∈ FnA. Thus MA = {Az : z ∈ M∗

A} is a Markov basis for FnA.

‘=1

‘=1

Locality of moves. First consider the case where all variables are part of some observed table  as
in Dobra’s setting. The practical message so far is that to sample from p(nC | nD)  it sufﬁces to
generate moves from the projected Dobra basis MD. This is done by ﬁrst selecting a degree-two
move z ∈ M∗
D  and then marginalizing z onto each clique of C. Naively  it appears that a single
move may require us to update each clique. However  we will show that z ↓ C will be zero for many
cliques  a fact we can exploit to implement moves more efﬁciently. Let (A  S  B) be the partition

5

used to generate z. We deduce from the discussion following Deﬁnition 3 that z ↓ C = 0 unless C
has a nonempty intersection with both A and B  so we may restrict our attention to these cliques 
which form a connected subtree (Proposition S.1 in supplementary material). An implementation
can then exploit this by pre-computing the connected subtrees for each separator and only generating
the necessary components of the move. Algorithm 1 gives the details of generating moves.

1

2

3

4

5

6
7

VS =SCS.

Algorithm 1: The projected Dobra basis MA
Input: Junction tree TA with separators SA
Before sampling

For each S ∈ SA  ﬁnd the associated
decomposition (A  S  B)
Find the cliques C ∈ C that have non-empty
intersection with both A and B. These form a
subtree of TC. Denote these cliques by CS and let
Let AS = A ∩ VS and BS = B ∩ VS

Unobserved variables. Let us now consider
settings where some variables are not part of
any observed table  which may happen when
the individual model has hidden variables  or 
later  with noisy observations. Additional
moves are needed to connect two conﬁgura-
tions that disagree on marginal tables involv-
ing unobserved variables. Several approaches
are possible. All require the introduction
of degree-one moves z ∈ Md=1(A  B) 
which partition the variables into two sets
(A  B) and have two nonzero entries z(i  j) =
1  z(i0  j) = −1 for i 6= i0 ∈ XA  j ∈ XB. In
the parlance of two-dimensional tables  these
moves adjust two entries in a single column so
they preserve the column sums (nB) but mod-
ify the row sums (nA). The cycle in Figure 1(d) is a degree-one move which adjusts the marginal
table over A = {X2}  but preserves the marginal table over B = {X1  X3}. We proceed once again
by constructing a basis for complete tables and then marginalizing the moves onto cliques.
and let D0 = D ∪ U. Let M∗ consist of the moves M∗
for each A ∈ U. Then M∗ is a Markov basis for F∗
basis for FnD.
Theorem 3 is proved in the supplementary material. The degree-one moves also become local upon
marginalization: it is easy to check that z ↓ C is zero unless C ∩ A is nonempty. These cliques also
form a connected subtree. We recommend choosing U by restricting TC to the variables in U. This
has the effect of adding degree-one moves for each clique of C. By matching the structure of TC 
many of the additional degree-two moves become zero upon marginalization.

Theorem 3. Let U be any decomposable collection on the set of unobserved variables U = V \SD 

D0 together with the moves Md=1(A  V \ A)
nD  and M = {Az : z ∈ M∗} is a Markov

During sampling: to generate a move for separator
S ∈ SA

Select z ∈ Md=2(AS  S  BS)
For each clique C ∈ CS  calculate z ↓ C

3.2 Constructing an efﬁcient MCMC sampler

The second key challenge in constructing the MCMC sampler is utilizing the moves from the
Markov basis in a way that efﬁciently explores the state space. A standard approach is to select
a random move z  a direction δ = ±1 (each with probability 1/2)  and then propose the move
nC + δz in a Metropolis Hastings sampler. Although these moves are enough to connect any two
conﬁgurations  we are particularly interested in problems where M is large  for which moving by
increments of ±1 will be prohibitively slow.
For general Markov bases  Diaconis and Sturmfels [5] suggest instead to construct a Gibbs sampler
that uses the moves as directions for longer steps  by choosing the value of δ from the following
distribution:
(5)
Lemma 2 (Adapted from Diaconis and Sturmfels [5]). Let M be a Markov basis for FnD. Consider
the Markov chain with moves δz generated by ﬁrst choosing z uniformly at random from M and
then choosing δ according to (5). This is a connected  reversible  aperiodic Markov chain on FnD
with stationary distribution p(nC | nD).
However  it is not obvious how to sample from p(δ). They suggest running a Markov chain in δ 
again having the property of moving in increments of one (see also [16]). In our case  the support of
p(δ) may be as big as the population size M  so this solution remains unsatisfactory.
Fortunately  p(δ) has several properties that allow us to create a very efﬁcient sampling algorithm.
For a separator S ∈ S  deﬁne zS as zC ↓ S for any clique C containing S. Now let C(z) be the

p(δ) ∝ p(nC + δz | nD) 

δ ∈ {δ : nC + δz ≥ 0}.

6

Algorithm 2: Sampling from p(δ) in constant time
Input: move z and current conﬁguration nC  with |C(z)| > 1
Calculate δmin and δmax using (8)
Extend the function f (δ) := log p(δ) to the real line using the
equality n! = Γ(n + 1) in Equation (7) for each constituent
function fA(δ) := log pA(δ)  A ∈ S(z) ∪ C(z).
Use the logarithm of Equation (6) to evaluate f (δ) (for sampling)
and its derivatives (for Newton’s method):

f (q)(δ) =

f (q)
S (δ).

q = 0  1  2.

X

C (δ) − X

f (q)

C∈C(z)

S∈S(z)

dn2 Γ(n).

Evaluate the derivatives of fA(δ) using the logarithm of Equation
(7) and the digamma and trigamma functions ψ(n) = d
and ψ1(n) = d2
Find the mode δ∗ by ﬁrst using Newton’s method to ﬁnd δ0
maximizing f (δ) over the real line  and then letting δ∗ be the
value in {bδ0c dδ0e  δmin  δmax} that attains the maximum.
Run the rejection sampling algorithm of Devroye [3].

dn Γ(n)

Figure 2: Top:
running time
vs. M for a small CGM. Bottom:
convergence of MCMC for ran-
dom Bayes nets.

1

2

3

4

5

set of cliques C for which zC is nonzero  and let S(z) be deﬁned analogously. For A ∈ S ∪ C  let
I +(zA) ⊆ XA be the indices of +1 entries of zA and let I−(zA) be the indices of −1 entries. By
ignoring constant terms in (2)  we can write (5) as

p(δ) ∝ Y

C∈C(z)

µA(i)δ

(nA(i) + δ)!

pC(δ) Y
Y

S∈S(z)

j∈I−(zA)

pS(δ)−1 

µA(j)−δ
(nA(j) − δ)!  

pA(δ) := Y

i∈I+(zA)

(6)

(7)

A ∈ S ∪ C.

δmin := −

To maintain the non-negativity of nC  δ is restricted to the support δmin  . . .   δmax with:

min

min

nC(i) 

δmax :=

C∈C(z) i∈I+(zC )

C∈C(z) j∈I−(zC )

(8)
Notably  each move in our basis satisﬁes |I +(zA) ∪ I +(zA)| ≤ 4  so p(δ) can be evaluated by
examining at most four entries in each table for cliques in C(z). It is worth noting that Equation
(7) reduces to the binomial distribution for degree-one moves and the (noncentral) hypergeomet-
ric distribution for degree-two moves  so we may sample from these distributions directly when
|C(z)| = 1. More importantly  we will now show that p(δ) is always a member of the log-concave
class of distributions  which are unimodal and can be sampled very efﬁciently.
Deﬁnition 4. A discrete distribution {pk} is log-concave if p2
Theorem 4. For any degree-one or degree-two move z  the distribution p(δ) is log-concave.

k ≥ pk−1pk+1 for all k [3].

nC(j).

It is easy to show that both pC(δ) and pS(δ) are log-concave. The proof of Theorem 4  which is
found in the supplementary material  then pairs each separator S with a clique C and uses properties
of the moves to show that pC(δ)/pS(δ) is also log-concave. Then  by Equation (6)  we see that p(δ)
is a product of log-concave distributions  which is also log-concave.
We have implemented the rejection sampling algorithm of Devroye [3]  which applies to any discrete
log-concave distribution and is simple to implement. The expected number of times it evaluates p(δ)
(up to normalization) is fewer than 5. We must also provide the mode of the distribution  which we
ﬁnd by Newton’s method  usually taking only a few steps. The running time for each move is thus
independent of the population size. Additional details are given in Algorithm 2.

3.3 Noisy Observations

Population-level counts from real survey data are rarely exact  and it is thus important to incorpo-
rate noisy observations into our model. In this section  we describe how to modify the sampler for

7

101102100102104Population sizeSeconds  VEMCMC05010000.10.20.30.4SecondsRelative error  exact−nodesexact−chainnoisy−nodesnoisy−chainthe case when all observations are noisy; it is a straightforward generalization to allow both noisy
and exact observations. Suppose that we make noisy observations yR = {yR : R ∈ R} corre-
sponding to the true marginal tables nR for a collection R (cid:22) C (that need not be decomposable).
For simplicity  we restrict our attention to models where each entry n in the true table is corrupted
independently according to a univariate noise model p(y | n).
We assume that the noise model is log-concave  meaning in this case that log p(y | n) is a concave
function of the parameter n. Most commonly-used univariate densities are log-concave with respect
to various parameters [17]. A canonical example from the bird migration model is p(y | n) =
Poisson(αn)  so the survey count is Poisson with mean proportional to the true number of birds
present. This example and others are discussed in [2]. We also assume that the support of p(y | n)
does not depend on n  so that observations do not restrict the support of the sampling distribution.
For example  we must modify our Poisson noise model to be p(y | n) = Poisson(αn + λ0) with
small background rate λ0 to avoid the hard constraint that n must be positive if y is positive.
In analogy with (3)  we can then write p(nC | yR) ∝ p(nC)p(yR|nC) (the hard constraint is now
replaced with the likelihood term p(yR|nC)). Given our assumption on p(y | n)  the support of
p(nC | yR) is the same as the support of p(nC)  and a Markov basis can be constructed using the
tools from Section 3.1  with all variables being unobserved. In the sampler  the expression for p(δ)
must now be updated to incorporate the likelihood term p(yR|nC +δz). Following reasoning similar
to before  we let R(z) be the sets in R for which z ↓ R is nonzero and ﬁnd that Equation (6) gains

the additional factorQ

pR(δ) = Y

R∈R(z) pR(δ)  where

p(yR(i) | nR(i) + δ) Y

i∈I+(zR)

j∈I−(zR)

Each factor in (9) is log-concave in δ by our assumption on p(y | n)  and hence the overall distribu-
tion p(δ) remains log-concave. To update the sampler for p(δ)  modify line 3 of Algorithm 2 in the
obvious fashion to include these new factors when computing log p(δ) and its derivatives.

p(yR(j) | nR(j) − δ).

(9)

4 Experiments

We implemented our sampler in MATLAB using Murphy’s Bayes net toolbox [18] for the underlying
operations on graphical models and junction trees. Figure 2 (top) compares the running time of our
method vs. exact inference in the CGM by variable elimination (VE) for a very small model. The
task was to estimate E[n2 3 | n1  n3] in the bird migration model for L = 2  T = 3  and varying M.
The running time of VE is O(M L2−1)  which is cubic in M (linear on a log-log plot)  while the time
for our method to estimate the same quantity within 2% relative error actually decreases slightly with
population size. Figure 2 (bottom) shows convergence of the sampler for more complex models. We
generated 30 random Bayes nets on 10 binary variables  and generated two sets of observed tables
for a population of M = 100  000: the set NODES has a table for each single variable  while the
set CHAIN has tables for pairs of variables that are adjacent in a random ordering. We repeated the
same process with the noise model p(y | n) = Poisson(0.2n + 0.1) to generate noisy observations.
We then ran our sampler to estimate E[nC | nD] as would be done in the EM algorithm. The plots
show relative error in this estimate as a function of time  averaged over the 30 nets. For more details 
including how we derived the correct answer for comparison  see Section 4.1 in the supplementary
material. The sampler converged quickly in all cases with the more complex CHAIN observation
model taking longer than NODES  and noisy observations taking slightly longer than exact ones. We
found (not shown) that the biggest source of variability in convergence time was due to individual
Bayes nets  while repeat trials using the same net demonstrated very similar behavior.
Concluding Remarks. An important area of future research is to further explore the use of CGMs
within learning algorithms  as well as the limitations of that approach: when is it possible to learn in-
dividual models from aggregate data? We believe that the ability to model noisy observations will be
an indispensable tool in real applications. For complex models  convergence may be difﬁcult to di-
agnose. Some mixing results are known for samplers in related problems with hard constraints [16];
any such results for our model would be a great advance. The use of distributional approximations
for the CGM model and other methods of approximate inference also hold promise.
Acknowledgments. We thank Lise Getoor for pointing out the connection between CGMs and lifted
inference. This research was supported in part by the grant DBI-0905885 from the NSF.

8

References
[1] D. Sheldon  M. A. S. Elmohamed  and D. Kozen. Collective inference on Markov models for
modeling bird migration. In Advances in Neural Information Processing Systems (NIPS 2007) 
pages 1321–1328  Cambridge  MA  2008. MIT Press.

[2] Daniel Sheldon. Manipulation of PageRank and Collective Hidden Markov Models. PhD

thesis  Cornell University  2009.

[3] L. Devroye. A simple generator for discrete log-concave distributions. Computing  39(1):

87–91  1987.

[4] A. Agresti. A survey of exact inference for contingency tables. Statistical Science  7(1):131–

153  1992.

[5] P. Diaconis and B. Sturmfels. Algebraic algorithms for sampling from conditional distribu-

tions. The Annals of statistics  26(1):363–397  1998. ISSN 0090-5364.

[6] A. Dobra. Markov bases for decomposable graphical models. Bernoulli  9(6):1093–1108 

2003. ISSN 1350-7265.

[7] S.L. Lauritzen. Graphical models. Oxford University Press  USA  1996.
[8] D. Poole. First-order probabilistic inference. In Proc. IJCAI  volume 18  pages 985–991  2003.
[9] R. de Salvo Braz  E. Amir  and D. Roth. Lifted ﬁrst-order probabilistic inference. Introduction

to Statistical Relational Learning  page 433  2007.

[10] B. Milch  L.S. Zettlemoyer  K. Kersting  M. Haimes  and L.P. Kaelbling. Lifted probabilistic

inference with counting formulas. Proc. 23rd AAAI  pages 1062–1068  2008.

[11] P. Sen  A. Deshpande  and L. Getoor. Bisimulation-based approximate lifted inference.

In
Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁcial Intelligence  pages
496–505. AUAI Press  2009.

[12] J. Kisynski and D. Poole. Lifted aggregation in directed ﬁrst-order probabilistic models. In

Proc. IJCAI  volume 9  pages 1922–1929  2009.

[13] Udi Apsel and Ronen Brafman. Extended lifted inference with joint formulas. In Proceedings
of the Proceedings of the Twenty-Seventh Conference Annual Conference on Uncertainty in
Artiﬁcial Intelligence (UAI-11)  pages 11–18  Corvallis  Oregon  2011. AUAI Press.

[14] R. Sundberg. Some results about decomposable (or Markov-type) models for multidimensional
contingency tables: distribution of marginals and partitioning of tests. Scandinavian Journal
of Statistics  2(2):71–79  1975.

[15] M.J. Wainwright and M.I. Jordan. Graphical models  exponential families  and variational

inference. Foundations and Trends in Machine Learning  1(1-2):1–305  2008.

[16] P. Diaconis  S. Holmes  and R.M. Neal. Analysis of a nonreversible Markov chain sampler.

The Annals of Applied Probability  10(3):726–752  2000.

[17] W.R. Gilks and P. Wild. Adaptive Rejection sampling for Gibbs Sampling. Journal of the Royal

Statistical Society. Series C (Applied Statistics)  41(2):337–348  1992. ISSN 0035-9254.

[18] K. Murphy. The Bayes net toolbox for MATLAB. Computing science and statistics  33(2):

1024–1034  2001.

9

,Siddartha Ramamohan
Arun Rajkumar
Shivani Agarwal
Shivani Agarwal