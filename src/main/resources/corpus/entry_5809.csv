2019,User-Specified Local Differential Privacy in Unconstrained Adaptive Online Learning,Local differential privacy is a strong notion of privacy in which the provider of the data guarantees privacy by perturbing the data with random noise. In the standard application of local differential differential privacy the distribution of the noise is constant and known by the learner. In this paper we generalize this approach by allowing the provider of the data to choose the distribution of the noise without disclosing any parameters of the distribution to the learner  under the constraint that the distribution is symmetrical. We consider this problem in the unconstrained Online Convex Optimization setting with noisy feedback. In this setting the learner receives the subgradient of a loss function  perturbed by noise  and aims to achieve sublinear regret with respect to some competitor  without constraints on the norm of the competitor. We derive the first algorithms that have adaptive regret bounds in this setting  i.e. our algorithms adapt to the unknown competitor norm  unknown noise  and unknown sum of the norms of the subgradients  matching state of the art bounds in all cases.,User-Speciﬁed Local Differential Privacy in
Unconstrained Adaptive Online Learning

Dirk van der Hoeven
Mathematical Institute

Leiden University
Leiden  2333 CA

dirkvderhoeven@gmail.com

Abstract

Local differential privacy is a strong notion of privacy in which the provider of
the data guarantees privacy by perturbing the data with random noise. In the
standard application of local differential privacy the distribution of the noise is
constant and known by the learner. In this paper we generalize this approach by
allowing the provider of the data to choose the distribution of the noise without
disclosing any parameters of the distribution to the learner  under the constraint
that the distribution is symmetrical. We consider this problem in the unconstrained
Online Convex Optimization setting with noisy feedback. In this setting the learner
receives the subgradient of a loss function  perturbed by noise  and aims to achieve
sublinear regret with respect to some competitor  without constraints on the norm
of the competitor. We derive the ﬁrst algorithms that have adaptive regret bounds
in this setting  i.e. our algorithms adapt to the unknown competitor norm  unknown
noise  and unknown sum of the norms of the subgradients  matching state of the art
bounds in all cases.

1

Introduction

In learning  a natural tension exists between learners and the providers of data. The learner aims to
make optimal use of the data  perhaps even at the cost of the privacy of the providers. To nevertheless
ensure sufﬁcient privacy the provider can add random noise to the data that he sends to the learner.
This idea is called -local differential privacy (Wasserman and Zhou  2010; Duchi et al.  2014) and the
standard implementation has constant  for all providers. However  not all providers care equivalently
about their privacy (Song et al.  2015). Some providers may wish to aid the learner in making optimal
use of their data  while other providers value their privacy over helping the learner. For instance 
celebrities might care more for their privacy than others because they want to preserve the privacy
they have left. To complicate things further  the providers of the data may not wish to reveal how
much they care about their privacy  because when privacy levels differ between providers these
privacy levels become privacy sensitive themselves. Furthermore  not all parts of the data are equally
privacy sensitive. For example  tweets are already publicly available  but browsing history may
contain sensitive information that should be kept private. To capture these varying privacy constraints
we allow each provider to choose how much noise is added for each dimension of the data.
In this paper  we consider these problems in the Online Convex Optimization (OCO) setting (Hazan 
2016) with local differential privacy guarantees. The OCO framework is a popular and successful
framework to design and analyse many algorithms used to train machine learning models. The OCO
setting proceeds in rounds t = 1  . . .   T . In a given round t the learner is to provide a prediction
wt ∈ Rd. An adversary then chooses a convex loss function (cid:96)t and sends a subgradient gt ∈ ∂(cid:96)t(wt)
to the learner. We work with an unconstrained domain for w  which has recently grown in popularity

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

(see McMahan and Orabona (2014); Foster et al. (2015); Orabona and Pál (2016); Foster et al. (2017);
Cutkosky and Boahen (2017); Kotłowski (2017); Cutkosky and Orabona (2018); Foster et al. (2018);
Jun and Orabona (2019)). We aim to develop online learning methods that make the best use of
data providers who wish to help the learner while at the same time guaranteeing the desired level of
privacy for providers that care about their privacy  without knowing how much each each provider
adds to the data.
We consider the local differential privacy model with varying levels of privacy unknown to the
learner. Differential privacy (Dwork and Roth  2014) is a privacy model that is used in many recent
machine-learning applications. The local differential privacy model is a variant of differential privacy
in which the learner can only access the data of the provider via noisy estimates (Wasserman and
Zhou  2010; Duchi et al.  2014). The local differential privacy model with varying levels of privacy
appeared before in Song et al. (2015)  but with known levels of noise and only two levels of noise.
Learning in our setting is modelled by the OCO framework with noisy estimates of the subgradient
(see also Jun and Orabona (2019)). To ensure local differential privacy the provider adds zero-mean
noise ξt ∈ Rd to the subgradient gt. The learner then receives the perturbed subgradient ˜gt = gt + ξt.
We allow each ξt to follow a different distribution each round to satisfy different privacy guarantees.
In the standard OCO framework the goal of the learner is to minimize the regret with respect to some
parameter u ∈ Rd:

T(cid:88)

t=1

RT (u) =

(cid:96)t(wt) − (cid:96)t(u).

E[RT (u)] = O

E[(cid:107)u(cid:107)

(cid:107)˜gt(cid:107)2

(2)

t=1

(cid:63)] ≤ 3 E[(cid:107)ξt(cid:107)2

(cid:63)] + 3 E[(cid:107)gt(cid:107)2
t=1 (cid:107)gt(cid:107)2

which implies (1) via Jensen’s inequality and E[(cid:107)˜gt(cid:107)2

motivated by work in the noiseless setting  where O((cid:107)u(cid:107)(cid:113)(cid:80)T

(cid:63)]. This bound was
(cid:63) ln(1 + (cid:107)u(cid:107)T ))) bounds
are possible (Cutkosky and Orabona  2018). With these type of bounds  when the sum of the
squared norms of the subgradients is small the regret is also small. To achieve (2) we require two
assumptions: bounded (cid:107)gt(cid:107)(cid:63) and zero-mean symmetrical noise ξt. The assumption on gt is common
in standard OCO. The symmetrical noise assumption is satisﬁed for common mechanisms to ensure
local differential privacy. The dependence on E[(cid:107)ξt(cid:107)2
(cid:63)] is unimprovable  which is shown
by the lower bound for this setting by Jun and Orabona (2019).
The algorithms in this paper are built using the recently developed wealth-regret duality approach
(Mcmahan and Streeter  2012). We provide two algorithms. The ﬁrst achieves the bound in (2). The
second algorithm satisﬁes (2) for each dimension separately. This second algorithm can exploit sparse
privacy structures  which combined with sparse subgradients yields low expected regret bounds.

(cid:63)] and E[(cid:107)gt(cid:107)2

2

However  since the learner receives perturbed subgradients we consider the expected regret E[R(u)] 
where the expectation is over the randomness in wt due to the noisy subgradients. The setting
will be formally introduced in section 2. Because ˜gt ∈ Rd  standard algorithms for unconstrained
domains do not work since they require bounded ˜gt. Initial work in this setting by Jun and Orabona
(2019) was motivated by a lower bound of Cutkosky and Boahen (2017)  which shows that one
can suffer an exponential penalty when both the domain and subgradients are unbounded. They
replace the boundedness assumption on ˜gt by a boundedness assumption on E[˜gt] and an assumption
on the tails of the noise distribution. Jun and Orabona (2019) achieved expected regret guarantees
(cid:63)]  G2 is a
(cid:63)  and (cid:107) · (cid:107) and (cid:107) · (cid:107)(cid:63) are dual norms. This bound is useful when the
uniform upper bound on (cid:107)gt(cid:107)2
distribution of the noise is constant and known and an adversary selects gt. We derive an algorithm
that satisﬁes

of O((cid:107)u(cid:107)(cid:112)(G2 + σ2)T ln(1 + (cid:107)u(cid:107)T ))  where σ2 is a uniform upper bound on E[(cid:107)ξt(cid:107)2

(cid:33)

E[RT (u)] = O

(cid:107)u(cid:107)

t ) ln(1 + (cid:107)u(cid:107)T ))
σ2

 

(1)

t = E[(cid:107)ξt(cid:107)2

where σ2
small. In fact  we will prove something stronger than (1):

(cid:63)]. This bound can be smaller in cases where only a few σt are large but most are

(cid:32)

(cid:32)

T(cid:88)

t=1

(cid:118)(cid:117)(cid:117)(cid:116)(G2T +
(cid:118)(cid:117)(cid:117)(cid:116) T(cid:88)

(cid:33)
(cid:63) ln(1 + (cid:107)u(cid:107)T ))]

 

Contributions We extend the known results in several directions. Many common local differential
privacy applications use symmetric additive noise (laplace mechanism  normal mechanism). We use
the symmetry of the noise to adapt to unknown levels of privacy and achieve adaptive expected regret
bounds. We also adapt to privacy for dimension speciﬁc dimension requirements  again without
requiring knowledge of the structure of the noise other than symmetry in each dimension. Our
algorithms interpolate between no noise and maximum noise  matching state of the art bounds in both
cases. This can reduce the cost of privacy in some cases  outlined in section 4. Our work partially
answers two problems left open by Jun and Orabona (2019). The ﬁrst question asks whether or not
data-dependent bounds are possible in the noisy OCO setting  which we answer afﬁrmatively. The
second question is how to adapt to different levels of noise without using extra parameters compared
to the noiseless setting  which we do for symmetric noise.

t=1 (cid:107)˜gt(cid:107)2

(cid:113)(cid:80)T

Related work There has been signiﬁcant work on unconstrained and adaptive methods in OCO
with noiseless subgradients gt Foster et al. (2015); Orabona and Pál (2016); Foster et al. (2017);
Cutkosky and Boahen (2017); Kotłowski (2017); Cutkosky and Orabona (2018); Foster et al. (2018).
However  these results do not extend to the setting with noisy unbounded subgradients ˜gt  which is
possible with our work. For bounded domains regret bounds of O(D
(cid:63)) are possible
without knowledge of the noise (Duchi et al.  2011; Orabona and Pál  2018)  where D is an upper
bound on (cid:107)u(cid:107). However  these bounds do not adapt to unknown (cid:107)u(cid:107)  which may be costly for large
D but small (cid:107)u(cid:107). We provide an algorithm that both scales with (cid:107)u(cid:107) instead of D and does not
require knowledge of the noise.
There is a body of literature in the differential privacy setting with online feedback (Jain et al.  2012;
Jain and Thakurta  2014; Thakurta and Smith  2013; Agarwal and Singh  2017; Abernethy et al. 
2017). In this paper we consider local differential privacy (Wasserman and Zhou  2010; Duchi et al. 
2014)  which is a stronger notion of privacy than differential privacy. Duchi et al. (2014) provide
an algorithm with constant local differential privacy that learns by using SGD. (Song et al.  2015)
derive how to use knowledge of several levels of local differential privacy for SGD  but only with
two different levels of noise. Jun and Orabona (2019) consider local privacy with an unbounded
domain and constant noise. With knowledge of the noise it is possible to extend the results of Jun and
Orabona (2019) to achieve (1)  but not (2).

Outline
In section 2 we introduce our problem formally and introduce the key techniques. In
section 3 we derive a one-dimensional algorithm that achieves our goals  which we use in a black-
box reduction in section 3.1 and we apply it coordinate-wise in section 3.2. Section 4 contains
two scenarios in which our new algorithm achieves improvements compared to current algorithms.
Finally  in section 5 we present our conclusions.

2 Problem Formulation and Preliminaries

In this section we describe our notation  introduce the version of local differential privacy we use 
brieﬂy introduce the OCO setting with noisy subgradients  and provide some background to the
reward-regret duality paradigm.

Notation. Random variable x is called symmetric if the density function ρ of the random variable
z = x − E[x] satisﬁes ρ(z) = ρ(−z). The inner product between vectors g ∈ Rd and w ∈ Rd
is denoted by (cid:104)w  g(cid:105). The Fenchel conjugate of a convex function F   F (cid:63) is deﬁned as F (cid:63)(w) =
supg(cid:104)w  g(cid:105) − F (g). (cid:107) · (cid:107) denotes a norm and (cid:107)g(cid:107)(cid:63) = supw:(cid:107)w(cid:107)≤1(cid:104)w  g(cid:105) denotes the dual norm.
gt j indicates the jth component of vector gt.

2.1 User-Speciﬁed Local Differential Privacy

In the local differential privacy setting each datum is kept private from the learner. The standard
deﬁnition of local privacy requires a randomiser R that perturbs gt with random noise ξt  where
ξ1  . . .   ξT are independently distributed (Wasserman and Zhou  2010; Kasiviswanathan et al.  2011;
Duchi et al.  2014). The amount of perturbation is controlled by   where smaller  means more
privacy. We allow the provider to specify his desired level of privacy  so in a given round t we have
t-local differential privacy.

3

Deﬁnition 1. [Duchi et al. (2014)] Let A = (X1  . . .   XT ) be a sensitive dataset where each
Xt ∈ A corresponds to data about individual t. A randomiser R which outputs a disguised version
of S = (U1  . . .   UT ) of A is said to provide -local differential privacy to individual t  if for all
x  x(cid:48) ∈ A and for all S ⊆ S 

Pr(Ut ∈ S|Xt = x) ≤ exp() Pr(Ut ∈ S|Xt = x(cid:48)).

In this paper we make use of randomisers of the form Rt(gt) = gt + ξt  where ξt is generated
by a zero-mean symmetrical distribution ρt. A common choice for ρt is ρt(z) ∝ exp(− t
2 (cid:107)z(cid:107))
(Song et al.  2015). This randomiser is t-local differentially private for (cid:107)gt(cid:107) ≤ 1 (Song et al.  2015 
Theorem 1). We make use a small variation of this randomiser  which we call the local Laplace
j=1 τt j = t  τt j ≥ 0. The following result
shows that the local Laplace randomiser preserves t-local differential privacy.
Lemma 1. Suppose |gt j| ≤ 1  then the local Laplace randomiser is t-local differentially private 

randomiser: ρt(z) ∝ exp(−(cid:80)d
where t =(cid:80)d

2 |zj|)  where(cid:80)d

j=1

τt j

j=1 τt j.

The proof follows from applying Theorem 1 of Song et al. (2015) to each dimension and summing
the τt j. For completeness the proof is provided in Appendix A. This randomiser is the Laplace
randomiser (Dwork and Roth  2014) applied to each dimension with a possibly different  per
dimension. The local Laplace randomiser gives the user more control over the details of the privacy
guarantees: with the local Laplace randomiser each dimension j is τt j-local differentially private.
This can also lead to lower regret in some cases  of which we give an example in section 4.

2.2 Online Convex Optimization with Noisy Subgradients

The analysis of many efﬁcient online learning tools has been inﬂuenced by the Online Convex
Optimization framework. As mentioned in the introduction  the OCO setting with noisy subgradients
proceeds in rounds t = 1  . . .   T . In each round t

1. The learner sends wt ∈ Rd to the provider of the tth subgradient.
2. The provider samples ξt from zero-mean and symmetrical ρt and computes subgradient
3. The provider sends ˜gt = gt + ξt ∈ Rd to the learner.

gt ∈ ∂(cid:96)t(wt)  where (cid:107)gt(cid:107)(cid:63) ≤ G.

This protocol is a slight adaptation of the protocol of Duchi et al. (2014)  where we allow a different
ρt in each round t instead of using a constant ρ. In each round the provider only sends ˜gt to the
learner. The learner has no information about ρt other than that ρt is symmetrical and zero-mean.
Also note that ρt is allowed to change with each round t  complicating things even further. Since
the feedback the learner receives is random we are interested in the expected regret. To bound the
expected regret we upper bound the losses by their tangents:
(cid:104)wt − u  gt(cid:105)] = E[

E[RT (u)] ≤ E[

(cid:104)wt − u  ˜gt(cid:105)] 

T(cid:88)

T(cid:88)

(3)

where the equality holds because of the law of total expectation. The analysis focusses on bounding
the r.h.s of (3)  which is a standard approach in OCO. In the following we introduce a recently
popularized method to control the regret when wt and u are unbounded.

t=1

t=1

2.3 Reward Regret Duality

cT ∈ R  then E[RT (u)] ≤ E[cT ] + F (cid:63)

For noisy ˜gt  the formal result is found in the following lemma (see also Theorem 3 of Jun and
Orabona (2019)).
t=1 ˜gt) − cT ] for some convex function FT and

Lemma 2. If − E[(cid:80)T
Proof. From the deﬁnition of Fenchel conjugates we have E[FT (−(cid:80)T
(cid:80)T
t=1(cid:104)u  ˜gt(cid:105)] = −F (cid:63)

t=1(cid:104)wt  gt(cid:105)] ≥ E[FT (−(cid:80)T
T (u) −(cid:80)T

t=1(cid:104)wt  gt(cid:105)] ≥ E[FT (−(cid:80)T

t=1(cid:104)u  gt(cid:105). Using − E[(cid:80)T

T (u) −
t=1 ˜gt) − cT ]

t=1 ˜gt)] ≥ E[−F (cid:63)

T (u).

and reordering the terms completes the proof.

4

t=1 ˜gt(cid:107)2

t=1 ˜gt) = η

2 and cT =(cid:80)T

2(cid:107)(cid:80)T
s=1(cid:104)ws  gs(cid:105)] ≥ E[Ft(−(cid:80)t

with learning rate η to ﬁnd FT (−(cid:80)T
assuming that − E[(cid:80)t
satisfy Ft−1(x) − (cid:104)wt  gt(cid:105) ≥ E˜gt[Ft(x − ˜gt)]  − E[(cid:80)T

The difﬁculty lies in ﬁnding a suitable FT and cT . For example  we could use gradient descent
2. However 
it would be impossible to tune η optimally due to the dependence on the unknown u in F ∗
T (u) =
2η(cid:107)u(cid:107)2
2. For noiseless subgradients gt (Cutkosky and Orabona  2018) provide a route to ﬁnd a
1
suitable FT   with a constant cT . Jun and Orabona (2019) extend this idea to noisy subgradients
˜gt: one needs to ﬁnd an Ft  Ft−1  and wt that satisfy Ft−1(x) − (cid:104)wt  gt(cid:105) ≥ E˜gt[Ft(x − ˜gt)]. By
s=1 ˜gs)] holds one can show that if Ft and Ft−1
t=1 ˜gt)] holds by
induction. The result is given in the following lemma  of which the proof can be found in Appendix
A.
Lemma 3. Suppose that Ft−1(x) − (cid:104)wt  gt(cid:105) ≥ E˜gt[Ft(x − ˜gt)] holds for all t  then

t=1(cid:104)wt  gt(cid:105)] ≥ E[FT (−(cid:80)T

2(cid:107)˜gt(cid:107)2

t=1

η

T(cid:88)

(cid:104)wt  gt(cid:105)] ≥ E[FT (− T(cid:88)

− E[

˜gt)].

3 One-Dimensional Private Adaptive Potential Function

t=1

t=1

Algorithm 1 Local Differentially Private Adaptive Potential Function
Require: G such that | E[˜gt]| ≤ G and prior P on v ∈ [− 1
1: for t = 1  . . .   T do
2:
3:
4: end for

Play wt = Ev∼P [v exp(−(cid:80)t−1

Receive symmetric ˜gt ∈ R.

s=1 v˜gs − (v˜gs)2)].

5G   1

5G ].

In this section we derive a suitable potential function for a one-dimensional problem. In the remainder
of this paper we use this one-dimensional potential to derive new algorithms. To derive our one-
dimensional potential function we we rely on a property of symmetric random variables with bounded
means. The following Lemma is key deriving our potential function FT .
Lemma 4. Suppose x is a symmetrical random variable with | E[(cid:104)v  x(cid:105)]| ≤ 1
E[exp((cid:104)v  x(cid:105) − (cid:104)v  x(cid:105)2)] ≤ 1 + E[(cid:104)v  x(cid:105)].
The proof of Lemma 4 can be found in Appendix B. We can now use Lemma 4 to derive a one-
dimensional potential function. Suppose ˜gt ∈ R is a symmetrical random variable with E[˜gt] ≤ G.
Then v˜gt with v ∈ [− 1
5G ] satisﬁes the assumptions in Lemma 4. Multiplying the lower bound of
Lemma 4 for 1 − E[v˜gt]  for t = 1  . . .   T   yields a potential function via Lemma 3. The potential
we ﬁnd is

5 for some v. Then

5G   1

s=1

v˜gs − (v˜gs)2) − 1]] 

function is the incorporation of the symmetrical noise. The(cid:80)t

˜gs)] = E[ E
v∼P
where P is an (improper) prior on v ∈ [− 1
5G ]  the ﬁrst expectation is over ˜g1  . . .   ˜gt  and
F0(0) = 0. This kind of potential function has been used before by Chernov and Vovk (2010);
Koolen and Van Erven (2015); Jun and Orabona (2019). The novelty in this particular potential
s=1(v˜gs)2 term is unique to our
potential function and allows us to derive adaptive regret bounds for unconstrained u. Note that the
cT = 1 term has moved inside the deﬁnition of FT . While this does not inﬂuence the analysis for
proper priors it does inﬂuence the analysis for improper priors. The corresponding prediction strategy
is given by

5G   1

(4)

s=1

E[Ft(− t(cid:88)

[exp(− t(cid:88)

[v exp(− t−1(cid:88)

s=1

wt = E
v∼P

v˜gs − (v˜gs)2)].

(5)

Algorithm 1 summarizes the strategy. Note that Algorithm 1 does not require any extra parameters
compared to the setting with noiseless subgradients.
The following result shows that FT deﬁned by (4) and wt deﬁned by (5) satisfy our assumptions.
Lemma 5. Suppose ˜gt is a symmetrical random variable with E[˜gt] ≤ G. Then Ft deﬁned by (4)

and wt deﬁned by (5) satisfy E˜gt[Ft(−(cid:80)t

s=1 ˜gs)] ≤ Ft−1(−(cid:80)t−1

s=1 ˜gs) − wt E[˜gt].

5

The proof follows from an application of Lemma 4 and can be found in Appendix B. We consider
two types of priors. The ﬁrst type are proper priors that are of the form:

(6)

ν(v) exp(−bv2)

dP (v)

5G ] (cid:55)→ R+  and Z =(cid:82) 1

dv

=

 

Z
ν(v)e−bv2

1

5G− 1

5G

dv =

5G   1

dv = exp(−bv2)

Z

Z|v| ln(|v|)2 (for G > 1

dv is a normalizing constant. This

Where b ≥ 0  ν : [− 1
(Koolen and
captures several priors used in literature  including the conjugate prior dP
Van Erven  2015)  a variant of the CV prior dP
5)  (Chernov and Vovk 
2010; Koolen and Van Erven  2015)  and the uniform prior on [− 1
5G ] (Jun and Orabona  2019).
The second type of prior is an improper prior: dP
dv = 1|v|. A variant of this prior was previously used
by (Koolen and Van Erven  2015). For all priors we derive a regret bound by computing an upper
bound on the convex conjugate of FT   F (cid:63)
T . For conciseness we only present the regret bound for the
conjugate prior in the main text. In Appendix C we present the analysis of the regret of the improper
prior  for which a slightly different analysis is required compared to the proper priors. The analysis
for all priors can be seen as performing a Laplace approximation of the integral over v to show that
the prior places sufﬁcient mass in a neighbourhood of the optimal v.
s=1 ˜gs  and C = 1

s  Lt = −(cid:80)t−1
Abbreviating Bt = b +(cid:80)t−1
(cid:17)(cid:16)
(cid:16) Lt−2CBt
(cid:16) (L+2CBt)2
(cid:17) − erf

5G  the predictions (5) with the

(cid:16) Lt+2CBt

conjugate prior are given by:

(cid:17)(cid:17)

5G   1

s=1 ˜g2

√

erf

bLt exp

√

+ 2

Bt (exp(2CLt) − 1)

.

√
2

Bt

4Bt

wt =

√
√
2

Bt

erf(C

b) exp(C (Lt + CBt))4B

3
2
t

(7)
These wt can be computed efﬁciently  but see Koolen and Van Erven (2015) for numerically stable
evaluation. With the conjugate prior we ﬁnd the following result:
Theorem 1. Suppose ˜gt is a symmetrical random variable with | E[˜gt]| ≤ G for all t. The predictions
(7) satisfy:

E[RT (u)] ≤ 1 + |u| max

ln(|u|11G) − 1 + ln

(cid:32)

(cid:40)

(cid:118)(cid:117)(cid:117)(cid:117)(cid:116)8

E

11G

(cid:32)

b +

(cid:33)

T(cid:88)

t=1

˜g2
t

ln(16|u|2

π

(cid:33)(cid:33)
(cid:33) 3

√
√
5G
4

(cid:32)√
T(cid:88)

b

b +

˜g2
t

 

2 √
π√
b

t=1

(cid:32)



(cid:41)

.

+ 1)

The proof of Theorem 1 can be found in Appendix B.1 and follows from computing the Fenchel
conjugate of the potential function. For noisy subgradients this is the ﬁrst bound that is adaptive to
the sum of the squares of the noisy subgradients. Compared to the expected regret bound for the
improper prior (see Theorem 3 in Appendix C) this bound has worse constants. However  with the
conjugate prior all non-constant terms scale with |u|  which is not the case with the improper prior.
For all proper priors of the form (6) a similar regret bound can be computed. This can be seen from
Lemma 8 in Appendix B.1  which shows that the convex conjugate of the potential function for these

priors is O(E[|u|(cid:113)(cid:80)T

t ln(|u|T + 1))]).

t=1 ˜g2

3.1 Black-Box Reductions

In this section we use our potential function in a black-box reduction: we take a constrained noisy
OCO algorithm AZ and turn it into an unconstrained algorithm using our potential function. The
same reduction is used by Cutkosky and Orabona (2018) and Jun and Orabona (2019). The algorithm
can be found in Figure 2. The potential function and the OCO algorithm each have their task: the
potential function is to learn the norm of u and the constrained OCO algorithm is to learn the direction
of u. In each round t we play wt = vtzt  where zt ∈ Z  Z = {z : (cid:107)z(cid:107) ≤ 1}  is the prediction
of the OCO algorithm and vt is the prediction of Algorithm 1. We feed ˜gt as feedback to AZ and
(cid:104)zt  ˜gt(cid:105) as feedback to Algorithm 1. Since ˜gt is a symmetrical random variable and E[(cid:104)zt  ˜gt(cid:105)] ≤ G 

6

Algorithm 2 Black-Box Reduction
Require: G such that (cid:107) E[˜gt](cid:107)(cid:63) ≤ G and Algorithm AZ with domain Z = {z : (cid:107)z(cid:107) ≤ 1}
1: for t = 1  . . .   T do
2:
3:
4:
5:
6:
7: end for

Get zt ∈ Z from AZ
Get vt ∈ R from Algorithm 1
Play wt = vtzt  receive symmetrical ˜gt such that (cid:107) E[˜gt](cid:107)(cid:63) ≤ G
Send ˜gt to AZ
Send (cid:104)zt  ˜gt(cid:105) to Algorithm 1

(cid:104)zt  ˜gt(cid:105) satisﬁes the assumptions in Lemma 4. This allows us to control the regret for learning the
norm of u using Theorem 1.
As outlined by Cutkosky and Orabona (2018) the expected regret of Algorithm 2 decomposes into
two parts. The ﬁrst part of the regret is for learning the norm of u  and is controlled by Algorithm 1.
The second part of the regret for learning the direction of u and is controlled by AZ. The proof is
given by Cutkosky and Orabona (2018)  but for completeness we provide the proof in Appendix B.2.
Lemma 6. Suppose ˜gt is a symmetrical random variable with (cid:107) E[˜gt](cid:107)(cid:63) ≤ G for all t. Let
t=1(vt − (cid:107)u(cid:107))(cid:104)zt  ˜gt(cid:105)] be the regret for learning (cid:107)u(cid:107) by Algorithm 1 and let
RV
RZ
t=1(cid:104)zt − u(cid:107)u(cid:107)   ˜gt(cid:105)] be the regret for learning u(cid:107)u(cid:107) by AZ. Then Algorithm 2
satisﬁes E[RT (u)] = RV

T ((cid:107)u(cid:107)) = E[(cid:80)T
T ( u(cid:107)u(cid:107) ) = E[(cid:80)T

T ((cid:107)u(cid:107)) + (cid:107)u(cid:107)RZ

(cid:16) u(cid:107)u(cid:107)

(cid:17)

T

.

Orabona and Pál (2018) show that Mirror Descent with learning rates ηt = (
yields RZ

T ( u(cid:107)u(cid:107) ) = O(E[

t=1 (cid:107)˜gt(cid:107)2
(cid:63)]).
t=1 (cid:107)˜gt(cid:107)2
(cid:63) + 1)]) the total regret of Algorithm 2 is

Since Algorithm 1 satisﬁes RV

O(E[(cid:107)u(cid:107)(cid:113)(cid:80)T

t=1 (cid:107)˜gt(cid:107)2

s=1 (cid:107)˜gs(cid:107)2
(cid:63))−1
T ((cid:107)u(cid:107)) =

(cid:113)(cid:80)T
(cid:63) ln((cid:107)u(cid:107)(cid:80)T
(cid:107)u(cid:107) E

E[RT (u)] = O

(cid:113)(cid:80)t
 .

(cid:118)(cid:117)(cid:117)(cid:116) T(cid:88)


(cid:63) ln((cid:107)u(cid:107) T(cid:88)

(cid:107)˜gt(cid:107)2

(cid:107)˜gt(cid:107)2

(cid:63) + 1)

(8)

This bound matches state of the art bounds for for noiseless subgradients and is never worse than the
bound of Jun and Orabona (2019) for noisy subgradients  but can be substantially better.

t=1

t=1

3.2 Private Unconstrained Adaptive Sparse Gradient Descent

Play wt
for j = 1  . . .   d do

Algorithm 3 Private Unconstrained Adaptive Sparse Gradient Descent
Require: G such that | E[˜gt j]|(cid:63) ≤ G.
1: for t = 1  . . .   T do
2:
3:
4:
5:
6:
7:
8:
9: end for

Receive symmetrical ˜gt j such that |˜gt j| ≤ G
Send ˜gt j to Algorithm 1
Receive vt+1 ∈ R from Algorithm 1 with the conjugate prior
Set wt+1 j = vt+1

end for

In this section we propose a noisy unconstrained OCO algorithm that can exploit sparse subgradients.
The algorithm is summarized in Algorithm 3. Algorithm 3 runs a copy of Algorithm 1 with the
conjugate prior coordinate-wise. A similar strategy is used by Orabona and Tommasi (2017). This
strategy can exploit sparse privacy structures  which  combined with sparse subgradients  may yield
low regret (see section 4). Its expected regret bound is given below. The proof follows from applying
Theorem 1 per dimension.

7

Theorem 2. Suppose ˜gt j is a symmetric random variable with | E[˜gt j]| ≤ G for all t and j. Then
the expected regret of Algorithm 3 satisﬁes

E[RT (u)] ≤d +

|uj| max

11G

ln(|uj|11G) − 1 + ln

d(cid:88)

(cid:118)(cid:117)(cid:117)(cid:117)(cid:116)8

j=1

(cid:32)

(cid:32)
(cid:33)

(cid:40)
T(cid:88)

t=1

E

bj +

˜g2
t j

ln(16|uj|2

bj +

˜g2
t j

π

5G

√

(cid:32)√
4(cid:112)bj
(cid:33) 3
π(cid:112)bj

2 √

(cid:33)(cid:33)

 

+ 1))



(cid:41)

.

(cid:32)

T(cid:88)

t=1

4 Motivating Examples

d

2

d


In this section we present two scenarios in which our algorithms provide better expected regret
guarantees than standard algorithms. The ﬁrst scenario concerns a case where many providers do not
care for their privacy (so they do not perturb the subgradients) and few providers care substantially
for their privacy. Suppose that the providers who care for their privacy are (cid:100)ln(T )(cid:101) of the total
number of providers T . Suppose that (cid:107)gt(cid:107)2
2 ≤ 1 and that the providers who care for their privacy use
ρ(z) ∝ exp(− 
2(cid:107)z(cid:107)2)  then E[(cid:107)ξt(cid:107)2
(Song et al.  2015  Theorem 1). Using Algorithm
2  Jensen’s inequality  and the fact that the square root is subadditive we see from (8) that the expected
regret is upper bounded by O((cid:107)u(cid:107)2
 ln((cid:107)u(cid:107)2T + T )) instead
of O((cid:107)u(cid:107)2
instead of letting the providers choose their desired level of privacy.
In the second scenario the providers use the local Laplace randomiser.
is sparse. A standard algorithm that has good performance for sparse gt

(cid:112)T ln(1 + (cid:107)u(cid:107)2T )) had we used the maximum privacy guarantee for all providers

2] ≤ 4 + 4 d2+d
t=1 (cid:107)gt(cid:107)2

2 ln(1 + (cid:107)u(cid:107)2T ) +(cid:107)u(cid:107)2

(cid:113)(cid:80)T

(cid:113)(cid:80)T
(Duchi et al.  2011). AdaGrad achieves O(E[D(cid:80)d
(cid:113)(cid:80)T
per bounded by O(D(cid:80)d
(cid:113)
O((cid:80)d
3(cid:80)T

Suppose that gt
is AdaGrad
t=1 |˜gt j|2]) expected regret  where
maxj |uj| ≤ D  and D has to be guessed prior to running AdaGrad. Using Jensen’s
inequality and the fact that the square root is subadditive the expected regret can be up-
t j])). Algorithm 3 achieves
t j] ln(|uj|T + 1))) regret  which
can be signiﬁcantly smaller than the bound of AdaGrad if D is much larger than uj or if u is
sparse. Furthermore  since we allow the provider of the data to choose τt j  ξt can be sparse as
well. While this does not give local differential privacy guarantees for all attributes it does give
local differential privacy guarantees for attributes with τj < ∞. If instead we would have used the
standard application of local differential privacy there would be no hope in exploiting sparse gt since

(cid:113)
3(cid:80)T
j=1(
t j] +
t j] ln(|uj|T + 1) +
E[g2

(cid:113)
3(cid:80)T

t=1 3 E[ξ2

j=1 |uj|(

E[g2

E[ξ2

j=1

t=1

t=1

t=1

E[ξ2

t=1

t j] would be the dominant term in the regret bound.

j=1 |uj|(cid:113)
(cid:80)d

3(cid:80)T

5 Conclusions

In this paper  we extended the local differential privacy framework in unconstrained Online Convex
Optimization by allowing the provider of the data to choose their privacy guarantees. Standard
algorithms do not yield satisfactory regret bounds in this setting  either due to dependence on the
unknown parameters of the noise or dependence on bounded subgradients. Hence  we proposed
two new algorithms that match state of the art regret algorithms in both the noisy and noiseless
setting  without requiring knowledge of the noise other than symmetry. Our algorithms do not require
parameters other than a bound on the norm of expectation of the subgradients  which allows the
privacy requirements of all providers to be private itself. The new algorithms are a step towards
practically useful algorithms with local differential privacy guarantees that have sound theoretical
guarantees. Our algorithms are the ﬁrst adaptive unconstrained algorithms in the noisy OCO setting
without requiring extra parameters compared to the standard OCO setting  solving two problems left
open by Jun and Orabona (2019).

8

Acknowledgments

The author would like to thank Tim van Erven for his comments on an earlier version of this paper.
The author was supported by the Netherlands Organization for Scientiﬁc Research (NWO grant
TOP2EW.15.211).

References
Abernethy  J.  C. Lee  A. McMillan  and A. Tewari

2017. Online learning via differential privacy. arXiv preprint arXiv:1711.10019.

Agarwal  N. and K. Singh

2017. The price of differential privacy for online learning. In Proceedings of the 34th International
Conference on Machine Learning (ICML)  Pp. 32–40.

Cesa-Bianchi  N. and G. Lugosi

2006. Prediction  Learning  and Games. Cambridge university press.

Chernov  A. and V. Vovk

2010. Prediction with advice of unknown number of experts. Uncertainty in Aritiﬁcial Intelligence 
Pp. 117–125.

Cutkosky  A. and K. Boahen

2017. Online learning without prior information. In Proceedings of the 30th Annual Conference
on Learning Theory (COLT)  Pp. 643–677.

Cutkosky  A. and F. Orabona

2018. Black-box reductions for parameter-free online learning in banach spaces. In Proceedings
of the 31th Annual Conference on Learning Theory (COLT)  Pp. 1493–1529.

Duchi  J.  E. Hazan  and Y. Singer

2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of
Machine Learning Research  12(Jul):2121–2159.

Duchi  J. C.  M. I. Jordan  and M. J. Wainwright

2014. Privacy aware learning. Journal of the ACM (JACM)  61(6):38.

Dwork  C. and A. Roth

2014. The algorithmic foundations of differential privacy. Foundations and Trends in Theoretical
Computer Science  9(3–4):211–407.

Foster  D. J.  S. Kale  M. Mohri  and K. Sridharan

2017. Parameter-free online learning via model selection. In Advances in Neural Information
Processing Systems  Pp. 6020–6030.

Foster  D. J.  A. Rakhlin  and K. Sridharan

2015. Adaptive online learning. In Advances in Neural Information Processing Systems  Pp. 3375–
3383.

Foster  D. J.  A. Rakhlin  and K. Sridharan

2018. Online learning: Sufﬁcient statistics and the burkholder method. In Proceedings of the 31th
Annual Conference on Learning Theory (COLT)  Pp. 3028–3064.

Hazan  E.

2016.
2(3-4):157–325.

Introduction to online convex optimization. Foundations and Trends in Optimization 

Hiriart-Urruty  J.-B.

2006. A note on the legendre-fenchel transform of convex composite functions. In Nonsmooth
Mechanics and Analysis  Pp. 35–46. Springer.

Jain  P.  P. Kothari  and A. Thakurta

2012. Differentially private online learning. In Proceedings of the 25th Annual Conference on
Learning Theory (COLT)  Pp. 24–1.

9

Jain  P. and A. G. Thakurta

2014. (near) dimension independent risk bounds for differentially private learning. In Proceedings
of the 31th International Conference on Machine Learning (ICML)  Pp. 476–484.

Jun  K.-S. and F. Orabona

2019. Parameter-free online convex optimization with sub-exponential noise. Proceedings of the
32nd Annual Conference on Learning Theory (COLT).

Kasiviswanathan  S. P.  H. K. Lee  K. Nissim  S. Raskhodnikova  and A. Smith

2011. What can we learn privately? SIAM Journal on Computing  40(3):793–826.

Koolen  W. M. and T. van Erven

2015. Second-order quantile methods for experts and combinatorial games. In Proceedings of The
28th Conference on Learning Theory (COLT)  Pp. 1155–1175.

Kotłowski  W.

2017. Scale-invariant unconstrained online learning. In Proceedings of the International Conference
on Algorithmic Learning Theory (ALT)  Pp. 412–433.

Mcmahan  B. and M. Streeter

2012. No-regret algorithms for unconstrained online convex optimization. In Advances in neural
information processing systems  Pp. 2402–2410.

McMahan  H. B. and F. Orabona

2014. Unconstrained online linear learning in hilbert spaces: Minimax algorithms and normal
approximations. In Proceedings of the 27th Annual Conference on Learning Theory (COLT) 
Pp. 1020–1039.

Orabona  F. and D. Pál

2016. Coin betting and parameter-free online learning.
Processing Systems  Pp. 577–585.

In Advances in Neural Information

Orabona  F. and D. Pál

2018. Scale-free online learning. Theoretical Computer Science  716:50–69.

Orabona  F. and T. Tommasi

2017. Training deep networks without learning rates through coin betting. In Advances in Neural
Information Processing Systems  Pp. 2160–2170.

Song  S.  K. Chaudhuri  and A. Sarwate

2015. Learning from data with heterogeneous noise using sgd. In Artiﬁcial Intelligence and
Statistics  Pp. 894–902.

Thakurta  A. G. and A. Smith

2013. (nearly) optimal algorithms for private online learning in full-information and bandit settings.
In Advances in Neural Information Processing Systems  Pp. 2733–2741.

Wasserman  L. and S. Zhou

2010. A statistical framework for differential privacy. Journal of the American Statistical Associa-
tion  105(489):375–389.

10

,Dirk van der Hoeven