2013,How to Hedge an Option Against an Adversary: Black-Scholes Pricing is Minimax Optimal,We consider a popular problem in finance  option pricing  through the lens of an online learning game between Nature and an Investor.  In the Black-Scholes option pricing model from 1973  the Investor can continuously hedge the risk of an option by trading the underlying asset  assuming that the asset's price fluctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model  in which Nature chooses a sequence of price fluctuations under a cumulative quadratic volatility constraint  and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game  which is the regret'' of hedging strategy  converges to the Black-Scholes option price. We use significantly weaker assumptions than previous work---for instance  we allow large jumps in the asset price---and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework.",How to Hedge an Option Against an Adversary:

Black-Scholes Pricing is Minimax Optimal

Jacob Abernethy

University of Michigan

jabernet@umich.edu

Peter L. Bartlett

University of California at Berkeley

and Queensland University of Technology

bartlett@cs.berkeley.edu

Rafael M. Frongillo
Microsoft Research

raf@cs.berkeley.edu

Andre Wibisono

University of California at Berkeley
wibisono@cs.berkeley.edu

Abstract

We consider a popular problem in ﬁnance  option pricing  through the lens of an
online learning game between Nature and an Investor. In the Black-Scholes op-
tion pricing model from 1973  the Investor can continuously hedge the risk of
an option by trading the underlying asset  assuming that the asset’s price ﬂuctu-
ates according to Geometric Brownian Motion (GBM). We consider a worst-case
model  in which Nature chooses a sequence of price ﬂuctuations under a cumula-
tive quadratic volatility constraint  and the Investor can make a sequence of hedg-
ing decisions. Our main result is to show that the value of our proposed game 
which is the “regret” of hedging strategy  converges to the Black-Scholes option
price. We use signiﬁcantly weaker assumptions than previous work—for instance 
we allow large jumps in the asset price—and show that the Black-Scholes hedging
strategy is near-optimal for the Investor even in this non-stochastic framework.

1

Introduction

An option is a ﬁnancial contract that allows the purchase or sale of a given asset  such as a stock 
bond  or commodity  for a predetermined price on a predetermined date. The contract is named as
such because the transaction in question is optional for the purchaser of the contract. Options are
bought and sold for any number of reasons  but in particular they allow ﬁrms and individuals with
risk exposure to hedge against potential price ﬂuctuations. Airlines  for example  have heavy fuel
costs and hence are frequent buyers of oil options.
What ought we pay for the privilege of purchasing an asset at a ﬁxed price on a future expiration
date? The difﬁculty with this question  of course  is that while we know the asset’s previous prices 
we are uncertain as to its future price. In a seminal paper from 1973  Fischer Black and Myron
Scholes introduced what is now known as the Black-Scholes Option Pricing Model  which led to a
boom in options trading as well as a huge literature on the problem of derivative pricing [2]. Black
and Scholes had a key insight that a ﬁrm which had sold/purchased an option could “hedge” against
the future cost/return of the option by buying and selling the underlying asset as its price ﬂuctuates.
Their model is based on stochastic calculus and requires a critical assumption that the asset’s price
behaves according to a Geometric Brownian Motion (GBM) with known drift and volatility.
The GBM assumption in particular implies that (almost surely) an asset’s price ﬂuctuates continu-
ously. The Black-Scholes model additionally requires that the ﬁrm be able to buy and sell contin-
uously until the option’s expiration date. Neither of these properties are true in practice: the stock
market is only open eight hours per day  and stock prices are known to make signiﬁcant jumps even

1

during regular trading. These and other empirical observations have led to much criticism of the
Black-Scholes model.
An alternative model for option pricing was considered1 by DeMarzo et al. [3]  who posed the
question: “Can we construct hedging strategies that are robust to adversarially chosen price ﬂuc-
tuations?” Essentially  the authors asked if we may consider hedging through the lens of regret
minimization in online learning  an area that has proved fruitful  especially for obtaining guarantees
robust to worst-case conditions. Within this minimax option pricing framework  DeMarzo et al. pro-
vided a particular algorithm resembling the Weighted Majority and Hedge algorithms [5  6] with a
nice bound.
Recently  Abernethy et al. [1] took the minimax option pricing framework a step further  analyzing
the zero-sum game being played between an Investor  who is attempting to replicate the option
payoff  and Nature  who is sequentially setting the price changes of the underlying asset. The
Investor’s goal is to “hedge” the payoff of the option as the price ﬂuctuates  whereas Nature attempts
to foil the Investor by choosing a challenging sequence of price ﬂuctuations. The value of this game
can be interpreted as the “minimax option price ” since it is what the Investor should pay for the
option against an adversarially chosen price path. The main result of Abernethy et al. was to show
that the game value approaches the Black-Scholes option price as the Investor’s trading frequency
increases. Put another way  the minimax price tends to the option price under the GBM assumption.
This lends signiﬁcant further credibility to the Black-Scholes model  as it suggests that the GBM
assumption may already be a “worst-case model” in a certain sense.
The previous result  while useful and informative  left two signiﬁcant drawbacks. First  their tech-
niques used minimax duality to compute the value of the game  but no particular hedging algorithm
for the Investor is given. This is in contrast to the Black-Scholes framework (as well as to the De-
Marzo et al.’s result [3]) in which a hedging strategy is given explicitly. Second  the result depended
on a strong constraint on Nature’s choice of price path: the multiplicative price variance is uniformly
constrained  which forbids price jumps and other large ﬂuctuations.
In this paper  we resolve these two drawbacks. We consider the problem of minimax option pricing
with much weaker constraints: we restrict the sum over the length of the game of the squared price
ﬂuctuations to be no more than a constant c  and we allow arbitrary price jumps  up to a bound ⇣. We
show that the minimax option price is exactly the Black-Scholes price of the option  up to an additive
term of O(c⇣1/4). Furthermore  we give an explicit hedging strategy: this upper bound is achieved
when the Investor’s strategy is essentially a version of the Black-Scholes hedging algorithm.

2 The Black-Scholes Formula

Let us now brieﬂy review the Black-Scholes pricing formula and hedging strategy. The derivation
requires some knowledge of continuous random walks and stochastic calculus—Brownian motion 
Itˆo’s Lemma  a second-order partial differential equation—and we shall only give a cursory treat-
ment of the material. For further development we recommend a standard book on stochastic cal-
culus  e.g. [8]. Let us imagine we have an underlying asset A whose price is ﬂuctuating. We let
W (t) be a Brownian motion  also known as a Weiner process  with zero drift and unit variance; in
particular  W (0) = 0 and W (t) ⇠ N(0  t) for t > 0. We shall imagine that A’s price path G(t) is
described by a geometric Brownian motion with drift µ and volatility   which we can describe via
the deﬁnition of a Brownian motion: G(t) d= exp{(µ  1
If an Investor purchases a European call option on some asset A (say  MSFT stock) with a strike
price of K > 0 that matures at time T   then the Investor has the right to buy a share of A at price K
at time T . Of course  if the market price of A at T is G(T )  then the Investor will only “exercise”
the option if G(T ) > K  since the Investor has no beneﬁt of purchasing the asset at a price higher
than the market price. Hence  the payoff of a European call option has a proﬁt function of the form
max{0  G(T )  K}. Throughout the paper we shall use gEC(x) := max{0  x  K} to refer to the
payout of the European call when the price of asset A at time T is x (the parameter K is implicit).

2 2)t + W (t)}.

1Although it does not have quite the same ﬂavor  a similar approach was explored in the book of Vovk and

Shafer [7].

2

We assume the current time is t. The Black-Scholes derivation begins with a guess: assume that the
“value” of the European call option can be described by a smooth function V(G(t)  t)  depending
only on the current price of the asset G(t) and the time to expiration T  t. We can immedi-
ately deﬁne a boundary condition on V  since at the expiration time T the value of the option is
V(G(T )  0) = gEC(G(T )).
So how do we arrive at a value for the option at another time point t? We assume the Investor has
a hedging strategy  (x  t) that determines the amount to invest when the current price is x and the
time is t. Notice that if the asset’s current price is G(t) and the Investor purchases (G(t)  t) dollars
of asset A at t  then the incremental amount of money made in an inﬁnitesimal amount of time is
(G(t)  t) dG/G(t)  since dG/G(t) is the instantaneous multiplicative price change at time t. Of
course  if the earnings of the Investor are guaranteed to exactly cancel out the inﬁnitesimal change
in the value of the option dV(G(t)  t)  then the Investor is totally hedged with respect to the option
payout for any sample of G for the remaining time to expiration. In other words  we hope to achieve
dV(G  t) = (G  t) dG/G. However  by Itˆo’s Lemma [8] we have the following useful identity:

dV(G  t) = @V

@x

dG + @V
@t

dt +

1
2 2G2 @2V

@x2 dt.

(1)

(2)

Black and Scholes proposed a generic hedging strategy  that the investor should invest

(x  t) = x

@V
@x

dollars in the asset A when the price of A is x at time t. As mentioned  the goal of the Investor is
to hedge out risk so that it is always the case that dV(G  t) = (G  t) dG/G. Combining this goal
with Equations (1) and (2)  we have

@V
@t

+

1
2 2x2 @2V

@x2 = 0.

(3)

V(x  t) = EY [gEC(x · exp(Y ))] where

Notice the latter is an entirely non-stochastic PDE  and indeed it can be solved explicitly:
2 2(T  t)  2(T  t))

(4)
Remark: While we have described the derivation for the European call option  with payoff function
gEC  the analysis above does not rely on this speciﬁc choice of g. We refer the reader to a standard
text on asset pricing for more on this [8].

Y ⇠ N ( 1

3 The Minimax Hedging Game

We now describe a sequential decision protocol in which an Investor makes a sequence of trading
decisions on some underlying asset  with the goal of hedging away the risk of some option (or other
ﬁnancial derivative) whose payout depends on the ﬁnal price of the asset at the expiration time T .
We assume the Investor is allowed to make a trading decision at each of n time periods  and before
making this trade the investor observes how the price of the asset has changed since the previous
period. Without loss of generality  we can assume that the current time is 0 and the trading periods
occur at {T /n  2T /n  . . .   1}  although this will not be necessary for our analysis.
The protocol is as follows.
1: Initial price of asset is S = S0.
2: for i = 1  2  . . .   n do
3:
4:
5:
6: end for

Investor hedges  invests i 2 R dollars in asset.
Nature selects a price ﬂuctuation ri and updates price S S(1 + ri).
Investor receives (potentially negative) proﬁt of iri.

Stepping back for a moment  we see that the Investor is essentially trying to minimize the following
objective:

7: Investor is charged the cost of the option  g(S) = g (S0 ·Qn
nXi=1

(1 + ri)! 

g S0 ·

nYi=1

iri.

i=1(1 + ri)).

3

We can interpret the above expression as a form of regret: the Investor chose to execute a trading
i=1 iri  but in hindsight might have rather purchased the option instead 
i=1(1 + ri)). What is the best hedging strategy the Investor can execute
to minimize the difference between the option payoff and the gains/losses from hedging? Indeed 
how much regret may be suffered against a worst-case sequence of price ﬂuctuations?

strategy  earning himPn
with a payout of g (S0 ·Qn

Constraining Nature. The cost of playing the above sequential game is clearly going to de-
In the original Black-Scholes formula-
pend on how much we expect the price to ﬂuctuate.
tion  the price volatility  is a major parameter in the pricing function.
In the work of Aber-
nethy et al.  a key assumption was that Nature may choose any r1  . . .   rn with the constraint that
i | r1  . . .   ri1] = O(1/n). 2 Roughly  this constraint means that in any ✏-sized time interval 
E[r2
the price ﬂuctuation variance shall be no more than ✏. This constraint  however  does not allow for
large price jumps during trading. In the present work  we impose a much weaker set of constraints 
described as follows:3

• TotVarConstraint: The total price ﬂuctuation is bounded by a constant c:Pn
i  c.
• JumpConstraint: Every price jump |ri| is no more than ⇣  for some ⇣ > 0 (which may

i=1 r2

depend on n).

The ﬁrst constraint above says that Nature is bounded by how much  in total  the asset’s price path
can ﬂuctuate. The latter says that at no given time can the asset’s price jump more than a given value.
It is worth noting that if c  n⇣2 then TotVarConstraint is superﬂuous  whereas JumpConstraint
becomes superﬂuous if c < ⇣2.

The Minimax Option Price We are now in a position to deﬁne the value of the sequential option
pricing game using a minimax formulation. That is  we shall ask how much the Investor loses
when making optimal trading decisions against worst-case price ﬂuctuations chosen by Nature. Let
V (n)
(S; c  m) be the value of the game  measured by the investor’s loss  when the asset’s current
⇣
price is S  0  the TotVarConstraint is c  0  the JumpConstraint is ⇣ > 0  the total number of
trading rounds are n 2 N  and there are 0  m  n rounds remaining. We deﬁne recursively:

V (n)
⇣

⇣

sup

r : |r|min{⇣ pc}

r + V (n)

⇣

((1 + r)S; c  r2  m  1) 

(S; c  n). This is the value of the game that we are interested in analyzing.

(S; c  m) = inf
2R
(S; c  0) = g(S). Notice that the constraint under the supremum en-
(S; c) :=

with the base case V (n)
forces both TotVarConstraint and JumpConstraint. For simplicity  we will write V (n)
V (n)
⇣
Towards establishing an upper bound on the value (5)  we shall discuss the question of how to
choose the hedge parameter  on each round. We can refer to a “hedging strategy” in this game as
a function of the tuple (S  c  m  n  ⇣  g(·)) that returns hedge position. In our upper bound  in fact
we need only consider hedging strategies (S  c) that depend on S and c; there certainly will be a
dependence on g(·) as well but we leave this implicit.
4 Asymptotic Results

(5)

⇣

⇣

The central focus of the present paper is the following question: “For ﬁxed c and S  what is the
asymptotic behavior of the value V (n)
(S; c)?” and “Is there a natural hedging strategy (S  c) that
(roughly) achieves this value?” In other words  what is the minimax value of the option  as well
as the optimal hedge  when we ﬁx the variance budget c and the asset’s current price S  but let the
number of rounds tend to 1? We now give answers to these questions  and devote the remainder of
the paper to developing the results in detail.
We consider payoff functions g : R0 ! R0 satisfying three constraints:
2The constraint in [1] was E[r2
i | r1  . . .   ri1]  exp(c/n)  1  but this is roughly equivalent.
3We note that Abernethy et al. [1] also assumed that the multiplicative price jumps |ri| are bounded by
ˆ⇣n = ⌦(p(log n)/n); this is a stronger assumption than what we impose on (⇣n) in Theorem 1.

4

1. g is convex.
2. g is L-Lipschitz  i.e. |g(x)  g(y)|  L|x  y|.
3. g is eventually linear  i.e. there exists K > 0 such that g(x) is a linear function for all
x  K; in this case we also say g is K-linear.

We believe the ﬁrst two conditions are strictly necessary to achieve the desired results. The K-
linearity may not be necessary but makes our analysis possible. We note that the constraints above
encompass the standard European call and put options.
Henceforth we shall let G be a zero-drift GBM with unit volatility.
log G(t) ⇠ N ( 1

2 t  t). For S  c  0  deﬁne the function

In particular  we have that

U(S  c) = EG[g(S · G(c))] 

and observe that U(S  0) = g(S). Our goal will be to show that U is asymptotically the minimax
price of the option. Most importantly  this function U(S  c) is identical to V(S  1
2 (T  c))  the
Black-Scholes value of the option in (4) when the GBM volatility parameter is  in the Black-
Scholes analysis. In particular  analogous to to (3)  U(S  c) satisﬁes a differential equation:

1
2 S2 @2U
@S2 

@U
@c

= 0.

(6)

The following is our main result of this paper.
Theorem 1. Let S > 0 be the initial asset price and let c > 0 be the variance budget. Assume we
have a sequence {⇣n} with limn!1 ⇣n = 0 and lim inf n!1 n⇣2
(S; c) = U(S  c).

n > c. Then

V (n)
⇣n

lim
n!1

This statement tells us that the minimax price of an option  when Nature has a total ﬂuctuation
budget of c  approaches the Black-Scholes price of the option when the time to expiration is c.
This is particularly surprising since our minimax pricing framework made no assumptions as to
the stochastic process generating the price path. This is the same conclusion as in [1]  but we
obtained our result with a signiﬁcantly weaker assumption. Unlike [1]  however  we do not show
that the adversary’s minimax optimal stochastic price path necessarily converges to a GBM. The
convergence of Nature’s price path to GBM in [1] was made possible by the uniform per-round
variance constraint.
The previous theorem is the result of two main technical contributions. First  we prove a lower
bound on the limiting value of V (n)
(S; c) by exhibiting a simple randomized strategy for Nature
⇣n
in the form of a stochastic price path  and appealing to the Lindeberg-Feller central limit theorem.
Second  we prove an O(c⇣1/4) upper bound on the deviation between V (n)
(S; c) and U(S  c). The
⇣
upper bound is obtained by providing an explicit strategy for the Investor:

(S  c) = S

@U(S  c)

@S

and carefully bounding the difference between the output using this strategy and the game value. In
the course of doing so  because we are invoking Taylor’s remainder theorem  we need to bound the
ﬁrst few derivatives of U(S  c). Bounding these derivatives turns out to be the crux of the analysis;
in particular  it uses the full force of the assumptions on g  including that g is eventually linear  to
avoid the pathological cases when the derivative of g converges to its limiting value very slowly.

5 Lower Bound

In this section we prove that U(S  c) is a lower bound to the game value V (n)
(S; c). We note that the
⇣n
result in this section does not use the assumptions in Theorem 1 that ⇣n ! 0  nor that g is convex
and eventually linear. In particular  the following result also applies when the sequence (⇣n) is a
constant ⇣ > 0.

5

Theorem 2. Let g : R0 ! R0 be an L-Lipschitz function  and let {⇣n} be a sequence of positive
numbers with lim inf n!1 n⇣2

n > c. Then for every S  c > 0 

lim inf
n!1

V (n)
⇣n

(S; c)  U(S  c).

The proof of Theorem 2 is based on correctly “guessing” a randomized strategy for Nature. For each

n 2 N  deﬁne the random variables R1 n  . . .   Rn n ⇠ Uniform{±pc/n} i.i.d. Note that (Ri n)n
plies ⇣n >pc/n for all sufﬁciently large n  so eventually (Ri n) also satisﬁes JumpConstraint.

satisﬁes TotVarConstraint by construction. Moreover  the assumption lim inf n!1 n⇣2
We have the following convergence result for (Ri n)  which we prove in Appendix A.
Lemma 3. Under the same setting as in Theorem 2  we have the convergence in distribution

i=1
n > c im-

nYi=1

(1 + Ri n)

d! G(c)
Moreover  we also have the convergence in expectation
(1 + Ri n)!# = U(S  c).
nYi=1

E"g S ·

n ! 1.

lim
n!1

as

With the help of Lemma 3  we are now ready to prove Theorem 2.

(7)

V (n)
⇣n

sup
r1 ··· inf

(S; c) = inf
1

n > c. Let Ri n ⇠ Uniform{±pc/n}
Proof of Theorem 2. Let n be sufﬁciently large such that n⇣2
i.i.d.  for 1  i  n. As noted above  (Ri n) satisﬁes both TotVarConstraint and JumpConstraint.
Then we have
g⇣S ·
(1 + ri)⌘ 
nYi=1
nXi=1
iRi ni
(1 + Ri n)⌘ 
Ehg⇣S ·
nXi=1
nYi=1
1 ··· inf
 inf
(1 + Ri n)⌘i.
= Ehg⇣S ·
nYi=1

The ﬁrst line follows from unrolling the recursion in the deﬁnition (5); the second line from replacing
the supremum over (ri) with expectation over (Ri n); and the third line from E[Ri n] = 0. Taking
limit on both sides and using (7) from Lemma 3 give us the desired conclusion.

sup
rn

iri

n

n

6 Upper Bound
In this section we prove that U(S  c) is an upper bound to the limit of V (n)
Theorem 4. Let g : R0 ! R0 be a convex  L-Lipschitz  K-linear function. Let 0 < ⇣  1/16. Then
for any S  c > 0 and n 2 N  we have

(S; c).

⇣

V (n)
⇣

(S; c)  U(S  c) +✓18c +

8

p2⇡◆ LK ⇣1/4.

We remark that the right-hand side of the above bound does not depend on the number of trading
periods n. The key parameter is ⇣  which determines the size of the largest price jump of the stock.
However  we expect that as the trading frequency increases  the size of the largest price jump will
shrink. Plugging a sequence {⇣n} in place of ⇣ in Theorem 4 gives us the following corollary.
Corollary 1. Let g : R0 ! R0 be a convex  L-Lipschitz  K-linear function. Let {⇣n} be a sequence
of positive numbers with ⇣n ! 0. Then for S  c > 0 

lim sup
n!1

V (n)
⇣n

(S; c)  U(S  c).

Note that the above upper bound relies on the convexity of g  for if g were concave  then we would
have the reverse conclusion:

V (n)
⇣

(S; c)  g(S) = g(S · E[G(c)])  E[g(S · G(c))] = U(S  c).

Here the ﬁrst inequality follows from setting all r = 0 in (5)  and the second is by Jensen’s inequality.

6

6.1

Intuition

For brevity  we write the partial derivatives Uc(S  c) = @U(S  c)/@c  US(S  c) = @U(S  c)/@S  and
US2(S  c) = @2U(S  c)/@S2. The proof of Theorem 4 proceeds by providing a “guess” for the In-
vestor’s action  which is a modiﬁcation of the original Black-Scholes hedging strategy. Speciﬁcally 
when the current price is S and the remaining budget is c  then the Investor invests

(S  c) := SUS(S  c).

We now illustrate how this strategy gives rise to a bound on V (n)
suppose for some m  1 we know that V (n)
m) around U(S  c) gives us
that a Taylor approximation of the function rm 7! U(S + Srm  c  r2
1
mUc(S  c) +
2 r2

(S; c) as stated in Theorem 4. First
(S; c  m1) is a rough approximation to U(S  c). Note

m) = U(S  c) + rmSUS(S  c)  r2

U(S + Srm  c  r2

mS2US2(S  c) + O(r3
m)

⇣

⇣

= U(S  c) + rmSUS(S  c) + O(r3

m) 

where the last line follows from the Black-Scholes equation (6). Now by setting  = SUS(S  c) in
the deﬁnition (5)  and using the assumption and the Taylor approximation above  we obtain
m  m  1)

rm + V (n)

V (n)
⇣

⇣

sup

|rm|min{⇣ pc}

(S; c  m) = inf
2R
rm rmSUS(S  c) + V (n)
 sup
= sup
rm rmSUS(S  c) + U(S + Srm  c  r2

(S + Srm; c  r2

(S + Srm; c  r2
m  m  1)

⇣

m) + (approx terms)

= U(S  c) + O(r3

m) + (approx terms).

In other words  on each round of the game we add an O(r3
time we reach V (n)

(S; c  n) we will have an error term that is roughly on the order ofPn
m  c and |rm|  ⇣ by assumption  we getPn

m=1 |rm|3  ⇣c.

m) term to the approximation error. By the
m=1 |rm|3.

The details are more intricate because the error O(r3
on S and c. Trading off the dependencies of c and ⇣ leads us to the bound stated in Theorem 4.

m) from the Taylor approximation also depends

SincePn

m=1 r2

⇣

6.2 Proof (Sketch) of Theorem 4

In this section we describe an outline of the proof of Theorem 4. Throughout  we assume g is a
convex  L-Lipschitz  K-linear function  and 0 < ⇣  1/16. The proofs of Lemma 5 and Lemma 7
are provided in Appendix B  and Lemma 6 is proved in Appendix C.
For S  c > 0 and |r|  pc  we deﬁne the (single-round) error term of the Taylor approximation 

✏r(S  c) := U(S + Sr  c  r2)  U(S  c)  rSUS(S  c).

(8)
m=0 to keep track of the cumulative errors. We deﬁne

We also deﬁne a sequence {↵(n)(S  c  m)}n
this sequence by setting ↵(n)(S  c  0) = 0  and for 1  m  n 

↵(n)(S  c  m) :=

sup

|r|min{⇣ pc}

✏r(S  c) + ↵(n)(S + Sr  c  r2  m  1).

(9)

For simplicity  we write ↵(n)(S  c) ⌘ ↵(n)(S  c  n). Then we have the following result  which
formalizes the notion from the preceding section that V (n)
(S; c  m) is an approximation to U(S  c).
Lemma 5. For S  c > 0  n 2 N  and 0  m  n  we have

⇣

V (n)
⇣

(S; c  m)  U(S  c) + ↵(n)(S  c  m).

(10)

It now remains to bound ↵(n)(S  c) from above. A key step in doing so is to show the following
bounds on ✏r. This is where the assumptions that g be L-Lipschitz and K-linear are important.

7

Lemma 6. For S  c > 0  and |r|  min{1/16  pc/8}  we have

✏r(S  c)  16LK ⇣max{c3/2  c1/2} |r|3 + max{c2  c1/2} r4⌘ .

Moreover  for S > 0  0 < c  1/4  and |r|  pc  we also have
r2
pc

✏r(S  c) 

4LK
p2⇡ ·

.

(11)

(12)

Using Lemma 6  we have the following bound on ↵(n)(S  c).
Lemma 7. For S  c > 0  n 2 N  and 0 < ⇣  1/16  we have

↵(n)(S  c) ✓18c +

8

p2⇡◆ LK ⇣1/4.

Proof (sketch). By unrolling the inductive deﬁnition (9)  we can write ↵(n)(S  c) as the supremum
of f(r1  . . .   rn)  where

f(r1  . . .   rn) =

✏rm⇣S
i⌘.
Let (r1  . . .   rn) be such that |rm|  ⇣ andPn
(18c + 8/p2⇡) LK ⇣1/4. Let 0  n⇤  n be the largest index such thatPn⇤

m1Yi=1
(1 + ri)  c 
m  c. We will show that f(r1  . . .   rn) 
m  c  p⇣. We

split the analysis into two parts.

m1Xi=1

nXm=1

m=1 r2

m=1 r2

r2

1. For 1  m  min{n  n⇤ + 1}: By (11) from Lemma 6 and a little calculation  we have

✏rm⇣S

m1Yi=1

(1 + ri)  c 

m1Xi=1

r2

i⌘  18LK ⇣1/4 r2

m.

Summing over 1  m  min{n  n⇤ + 1} then gives us
i⌘  18LK ⇣1/4
min{n  n⇤+1}Xm=1
min{n  n⇤+1}Xm=1
2. For n⇤ + 2  m  n (if n⇤  n  2): By (12) from Lemma 6  we have

✏rm⇣S

(1+ri)  c

m1Xi=1

m1Yi=1

r2

m1Yi=1

(1 + ri)  c 

r2

i⌘ 

4LK
p2⇡ ·

m1Xi=1
i⌘ 

r2
i=m r2
i

.

mpPn
mpPn

m  18LK ⇣1/4 c.
r2

✏rm⇣S
m1Yi=1

Therefore 

nXm=n⇤+2

✏rm⇣S

(1 + ri)  c 

r2

m1Xi=1

4LK
p2⇡

nXm=n⇤+2

r2
i=m r2

i 

8LK
p2⇡

⇣1/4 

where the last inequality follows from Lemma 8 in Appendix B.

Combining the two cases above gives us the desired conclusion.

Proof of Theorem 4. Theorem 4 follows immediately from Lemma 5 and Lemma 7.

Acknowledgments. We gratefully acknowledge the support of the NSF through grant CCF-
1115788 and of the ARC through Australian Laureate Fellowship FL110100281.

8

References
[1] J. Abernethy  R. M. Frongillo  and A. Wibisono. Minimax option pricing meets Black-Scholes
in the limit. In Howard J. Karloff and Toniann Pitassi  editors  STOC  pages 1029–1040. ACM 
2012.

[2] F. Black and M. Scholes. The pricing of options and corporate liabilities. The Journal of Political

Economy  pages 637–654  1973.

[3] P. DeMarzo  I. Kremer  and Y. Mansour. Online trading algorithms and robust option pricing.
In Proceedings of the 38th Annual ACM Symposium on Theory of Computing  pages 477–486.
ACM  2006.

[4] R. Durrett. Probability: Theory and Examples (Fourth Edition). Cambridge University Press 

2010.

[5] Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an appli-

cation to boosting. In Computational learning theory  pages 23–37. Springer  1995.

[6] N. Littlestone and M. K. Warmuth. The weighted majority algorithm. Information and Compu-

tation  108(2):212–261  1994.

[7] G. Shafer and V. Vovk. Probability and Finance: It’s Only a Game!  volume 373. Wiley-

Interscience  2001.

[8] J. M. Steele. Stochastic Calculus and Financial Applications  volume 45. Springer Verlag 

2001.

9

,Jacob Abernethy
Peter Bartlett
Rafael Frongillo
Andre Wibisono
Neil Houlsby
David Blei