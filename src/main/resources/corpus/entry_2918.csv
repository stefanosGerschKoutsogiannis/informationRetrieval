1997,Learning Generative Models with the Up Propagation Algorithm,Up-propagation is an algorithm for inverting and learning neural network
generative models Sensory input is processed by inverting a model that
generates patterns from hidden variables using topdown connections
The inversion process is iterative utilizing a negative feedback loop that
depends on an error signal propagated by bottomup connections The
error signal is also used to learn the generative model from examples
The algorithm is benchmarked against principal component analysis in
experiments on images of handwritten digits.,Learning Generative Models with the

Up(cid:2)Propagation Algorithm

Jong(cid:2)Hoon Oh and H(cid:3) Sebastian Seung

Bell Labs(cid:2) Lucent Technologies

Murray Hill(cid:2) NJ 	

fjhoh(cid:2)seungg(cid:3)bell(cid:4)labs(cid:5)com

Abstract

Up(cid:2)propagation is an algorithm for inverting and learning neural network
generative models(cid:3) Sensory input is processed by inverting a model that
generates patterns from hidden variables using top(cid:2)down connections(cid:3)
The inversion process is iterative(cid:4) utilizing a negative feedback loop that
depends on an error signal propagated by bottom(cid:2)up connections(cid:3) The
error signal is also used to learn the generative model from examples(cid:3)
The algorithm is benchmarked against principal component analysis in
experiments on images of handwritten digits(cid:3)

In his doctrine of unconscious inference(cid:2) Helmholtz argued that perceptions are
formed by the interaction of bottom(cid:7)up sensory data with top(cid:7)down expectations(cid:8)
According to one interpretation of this doctrine(cid:2) perception is a procedure of sequen(cid:7)
tial hypothesis testing(cid:8) We propose a new algorithm(cid:2) called up(cid:7)propagation(cid:2) that
realizes this interpretation in layered neural networks(cid:8) It uses top(cid:7)down connections
to generate hypotheses(cid:2) and bottom(cid:7)up connections to revise them(cid:8)

It is important to understand the di(cid:9)erence between up(cid:7)propagation and its an(cid:7)
cestor(cid:2) the backpropagation algorithm(cid:10)(cid:12)(cid:8) Backpropagation is a learning algorithm
for recognition models(cid:8) As shown in Figure a(cid:2) bottom(cid:7)up connections recognize
patterns(cid:2) while top(cid:7)down connections propagate an error signal that is used to learn
the recognition model(cid:8)

In contrast(cid:2) up(cid:7)propagation is an algorithm for inverting and learning generative
models(cid:2) as shown in Figure b(cid:8) Top(cid:7)down connections generate patterns from a
set of hidden variables(cid:8) Sensory input is processed by inverting the generative
model(cid:2) recovering hidden variables that could have generated the sensory data(cid:8)
This operation is called either pattern recognition or pattern analysis(cid:2) depending
on the meaning of the hidden variables(cid:8) Inversion of the generative model is done
iteratively(cid:2) through a negative feedback loop driven by an error signal from the
bottom(cid:7)up connections(cid:8) The error signal is also used for learning the connections

error

recognition

generation

error

(a)

(b)

Figure (cid:13) Bottom(cid:7)up and top(cid:7)down processing in neural networks(cid:8) (cid:14)a(cid:15) Backprop
network (cid:14)b(cid:15) Up(cid:7)prop network

in the generative model(cid:8)

Up(cid:7)propagation can be regarded as a generalization of principal component analysis
(cid:14)PCA(cid:15) and its variants like Conic(cid:10)(cid:12) to nonlinear(cid:2) multilayer generative models(cid:8) Our
experiments with images of handwritten digits demonstrate that up(cid:7)propagation
learns a global(cid:2) nonlinear model of a pattern manifold(cid:8) With its global parametriza(cid:7)
tion(cid:2) this model is distinct from locally linear models of pattern manifolds(cid:10)(cid:12)(cid:8)



INVERTING THE GENERATIVE MODEL

The generative model is a network of L (cid:18)  layers of neurons(cid:2) with layer  at the
bottom and layer L at the top(cid:8) The vectors xt(cid:2) t (cid:19)  (cid:2) (cid:2) (cid:2) L(cid:2) are the activations of
the layers(cid:8) The pattern x is generated from the hidden variables xL by a top(cid:7)down
pass through the network(cid:2)

xt(cid:0) (cid:19) f (cid:14)Wtxt(cid:15)(cid:3)

t (cid:19) L(cid:3) (cid:2) (cid:2) (cid:2) (cid:3)  (cid:2)

(cid:14)(cid:15)

The nonlinear function f acts on vectors component by component(cid:8) The matrix
Wt contains the synaptic connections from the neurons in layer t to the neurons in
layer t (cid:2) (cid:8) A bias term bt(cid:0) can be added to the argument of f (cid:2) but is omitted
here(cid:8) It is convenient to de(cid:20)ne auxiliary variables (cid:21)xt by xt (cid:19) f (cid:14)(cid:21)xt(cid:15)(cid:8) In terms of
these auxiliary variables(cid:2) the top(cid:7)down pass is written as

(cid:21)xt(cid:0) (cid:19) Wtf (cid:14)(cid:21)xt(cid:15)

(cid:14)(cid:15)

Given a sensory input d(cid:2) the top(cid:7)down generative model can be inverted by (cid:20)nding
hidden variables xL that generate a pattern x matching d(cid:8)
If some of the hid(cid:7)
den variables represent the identity of the pattern(cid:2) the inversion operation is called
recognition(cid:8) Alternatively(cid:2) the hidden variables may just be a more compact repre(cid:7)
sentation of the pattern(cid:2) in which case the operation is called analysis or encoding(cid:8)
The inversion is done iteratively(cid:2) as described below(cid:8)

In the following(cid:2) the operator (cid:3) denotes elementwise multiplication of two vectors(cid:2)
so that z (cid:19) x (cid:3) y means zi (cid:19) xiyi for all i(cid:8) The bottom(cid:7)up pass starts with the
mismatch between the sensory data d and the generated pattern x(cid:2)

(cid:4) (cid:19) f (cid:14)(cid:21)x(cid:15) (cid:3) (cid:14)d (cid:2) x(cid:15) (cid:3)

which is propagated upwards by

(cid:4)t (cid:19) f (cid:14)(cid:21)xt(cid:15) (cid:3) (cid:14)W T

t (cid:4)t(cid:0)(cid:15) (cid:2)

(cid:14)(cid:15)

(cid:14)(cid:15)

When the error signal reaches the top of the network(cid:2) it is used to update the hidden
variables xL(cid:2)

(cid:22)xL (cid:4) W T

L (cid:4)L(cid:0) (cid:2)

(cid:14)(cid:15)

This update closes the negative feedback loop(cid:8) Then a new pattern x is generated
by a top(cid:7)down pass (cid:14)(cid:15)(cid:2) and the process starts over again(cid:8)

This iterative inversion process performs gradient descent on the cost function 
 jd(cid:2)
xj(cid:2) subject to the constraints (cid:14)(cid:15)(cid:8) This can be proved using the chain rule(cid:2) as in
the traditional derivation of the backprop algorithm(cid:8) Another method of proof is
to add the equations (cid:14)(cid:15) as constraints(cid:2) using Lagrange multipliers(cid:2)




jd (cid:2) f (cid:14)(cid:21)x(cid:15)j (cid:18)

L

X

t(cid:4)

(cid:4)T
t(cid:0)(cid:10)(cid:21)xt(cid:0) (cid:2) Wtf (cid:14)(cid:21)xt(cid:15)(cid:12) (cid:2)

(cid:14)(cid:15)

This derivation has the advantage that the bottom(cid:7)up activations (cid:4)t have an inter(cid:7)
pretation as Lagrange multipliers(cid:8)

Inverting the generative model by negative feedback can be interpreted as a process
of sequential hypothesis testing(cid:8) The top(cid:7)down connections generate a hypothesis
about the sensory data(cid:8) The bottom(cid:7)up connections propagate an error signal
that is the disagreement between the hypothesis and data(cid:8) When the error signal
reaches the top(cid:2) it is used to generate a revised hypothesis(cid:2) and the generate(cid:7)test(cid:7)
revise cycle starts all over again(cid:8) Perception is the convergence of this feedback loop
to the hypothesis that is most consistent with the data(cid:8)

 LEARNING THE GENERATIVE MODEL

The synaptic weights Wt determine the types of patterns that the network is able to
generate(cid:8) To learn from examples(cid:2) the weights are adjusted to improve the network(cid:25)s
generation ability(cid:8) A suitable cost function for learning is the reconstruction error
 jd (cid:2) xj averaged over an ensemble of examples(cid:8) Online gradient descent with
respect to the synaptic weights is performed by a learning rule of the form



(cid:22)Wt (cid:4) (cid:4)t(cid:0)xT
t

(cid:2)

(cid:14)(cid:15)

The same error signal (cid:4) that was used to invert the generative model is also used
to learn it(cid:8)

The batch form of the optimization is compactly written using matrix notation(cid:8)
To do this(cid:2) we de(cid:20)ne the matrices D(cid:3) X(cid:3) (cid:2) (cid:2) (cid:2) (cid:3) XL whose columns are the vectors d(cid:2)
x(cid:3) (cid:2) (cid:2) (cid:2) (cid:3) xL corresponding to examples in the training set(cid:8) Then computation and
learning are the minimization of

min
XL(cid:2)Wt




jD (cid:2) Xj (cid:3)

subject to the constraint that

Xt(cid:0) (cid:19) f (cid:14)WtXt(cid:15) (cid:3)

t (cid:19) (cid:3) (cid:2) (cid:2) (cid:2) (cid:3) L (cid:2)

(cid:14)(cid:15)

(cid:14)	(cid:15)

In other words(cid:2) up(cid:7)prop is a dual minimization with respect to hidden variables and
synaptic connections(cid:8) Computation minimizes with respect to the hidden variables
XL(cid:2) and learning minimizes with respect to the synaptic weight matrices Wt(cid:8)

From the geometric viewpoint(cid:2) up(cid:7)propagation is an algorithm for learning pattern
manifolds(cid:8) The top(cid:7)down pass (cid:14)(cid:15) maps an nL(cid:7)dimensional vector xL to an n(cid:7)
dimensional vector x(cid:8) Thus the generative model parametrizes a continuous nL(cid:7)
dimensional manifold embedded in n(cid:7)dimensional space(cid:8) Inverting the generative
model is equivalent to (cid:20)nding the point on the manifold that is closest to the sensory
data(cid:8) Learning the generative model is equivalent to deforming the manifold to (cid:20)t
a database of examples(cid:8)

W

principal components

Figure (cid:13) One(cid:7)step generation of handwritten digits(cid:8) Weights of the (cid:7)	 up(cid:7)prop
network (cid:14)left(cid:15) versus the top 	 principal components (cid:14)right(cid:15)

target image

x0 t=0

t=1

t=10

t=100

t=1000

x1

4

2

0

4

2

0

4

2

0

4

2

0

4

2

0

0

5

10

0

5

10

0

5

10

0

5

10

0

5

10

Figure (cid:13) Iterative inversion of a generative model as sequential hypothesis testing(cid:8)
A fully trained (cid:27)	 network is inverted to generate an approximation to a target
image that was not previously seen during training(cid:8) The stepsize of the dynamics
was (cid:20)xed to (cid:2) to show time evolution of the system(cid:8)

Pattern manifolds are relevant when patterns vary continuously(cid:8) For example(cid:2) the
variations in the image of a three(cid:7)dimensional object produced by changes of view(cid:7)
point are clearly continuous(cid:2) and can be described by the action of a transformation
group on a prototype pattern(cid:8) Other types of variation(cid:2) such as deformations in
the shape of the object(cid:2) are also continuous(cid:2) even though they may not be readily
describable in terms of transformation groups(cid:8) Continuous variability is clearly not
con(cid:20)ned to visual images(cid:2) but is present in many other domains(cid:8) Many existing
techniques for modeling pattern manifolds(cid:2) such as PCA or PCA mixtures(cid:10)(cid:12)(cid:2) de(cid:7)
pend on linear or locally linear approximations to the manifold(cid:8) Up(cid:7)prop constructs
a globally parametrized(cid:2) nonlinear manifold(cid:8)

 ONE(cid:5)STEP GENERATION

The simplest generative model of the form (cid:14)(cid:15) has just one step (cid:14)L (cid:19) (cid:15)(cid:8) Up(cid:7)
propagation minimizes the cost function

min
X(cid:2)W




jD (cid:2) f (cid:14)WX(cid:15)j (cid:2)

(cid:14)(cid:15)

For a linear f this reduces to PCA(cid:2) as the cost function is minimized when the vec(cid:7)
tors in the weight matrix W span the same space as the top principal components
of the data D(cid:8)

Up(cid:7)propagation with a one(cid:7)step generative model was applied to the USPS
database(cid:10)(cid:12)(cid:2) which consists of example images of handwritten digits(cid:8) Each of the
	 training and  testing images was normalized to a  (cid:5)  grid with pixel
intensities in the range (cid:10)(cid:3) (cid:12)(cid:8) A separate model was trained for each digit class(cid:8) The
nonlinearity f was the logistic function(cid:8) Batch optimization of (cid:14)(cid:15) was done by

Reconstruction Error

PCA  training 
Up−prop  training
PCA  test 
Up−prop  test 

0.025

0.02

r
o
r
r

E

0.015

0.01

0.005

0

5

10

15

20

25

number of vectors

30

35

40

Figure (cid:13) Reconstruction error for (cid:27)n networks as a function of n(cid:8) The error of
PCA with n principal components is shown for comparison(cid:8) The up(cid:7)prop network
performs better on both the training set and test set(cid:8)

gradient descent with adaptive stepsize control by the Armijo rule(cid:10)(cid:12)(cid:8) In most cases(cid:2)
the stepsize varied between (cid:0) and (cid:0)(cid:2) and the optimization usually converged
within  epochs(cid:8) Figure  shows the weights of a (cid:27)	 network that was trained
on  di(cid:9)erent images of the digit (cid:28)two(cid:8)(cid:29) Each of the 	 subimages is the weight
vector of a top(cid:7)level neuron(cid:8) The top 	 principal components are also shown for
comparison(cid:8)

Figure  shows the time evolution of a fully trained (cid:27)	 network during iterative
inversion(cid:8) The error signal from the bottom layer x quickly activates the top layer
x(cid:8) At early times(cid:2) all the top layer neurons have similar activation levels(cid:8) However(cid:2)
the neurons with weight vectors more relevant to the target image become dominant
soon(cid:2) and the other neurons are deactivated(cid:8)

The reconstruction error (cid:14)(cid:15) of the up(cid:7)prop network was much better than that of
PCA(cid:8) We trained  di(cid:9)erent up(cid:7)prop networks(cid:2) one for each digit(cid:2) and these were
compared with  corresponding PCA models(cid:8) Figure  shows the average squared
error per pixel that resulted(cid:8) A (cid:27) up(cid:7)prop network performed as well as PCA
with  principal components(cid:8)

 TWO(cid:5)STEP GENERATION

Two(cid:7)step generation is a richer model(cid:2) and is learned using the cost function

min

X(cid:2)W(cid:2)W




jD (cid:2) f (cid:14)Wf (cid:14)WX(cid:15)(cid:15)j (cid:2)

(cid:14)(cid:15)

Note that a nonlinear f is necessary for two(cid:7)step generation to have more represen(cid:7)
tational power than one(cid:7)step generation(cid:8) When this two(cid:7)step generative model was
trained on the USPS database(cid:2) the weight vectors in W learned features resembling
principal components(cid:8) The activities of the X neurons tended to be close to their
saturated values of one or zero(cid:8)

The reconstruction error of the two(cid:7)step generative network was compared to that of
the one(cid:7)step generative network with the same number of neurons in the top layer(cid:8)

Our (cid:27)(cid:27)	 network outperformed our (cid:27)	 network on the test set(cid:2) though
both networks used nine hidden variables to encode the sensory data(cid:8) However(cid:2)
the learning time was much longer(cid:2) and iterative inversion was also slow(cid:8) While
up(cid:7)prop for one(cid:7)step generation converged within several hundred epochs(cid:2) up(cid:7)prop
for two(cid:7)step generation often needed several thousand epochs or more to converge(cid:8)
We often found long plateaus in the learning curves(cid:2) which may be due to the
permutation symmetry of the network architecture(cid:10)(cid:12)(cid:8)

 DISCUSSION

To summarize the experiments discussed above(cid:2) we constructed separate generative
models(cid:2) one for each digit class(cid:8) Relative to PCA(cid:2) each generative model was
superior at encoding digits from its corresponding class(cid:8) This enhanced generative
ability was due to the use of nonlinearity(cid:8)

We also tried to use these generative models for recognition(cid:8) A test digit was
classi(cid:20)ed by inverting all the generative models(cid:2) and then choosing the one best able
to generate the digit(cid:8) Our tests of this recognition method were not encouraging(cid:8)
The nonlinearity of up(cid:7)propagation tended to improve the generation ability of
models corresponding to all classes(cid:2) not just the model corresponding to the correct
classi(cid:20)cation of the digit(cid:8) Therefore the improved encoding performance did not
immediately transfer to improved recognition(cid:8)

We have not tried the experiment of training one generative model on all the digits(cid:2)
with some of the hidden variables representing the digit class(cid:8) In this case(cid:2) pattern
recognition could be done by inverting a single generative model(cid:8) It remains to be
seen whether this method will work(cid:8)

Iterative inversion was surprisingly fast(cid:2) as shown in Figure (cid:2) and gave solutions
of surprisingly good quality in spite of potential problems with local minima(cid:2) as
shown in Figure (cid:8) In spite of these virtues(cid:2) iterative inversion is still a problematic
method(cid:8) We do not know whether it will perform well if a single generative model
is trained on multiple pattern classes(cid:8) Furthermore(cid:2) it seems a rather indirect way
of doing pattern recognition(cid:8)

The up(cid:7)prop generative model is deterministic(cid:2) which handicaps its modeling of
pattern variability(cid:8) The model can be dressed up in probabilistic language by de(cid:20)n(cid:7)
ing a prior distribution P (cid:14)xL(cid:15) for the hidden variables(cid:2) and adding Gaussian noise
to x to generate the sensory data(cid:8) However(cid:2) this probabilistic appearance is only
skin deep(cid:2) as the sequence of transformations from xL to x is still completely de(cid:7)
terministic(cid:8) In a truly probabilistic model(cid:2) like a belief network(cid:2) every layer of the
generation process adds variability(cid:8)

In conclusion(cid:2) we brie(cid:30)y compare up(cid:7)propagation to other algorithms and architec(cid:7)
tures(cid:8)

(cid:8) In backpropagation(cid:10)(cid:12)(cid:2) only the recognition model is explicit(cid:8) Iterative gra(cid:7)
dient descent methods can be used to invert the recognition model(cid:2) though
this implicit generative model generally appears to be inaccurate(cid:10)(cid:2) (cid:12)(cid:8)

(cid:8) Up(cid:7)propagation has an explicit generative model(cid:2) and recognition is done
by inverting the generative model(cid:8) The accuracy of this implicit recognition
model has not yet been tested empirically(cid:8) Iterative inversion of generative
models has also been proposed for linear networks(cid:10)(cid:2) 	(cid:12) and probabilistic
belief networks(cid:10)(cid:12)(cid:8)

(cid:8) In the autoencoder(cid:10)(cid:12) and the Helmholtz machine(cid:10)(cid:12)(cid:2) there are separate

models of recognition and generation(cid:2) both explicit(cid:8) Recognition uses only
bottom(cid:7)up connections(cid:2) and generation uses only top(cid:7)down connections(cid:8)
Neither process is iterative(cid:8) Both processes can operate completely inde(cid:7)
pendently(cid:31) they only interact during learning(cid:8)

(cid:8) In attractor neural networks(cid:10)(cid:2) (cid:12) and the Boltzmann machine(cid:10)(cid:12)(cid:2) recog(cid:7)
nition and generation are performed by the same recurrent network(cid:8) Each
process is iterative(cid:2) and each utilizes both bottom(cid:7)up and top(cid:7)down connec(cid:7)
tions(cid:8) Computation in these networks is chie(cid:30)y based on positive(cid:2) rather
than negative feedback(cid:8)

Backprop and up(cid:7)prop su(cid:9)er from a lack of balance in their treatment of bottom(cid:7)up
and top(cid:7)down processing(cid:8) The autoencoder and the Helmholtz machine su(cid:9)er from
inability to use iterative dynamics for computation(cid:8) Attractor neural networks lack
these de(cid:20)ciencies(cid:2) so there is incentive to solve the problem of learning attractors(cid:10)(cid:12)(cid:8)

This work was supported by Bell Laboratories(cid:8) JHO was partly supported by the
Research Professorship of the LG(cid:7)Yonam Foundation(cid:8) We are grateful to Dan Lee
for helpful discussions(cid:8)

References

(cid:5)(cid:7) D(cid:3) E(cid:3) Rumelhart(cid:4) G(cid:3) E(cid:3) Hinton(cid:4) and R(cid:3) J(cid:3) Williams(cid:3) Learning internal representations

by back(cid:2)propagating errors(cid:3) Nature(cid:4) (cid:10)(cid:12)(cid:4) 	(cid:3)

(cid:5)(cid:7) D(cid:3) D(cid:3) Lee and H(cid:3) S(cid:3) Seung(cid:3) Unsupervised learning by convex and conic coding(cid:3) Adv(cid:2)

Neural Info(cid:2) Proc(cid:2) Syst(cid:2)(cid:4) 	(cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) G(cid:3) E(cid:3) Hinton(cid:4) P(cid:3) Dayan(cid:4) and M(cid:3) Revow(cid:3) Modeling the manifolds of images of hand(cid:2)

written digits(cid:3) IEEE Trans(cid:2) Neural Networks(cid:4) (cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) Y(cid:3) LeCun et al(cid:3) Learning algorithms for classi(cid:18)cation(cid:10) a comparison on handwritten
digit recognition(cid:3) In J(cid:3)(cid:2)H(cid:3) Oh(cid:4) C(cid:3) Kwon(cid:4) and S(cid:3) Cho(cid:4) editors(cid:4) Neural networks(cid:3) the
statistical mechanics perspective(cid:4) pages (cid:12)(cid:4) Singapore(cid:4) 		(cid:3) World Scienti(cid:18)c(cid:3)

(cid:5)(cid:7) D(cid:3) P(cid:3) Bertsekas(cid:3) Nonlinear programming(cid:3) Athena Scienti(cid:18)c(cid:4) Belmont(cid:4) MA(cid:4) 		(cid:3)
(cid:5)(cid:7) K(cid:3) Kang(cid:4) J(cid:3)(cid:2)H(cid:3) Oh(cid:4) C(cid:3) Kwon(cid:4) and Y(cid:3) Park(cid:3) Generalization in a two(cid:2)layer neural

network(cid:3) Phys(cid:2) Rev(cid:2)(cid:4) E(cid:10)(cid:12)	(cid:4) 		(cid:3)

(cid:5)(cid:7) J(cid:3) Kindermann and A(cid:3) Linden(cid:3)

Inversion of neural networks by gradient descent(cid:3)

Parallel Computing(cid:4) (cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) Y(cid:3) Lee(cid:3) Handwritten digit recognition using K nearest(cid:2)neighbor(cid:4) radial(cid:2)basis function(cid:4)

and backpropagation neural networks(cid:3) Neural Comput(cid:2)(cid:4) (cid:10)(cid:12)	(cid:4) 		(cid:3)

(cid:5)	(cid:7) R(cid:3) P(cid:3) N(cid:3) Rao and D(cid:3) H(cid:3) Ballard(cid:3) Dynamic model of visual recognition predicts neural

response properties in the visual cortex(cid:3) Neural Comput(cid:2)(cid:4) 	(cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) L(cid:3) K(cid:3) Saul(cid:4) T(cid:3) Jaakkola(cid:4) and M(cid:3) I(cid:3) Jordan(cid:3) Mean (cid:18)eld theory for sigmoid belief

networks(cid:3) J(cid:2) Artif(cid:2) Intell(cid:2) Res(cid:2)(cid:4) (cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) G(cid:3) W(cid:3) Cottrell(cid:4) P(cid:3) Munro(cid:4) and D(cid:3) Zipser(cid:3) Image compression by back propagation(cid:10) an
example of extensional programming(cid:3) In N(cid:3) E(cid:3) Sharkey(cid:4) editor(cid:4) Models of cognition(cid:3)
a review of cognitive science(cid:3) Ablex(cid:4) Norwood(cid:4) NJ(cid:4) 		(cid:3)

(cid:5)(cid:7) G(cid:3) E(cid:3) Hinton(cid:4) P(cid:3) Dayan(cid:4) B(cid:3) J(cid:3) Frey(cid:4) and R(cid:3) M(cid:3) Neal(cid:3) The (cid:20)wake(cid:2)sleep(cid:21) algorithm for

unsupervised neural networks(cid:3) Science(cid:4) (cid:10)(cid:12)(cid:4) 		(cid:3)

(cid:5)(cid:7) H(cid:3) S(cid:3) Seung(cid:3) Pattern analysis and synthesis in attractor neural networks(cid:3) In K(cid:3)(cid:2)Y(cid:3) M(cid:3)
Wong(cid:4) I(cid:3) King(cid:4) and D(cid:3)(cid:2)Y(cid:3) Yeung(cid:4) editors(cid:4) Theoretical Aspects of Neural Computation(cid:3)
A Multidisciplinary Perspective(cid:4) Singapore(cid:4) 		(cid:3) Springer(cid:2)Verlag(cid:3)

(cid:5)(cid:7) H(cid:3) S(cid:3) Seung(cid:3) Learning continuous attractors in recurrent networks(cid:3) Adv(cid:2) Neural Info(cid:2)

Proc(cid:2) Syst(cid:2)(cid:4) (cid:4) 		(cid:3)

(cid:5)(cid:7) D(cid:3) H(cid:3) Ackley(cid:4) G(cid:3) E(cid:3) Hinton(cid:4) and T(cid:3) J(cid:3) Sejnowski(cid:3) A learning algorithm for Boltzmann

machines(cid:3) Cognitive Science(cid:4) 	(cid:10)(cid:12)	(cid:4) 	(cid:3)

,Jong-Hoon Oh
H. Sebastian Seung
Craig Greenberg
Nicholas Monath
Ari Kobren
Patrick Flaherty
Andrew McGregor
Andrew McCallum