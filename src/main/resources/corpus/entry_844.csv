2018,Boosting Black Box Variational Inference,Approximating a probability density in a tractable manner is a central task in Bayesian statistics. Variational Inference (VI) is a popular technique that achieves tractability by choosing a relatively simple variational approximation. Borrowing ideas from the classic boosting framework  recent approaches attempt to \emph{boost} VI by replacing the selection of a single density with an iteratively constructed mixture of densities. In order to guarantee convergence  previous works impose stringent assumptions that require significant effort for practitioners. Specifically  they require a custom implementation of the greedy step (called the LMO) for every probabilistic model with respect to an unnatural variational family of truncated distributions. Our work fixes these issues with novel theoretical and algorithmic insights. On the theoretical side  we show that boosting VI satisfies a relaxed smoothness assumption which is sufficient for the convergence of the functional Frank-Wolfe (FW) algorithm. Furthermore  we rephrase the LMO problem and propose to maximize the Residual ELBO (RELBO) which replaces the standard ELBO optimization in VI. These theoretical enhancements allow for black box implementation of the boosting subroutine. Finally  we present a stopping criterion drawn from the duality gap in the classic FW analyses and exhaustive experiments to illustrate the usefulness of our theoretical and algorithmic contributions.,Boosting Black Box Variational Inference

Francesco Locatello⇤1 2  Gideon Dresdner⇤2  Rajiv Khanna3  Isabel Valera1  and Gunnar Rätsch2

2Dept. for Computer Science  ETH Zurich  Universitätsstrasse 6  8092 Zurich  Switzerland.

1Max-Planck Institute for Intelligent Systems  Germany

3The University of Texas at Austin  USA

Abstract

Approximating a probability density in a tractable manner is a central task in
Bayesian statistics. Variational Inference (VI) is a popular technique that achieves
tractability by choosing a relatively simple variational approximation. Borrowing
ideas from the classic boosting framework  recent approaches attempt to boost
VI by replacing the selection of a single density with an iteratively constructed
mixture of densities. In order to guarantee convergence  previous works impose
stringent assumptions that require signiﬁcant effort for practitioners. Speciﬁcally 
they require a custom implementation of the greedy step (called the LMO) for every
probabilistic model with respect to an unnatural variational family of truncated
distributions. Our work ﬁxes these issues with novel theoretical and algorithmic
insights. On the theoretical side  we show that boosting VI satisﬁes a relaxed
smoothness assumption which is sufﬁcient for the convergence of the functional
Frank-Wolfe (FW) algorithm. Furthermore  we rephrase the LMO problem and
propose to maximize the Residual ELBO (RELBO) which replaces the standard
ELBO optimization in VI. These theoretical enhancements allow for black box
implementation of the boosting subroutine. Finally  we present a stopping criterion
drawn from the duality gap in the classic FW analyses and exhaustive experiments
to illustrate the usefulness of our theoretical and algorithmic contributions.

1

Introduction

Approximating probability densities is a core problem in Bayesian statistics  where inference translates
to the computation of a posterior distribution. Posterior distributions depend on the modeling
assumptions and can rarely be computed exactly. Variational Inference (VI) is a technique to
approximate posterior distributions through optimization. It involves choosing a set of tractable
densities  a.k.a. variational family  out of which the ﬁnal approximation is to be chosen. The
approximation is done by selecting a density in the candidate set that is close to the true posterior in
terms of Kullback-Leibler (KL) divergence [1]. There is an inherent trade-off involved in ﬁxing the
set of tractable densities. Increasing the capacity of the variational family to approximate the posterior
also increases the complexity of the optimization problem. Consider a degenerate case where the
variational family contains just a single density. The optimization problem is trivial and runs in
constant time  but the quality of the solution is poor and stands in no relation to the true posterior.
This contrived example is clearly too restrictive  and in practice  the mean ﬁeld approximation offers
a good trade-off between expressivity and tractability [2]. However  in many real-world applications 
mean ﬁeld approximations are lacking in their ability to accurately approximate the posterior.
Imagine a practitioner that  after designing a Bayesian model and using a VI algorithm to approximate
the posterior  ﬁnds that the approximation is too poor to be useful. Standard VI does not give the

*Authors contributed equally

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

practitioner the option to trade additional computational cost for a better approximation. As a result 
there have been several efforts to ramp up the representative capacity of the variational family while
maintaining tractability.
One line of work in this direction involves replacing the simple mean ﬁeld family by a mixture
of Gaussians. It is known that mixtures of Gaussians can approximate any distribution arbitrarily
closely [18]. Boosting is a practical approach to ﬁnding the optimal approximating mixture and
involves adding components to the mixture greedily one at a time [5  13  16]. Not only is boosting a
practical solution  it also has well-studied trade-off bounds for number of iterations vs. approximation
quality [13] by virtue of being essentially a variant of the classical Frank-Wolfe (FW) algorithm [8  13].
Unfortunately  these greedy algorithms require a specialized  restricted variational family to ensure
convergence and therefore a white box implementation of the boosting subroutine. These restrictions
include that (a) each potential component of the mixture has a bounded support i.e.  truncated
densities  and (b) the subroutine should not return degenerate distributions. These assumptions
require specialized care during implementation  and therefore  one cannot simply take existing VI
solvers and boost them. This makes boosting VI unattractive for practitioners. In this work  we ﬁx
this issue by proposing a boosting black box VI algorithm that has many practical beneﬁts.
Our work presents several key algorithmic and theoretical contributions  which we summarize below:
• We relax the previously known conditions for guaranteed convergence from smoothness to
bounded curvature. As a consequence  the set of candidate densities no longer needs to be
truncated  thereby easing its implementation and improving on the convergence guarantees.
• We propose a modiﬁed form of the ELBO optimization  the Residual ELBO (RELBO) 
which guarantees that the selected density is non-degenerate and is suitable for black box
solvers (e.g. black box variational inference [19]).

any boosting VI algorithm.

• We propose a novel stopping criterion using the duality gap from FW  which is applicable to
In addition to these theoretical contributions  we present extensive simulated and real-world empirical
experiments to show the applicability of our proposed algorithmic extensions.
While our work is motivated by applications to VI  our theoretical results have a more general
impact. We essentially analyze the application of the functional FW algorithm to the general task of
minimizing the KL-divergence over a space of probability densities.

1.1 Related work

There is a vast literature on VI. We refer to [1] for a thorough review. Our focus is to use boosting
to increase the complexity of a density  similar to the goal of Normalizing Flows [20]  MCMC-VI
hybrid methods [22  21]  or distribution transformations [23]. Our approach is in line with several
previous approaches using mixtures of distributions to improve the expressiveness of the variational
approximation [9  6] but goes further to draw connections with classic optimization to obtain several
novel theoretical and algorithmic insights.
While boosting has been well studied in other settings [15]  it has only recently been applied to the
problem of VI. Related works of [5] and [16] developed the algorithmic framework and conjectured
a possible convergence rate of O(1/T ) but without theoretical analyses. The authors in [5] identify
the need of truncated densities to ensure smoothness of the KL cost function. A more recent
work [13] provides a theoretical base for analyzing the algorithm. They identify the sufﬁcient
conditions for guaranteeing convergence and provide explicit constants to the conjectured O(1/T )
rate. Unfortunately  these sufﬁcient conditions amount to restrictive assumptions about the variational
family and therefore require the practitioner to have white box access to the variational family and
underlying VI algorithm. In this work  we remove these assumptions to allow use of black box VI
methods.
Our analysis is mainly based on the FW algorithm [8]  which is a commonly used algorithm for
projection free constrained optimization. The convergence rates and requisite assumptions are
well studied in various settings [12  11  14]. Its applications include non-Euclidean spaces  e.g.  a
variational objective for approximate marginal inference over the marginal polytope [10].
The rest of the paper is organized as follows. We begin by introducing and formalizing the boosting VI
framework in Section 2. In Section 3  we review and analyze the Functional FW algorithm to greedily

2

solve the boosting VI. In Section 4  we ﬁrst propose RELBO  an alternative of the contemporary
ELBO optimization to implement a black box LMO (linear minimization oracle). Then  we propose
a duality gap based stopping criterion for boosting VI algorithms. Finally  experimental evaluation is
presented in Section 5. We refer the reader to the appendix for all proofs.
Notation. We represent vectors by small letters bold  (e.g. x) and matrices by capital bold  (e.g. X).
For a non-empty subset A of some Hilbert space H  let conv(A) denote its convex hull. A is often
called atom set in the literature  and its elements are called atoms. The support of a density function q
is a measurable set denoted by capital letters sans serif i.e.  Z. The inner product between two density
functions p  q : Z ! R in L2 is deﬁned as hp  qi :=RZ p(z)q(z)dz.

2 Variational inference and boosting

Bayesian inference involves computing the posterior distribution given a model and the data. More
formally  we choose a distribution for our observations x given unobserved latent variables z  called
the likelihood p(x|z)  and a prior distribution over the latent variables  p(z). Our goal is to infer
the posterior  p(z|x) [1]. Bayes theorem relates these three distributions by expressing the posterior
as equal to the product of prior and likelihood divided by the normalization constant  p(x). The
posterior is often intractable because the normalization constant p(x) =RZ p(x|z)p(z)dz requires
integrating over the full latent variable space.
The goal of VI is to ﬁnd a tractable approximation q(z) of p(z|x). From an optimization viewpoint 
one can think of the posterior as an unknown function p(z|x) : Z ! R+
>0 where Z is a measurable
set. The task of VI is to ﬁnd the best approximation  in terms of KL divergence  to this unknown
function within a family of tractable distributions Q. Therefore  VI can be written as the following
optimization problem:

min
q(z)2Q

DKL(q(z)kp(z|x)).

(1)

It should be obvious that the quality of the approximation directly depends on the expressivity of the
family Q. However  as we increase the complexity of Q  the optimization problem (1) also becomes
more complex.
Rather than optimizing the objective (1) which requires access to an unknown function p(z|x) and is
therefore not computable  VI equivalently maximizes instead the so-called Evidence Lower BOund
(ELBO) [1]:

(2)
A recent line of work [5  16  13] aims at replacing Q with conv(Q) thereby expanding the capacity
of the variational approximation to the class of mixtures of the base family Q:

Eq [log q(z)] + Eq [log p(x  z)] .

min

q(z)2conv(Q)

DKL(q(z)||p(x  z)).

(3)

The boosting approach to this problem consists of specifying an iterative procedure  in which the
problem (3) is solved via the greedy combination of solutions from simpler surrogate problems.
This approach was ﬁrst proposed in [5]  and its connection to the FW algorithm was studied in [13].
Contrary to the boosting approaches in the deep generative modeling literature initiated by [24] 
boosting VI does not enjoy a simple and elegant subproblem as we discuss in Section 3.1. Next  we
show how to tackle (3) from a formal and yet very practical optimization perspective.

3 Functional Frank-Wolfe for boosting variational inference

Taking a step back from the problem (3)  we ﬁrst deﬁne the general optimization problem and the
relevant quantities needed for proving the convergence of FW. Then  we present the extension to
boosting black box VI.
We start with the general optimization problem:

min

q2conv(A)

f (q).

3

(4)

where A ⇢ H is closed and bounded and f : conv(A)! R is a convex functional with bounded
curvature over its domain. Here the curvature is deﬁned as in [8]:

Cf A :=

sup

s2A  q2conv(A)
y=q+(sq)

2[0 1]

2
2 D(y  q) 

(5)

where

D(y  q) := f (y)  f (q)  hy  q rf (q)i.

t+2

It is known that if rf is Lipschitz continuous with constant L (often referred to as L-smoothness)
over conv(A)  then Cf A  L diam(A)2 where diam(A) := maxp q2A ||p  q||2 [8].
The FW algorithm is depicted in Algo-
Algorithm 1 Afﬁne Invariant Frank-Wolfe
rithm 1. Note that Algorithm 2 in [5]
1: init q0 2 conv(A)  S := {q0}  and accuracy  > 0
is a variant of Algorithm 1. In each
2: for t = 0 . . . T
iteration  the FW algorithm queries a
so-called Linear Minimization Oracle
3:
(LMO) which solves the following in-
4:
ner optimization problem:
5:
6:
LMOA(y) := arg min
7:
8:
9: end for

Find st := (Approx-)LMOA(rf (qt))
Variant 0:  = 2
Variant 1:  = arg min2[0 1] f ((1  )qt + st)
qt+1 := (1  )qt + st
Variant 2: S = S [ st

for a given y 2 H and A ⇢ H. To
tackle the constrained convex mini-
mization problem in Eq. (4)  Frank-
Wolfe iteratively solves a linear constrained problem where  at iteration t  the function f is replaced
by its ﬁrst-order Taylor approximation around the current iterate qt. It is easy to see that the so-
lution of this problem can be obtained by querying LMO(rf (qt)). Indeed  the following holds:
arg mins2conv(A) f (qt) + hrf (qt)  s  qti = arg mins2conv(A)hrf (qt)  si =: LMO(rf (qt)).
Depending on A  computing an exact solution of (6) can be hard in practice. This motivates the
approximate LMO which returns an approximate minimizer ˜s of (6) for some accuracy parameter 
and the current iterate qt such that:

qt+1 = arg minq2conv(S) f (q)

s2A hy  si 

(6)

hy  ˜s  qti   min

s2Ahy  s  qti

(7)

We discuss a simple algorithm to implement the LMO in Section 4. Finally  we ﬁnd that Algorithm 1
is known to converge sublinearly to the minimizer q? of (4) with the following rate:
Theorem 1 ([8]). Let A ⇢ H be a closed and bounded set and let f : H! R be a convex function
with bounded curvature Cf A over A. Then  the Afﬁne Invariant FW algorithm (Algorithm 1)
converges for t  0 as

f (qt)  f (q?) 

2 1
 Cf A + "0

t + 2

where "0 := f (q0)  f (q?) is the initial error in objective  and  2 (0  1] is the accuracy parameter
of the approximate LMO.

Discussion. Theorem 1 has several implications for boosting VI. First  the LMO problem does not
need to be solved exactly in order to guarantee convergence. Second  Theorem 1 guarantees that
Algorithm 1 converges to the best approximation in conv(A) which  depending on the expressivity of
the base family  could even contain the full posterior. Furthermore  the theorem gives a convergence
rate which states that  in order to achieve an error of ✏  we need to perform O( 1
Similar discussions are also presented by [13]. The crucial question  which they leave unaddressed 
is whether under their assumptions there exists a variational family of densities which (a) is expres-
sive enough to well-approximate the posterior; (b) satisﬁes the conditions required to guarantee
convergence; and (c) allows for efﬁcient implementation of the LMO.

✏ ) iterations.

3.1 Curvature of boosting variational inference
In order to boost VI using FW in practice  we need to ensure that the assumptions are not violated.
Assume that A ⇢ Q is the set of probability density functions with compact parameter space as well

4

as bounded inﬁnity norm and L2 norm. These assumptions on the search space are easily justiﬁed
since it is reasonable to assume that the posterior is not degenerate (bounded inﬁnity norm) and has
modes that are not arbitrarily far away from each other (compactness). Under these assumptions  the
optimization domain is closed and bounded. It is simple to show that the solution of the LMO problem
over conv(A) is an element of A. Therefore  A is closed. The troublesome condition that needs to
be satisﬁed for the convergence of FW is smoothness. Indeed  the work of [5] already recognized
that the boosting literature typically require a smooth objective and showed that densities bounded
away from zero are sufﬁcient. [13] showed that the necessary condition to achieve smoothness is that
the approximation be not arbitrarily far from the optimum. They argue that while this is a practical
assumption  the general theory would require truncated densities. We relax this assumption. As per
Theorem 1  a bounded curvature is actually sufﬁcient to guarantee convergence. This condition is
weaker than smoothness  which was assumed by [13  5]. For the KL divergence  the following holds.
Theorem 2. Cf A is bounded for the KL divergence if the parameter space of the densities in A is
bounded.

The proof is provided in Appendix A.
Discussion. Surprisingly  a bounded curvature for the DKL can be obtained as long as:

2
2 DKL(ykq)

sup

s2A  q2conv(A)
y=q+(sq)

2[0 1]

is bounded. The proof sketch proceeds as follows. For any pair s and q  we need to check that
2 DKL(ykq) is bounded as a function of  2 [0  1]. The two limit points  DKL(skq) for  = 1
2
2 for  = 0  are both bounded for any choice of s and q. Hence  the Cf A is bounded
and ks  qk2
as it is a continuous function of  in [0  1] with bounded function values at the extreme points.
DKL(skq) is bounded because the parameter space is bounded. ks  qk2
2 is bounded by the triangle
inequality and bounded L2 norm of the elements of A. This result is particularly relevant  as it
makes the complicated truncation described in [13] unnecessary without any additional assumption.
Indeed  while a bounded parameter space was already assumed in [13] and is a practical assumption 
truncation is tedious to implement. Note that [5] considers full densities as an approximation of the
truncated one. They also argue that the theoretically grounded family of distributions for boosting
should contain truncated densities. Avoiding truncation has another very important consequence for
the optimization. Indeed  [13] proves convergence of boosting VI only to a truncated version of the
posterior. Therefore  Theorem 8 in [13] contains a term that does not decrease when the number of
iteration increases. While this term could be small  as it contains the error of the approximation on
the tails  it introduces a crucial hyperparameter in the algorithm i.e.  where to truncate. Instead  we
here show that under much weaker assumptions on the set A  it is possible to converge to the true
posterior.

4 The residual ELBO: implementing a black box LMO
Note that the LMO is a constrained linear problem in a function space. A complicated heuristic
is developed in [5] to deal with the fact that the unconstrained linear problem they consider has a
degenerate solution. The authors of [13] propose to use projected stochastic gradient descent on the
parameters of s. The problem with this is that  to the best of our knowledge  the convergence of
projected stochastic gradient descent is not yet understood in this setting. To guarantee convergence
of the FW procedure  it is crucial to make sure that the solution of the LMO is not a degenerate
distribution. This translates to a constraint on the inﬁnity norm of s. Such a constraint is hardly
practical. Indeed  one must be able to compute the maximum value of s as a function of its parameters
which depends on the particular choice of A. In contrast  the entropy is a general term that can be
approximated via sampling and therefore allows for black box computation. We relate inﬁnity norm
and entropy in the following lemma.
Lemma 3. A density with bounded inﬁnity norm has entropy bounded from below. The converse is
true for many of the distributions which are commonly used in VI (for example Gaussian  Cauchy
and Laplace).

The proof is provided in Appendix A.

5

In general  bounded entropy does not always imply bounded inﬁnity norm. While this is precisely the
statement we need  a simple veriﬁcation is sufﬁcient to show that it holds in most cases of interest.
We assume that A is a family for which bounded entropy implies bounded inﬁnity norm. Therefore 
we can constrain the optimization problem with the entropy instead of the inﬁnity norm. We call ¯A
the family A without the inﬁnity norm constraint. At every iteration  we need to solve:

arg min

H(s)M⌧s  log✓ qt
p◆

s2 ¯A

Note that this is simply the LMO from Equation (6) with y = rqDKL(qtkp) = log qt
p but with an
additional constraint on the entropy. This constraint on the entropy is crucial since otherwise the
solution of the LMO would be a degenerate distribution as the authors of [5] have also argued.
We now replace this problem with its regularized form using Lagrange multipliers and solve for s
given a ﬁxed value of :

arg min

s2 ¯A ⌧s  log✓ qt

p◆ +  (H(s)  M ) = arg min

(8)

= arg min

= arg min

p

s2 ¯A ⌧s  log✓ qt
p◆ + hs  log si
s2 ¯A *s  log s
qt!+
1A+ .
s2 ¯A *s  log0@ s
q p
r p

qt ) 

qt

Therefore  the regularized LMO problem is equivalent to the following minimization problem:

where Z is the normalization constant of q p

we call the Residual Evidence Lower Bound (RELBO) as:

1
Z

arg min

s2 ¯A

DKL(sk
qt . From this optimization problem  we can write what

RELBO(s  ) := Es[log p]  Es[log s]  Es[log qt].

(9)

Discussion. Let us now analyze the RELBO and compare it with the ELBO in standard VI [1]. First 
note that we introduce the hyperparameter  which controls the weight of the entropy. In order to
obtain the true LMO solution  one would need to maximize the LHS of Equation (8) for  and solve
the saddle point problem. In light of the fact that an approximate solution is sufﬁcient for convergence 
we consider the regularized problem as a simple heuristic. One can then ﬁx an arbitrary value for
 or decrease it when t increases. The latter amounts to allowing increasingly sharp densities as
optimization proceeds. The other important difference between ELBO and RELBO is the residual
term which is expressed through Es[log p]  Es[log qt]. Maximizing this term amounts to looking
for a density with low cross entropy with the joint p and high cross entropy with the current iterate
qt. In other words  the next component st needs to be as close as possible to the target p but also
sufﬁciently different from the current approximation qt. Indeed  st should capture the aspects of the
posterior that the current mixture could not approximate yet.
Failure Modes. Using a black box VI as an implementation for the LMO represents an attractive
practical solution. Indeed  one could just run VI once and  if the result is not good enough  run it
again on the residual without changing the structure of the implementation. Unfortunately  there are
two failure modes that should be discussed. First  if the target posterior is a perfectly symmetric
multimodal distribution  then the residual is also symmetric and the algorithm may get stuck. A
simple solution to this problem is to run the black box VI for fewer iterations  breaking the symmetry
of the residual. The second problem arises in scenarios where the posterior distribution can be
approximated well by a single element of Q. In such cases  most of the residual will be on the tails.
The algorithm will then ﬁt the tails and in the following iterations re-learn a distribution close to q0.
As a consequence  it is important to identify good solutions before investing additional computational
effort by adding more components to the mixture. Note that the ELBO cannot be used for this
purpose  as its value at the maximum is unknown.

6

Stopping criterion. We propose a stopping criterion for boosting VI which allows us to identify
when a reasonably good approximation is reached and save computational effort. To this end  we
rephrase the notion of duality gap [8  7] in the context of boosting VI  which gives a surprisingly
simple stopping criterion for the algorithm.
Lemma 4. The duality gap g(q) := maxs2conv(A)hq  s  log q
conv(A) is an upper bound on the primal error DKL(qkp)  DKL(q?kp).
The proof is provided in Appendix A.
Note that the arg maxs2conv(A)hq  s  log q
pi is precisely the LMO solution to the problem (6).
Therefore  with an exact LMO  one obtains a certiﬁcate on the primal error for free  without knowing
the value of DKL(q?kp). It is possible to show that a convergence rate similar to Theorem 1 also
holds for the duality gap [8]. If the oracle is inexact  the estimate of the duality gap ˜g(q) satisﬁes that
 ˜g(q)  g(q)  as a consequence of (7).
1
5 Experimental evaluation

pi computed at some iterate q 2

Notably  our VI algorithm is black box in the sense that it leaves the deﬁnition of the model and the
choice of variational family up to the user. Therefore  we are able to reuse the same boosting black
box VI solver to run all our experiments  and more generally  any probabilistic model and choice of
variational family. We chose to implement our algorithm as an extension to the Edward probabilistic
programming framework [25] thereby enabling users to apply boosting VI to any probabilistic model
and variational family which are deﬁnable in Edward. In Appendix B  we show a code sample of our
implementation of Bayesian logistic regression.
For comparisons to baseline VI  we use Edward’s built-in black box VI (BBVI) algorithm without
modiﬁcation. We run these baseline VI experiments for 10 000 iterations which is orders of magnitude
more than what is required for convergence. Unless otherwise noted  we use Gaussians as our base
family. Note that FW with ﬁxed step size is not monotonic and so in the experiments in which
we use a ﬁxed step size  it is expected that the last iteration is not optimal. We use the training
log-likelihood to select the best iteration and we used the duality gap as a diagnostic tool in the
implementation to understand the impact of . We found that  = 1pt+1 worked well in all
the experiments. Code to reproduce the experiments is available at: https://github.com/
ratschlab/boosting-bbvi.

5.1 Synthetic data

First  we use synthetic data to visualize the ap-
proximation of our algorithm of a bimodal poste-
rior. In particular  we consider a mixture of two
Gaussians with parameters µ = (1  +1)   =
(0.5  0.5)  and mixing weights ⇡ = (0.4  0.6).
We performed experiments with all three vari-
ants of FW described in Algorithm 1. For the
fully corrective variant  we used FW to solve
the subproblem of ﬁnding the optimal weights
for the current atom set. We observe that un-
like BBVI  all three variants are able to ﬁt both
modes of the bimodal target distribution. The
fully corrective version gives the best ﬁt. Un-
fortunately  this improved solution comes at a
computational cost — solving the line search
and fully corrective subproblems is dramatically
slower than the ﬁxed step size variant. In the experiments that follow we were able to improve upon
the initial VI solution using the simple ﬁxed step size. We believe this is the most interesting variant
for practitioners as it does not require any additional implementation other than the VI subroutine.
Our synthetic data results are summarized in Figure 1.

Figure 1: Comparison between BBVI and three
variants of our boosting BBVI method on a mixture
of Gaussians example.

7

Table 1: Comparison of boosting BBVI on the CHEMREACT dataset. We observe that using the
Laplace distribution as the base family  our method outperforms BBVI using either Laplace or
Gaussian distributions as the variational family. In addition  boosting BBVI has lower variance across
repetitions.

Boosting BBVI (Laplace)
BBVI Edward (Laplace)
BBVI Edward (Gaussian)
Line Search Boosting VI ([5])
Fixed Step Boosting VI ([13])
Norm Corrective Boosting VI ([13])

Train LL

-.677 ± 0.002
-0.681 ± 0.003
-0.671 ± 0.002

-2.808
-3.045
-2.725

Test AUROC
0.794 ± 0.005
0.781 ± 0.012
0.790 ± 0.009

0.6377
0.6193
0.6440

Table 2: Comparison of boosting BBVI on EICU COLLABORATIVE RESEARCH dataset. We observe
that our method outperforms BBVI with the Laplace distribution. In addition  boosting BBVI has
lower variance across repetitions.

Train LL

-0.195 ± 0.007
-0.200 ± 0.032

Test AUROC
0.844 ± 0.006
0.838 ± 0.016

Boosting BBVI (Laplace)
BBVI Edward (Laplace)

Table 3: Matrix factorization results for latent dimension D = 3  5  10 on the CBCL FACE dataset.
We observe that our method outperforms the baseline BBVI method on mean-squared error (MSE).

D=3
D=5
D=10

BBVI MSE
0.0184 ± 0.001
0.0187 ± 0.001
0.0188 ± 0.001

Boosting BBVI MSE
0.0139 ± 0.44e-04
0.0137 ± 0.53e-04
0.0135 ± 0.52e-04

BBVI Test LL
-0.9363 ± 0.6e-3
-0.9391 ± 0.6e-3
-0.9468 ± 0.3e-3

5.2 Bayesian logistic regression on two real-world datasets

Boosting BBVI Test LL

-0.9354 ± 0.3e-3
-0.9393 ± .4e-3
-0.9492 ± .001

In this experiment  we consider two real-world binary-classiﬁcation tasks: predicting the reactivity
of a chemical and predicting mortality in the intensive case unit (ICU). For both tasks we use the
Bayesian logistic regression model. This allows us to compare to previous work in [13]. Bayesian
logistic regression is a conditional prediction model with prior p(w) = N (0  1) on the weights and
conditional likelihood p(y|X) = Bernoulli(p = sigmoid(X>w)). This model is commonly used
as an example of a simple model which does not have a closed form posterior. [1]
We use the CHEMREACT dataset which contains 26 733 chemicals  each with 100 features. For this
experiment  we ran our algorithm for 35 iterations and found that iteration 17 had the best performance.
We observe that running merely one single well-tuned iteration of BBVI as implemented in the Edward
framework using Gaussian as the variational class outperforms 10 iterations of boosting VI in [13].
While BBVI already has good performance in terms of AUROC  we are able to improve it further by
using the ﬁxed step size variant of FW and the Laplace distributions as the base family. In addition 
our solution is more stable  namely it has lower standard deviation across replications. Results are
summarized in Table 1.
For the mortality prediction task  we used a preprocessed dataset created by the authors of [3] from the
EICU COLLABORATIVE RESEARCH database [4]. The preprocessing included selecting patient stays
between 1 and 30 days  removing patients with missing values  and selecting a subset of clinically
relevant features. The ﬁnal dataset contains 71 366 patient stays and 70 relevant features ranging
from age and gender to lab test results. We performed a 70-30% train-test split. We ran our algorithm
for 29 iterations and again found that iteration 17 had the best performance. We observed that our
method improves upon the AUROC of Edward’s baseline VI solution and is also more stable. Results
are summarized in Table 2.

5.3 Bayesian matrix factorization
Bayesian Matrix Factorization [17] is a more complex model deﬁned in terms of two latent variables 
U and V for some choice of the latent dimension D. In the base distribution  each entry of the
matrices U and V are independent Gaussians. To sample from Rt  we sample U  V from the

8

i ↵isi(U  V) and si(U  V) is the t-th iterate returned by the LMO.

boosted posterior (U  V)t and then sample from N (U>V  I). Thus  Rt ⇠ N (Ut>Vt  I) where
(U  V)t ⇠Pt

We use the CBCL FACE1 dataset which is composed of 2 492 images of 361 pixels each  arranged
into a matrix. Using a 50% mask for the train-test split  we performed matrix completion on this
data using the above model. We compared our boosting BBVI to BBVI for three choices of the
latent dimension D = 3  5  10 and observe improvements across all three in mean-squared error. For
held-out test log-likelihood  we observe an improved performance for D = 3. Similar to the results
for Bayesian linear regression  we observe that the variance across replications is also smaller for our
method. Surprisingly  increasing D does not have a signiﬁcant effect on either of the metrics which
may indicate that a relatively inexpressive model (D = 3) already contains a good approximation.
Results are summarized in Table 3.
6 Conclusion

We have presented a reﬁned yet practical theoretical analysis for the boosting variational inference
paradigm. Our approach incorporates black box VI solvers into a general gradient boosting framework
based on the Frank-Wolfe algorithm. Furthermore  we introduced a subroutine which is ﬁnally
attractive to practitioners as it does not require any additional overhead beyond running a general
black box VI solver multiple times. This is an important step forward in adding boosting VI to the
standard toolbox of Bayesian inference.

Acknowledgements. FL is partially supported by the Max-Planck ETH Center for Learning Systems.
FL  GD are partially supported by an ETH core grant (to GR). RK is supported by NSF Grant IIS
1421729. We thank Matthias Hüser for providing the preprocessed eICU dataset. We also thank
David Blei and Anant Raj for helpful discussions.

1http://cbcl.mit.edu/software-datasets/FaceData2.html

9

References
[1] David M Blei  Alp Kucukelbir  and Jon D McAuliffe. Variational inference: A review for

statisticians. arXiv preprint arXiv:1601.00670  2016.

[2] M Bishop Christopher. Pattern Recognition and Machine Learning. Springer-Verlag New York 

2016.

[3] Vincent Fortuin  Matthias Hüser  Francesco Locatello  Heiko Strathmann  and Gunnar Rätsch.
Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series. arXiv
preprint arXiv:1806.02199  2018.

[4] Ary L. Goldberger  Luis A. N. Amaral  Leon Glass  Jeffrey M. Hausdorff  Plamen Ch. Ivanov 
Roger G. Mark  Joseph E. Mietus  George B. Moody  Chung-Kang Peng  and H. Eugene Stanley.
Physiobank  physiotoolkit  and physionet. Circulation  101(23):e215–e220  2000.

[5] Fangjian Guo  Xiangyu Wang  Kai Fan  Tamara Broderick  and David B Dunson. Boosting

variational inference. arXiv preprint arXiv:1611.05559  2016.

[6] Tommi S. Jaakkola and Michael I. Jordan. Improving the mean ﬁeld approximation via the use

of mixture distributions  1998.

[7] Martin Jaggi. Convex Optimization without Projection Steps. arXiv math.OC  August 2011.
[8] Martin Jaggi. Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization. In ICML

2013 - Proceedings of the 30th International Conference on Machine Learning  2013.

[9] Ghassen Jerfel. Boosted stochastic backpropagation for variational inference  2017.
[10] Rahul G. Krishnan  Simon Lacoste-Julien  and David Sontag. Barrier frank-wolfe for marginal

inference. pages 532–540  2015.

[11] Simon Lacoste-Julien. Convergence rate of frank-wolfe for non-convex objectives. arXiv

preprint arXiv:1607.00345  2016.

[12] Simon Lacoste-Julien and Martin Jaggi. On the Global Linear Convergence of Frank-Wolfe

Optimization Variants. In NIPS 2015  pages 496–504  2015.

[13] Francesco Locatello  Rajiv Khanna  Joydeep Ghosh  and Gunnar Rätsch. Boosting variational
inference: an optimization perspective. In Proceedings of the 21st International Conference
on Artiﬁcial Intelligence and Statistics (AISTATS 2018)  volume 84 of Proceedings of Machine
Learning Research  pages 464–472. PMLR  2018.

[14] Francesco Locatello  Rajiv Khanna  Michael Tschannen  and Martin Jaggi. A uniﬁed optimiza-
tion view on generalized matching pursuit and frank-wolfe. In Proc. International Conference
on Artiﬁcial Intelligence and Statistics (AISTATS)  2017.

[15] Ron Meir and Gunnar Rätsch. An introduction to boosting and leveraging. In Advanced lectures

on machine learning  pages 118–183. Springer  2003.

[16] Andrew C Miller  Nicholas Foti  and Ryan P Adams. Variational boosting: Iteratively reﬁning

posterior approximations. arXiv preprint arXiv:1611.06585  2016.

[17] Andriy Mnih and Ruslan R Salakhutdinov. Probabilistic matrix factorization. In Advances in

neural information processing systems  pages 1257–1264  2008.

[18] Emanuel Parzen. On estimation of a probability density function and mode. The Annals of

Mathematical Statistics  33:pp. 1065–1076  1962.

[19] Rajesh Ranganath  Sean Gerrish  and David M Blei. Black box variational inference.

AISTATS  pages 814–822  2014.

In

[20] Danilo Jimenez Rezende and Shakir Mohamed. Variational inference with normalizing ﬂows.
In Francis R. Bach and David M. Blei  editors  ICML  volume 37 of JMLR Workshop and
Conference Proceedings  pages 1530–1538. JMLR.org  2015.

10

[21] Ardavan Saeedi  Tejas D. Kulkarni  Vikash K. Mansinghka  and Samuel J. Gershman. Variational

particle approximations. Journal of Machine Learning Research  18(69):1–29  2017.

[22] Tim Salimans  Diederik P. Kingma  and Max Welling. Markov chain monte carlo and variational

inference: Bridging the gap. In ICML  2015.

[23] Siddhartha Saxena  Shibhansh Dohare  and Jaivardhan Kapoor. Variational inference via

transformations on distributions. CoRR  abs/1707.02510  2017.

[24] Ilya Tolstikhin  Sylvain Gelly  Olivier Bousquet  Carl-Johann Simon-Gabriel  and Bernhard

Schölkopf. Adagan: Boosting generative models. arXiv preprint arXiv:1701.02386  2017.

[25] Dustin Tran  Alp Kucukelbir  Adji B. Dieng  Maja Rudolph  Dawen Liang  and David M.
Blei. Edward: A library for probabilistic modeling  inference  and criticism. arXiv preprint
arXiv:1610.09787  2016.

11

,Zhaoran Wang
Huanran Lu
Han Liu
Roland Kwitt
Stefan Huber
Marc Niethammer
Weili Lin
Ulrich Bauer
Behnam Neyshabur
Yuhuai Wu
Russ Salakhutdinov
Nati Srebro
Francesco Locatello
Gideon Dresdner
Rajiv Khanna
Isabel Valera
Gunnar Raetsch
Zhiqing Sun
Zhuohan Li
Haoqing Wang
Di He
Zi Lin
Zhihong Deng