2019,Combining Generative and Discriminative Models for Hybrid Inference,A graphical model is a structured representation of the data generating process. The traditional method to reason over random variables is to perform inference in this graphical model. However  in many cases the generating process is only a poor approximation of the much more complex true data generating process  leading to suboptimal estimation. The subtleties of the generative process are however captured in the data itself and we can ``learn to infer''  that is  learn a direct mapping from observations to explanatory latent variables. In this work we propose a hybrid model that combines graphical inference with a learned inverse model  which we structure as in a graph neural network  while the iterative algorithm as a whole is formulated as a recurrent neural network. By using cross-validation we can automatically balance the amount of work performed by graphical inference versus learned inference. We apply our ideas to the Kalman filter  a Gaussian hidden Markov model for time sequences  and show  among other things  that our model can estimate the trajectory of a noisy chaotic Lorenz Attractor much more accurately than either the learned or graphical inference run in isolation.,Combining Generative and Discriminative Models for

Hybrid Inference

Victor Garcia Satorras
UvA-Bosch Delta Lab
University of Amsterdam

Netherlands

v.garciasatorras@uva.nl

zeynep.akata@uni-tuebingen.de

Zeynep Akata ⇤

Cluster of Excellence ML
University of Tübingen

Germany

Max Welling

UvA-Bosch Delta Lab
University of Amsterdam

Netherlands

m.welling@uva.nl

Abstract

A graphical model is a structured representation of the data generating process.
The traditional method to reason over random variables is to perform inference
in this graphical model. However  in many cases the generating process is only
a poor approximation of the much more complex true data generating process 
leading to suboptimal estimations. The subtleties of the generative process are
however captured in the data itself and we can “learn to infer”  that is  learn a direct
mapping from observations to explanatory latent variables. In this work we propose
a hybrid model that combines graphical inference with a learned inverse model 
which we structure as in a graph neural network  while the iterative algorithm as a
whole is formulated as a recurrent neural network. By using cross-validation we
can automatically balance the amount of work performed by graphical inference
versus learned inference. We apply our ideas to the Kalman ﬁlter  a Gaussian
hidden Markov model for time sequences  and show  among other things  that our
model can estimate the trajectory of a noisy chaotic Lorenz Attractor much more
accurately than either the learned or graphical inference run in isolation.

1

Introduction

Before deep learning  one of the dominant paradigms in machine learning was graphical models
[4  27  21]. Graphical models structure the space of (random) variables by organizing them into a
dependency graph. For instance  some variables are parents/children (directed models) or neighbors
(undirected models) of other variables. These dependencies are encoded by conditional probabilities
(directed models) or potentials (undirected models). While these interactions can have learnable
parameters  the structure of the graph imposes a strong inductive bias onto the model. Reasoning
in graphical models is performed by a process called probabilistic inference where the posterior
distribution  or the most probable state of a set of variables  is computed given observations of other
variables. Many approximate algorithms have been proposed to solve this problem efﬁciently  among
which are MCMC sampling [29  33]  variational inference [18] and belief propagation algorithms
[10  21].
Graphical models are a kind of generative model where we specify important aspects of the generative
process. They excel in the low data regime because we maximally utilize expert knowledge (a.k.a.
inductive bias). However  human imagination often falls short of modeling all of the intricate details
of the true underlying generative process. In the large data regime there is an alternative strategy
which we could call “learning to infer”. Here  we create lots of data pairs {xn  yn} with {yn} the
observed variables and {xn} the latent unobserved random variables. These can be generated from
the generative model or are available directly in the dataset. Our task is now to learn a ﬂexible

⇤Majority of this work has been done when Zeynep Akata was at the University of Amsterdam.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: Examples of inferred 5K length trajectories for the Lorenz attractor with t = 0.01 trained
on 50K length trajectory. The mean squared errors from left to right are (Observations: 0.2462  GNN:
0.0613  E-Kalman Smoother: 0.0372  Hybrid: 0.0169).

mapping q(x|y) to infer the latent variables directly from the observations. This idea is known
as “inverse modeling” in some communities. It is also known as “amortized” inference [32] or
recognition networks in the world of variational autoencoders [18] and Helmholtz machines [11].
In this paper we consider inference as an iterative message passing scheme over the edges of the
graphical model. We know that (approximate) inference in graphical models can be formulated
as message passing  known as belief propagation  so this is a reasonable way to structure our
computations. When we unroll these messages for N steps we have effectively created a recurrent
neural network as our computation graph. We will enrich the traditional messages with a learnable
component that has the function to correct the original messages when there is enough data available.
In this way we create a hybrid message passing scheme with prior components from the graphical
model and learned messages from data. The learned messages may be interpreted as a kind of graph
convolutional neural network [5  15  20].
Our Hybrid model neatly trades off the beneﬁt of using inductive bias in the small data regime and
the beneﬁt of a much more ﬂexible and learnable inference network when sufﬁcient data is available.
In this paper we restrict ourselves to a sequential model known as a hidden Markov process.

2 The Hidden Markov Process

In this section we brieﬂy explain the Hidden Markov Process and how we intend to extend it. In a
Hidden Markov Model (HMM)  a set of unobserved variables x = {x1  . . .   xK} deﬁne the state of
a process at every time step 0 < k < K. The set of observable variables from which we want to
infer the process states are denoted by y = {y1  . . . yK}. HMMs are used in diverse applications
as localization  tracking  weather forecasting and computational ﬁnance among others. (in fact  the
Kalman ﬁlter was used to land the eagle on the moon.)
We can express p(x|y) as the probability distribution of the hidden states given the observations. Our
goal is to ﬁnd which states x maximize this probability distribution. More formally:
(1)

ˆx = arg max

p(x|y)

x

Under the Markov assumption i) the transition model is described by the transition probability
p(xt|xt1)  and ii) the measurement model is described by p(yt|xt). Both distributions are stationary
for all k. The resulting graphical model can be expressed with the following equation:

p(x  y) = p(x0)

p(xk|xk1)p(yk|xk)

(2)

KYk=1

One of the best known approaches for inference problems in this graphical model is the Kalman
Filter [17] and Smoother [31]. The Kalman Filter assumes both the transition and measurement
distributions are linear and Gaussian. The prior knowledge we have about the process is encoded in
linear transition and measurement processes  and the uncertainty of the predictions with respect to
the real system is modeled by Gaussian noise:

(3)
(4)
Here qk  rk come from Gaussian distributions qk ⇠N (0  Q)  rk ⇠N (0  R). F  H are the linear
transition and measurement functions respectively. If the process from which we are inferring x is

xk = Fxk1 + qk
yk = Hxk + rk

2

actually Gaussian and linear  a Kalman Filter + Smoother with the right parameters is able to infer
the optimal state estimates.
The real world is usually non-linear and complex  assuming that a process is linear may be a strong
limitation. Some alternatives like the Extended Kalman Filter [24] and the Unscented Kalman
Filter [34] are used for non-linear estimation  but even when functions are non-linear  they are still
constrained to our knowledge about the dynamics of the process which may differ from real world
behavior.
To model the complexities of the real world we intend to learn them from data through ﬂexible models
such as neural networks. In this work we present an hybrid inference algorithm that combines the
knowledge from a generative model (e.g. physics equations) with a function that is automatically
learned from data using a neural network. In our experiments we show that this hybrid method
outperforms the graphical inference methods and also the neural network methods for low and high
data regimes respectively. In other words  our method beneﬁts from the inductive bias in the limit of
small data and also the high capacity of a neural networks in the limit of large data. The model is
shown to gracefully interpolate between these regimes.

3 Related Work

The proposed method has interesting relations with meta learning [2] since it learns more ﬂexible
messages on top of an existing algorithm. It is also related to structured prediction energy networks
[3] which are discriminative models that exploit the structure of the output. Structured inference in
relational outputs has been effective in a variety of tasks like pose estimation [35]  activity recognition
[12] or image classiﬁcation [28]. One of the closest works is Recurrent Inference Machines (RIM)
[30] where a generative model is also embedded into a Recurrent Neural Network (RNN). However
in that work graphical models played no role. In the same line of learned recurrent inference  our
optimization procedure shares similarities with Iterative Amortized Inference [25]  although in our
work we are reﬁning the gradient using a hybrid setting while they are learning it.
Another related line of research is the convergence of graphical models with neural networks  [26]
replaced the joint probabilities with trainable factors for time series data. Learning the messages
in conditional random ﬁelds has been effective in segmentation tasks [7  37]. Relatedly  [16] runs
message passing algorithms on top of a latent representation learned by a deep neural network. More
recently [36] showed the efﬁcacy of using Graph Neural Networks (GNNs) for inference on a variety
of graphical models  and compared the performance with classical inference algorithms. This last
work is in a similar vein as ours  but in our case  learned messages are used to correct the messages
from graphical inference. In the experiments we will show that this hybrid approach really improves
over running GNNs in isolation.
The Kalman Filter is a widely used algorithm for inference in Hidden Markov Processes. Some
works have explored the direction of coupling them with machine learning techniques. A method
to discriminatively learn the noise parameters of a Kalman Filter was introduced by [1]. In order to
input more complex variables  [14] back-propagates through the Kalman Filter such that an encoder
can be trained at its input. Similarly  [9] replaces the dynamics deﬁned in the Kalman Filter with
a neural network. In our hybrid model  instead of replacing the already considered dynamics  we
simultaneously train a learnable function for the purpose of inference.

4 Model

We cast our inference model as a message passing scheme where the nodes of a probabilistic graphical
model can send messages to each other to infer estimates of the states x. Our aim is to develop a
hybrid scheme where messages derived from the generative graphical model are combined with GNN
messages:
Graphical Model Messages (GM-messages): These messages are derived from the generative
graphical model (e.g. equations of motion from a physics model).
Graph Neural Network Messages (GNN-messages): These messages are learned by a GNN which
is trained to reduce the inference error on labelled data in combination with the GM-messages.

3

Figure 2: Graphical illustration of our Hybrid algorithm. The GM-module (blue box) sends messages
to the GNN-module (red box) which reﬁnes the estimation of x.

In the following two subsections we introduce the two types of messages and the ﬁnal hybrid inference
scheme.

4.1 Graphical Model Messages

In order to deﬁne the GM-messages  we interpret inference as an iterative optimization process to
estimate the maximum likelihood values of the states x. In its more generic form  the recursive update
for each consecutive estimate of x is given by:

x(i+1) = x(i) + rx(i)log(p(x(i)  y))

Factorizing equation 5 to the hidden Markov Process from equation 2  we get three input messages
for each inferred node xk:

x(i+1)
k
M(i)

k

k + M(i)
= x(i)
xk1!xk + µ(i)
k = µ(i)
@
log(p(x(i)

µ(i)
xk1!xk =

µ(i)
xk+1!xk =

µ(i)
yk!xk =

@x(i)
k
@

@x(i)
k
@

@x(i)
k

yk!xk

xk+1!xk + µ(i)
k |x(i)
k1))
k+1|x(i)
k ))

log(p(x(i)

log(p(yk|x(i)
k ))

(5)

(6)

(7)

(8)

(9)

These messages can be obtained by computing the three derivatives from equations 7  8  9. It is
often assumed that the transition and measurement distributions p(xk|xk1)  p(yk|xk) are linear and
Gaussian (e.g. Kalman Filter model). Next  we provide the expressions of the GM-messages when
assuming the linear and Gaussian functions from equations 3  4:

µxk1!xk = Q1(xk  Fxk1)
µxk+1!xk = FT Q1(xk+1  Fxk)
µyk!xk = HT R1(yk  Hxk)

(10)
(11)
(12)

4.2 Adding GNN-messages
We call v the collection of nodes of the graphical model v = x[ y. We also deﬁne an equivalent
graph where the GNN operates by propagating the GNN messages. We build the following mappings
from the nodes of the graphical model to the nodes of the GNN: hx = {(x) : x 2 x}  hy = {(y) :
y 2 y}. Analogously  the union of both collections would be hv = hx [ hy. Therefore  each node
of the graphical model has a corresponding node h in the GNN. The edges for both graphs are also
equivalent. Values of h(0)
x that correspond to unobserved variables x are randomly initialized. Instead 
values h(0)

y are obtained by forwarding yk through a linear layer.

4

Next we present the equations of the learned messages  which consist of a GNN message passing
operation. Similarly to [23  19]  a GRU [8] is added to the message passing operation to make it
recursive:
m(i)
k n = zk nfe(h(i)
m(i)
U(i)
k n

(message from GNN nodes to edge factor)
(message from edge factors to GNN node)

vn   µvn!xk )

(13)
(14)

xk   h(i)

k = Xvn6=xk

)

xk

k   h(i)
xk )

xk = GRU(U(i)
h(i+1)
✏(i+1)
= fdec(h(i+1)
k

(RNN update)
(computation of correction factor)

(15)
(16)
Each GNN message is computed by the function fe(·)  which receives as input two hidden states
from the last recurrent iteration  and their corresponding GM-message  this function is different for
each type of edge (e.g. transition or measurement for the HMM). zk n takes value 1 if there is an edge
between vn and xk  otherwise its value is 0. The sum of messages U(i)
k is provided as input to the
GRU function that updates each hidden state h(i)
xk for each node. The GRU is composed by a single
GRU cell preceded by a linear layer at its input. Finally a correction signal ✏(i+1)
is decoded from
each hidden state h(i+1)
and it is added to the recursive operation 6  resulting in the ﬁnal equation:

k

xk

k

)

= x(i)

x(i+1)
k

k + ✏(i+1)

k + (M(i)

(17)
In summary  equation 17 deﬁnes our hybrid model in a simple recursive form where xk is updated
through two contributions: one that relies on the probabilistic graphical model messages M(i)
k   and
✏(i)
k   that is automatically learned. We note that it is important that the GNN messages model the
"residual error" of the GM inference process  which is often simpler than modeling the full signal. A
visual representation of the algorithm is shown in Figure 2.
In the experimental section of this work we apply our model to the Hidden Markov Process  however 
the above mentioned GNN-messages are not constrained to this particular graphical structure. The
GM-messages can also be obtained for other arbitrary graph structures by applying the recursive
inference equation 5 to their respective graphical models.

4.3 Training procedure
In order to provide early feedback  the loss function is computed at every iteration with a weighted
sum that emphasizes later iterations  wi = i

N   more formally:

Loss(⇥) =

wiL(gt  (x(i)))

(18)

NXi=1

Where function (·) extracts the part of the hidden state x contained in the ground truth gt. In our
experiments we use the mean square error for L(·). The training procedure consists of three main
steps. First  we initialize x(0)
at the value that maximizes p(yk|xk). For example  in a trajectory
k
estimation problem we set the position values of xk as the observed positions yk. Second  we tune
the hyper-parameters of the graphical model as it would be done with a Kalman Filter  which are
usually the variance of Gaussian distributions. Finally  we train the model using the above mentioned
loss (equation 18).

5 Experiments

In this section we compare our Hybrid model with the Kalman Smoother and a recurrent GNN. We
show that our Hybrid model can leverage the beneﬁts of both methods for different data regimes.
Next we deﬁne the models used in the experiments 2:
Kalman Smoother: The Kalman Smoother is the widely known Kalman Filter algorithm [17] +
the RTS smoothing step [31]. In experiments where the transition function is non-linear we use the

2Available at: https://github.com/vgsatorras/hybrid-inference

5

k = H>yk + fdec(h(i)

Extended Kalman Filter + smoothing step which we will call “E-Kalman Smoother”.
GM-messages: As a special case of our hybrid model we propose to remove the learned signal ✏(i)
k
and base our predictions only on the graphical model messages from eq. 6.
GNN-messages: The GNN model is another special case of our model when all the GM-messages
are removed and only GNN messages are propagated. Instead of decoding a reﬁnement for the current
x(i)
k estimate  we directly estimate: x(i)
xk ). The resulting algorithm is equivalent
to a Gated Graph Neural Network [23].
Hybrid model: This is our full model explained in section 4.2.
We set  = 0.005 and use the Adam optimizer with a learning rate 103. The number of inference
iterations used in the Hybrid model  GNN-messages and GM-messages is N=50. fe and fdec are a
2-layers MLPs with Leaky Relu and Relu activations respectively. The number of features in the
hidden layers of the GRU  fe and fdec is nf=48. In trajectory estimation experiments  yk values may
take any value from the real numbers R. Shifting a trajectory to a non-previously seen position may
hurt the generalization performance of the neural network. To make the problem translation invariant
we modify yk before mapping it to hyk  we use the difference between the observed current position
with the previous one and with the next one.

5.1 Linear dynamics

The aim of this experiment is to infer the position of every node in trajectories generated by linear
and gaussian equations. The advantage of using a synthetic environment is that we know in advance
the original equations the motion pattern was generated from  and by providing the right linear and
gaussian equations to a Kalman Smoother we can obtain the optimal inferred estimate as a lower
bound of the test loss.
Among other tasks  Kalman Filters are used to reﬁne the noisy measurement of GPS systems. A
physics model of the dynamics can be provided to the graphical model that  combined with the noisy
measurements  gives a more accurate estimation of the position. The real world is usually more
complex than the equations we may provide to our graphical model  leading to a gap between the
assumed dynamics and the real world dynamics. Our hybrid model is able to ﬁll this gap without the
need to learn everything from scratch.
To show that  we generate synthetic trajectories T = {x  y}. Each state xk 2 R6 is a 6-dimensional
vector that encodes position  velocity and acceleration (p  v  a) for two dimensions. Each yk 2 R2 is a
noisy measurement of the position also for two dimensions. The transition dynamic is a non-uniform
accelerated motion that also considers drag (air resistance):

@p
@t

= v 

@v
@t

@a
@t

= ⌧v

= a  cv 

(19)
Where cv represents the air resistance [13]  with c being a constant that depends on the properties
of the ﬂuid and the object dimensions. Finally  the variable ⌧v is used to non-uniformly accelerate
the object.
To generate the dataset  we sample from the Markov
process of equation 2 where the transition proba-
bility distribution p(xk+1|xk) and the measurement
probability distribution p(yk|xk) follow equations
(3  4). Values F  Q  H  R for these distributions are
described in the Appendix  in particular  F is analyti-
cally obtained from the above mentioned differential
equations 19. We sample two different motion tra-
jectories from 50 to 100K time steps each  one for
validation and the other for training. An additional
10K time steps trajectory is sampled for testing. The
sampling time step is t = 1.
Alternatively  the graphical model of the algorithm
is limited to a uniform motion pattern p = p0 + vt.
Its equivalent differential equations form would be
@p
@t = v. Notice that the air friction is not considered

Figure 3: MSE comparison with respect to
the number of training samples for the linear
dynamics dataset.

6

anymore and velocity and acceleration are assumed to be uniform. Again the parameters for the
matrices F  Q  H  R when considering a uniform motion pattern are analytically obtained and
described in the Appendix.

Results. The Mean Square Error with respect to the number of training samples is shown for
different algorithms in Figure 3. The plot shows the average and the standard deviation over 7 runs 
the sampled test trajectory remains the same over all runs  this is not the case for the training and
validation sampled trajectories. Note that the MSE of the Kalman Smoother and GM-messages
overlap in the plot since both errors were exactly the same.
Our model outperforms both the GNN or Kalman Smoother in isolation in all data regimes  and it has
a signiﬁcant edge over the Kalman Smoother when the number of samples is larger than 1K. This
shows that our model is able to ensemble the advantages of prior knowledge and deep learning in a
single framework. These results show that our hybrid model beneﬁts from the inductive bias of the
graphical model equations when data is scarce  and simultaneously it beneﬁts from the ﬂexibility of
the GNN when data is abound.
A clear trade-off can be observed between the Kalman smoother and the GNN. The Kalman Smoother
clearly performs better for low data regimes  while the GNN outperforms it for larger amounts of
data (>10K). The hybrid model is able to beneﬁt from the strengths of both.

5.2 Lorenz Attractor
The Lorenz equations describe a non-linear chaotic system used for atmospheric convection. Learning
the dynamics of this chaotic system in a supervised way is expected to be more challenging than
for linear dynamics  making it an interesting evaluation of our Hybrid model. A Lorenz system is
modelled by three differential equations that deﬁne the convection rate  the horizontal temperature
variation and the vertical temperature variation of a ﬂuid:

@z1
@t

= 10(z2  z1) 

@z2
@t

= z1(28  z3)  z2 

@z3
@t

= z1z2 

8
3

z3

(20)

To generate a trajectory we run the Lorenz equations 20 with a dt = 105 from which we sample
with a time step of t = 0.05 resulting in a single trajectory of 104K time steps. Each point is then
perturbed with gaussian noise of standard deviation  = 0.5. From this trajectory  4K time steps are
separated for testing  the remaining trajectory of 100K time steps is equally split between training
and validation partitions.
Assuming x 2 R3 is a 3-dimensional vector x = [z1  z2  z3]>  we can write down the dynamics
matrix of the system as A|x from the Lorenz differential eq. 20  and obtain the transition function
F|xk [22] using the Taylor Expansion.

35"z1
z3#   F|xk = I +

z2

(A|xk t)j

j!

JXj=1

(21)

˙x = A|xx =24

10
10
28  z3 1
z2

0
0
0  8

3

where I is the identity matrix and J is the number of
terms from the Taylor expansion. We run simulations
for J=1  J=2 and J=5. For larger J the improvement
was minimal. For the measurement model H = I we
use the identity matrix. For the noise distributions
Q = 2tI and R = 0.52I we use diagonal ma-
trices. The only hyper-parameter to tune from the
graphical model is .
Since the dynamics are non-linear  the matrix F|xk
depends on the values xk. The presence of these
variables inside the matrix introduces a simple non-
linearity that makes the function much harder to learn.

Results. The results in Figure 4 show that the GNN
struggles to achieve low accuracies for this chaotic

Figure 4: MSE with respect to the the number
of training samples on the Lorenz Attractor.

7

system  i.e. it does not converge together with the hybrid model even when the training dataset
contains up to 105 samples and the hybrid loss is already 0.01 ⇠ 0.02. We attribute this difﬁculty to
the fact the matrix F|xk is different at every state xk  becoming harder to approximate.
This behavior is different from the previous experiment (linear dynamics) where both the Hybrid
model and the GNN converged to the optimal solution for high data regimes. In this experiment  even
when the GNN and the E-Kalman Smoother perform poorly  the Hybrid model gets closer to the
optimal solution  outperforming both of them in isolation. This shows that the Hybrid model beneﬁts
from the labeled data even in situations where its fully-supervised variant or the E-Kalman Smoother
are unable to properly model the process. One reason for this could be that the residual dynamics (i.e.
the error of the E-Kalman Smoother) are much more linear than the original dynamics and hence
easier to model by the GNN.
As can be seen in Figure 4  depending on the amount of prior knowledge used in our hybrid model
we will need more or less samples to achieve a particular accuracy. Following  we show in table 5.2
the approximate number of training samples required to achieve accuracies 0.1 and 0.05 depending
on the amount of knowledge we provide (i.e. the number of J terms of the Taylor expansion). The
hybrid method requires ⇠ 10 times less samples than the fully-learned method for MSE=0.1 and
⇠ 20 times less samples for MSE=0.05.

GNN (J=0) Hybrid (J=1) Hybrid (J=2 & J=5)
MSE = 0.1
⇠ 5.000
MSE = 0.05 ⇠ 90.000

⇠ 400
⇠ 4.000

⇠ 500
⇠ 5.000

Table 1: Number of samples required to achieve a particular MSE depending on the amount of prior
knowledge (i.e. J). These numbers have been extracted from Figure 4.

Qualitative results of estimated trajectories by the different algorithms on the Lorenz attractor are
depicted in Figure 1. The plots correspond to a 5K length test trajectory (with t = 0.01). All
trainable algorithms have been trained on 5K length trajectories.

5.3 Real World Dynamics: Michigan NCLT dataset

To demonstrate the generalizability of our Hybrid model to real world datasets  we use the
Michigan NCLT [6] dataset which is collected by a segway robot moving around the Uni-
versity of Michigan’s North Campus.
It comprises different trajectories where the GPS mea-
surements and the ground truth location of the robot are provided. Given these noisy GPS
observations  our goal is to infer a more accurate position of the segway at a given time.

ALGORITHM
OBSERVATIONS (BASELINE)
KALMAN SMOOTHER
GM-MESSAGES
GNN-MESSAGES
HYBRID MODEL

In our experiments we arbitrarily use the session
with date 2012-01-22 which consists of a single
trajectory of 6.1 Km on a cloudy day. Sampling
at 1Hz results in 4.629 time steps and after re-
moving the parts with a unstable GPS signal 
4.344 time steps remain. Finally  we split the
trajectory into three sections: 1.502 time steps
for training  1.469 for validation and 1.373 for
testing. The GPS measurements are assumed to
be the noisy measurements denoted by y.
For the transition and measurement graphical model distributions we assume the same uniform
motion model used in section 5.1  speciﬁcally the dynamics of a uniform motion pattern. The only
parameters to learn from the graphical model will be the variance from the measurement and transition
distributions. The detailed equations are presented in the Appendix.

Table 2: MSE for different methods on the Michi-
gan NCLT datset.

MSE
3.4974
3.0099
3.0048
1.7929
1.4109

Results. Our results show that our Hybrid model (1.4109 MSE) outperforms the GNN (1.7929
MSE)  the Kalman Smoother (3.0099 MSE) and the GM-messages (3.0048 MSE). One of the
advantages of the GNN and the Hybrid methods on real world datasets is that both can model the
correlations through time from the noise distributions while the GM-messages and the Kalman
Smoother assume the noise to be uncorrelated through time as it is deﬁned in the graphical model. In

8

summary  this experiment shows that our hybrid model can generalize with good performance to a
real world dataset.

6 Discussion

In this work  we explored the combination of recent advances in neural networks (e.g. graph neural
networks) with more traditional methods of graphical inference in hidden Markov models for time
series. The result is a hybrid algorithm that beneﬁts from the inductive bias of graphical models and
from the high ﬂexibility of neural networks. We demonstrated these beneﬁts in three different tasks
for trajectory estimation  a linear dynamics dataset  a non-linear chaotic system (Lorenz attractor)
and a real world positioning system. In three experiments  the Hybrid method learns to efﬁciently
combine graphical inference with learned inference  outperforming both when run in isolation.
Possible future directions include applying our idea to other generative models. The equations that
describe our hybrid model are deﬁned on edges and nodes  therefore  by modifying the input graph 
i.e. by modifying the edges and nodes of the input graph  we can run our algorithm on arbitrary graph
structures. Other future directions include exploring hybrid methods for performing probabilistic
inference in other graphical models (e.g. discrete variables)  as well learning the graphical model
itself. In this work we used cross-validation to make sure we did not overﬁt the GNN part of the
model to the data at hand  optimally balancing prior knowledge and data-driven inference. In the
future we intend to explore a more principled Bayesian approach to this. Finally  hybrid models like
the one presented on this paper can help improve the interpretability of model predictions due to their
graphical model backbone.

References
[1] P. Abbeel  A. Coates  M. Montemerlo  A. Y. Ng  and S. Thrun. Discriminative training of

kalman ﬁlters. In Robotics: Science and systems  volume 2  page 1  2005.

[2] M. Andrychowicz  M. Denil  S. Gomez  M. W. Hoffman  D. Pfau  T. Schaul  B. Shillingford 
and N. De Freitas. Learning to learn by gradient descent by gradient descent. In Advances in
Neural Information Processing Systems  pages 3981–3989  2016.

[3] D. Belanger  B. Yang  and A. McCallum. End-to-end learning for structured prediction energy
networks. In Proceedings of the 34th International Conference on Machine Learning-Volume
70  pages 429–439. JMLR. org  2017.

[4] C. M. Bishop. Pattern recognition and machine learning. springer  2006.

[5] J. Bruna  W. Zaremba  A. Szlam  and Y. LeCun. Spectral networks and locally connected

networks on graphs. arXiv preprint arXiv:1312.6203  2013.

[6] N. Carlevaris-Bianco  A. K. Ushani  and R. M. Eustice. University of michigan north campus
long-term vision and lidar dataset. The International Journal of Robotics Research  35(9):1023–
1035  2016.

[7] L.-C. Chen  G. Papandreou  I. Kokkinos  K. Murphy  and A. L. Yuille. Semantic image segmen-
tation with deep convolutional nets and fully connected crfs. arXiv preprint arXiv:1412.7062 
2014.

[8] J. Chung  C. Gulcehre  K. Cho  and Y. Bengio. Empirical evaluation of gated recurrent neural

networks on sequence modeling. arXiv preprint arXiv:1412.3555  2014.

[9] H. Coskun  F. Achilles  R. DiPietro  N. Navab  and F. Tombari. Long short-term memory kalman
ﬁlters: Recurrent neural estimators for pose regularization. arXiv preprint arXiv:1708.01885 
2017.

[10] C. Crick and A. Pfeffer. Loopy belief propagation as a basis for communication in sensor
networks. In Proceedings of the Nineteenth conference on Uncertainty in Artiﬁcial Intelligence 
pages 159–166. Morgan Kaufmann Publishers Inc.  2002.

9

[11] P. Dayan  G. E. Hinton  R. M. Neal  and R. S. Zemel. The helmholtz machine. Neural

computation  7(5):889–904  1995.

[12] Z. Deng  A. Vahdat  H. Hu  and G. Mori. Structure inference machines: Recurrent neural
networks for analyzing relations in group activity recognition. In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recognition  pages 4772–4781  2016.

[13] G. Falkovich. Fluid mechanics: A short course for physicists. Cambridge University Press 

2011.

[14] T. Haarnoja  A. Ajay  S. Levine  and P. Abbeel. Backprop kf: Learning discriminative determin-
istic state estimators. In Advances in Neural Information Processing Systems  pages 4376–4384 
2016.

[15] M. Henaff  J. Bruna  and Y. LeCun. Deep convolutional networks on graph-structured data.

arXiv preprint arXiv:1506.05163  2015.

[16] M. Johnson  D. K. Duvenaud  A. Wiltschko  R. P. Adams  and S. R. Datta. Composing graphical
models with neural networks for structured representations and fast inference. In Advances in
neural information processing systems  pages 2946–2954  2016.

[17] R. E. Kalman. A new approach to linear ﬁltering and prediction problems. Journal of basic

Engineering  82(1):35–45  1960.

[18] D. P. Kingma and M. Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 

2013.

[19] T. Kipf  E. Fetaya  K.-C. Wang  M. Welling  and R. Zemel. Neural relational inference for

interacting systems. arXiv preprint arXiv:1802.04687  2018.

[20] T. N. Kipf and M. Welling. Semi-supervised classiﬁcation with graph convolutional networks.

arXiv preprint arXiv:1609.02907  2016.

[21] D. Koller  N. Friedman  and F. Bach. Probabilistic graphical models: principles and techniques.

MIT press  2009.

[22] R. Labbe. Kalman and bayesian ﬁlters in python  2014.

[23] Y. Li  D. Tarlow  M. Brockschmidt  and R. Zemel. Gated graph sequence neural networks.

arXiv preprint arXiv:1511.05493  2015.

[24] L. Ljung. Asymptotic behavior of the extended kalman ﬁlter as a parameter estimator for linear

systems. IEEE Transactions on Automatic Control  24(1):36–50  1979.

[25] J. Marino  Y. Yue  and S. Mandt. Iterative amortized inference. arXiv preprint arXiv:1807.09356 

2018.

[26] P. Mirowski and Y. LeCun. Dynamic factor graphs for time series modeling. In Joint European
Conference on Machine Learning and Knowledge Discovery in Databases  pages 128–143.
Springer  2009.

[27] K. P. Murphy. A probabilistic perspective. 2012.

[28] N. Nauata  H. Hu  G.-T. Zhou  Z. Deng  Z. Liao  and G. Mori. Structured label inference for

visual understanding. arXiv preprint arXiv:1802.06459  2018.

[29] R. M. Neal et al. Mcmc using hamiltonian dynamics. Handbook of Markov Chain Monte Carlo 

2(11):2  2011.

[30] P. Putzky and M. Welling. Recurrent inference machines for solving inverse problems. arXiv

preprint arXiv:1706.04008  2017.

[31] H. E. Rauch  C. Striebel  and F. Tung. Maximum likelihood estimates of linear dynamic systems.

AIAA journal  3(8):1445–1450  1965.

10

[32] D. J. Rezende and S. Mohamed. Variational inference with normalizing ﬂows. arXiv preprint

arXiv:1505.05770  2015.

[33] T. Salimans  D. Kingma  and M. Welling. Markov chain monte carlo and variational inference:
Bridging the gap. In International Conference on Machine Learning  pages 1218–1226  2015.
[34] E. A. Wan and R. Van Der Merwe. The unscented kalman ﬁlter for nonlinear estimation.
In Adaptive Systems for Signal Processing  Communications  and Control Symposium 2000.
AS-SPCC. The IEEE 2000  pages 153–158. Ieee  2000.

[35] S.-E. Wei  V. Ramakrishna  T. Kanade  and Y. Sheikh. Convolutional pose machines.

In
Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages
4724–4732  2016.

[36] K. Yoon  R. Liao  Y. Xiong  L. Zhang  E. Fetaya  R. Urtasun  R. Zemel  and X. Pitkow. Inference
in probabilistic graphical models by graph neural networks. arXiv preprint arXiv:1803.07710 
2018.

[37] S. Zheng  S. Jayasumana  B. Romera-Paredes  V. Vineet  Z. Su  D. Du  C. Huang  and P. H.
Torr. Conditional random ﬁelds as recurrent neural networks. In Proceedings of the IEEE
international conference on computer vision  pages 1529–1537  2015.

11

,Victor Garcia Satorras
Zeynep Akata
Max Welling