2017,Multiplicative Weights Update with Constant Step-Size in Congestion Games:  Convergence  Limit Cycles and Chaos,The Multiplicative Weights Update (MWU) method is a ubiquitous meta-algorithm that works as follows: A distribution is maintained on a certain set  and at each step the probability assigned to action $\gamma$ is multiplied by $(1 -\epsilon C(\gamma))>0$ where $C(\gamma)$ is the ``cost" of action $\gamma$ and then rescaled to ensure that the new values form a distribution.  We analyze MWU in congestion games where agents use \textit{arbitrary admissible constants} as learning rates $\epsilon$ and prove convergence to \textit{exact Nash equilibria}. Interestingly  this convergence result does not carry over to the nearly homologous MWU variant where at each step the probability assigned to action $\gamma$ is multiplied by $(1 -\epsilon)^{C(\gamma)}$ even for the simplest case of two-agent  two-strategy load balancing games  where such dynamics can provably lead to limit cycles or even chaotic behavior.,Multiplicative Weights Update with Constant

Step-Size in Congestion Games: Convergence  Limit

Cycles and Chaos

Gerasimos Palaiopanos∗

SUTD

Singapore

gerasimosath@yahoo.com

Ioannis Panageas†

MIT

Cambridge  MA 02139

ioannis@csail.mit.edu

Georgios Piliouras‡

SUTD

Singapore

georgios@sutd.edu.sg

Abstract

The Multiplicative Weights Update (MWU) method is a ubiquitous meta-algorithm
that works as follows: A distribution is maintained on a certain set  and at each
step the probability assigned to action γ is multiplied by (1 − C(γ)) > 0 where
C(γ) is the “cost" of action γ and then rescaled to ensure that the new values form
a distribution. We analyze MWU in congestion games where agents use arbitrary
admissible constants as learning rates  and prove convergence to exact Nash
equilibria. Interestingly  this convergence result does not carry over to the nearly
homologous MWU variant where at each step the probability assigned to action γ
is multiplied by (1 − )C(γ) even for the simplest case of two-agent  two-strategy
load balancing games  where such dynamics can provably lead to limit cycles or
even chaotic behavior.

1

Introduction

The Multiplicative Weights Update (MWU) is a ubiquitous meta-algorithm with numerous appli-
cations in different ﬁelds [2]. It is particularly useful in game theory due to its regret-minimizing
properties [24  11]. It is typically introduced in two nearly identical variants  the one in which at
each step the probability assigned to action γ is multiplied by (1 − C(γ)) and the one in which
it is multiplied by (1 − )C(γ) where C(γ) is the cost of action γ. We will refer to the ﬁrst as the
linear variant  MWU(cid:96)  and the second as the exponential  MWUe (also known as Hedge). In the
literature there is little distinction between these two variants as both carry the same advantageous
regret-minimizing property. It is also well known that in order to achieve sublinear regret  the learning
rate  must be decreasing as time progresses. This constraint raises a natural question: Are there
interesting classes of games where MWU behaves well without the need to ﬁne-tune its learning rate?
A natural setting to test the learning behavior of MWU with constant learning rates  is the well-
studied class of congestion games. Unfortunately  even for the simplest instances of congestion
games MWUe fails to converge to equilibria. For example  even in the simplest case of two balls two

∗Gerasimos Palaiopanos would like to acknowledge a SUTD Presidential fellowship.
†Ioannis Panageas would like to acknowledge a MIT-SUTD postdoctoral fellowship. Part of this work was
completed while Ioannis Panageas was a PhD student at Georgia Institute of Technology and a visiting scientist
at the Simons Institute for the Theory of Computing.
‡Georgios Piliouras would like to acknowledge SUTD grant SRG ESD 2015 097  MOE AcRF Tier 2 Grant
2016-T2-1-170 and a NRF Fellowship. Part of this work was completed while Georgios Piliouras was a visiting
scientist at the Simons Institute for the Theory of Computing.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

bins games 4 MWUe with  = 1− e−10 is shown to converge to a limit cycle of period 2 for inﬁnitely
many initial conditions (Theorem 4.1). If the cost functions of the two edges are not identical then we
create instances of two player load balancing games such that MWUe has periodic orbits of length k
for all k > 0  as well as uncountable many initial conditions which never settle on any periodic orbit
but instead exhibit an irregular behavior known as Li-Yorke chaos (Theorem 4.2  see Corollary 4.3).
The source of these problems is exactly the large  ﬁxed learning rate   e.g.   ≈ 1 for costs in [0  1].
Intuitively  the key aspect of the problem can be captured by (simultaneous) best response dynamics.
If both agents start from the same edge and best-respond simultaneously they will land on the second
edge which now has a load of two. In the next step they will both jump back to the ﬁrst edge and this
motion will be continued perpetually. Naturally  MWUe dynamics are considerably more intricate as
they evolve over mixed strategies and allow for more complicated non-equilibrium behavior but the
key insight is correct. Each agent has the right goal  decrease his own cost and hence the potential of
the game  however  as they pursue this goal too aggressively they cancel each other’s gains and lead
to unpredictable non-converging behavior.
In a sense  the cautionary tales above agree with our intuition. Large  constant learning rates  nullify
the known performance guarantees of MWU. We should expect erratic behavior in such cases. The
typical way to circumvent these problems is through careful monitoring and possibly successive
halving of the  parameter  a standard technique in the MWU literature. In this paper  we explore an
alternative  cleaner  and surprisingly elegant solution to this problem. We show that applying MWU(cid:96) 
the linear variant of MWU  sufﬁces to guarantee convergence in all congestion games.
Our key contributions. Our key result is the proof of convergence of MWU(cid:96) in congestion games.
The main technical contribution is a proof that the potential of the mixed state is always strictly
decreasing along any nontrivial trajectory (Theorem 3.1). This result holds for all congestion games 
irrespective of the number of agents or the size  topology of the strategy sets. Moreover  each agent i
may be applying different learning rates i which will be constant along the dynamics (i does not
depend on the number of iterations T of the dynamics and therefore is bounded away from zero as
T → ∞; this is not the case for most of the results in the literature). The only restriction on the set
of allowable learning rates i is that for each agent the multiplicative factor (1 − iCi(s)) should
be positive for all strategy outcomes s.5 Arguing convergence to equilibria for all initial conditions
(Theorem 3.4) and further  convergence to Nash equilibria for all interior initial conditions (Theorem
3.8) follows. Proving that the potential always decreases (Theorem 3.1) hinges upon discovering a
novel interpretation of MWU dynamics. Speciﬁcally  we show that the class of dynamical systems
derived by applying MWU(cid:96) in congestion games is a special case of a convergent class of dynamical
systems introduced by Baum and Eagon [5] (see Theorem 2.4). The most well known member of this
class is the classic Baum-Welch algorithm  the standard instantiation of the Expectation-Maximization
(EM) algorithm for hidden Markov models (HMM). Effectively  the proof of convergence of both
these systems boils down to a proof of membership to the same class of Baum-Eagon systems (see
section 2.3 for more details on these connections).
In the second part we provide simple congestion games where MWUe provably fails to converge. The
ﬁrst main technical contribution of this section is proving convergence to a limit cycle  speciﬁcally a
periodic orbit of length two  for the simplest case of two balls two bins games for inﬁnitely many initial
conditions (Theorem 4.1). Moreover  after normalizing costs to lie in [0  1]  i.e. c(x) = x/2  we prove
that almost all symmetric non-equilibrium initial conditions converge to a unique limit cycle when
both agents use learning rate  = 1−e−10. In contrast  since 1−·C(s) ≥ 1−(1−e−10)1 = e−10 > 0 
MWU(cid:96) successfully converges to equilibrium. In other words  for the same learning rates  MWUe
exhibits chaotic behavior whereas MWU(cid:96) converges to Nash equilibrium. Establishing chaotic
behavior for the case of edges with different cost functions is rather straightforward in comparison
(Theorem 4.2). The key step is to exploit symmetries in the system to reduce it to a single dimensional
one and then establish the existence of a periodic orbit of length three. The existence of periodic
orbits of any length as well as chaotic orbits then follows from the Li-Yorke theorem 2.3 [30] (see
section 2.2 for background on chaos and dynamical systems). Finally  for any learning rate 1 >  > 0 
we construct n-player games so that MWUe has chaotic behavior for uncountably many starting
points.

4n balls n bin games are symmetric load balancing games with n agent and n edges/elements each with a

cost function of c(x)=x. We normalize costs equal to c(x) = x/n so that they lie in [0  1].

5This is an absolutely minimal restriction so that the denominator of MWU(cid:96) cannot become equal to zero.

2

Related work and Extensions/Implications of our results.

√

Connections to learning in games and price of anarchy: Several recent papers  e.g.  [40  22] focus
on proving welfare guarantees of no-regret dynamics in games exploiting connections to (robust)
price of anarchy literature [37] by establishing fast convergence of the time average behavior to
(approximate) coarse correlate equilibria. Although these approaches are rather powerful they are
not always applicable. For example  it is well known that when we consider the makespan (i.e. the
load of the most congested machine) instead of the social/total cost there can be an exponential gap
between the performance of coarse correlated equilibria and Nash equilibria. For example the price
of anarchy for the makespan objective for n balls n bins games is O(log(n)/ log log(n)) whereas for
the worst no regret algorithm it can be Ω(
n) [9]. Moreover  even if we focus on the social cost  the
price of anarchy guarantees do not carry over if we perform afﬁne transformation to the cost functions
(e.g. if there exist users of different tiers/types that the system designer wants to account for in a
differential manner). In contrast  our convergence results are robust to any afﬁne cost transformation.
In fact  our results apply for all weighted potential games [32] (Remark 3.5).
Connections to distributed computation and adversarial agent scheduling: A rather realistic
concern about results on learning in games has to do with their sensitivity to the ordering of the moves
of the agent dynamics. For example  better-response dynamics in congestion games are guaranteed to
converge only if in every round  exactly one agent deviates to a better strategy. A series of recent
papers has established strong non-termination (cycling) results for large classes of bounded recall
dynamics with a wide variety of interesting and timely applications: game theory  circuit design 
social networks  routing and congestion control [26  19  34  25]. In the case of games  these results
translate to corollaries such as: “If there are two or more pure Nash equilibria in a game with unique
best responses  then all bounded-recall self-independent dynamics6 for which those equilibria are
ﬁxed points can fail to converge in asynchronous environments." Even the simplest 2 balls 2 bins
game satisﬁes these properties (two pure Nash and unique best responses) which shows the strength
of this impossibility result. In contrast  our convergence result holds for any adversarial scheduling
with the minimal fairness assumption that given any mixed state at least one agent who is not best
responding eventually will be given the possibility to update their behavior  answering open questions
in [26  25]. In fact  our convergence result is in a sense the strongest possible  no matter how many
agents get to update their behavior (as long as one of them does) then the potential of the game will
strictly decrease (Corollary 3.6).
Connections to complexity theory: Whereas the complexity of computing both mixed Nash equilib-
ria in general games (PPAD-complete [17]) as well as the complexity of ﬁnding pure Nash equilibria
in congestion games (PLS-complete [20]) have both been completely characterized and are thus
unlikely to admit an efﬁcient time algorithm  the complexity of computing mixed Nash equilibria
in congestion games has withstood so far an exhaustive characterization. Naturally  it lies on the
intersection of both PPAD and PLS  known as CLS [18]. Such an equilibrium can be found both via
an end-of-line type of argument as well as a local search type of argument  but it is still not known
if it is CLS-complete. Given the active interest for producing CLS-complete problems [16  21] our
constructive/convergence proof may help shed light on this open question.
Chaos for arbitrary small learning rates : Although our example of chaotic behavior uses a very
high learning rate  = 1 − e−10  it should be noted that for any learning rate  (e.g.  = e−10)  as
well as for any number of agents n  we can create congestion games with n agents where MWUe
exhibits chaotic behavior (Corollary 4.3).
Congestion/potential games: Congestion games are amongst the most well known and thoroughly
studied class of games. Proposed in [36] and isomorphic to potential games [32]  they have been
successfully employed in myriad modeling problems. Despite the numerous positive convergence
results for concurrent dynamics in congestion games  e.g.  [33  23  7  1  6  28  10  13  12  31]  we
know of no prior work establishing such a deterministic convergence result of the day-to-day agent
behavior to exact Nash equilibria for general atomic congestion games. MWU has also been studied
in congestion games. In [29] randomized variants of the exponential version of the MWU are shown
to converge w.h.p. to pure Nash equilibria as long as the learning rate  is small enough. In contrast
our positive results for linear M W U(cid:96) hold deterministically and for all learning rates. Recently  [14]
showed that if the Hedge algorithm is run with a suitably decreasing learning factor   the sequence

6A dynamic is called self-independent if the agent’s response does not depend on his actions.

3

of play converges to a Nash equilibrium with probability 1 (in the bandit case). The result and the
techniques are orthogonal to ours  since we assume ﬁxed learning rates.
Non-convergent dynamics: Outside the class of congestion games  there exist several negative
results in the literature concerning the non-convergence of MWU and variants thereof. In particular 
in [15] it was shown that the multiplicative updates algorithm fails to ﬁnd the unique Nash equilibrium
of the 3 × 3 Shapley game. Similar non-convergent results have been proven for perturbed zero-sum
games [4]  as well as for the continuous time version of MWU  the replicator dynamics [27  35]. The
possibility of applying Li-Yorke type arguments for MWU in congestion games with two agents
was inspired by a remark in [3] for the case of continuum of agents. Our paper is the ﬁrst to our
knowledge where non-convergent MWU behavior in congestion games is formally proven capturing
both limit cycles and chaos and we do so in the minimal case of two balls two bin games.

2 Preliminaries

Notation. We use boldface letters  e.g.  x  to denote column vectors (points). For a function
f : Rm → Rm  by f n we denote the composition of f with itself n times  namely f ◦ f ◦ ··· ◦ f

.

(cid:124)

(cid:123)(cid:122)

n times

(cid:125)

2.1 Congestion Games
A congestion game [36] is deﬁned by the tuple (N ; E; (Si)i∈N ; (ce)e∈E) where N is the set of
agents  N = |N|  E is a set of resources (also known as edges or bins or facilities) and each player i
has a set Si of subsets of E (Si ⊆ 2E) and |Si| ≥ 1. Each strategy si ∈ Si is a set of edges and ce is
a positive cost (latency) function associated with facility e. We use small greek characters like γ  δ
to denote different strategies/paths. For a strategy proﬁle s = (s1  s2  . . .   sN )  the cost of player i
ce((cid:96)e(s))  where (cid:96)e(s) is the number of players using e in s (the load of

is given by ci(s) =(cid:80)
edge e). The potential function is deﬁned to be Φ(s) =(cid:80)
by ∆(Si) = {p ≥ 0 : (cid:80)
the expected cost of player i given that he chooses strategy γ and ˆci =(cid:80)

For each i ∈ N and γ ∈ Si  piγ denotes the probability player i chooses strategy γ. We denote
γ piγ = 1} the set of mixed (randomized) strategies of player i and
∆ = ×i∆(Si) the set of mixed strategies of all players. We use ciγ = Es−i∼p−ici(γ  s−i) to denote
piδciδ to denote his
expected cost.

(cid:80)(cid:96)e(s)

e∈E

j=1 ce(j).

δ∈Si

e∈si

2.2 Dynamical Systems and Chaos
Let x(t+1) = f (x(t)) be a discrete time dynamical system with update rule f : Rm → Rm. The
point z is called a ﬁxed point of f if f (z) = z. A sequence (f t(x(0)))t∈N is called a trajectory or
orbit of the dynamics with x(0) as starting point. A common technique to show that a dynamical
system converges to a ﬁxed point is to construct a function P : Rm → R such that P (f (x)) > P (x)
unless x is a ﬁxed point. We call P a Lyapunov or potential function.
Deﬁnition 2.1. C = {z1  . . .   zk} is called a periodic orbit of length k if zi+1 = f (zi) for 1 ≤ i ≤
k − 1 and f (zk) = z1. Each point z1  . . .   zk is called periodic point of period k. If the dynamics
converges to some periodic orbit  we also use the term limit cycle.

Some dynamical systems converge and their behavior can be fully understood and some others
have strange  chaotic behavior. There are many different deﬁnitions for what chaotic behavior and
chaos means. In this paper we follow the deﬁnition of chaos by Li and Yorke. Let us ﬁrst give
the deﬁnition of a scrambled set. Given a dynamical system with update rule f  a pair x and y is
called “scrambled" if limn→∞ inf |f n(x) − f n(y)| = 0 (the trajectories get arbitrarily close) and
also limn→∞ sup|f n(x) − f n(y)| > 0 (the trajectories move apart). A set S is called “scrambled"
if ∀x  y ∈ S  the pair is “scrambled".
Deﬁnition 2.2 (Li and Yorke). A discrete time dynamical system with update rule f  f : X → X
continuous on a compact set X ⊂ R is called chaotic if (a) for each k ∈ Z+  there exists a periodic
point p ∈ X of period k and (b) there is an uncountably inﬁnite set S ⊆ X that is “scrambled".
Li and Yorke proved the following theorem [30] (there is another theorem of similar ﬂavor due to
Sharkovskii [38]):

4

Theorem 2.3 (Period three implies chaos). Let J be an interval and let F : J → J be continuous.
Assume there is a point a ∈ J for which the points b = F (a)  c = F 2(a) and d = F 3(a)  satisfy

d ≤ a < b < c (or d ≥ a > b > c).

Then

1. For every k = 1  2  . . . there is a periodic point in J having period k.
2. There is an uncountable set S ⊂ J (containing no periodic points)  which satisﬁes the

following conditions:

• For every p  q ∈ S with p (cid:54)= q 

lim

n→∞ sup|F n(p) − F n(q)| > 0 and lim
• For every point p ∈ S and periodic point q ∈ J 

n→∞ inf |F n(p) − F n(q)| = 0.

n→∞ sup|F n(p) − F n(q)| > 0.

lim

Notice that if there is a periodic point with period 3  then the hypothesis of the theorem will be
satisﬁed.

2.3 Baum-Eagon Inequality  Baum-Welch and EM

We start this subsection by stating the Baum-Eagon inequality. This inequality will be used to show
that MWU(cid:96) converges to ﬁxed points and more speciﬁcally Nash equilibria for congestion games.
Theorem 2.4 (Baum-Eagon inequality [5]). Let P (x) = P ({xij}) be a polynomial with nonnegative
coefﬁcients homogeneous of degree d in its variables {xij}. Let x = {xij} be any point of the
j=1 xij = 1  i = 1  2  ...  p  j = 1  2  ...  qi. For x = {xij} ∈ D let
(cid:61)(x) = (cid:61){xij} denote the point of D whose i  j coordinate is

domain D : xij ≥ 0 (cid:80)qi

Then P ((cid:61)(x)) > P (x) unless (cid:61)(x) = x.

The Baum-Welch algorithm is a classic technique used to ﬁnd the unknown parameters of a hidden
Markov model (HMM). A HMM describes the joint probability of a collection of “hidden" and
observed discrete random variables. It relies on the assumption that the i-th hidden variable given the
(i − 1)-th hidden variable is independent of previous hidden variables  and the current observation
variables depend only on the current hidden state. The Baum-Welch algorithm uses the well known
EM algorithm to ﬁnd the maximum likelihood estimate of the parameters of a hidden Markov model
given a set of observed feature vectors. More detailed exposition of these ideas can be found here
[8]. The probability of making a speciﬁc time series of observations of length T can be shown to
be a homogeneous polynomial P of degree T with nonnegative (integer) coefﬁcients of the model
parameters. Baum-Welch algorithm is homologous to the iterative process derived by applying the
Baum-Eagon theorem to polynomial P [5  41].
In a nutshell  both Baum-Welch and MWU(cid:96) in congestion games are special cases of the Baum-Eagon
iterative process (for different polynomials P ).

2.4 Multiplicative Weights Update

In this section  we describe the MWU dynamics (both the linear MWU(cid:96)  and the exponential
MWUe variants) applied in congestion games. The update rule (function) ξ : ∆ → ∆ (where
p(t + 1) = ξ(p(t))) for the linear variant MWU(cid:96) is as follows:
1 − iciγ(t)
1 − iˆci(t)

piγ(t + 1) = (ξ(p(t)))iγ = piγ(t)

  ∀i ∈ N  ∀γ ∈ Si 

(1)

5

(cid:32)

(cid:33)(cid:44) qi(cid:88)

(cid:12)(cid:12)(cid:12)(cid:12)(x)

(cid:61)(x)ij =

xij

∂P
∂xij

xij(cid:48)

∂P
∂xij(cid:48)

j(cid:48)=1

(cid:12)(cid:12)(cid:12)(cid:12)(x)

def

where i is a constant (can depend on player i but not on p) so that both enumerator and denominator
of the fraction in (1) are positive (and thus the fraction is well deﬁned). Under the assumption that
1/i > 1
β
The update rule (function) η : ∆ → ∆ (where p(t + 1) = η(p(t))) for the exponential variant
MWUe is as follows:

= supi p∈∆ γ∈Si {ciγ}  it follows that 1/i > ciγ for all i  γ and hence 1/i > ˆci.

(cid:80)

(1 − i)ciγ (t)
piγ(cid:48)(t)(1 − i)ciγ(cid:48) (t)

γ(cid:48)∈Si

  ∀i ∈ N  ∀γ ∈ Si 

(2)

piγ(t + 1) = (η(p(t)))iγ = piγ(t)

denominator are positive) and also is true that(cid:80)

where i < 1 is a constant (can depend on player i but not on p). Note that i can be small when the
number of agents N is large enough.
Remark 2.5. Observe that ∆ is invariant under the discrete dynamics (1)  (2) deﬁned above. If
piγ = 0 then piγ remains zero  and if it is positive  it remains positive (both numerator and
piγ = 1 for all agents i. A point p∗ is called
a ﬁxed point if it stays invariant under the update rule of the dynamics  namely ξ(p∗) = p∗ or
η(p∗) = p∗. A point p∗ is a ﬁxed point of (1)  (2) if for all i  γ with p∗
iγ > 0 we have that ciγ = ˆci.
iγ  p∗
To see why  observe that if p∗
iγ(cid:48) > 0  then ciγ = ciγ(cid:48) and thus ciγ = ˆci. We conclude that the set
of ﬁxed points of both dynamics (1)  (2) coincide and are supersets of the set of Nash equilibria of the
corresponding congestion game.

γ∈Si

3 Convergence of MWU(cid:96) to Nash Equilibria

We ﬁrst prove that MWU(cid:96) (1) converges to ﬁxed points7. Technically  we establish that function
= Es∼p [Φ(s)] is strictly decreasing along any nontrivial (i.e. nonequilibrium) trajectory  where
def
Ψ
Φ is the potential function of the congestion game as deﬁned in Section 2. Formally we show the
following theorem:
Theorem 3.1 (Ψ is decreasing). Function Ψ is decreasing w.r.t. time  i.e.  Ψ(p(t + 1)) ≤ Ψ(p(t))
where equality Ψ(p(t + 1)) = Ψ(p(t)) holds only at ﬁxed points.

(cid:88)

γ∈Si

(cid:88)
(cid:124)

i∈N

We deﬁne the function

(1/i − 1/β) · (cid:88)

 + 1/β · (cid:89)
(cid:123)(cid:122)
(cid:80)
follows since Q = const − Ψ where const =(cid:80)

constant term

γ∈Si

and show that Q(p) is strictly increasing w.r.t time  unless p is a ﬁxed point. Observe that
piγ = 1 since p lies in ∆  but we include this terms in Q for technical reasons that will be
made clear later in the section. By showing that Q is increasing with time  Theorem 3.1 trivially
i∈N 1/i − 1/β(N − 1). To show that Q(p) is
strictly increasing w.r.t time  unless p is a ﬁxed point  we use a generalization of an inequality by
Baum and Eagon [5] on function Q.
Corollary 3.2 (Generalization of Baum-Eagon). Theorem 2.4 holds even if P is non-homogeneous.

−Ψ(p) 

(3)


(cid:125)

piγ

piγ

γ∈Si

i∈N

Q(p)

def
=

We want to apply Corollary 3.2 on Q. To do so  it sufﬁces to show that Q(p) is a polynomial with
nonnegative coefﬁcients.
Lemma 3.3. Q(p) is a polynomial with respect to piγ and has nonnegative coefﬁcients.

Using Lemma 3.3 and Corollary 3.2 we show the following:
Theorem 3.4. Let Q be the function deﬁned in (3). Let also p(t) ∈ ∆ be the point MWU(cid:96) (1)
def
= Q(ξ(p(t))) > Q(p(t)) unless
outputs at time t with update rule ξ. It holds that Q(p(t + 1))
ξ(p(t)) = p(t) (ﬁxed point). Namely Q is strictly increasing with respect to the number of iterations
t unless MWU(cid:96) is at a ﬁxed point.

7All missing proofs can be found in the full version of this paper http://arxiv.org/abs/1703.01138.

6

e∈E

(same for all players) function Φ =(cid:80)

(cid:80)(cid:96)e(s)
i  s−i) = wi(Φ(si  s−i) − Φ(s(cid:48)

Remark 3.5 (Weighted potential games). A congestion game is a potential game because if a player
deviates  the difference he experiences in his cost is exactly captured by the deviation of the global
j=1 ce(j). In a weighted potential game  it holds that
ci(si  s−i) − ci(s(cid:48)
i  s−i))  where wi is some constant not necessarily
1 (as in the potential games case) and vector s−i captures the strategies of all players but i. It
is not hard to see that Lemma 3.3 and thus Theorems 3.4 and 3.1 hold in this particular class of
games (which is a generalization of congestion games)  and so do the rest of the theorems of the
section. Effectively  in terms of the weighted potential games analysis  it is possible to reduce it to
the standard potential games analysis as follows: Consider the system with learning rates i and
cost functions wici so that the game with cost functions ci is a potential game. The only necessary
condition that we ask of this system is that iwici(s) < 1 for all i (as in the standard case) so that
the enumerators/denominators are positive.

By reduction  we can show that for every round T   even if a subset (that depends on the round T )
of the players update their strategy according to MWU(cid:96) and the rest remain ﬁxed  the potential still
decreases.
Corollary 3.6 (Any subset). Assume that at time t we partition the players in two sets St  S(cid:48)
we allow only players in St to apply MWU(cid:96) dynamics  whereas the players in S(cid:48)
holds that the expected potential function of the game at time t decreases.

t so that
t remain ﬁxed. It

As stated earlier in the section  if Q(p(t)) is strictly increasing with respect to time t unless p(t) is
a ﬁxed point  it follows that the expected potential function Ψ(p(t)) = const − Q(p(t)) is strictly
decreasing unless p(t) is a ﬁxed point and Theorem 3.1 is proved. Moreover  we can derive the fact
that our dynamics converges to ﬁxed points as a corollary of Theorem 3.1.
Theorem 3.7 (Convergence to ﬁxed points). MWU(cid:96) dynamics (1) converges to ﬁxed points.

We conclude the section by strengthening the convergence result (i.e.  Theorem 3.7). We show that if
the initial distribution p is in the interior of ∆ then we have convergence to Nash equilibria.
Theorem 3.8 (Convergence to Nash equilibria). Assume that the ﬁxed points of (1) are isolated. Let
p(0) be a point in the interior of ∆. It follows that limt→∞ p(t) = p∗ is a Nash equilibrium.

p∗. Also it is clear from the dynamics that ∆ is invariant  i.e. (cid:80)

Proof. We showed in Theorem 3.7 that MWU(cid:96) dynamics (1) converges  hence limt→∞ p(t) exists
(under the assumption that the ﬁxed points are isolated) and is equal to a ﬁxed point of the dynamics
pjδ(t) = 1  pjδ(t) > 0 for all
j and t ≥ 0 since p(0) is in the interior of ∆.
Assume that p∗ is not a Nash equilibrium  then there exists a player i and a strategy γ ∈ Si so that
iγ = 0. Fix a ζ > 0 and let Uζ = {p : ciγ(p) <
ciγ(p∗) < ˆci(p∗) (on mixed strategies p∗) and p∗
ˆci(p) − ζ}. By continuity we have that Uζ is open. It is also true that p∗ ∈ Uζ for ζ small enough.
Since p(t) converges to p∗ as t → ∞  there exists a time t0 so that for all t(cid:48) ≥ t0 we have that
p(t(cid:48)) ∈ Uζ. However  from MWU(cid:96) dynamics (1) we get that if p(t(cid:48)) ∈ Uζ then 1 − iciγ(t(cid:48)) >
1 − iˆci(t(cid:48)) and hence piγ(t(cid:48) + 1) = piγ(t(cid:48)) 1−iciγ (t(cid:48))
1−i ˆci(t(cid:48)) ≥ piγ(t(cid:48)) > 0  i.e.  piγ(t(cid:48)) is positive and
increasing with t(cid:48) ≥ t0. We reached a contradiction since piγ(t) → p∗
iγ = 0  thus p∗ is a Nash
equilibrium.

δ∈Sj

4 Non-Convergence of MWUe: Limit Cycle and Chaos

We consider a symmetric two agent congestion game with two edges e1  e2. Both agents have the
same two available strategies γ1 = {e1} and γ2 = {e2}. We denote x  y the probability that the ﬁrst
and the second agent respectively choose strategy γ1.
2 · l. Computing the expected
For the ﬁrst example  we assume that ce1(l) = 1
costs we get that c1γ1 = 1+y
2 . MWUe then becomes xt+1 =
(sec-
xt
ond player). We assume that 1 = 2 and also that x0 = y0 (players start with the same mixed

2 · l and ce2 (l) = 1
2   c2γ2 = 2−x

(1−1)
2 +(1−xt)(1−1)

(ﬁrst player) and yt+1 = yt

2   c1γ2 = 2−y

xt+1

(1−2)
2 +(1−yt)(1−2)

2

2   c2γ1 = 1+x

xt(1−1)

2−xt

2

yt(1−2)

xt+1

(yt+1)

2

yt+1

2−yt

2

7

(a) Exponential MWUe: Plot of function G (blue)
and its iterated versions G2 (red)  G3 (yellow).
Function y(x) = x is also included.

(b) Linear MWU(cid:96): Plot of function G(cid:96) (blue) and
its iterated versions G2
(cid:96) (yellow). Func-
tion y(x) = x is also included.

(cid:96) (red) and G3

(c) Exponential MWUe: Plot of function G10.
Function y(x) = x is also included.

(d) Linear MWU(cid:96): Plot of function G10
y(x) = x is also included.

(cid:96) . Function

Figure 1: We compare and contrast MWUe (left) and MWU(cid:96) (right) in the same two agent two
4 · l and same learning rate
strategy/edges congestion game with ce1(l) = 1
 = 1 − e−40. MWUe exhibits sensitivity to initial conditions whereas MWU(cid:96) equilibrates. Function
y(x) = x is also included in the graphs to help identify ﬁxed points and periodic points.

4 · l and ce2(l) = 1.4

strategy. Due to symmetry  it follows that xt = yt for all t ∈ N  thus it sufﬁces to keep track only of
one variable (we have reduced the number of variables of the update rule of the dynamics to one) and
. Finally  we choose  = 1 − e−10
the dynamics becomes xt+1 = xt
and we get

(1−)
2 +(1−xt)(1−)

xt(1−)

2−xt

xt+1

xt+1

2

2

xt+1 = H(xt) = xt

e−5(xt+1)

xte−5(xt+1) + (1 − xt)e−5(2−xt)

 

i.e.  we denote H(x) =

xe−5(x+1)

xe−5(x+1)+(1−x)e−5(2−x) .

For the second example  we assume that ce1(l) = 1
the expected costs we get that c1γ1 = 1+y
MWUe then becomes xt+1 = xt

4   c1γ2 = 1.4(2−y)

4

4 · l and ce2(l) = 1.4
4
  c2γ1 = 1+x

· l. Computing
4   c2γ2 = 1.4(2−x)
.
(ﬁrst player) and yt+1 =

1.4(2−yt)

4

(yt+1)

(1−1)
4 +(1−xt)(1−1)

4

(1−2)

xt(1−1)
(second player). We assume that 1 = 2 and also that x0 = y0
yt
(players start with the same mixed strategy. Similarly  due to symmetry  it follows that xt = yt
for all t ∈ N  thus it sufﬁces to keep track only of one variable and the dynamics becomes

4 +(1−yt)(1−2)

yt(1−2)

1.4(2−xt)

xt+1

xt+1

yt+1

4

4

4

8

xt+1 = xt

(1−)

xt+1

4

xt(1−)

xt+1

4 +(1−xt)(1−)

1.4(2−xt)

4

. Finally  we choose  = 1 − e−40 and we get

xt+1 = G(xt) = xt

e−10(xt+1)

xte−10(xt+1) + (1 − xt)e−14(2−xt)

 

i.e.  we denote G(x) =

xe−10(x+1)

xe−10(x+1)+(1−x)e−14(2−x) .

We show the following three statements  the proofs of which can be found in the full version.
Theorem 4.1. For all but a measure zero set S of x ∈ (0  1) we get that limt→∞ H 2t(x) = ρ1 or ρ2.
Moreover  H(ρ1) = ρ2 and H(ρ2) = ρ1  i.e.  {ρ1  ρ2} is a periodic orbit. Thus  all but a measure
zero set S of initial conditions converge to the limit cycle {ρ1  ρ2}. Finally  the initial points in S
converge to the equilibrium 1
2 .
Theorem 4.2. There exist two player two strategy symmetric congestion games such that MWUe has
periodic orbits of length n for any natural number n > 0 and as well as an uncountably inﬁnite set
of “scrambled" initial conditions (Li-Yorke chaos).

Using Theorem 4.2  we conclude with the following corollary.
Corollary 4.3. For any 1 >  > 0 and n  there exists a n-player congestion game G() (depending
on ) so that MWUe dynamics exhibits Li-Yorke chaos for uncountably many starting points.

5 Conclusion and Future Work

We have analyzed MWU(cid:96) in congestion games where agents use arbitrary admissible constants as
learning rates  and showed convergence to exact Nash equilibria. We have also shown that this
result is not true for the nearly homologous exponential variant MWUe even for the simplest case of
two-agent  two-strategy load balancing games. There we prove that such dynamics can provably lead
to limit cycles or even chaotic behavior.
For a small enough learning rate  the behavior of MWUe approaches that of its smooth variant 
replicator dynamics  and hence convergence is once again guaranteed [29]. This means that as we
increase the learning rate  from near zero values we start off with a convergent system and we
end up with a chaotic one. Numerical experiments establish that between the convergent region
and the chaotic region there exists a range of values for  for which the system exhibits periodic
behavior. Period doubling is known as standard route for 1-dimensional chaos (e.g. logistic map) and
is characterized by unexpected regularities such as the Feigenbaum constant [39]. Elucidating these
connections is an interesting open problem. More generally  what other type of regularities can be
established in these non-equilibrium systems?
Another interesting question has to do with developing a better understanding of the set of conditions
that result to non-converging trajectories. So far  it has been critical for our non-convergent examples
that the system starts from a symmetric initial condition. Whether such irregular MWUe trajectories
can be constructed for generic initial conditions  possibly in larger congestion games  is not known.
Nevertheless  the non-convergent results  despite their non-generic nature are rather useful since
they imply that we cannot hope to leverage the power of Baum-Eagon techniques for MWUe. In
conclusion  establishing generic (non)convergence results (e.g. for most initial conditions  most
congestion games) for MWUe with constant step size is an interesting future direction.

References
[1] H. Ackermann  P. Berenbrink  S. Fischer  and M. Hoefer. Concurrent imitation dynamics in

congestion games. In PODC  pages 63–72  New York  USA  2009. ACM.

[2] S. Arora  E. Hazan  and S. Kale. The multiplicative weights update method: a meta-algorithm

and applications. Theory of Computing  8(1):121–164  2012.

[3] I. Avramopoulos. Evolutionary stability implies asymptotic stability under multiplicative

weights. CoRR  abs/1601.07267  2016.

9

[4] M.-F. Balcan  F. Constantin  and R. Mehta. The weighted majority algorithm does not converge
in nearly zero-sum games. In ICML Workshop on Markets  Mechanisms and Multi-Agent
Models  2012.

[5] L. E. Baum and J. A. Eagon. An inequality with applications to statistical estimation for
probabilistic functions of markov processes and to a model of ecology. Bulletin of the American
Mathematical Society  73(3):360–363  1967.

[6] P. Berenbrink  M. Hoefer  and T. Sauerwald. Distributed selﬁsh load balancing on networks. In

ACM Transactions on Algorithms (TALG)  2014.

[7] P. Berenbrink  T. Friedetzky  L. A. Goldberg  P. W. Goldberg  Z. Hu  and R. Martin. Distributed

selﬁsh load balancing. SIAM J. Comput.  37(4):1163–1181  November 2007.

[8] J. A Bilmes et al. A gentle tutorial of the em algorithm and its application to parameter
estimation for gaussian mixture and hidden markov models. International Computer Science
Institute  4(510):126  1998.

[9] A. Blum  M. Hajiaghayi  K. Ligett  and A. Roth. Regret minimization and the price of total
anarchy. In Proceedings of the 40th annual ACM symposium on Theory of computing  STOC 
pages 373–382  2008.

[10] I. Caragiannis  A. Fanelli  N. Gravin  and A. Skopalik. Efﬁcient computation of approximate

pure nash equilibria in congestion games. In FOCS  2011.

[11] N. Cesa-Bianchi and G. Lugoisi. Prediction  Learning  and Games. Cambridge University

Press  2006.

[12] P. Chen and C. Lu. Generalized mirror descents in congestion games. Artiﬁcial Intelligence 

241:217–243  2016.

[13] S. Chien and A. Sinclair. Convergence to approximate nash equilibria in congestion games. In

Games and Economic Behavior  pages 315–327  2011.

[14] J. Cohen  A. Heliou  and P. Mertikopoulos. Learning with bandit feedback in potential games.
In Proceedings of the 31th International Conference on Neural Information Processing Systems 
2017.

[15] C. Daskalakis  R. Frongillo  C. Papadimitriou  G. Pierrakos  and G. Valiant. On learning
algorithms for Nash equilibria. Symposium on Algorithmic Game Theory (SAGT)  pages
114–125  2010.

[16] C. Daskalakis  C. Tzamos  and M. Zampetakis. A Converse to Banach’s Fixed Point Theorem

and its CLS Completeness. ArXiv e-prints  February 2017.

[17] C. Daskalakis  P. W. Goldberg  and C. H. Papadimitriou. The complexity of computing a nash

equilibrium. pages 71–78. ACM Press  2006.

[18] C. Daskalakis and C. Papadimitriou. Continuous local search. In Proceedings of the Twenty-
second Annual ACM-SIAM Symposium on Discrete Algorithms  SODA ’11  pages 790–804 
Philadelphia  PA  USA  2011. Society for Industrial and Applied Mathematics.

[19] R. Engelberg  A. Fabrikant  M. Schapira  and D. Wajc. Best-response dynamics out of sync:
In Proceedings of the Fourteenth ACM Conference on

Complexity and characterization.
Electronic Commerce  EC ’13  pages 379–396  New York  NY  USA  2013. ACM.

[20] A. Fabrikant  C. Papadimitriou  and K. Talwar. The complexity of pure Nash equilibria. In

ACM Symposium on Theory of Computing (STOC)  pages 604–612. ACM  2004.

[21] J. Fearnley  S. Gordon  R. Mehta  and R. Savani. CLS: New Problems and Completeness. ArXiv

e-prints  February 2017.

[22] D. J Foster  T. Lykouris  K. Sridharan  and E. Tardos. Learning in games: Robustness of fast
convergence. In Advances in Neural Information Processing Systems  pages 4727–4735  2016.

10

[23] D. Fotakis  A. C. Kaporis  and P. G. Spirakis. Atomic congestion games: Fast  myopic and
concurrent. In Burkhard Monien and Ulf-Peter Schroeder  editors  Algorithmic Game Theory 
volume 4997 of Lecture Notes in Computer Science  pages 121–132. Springer Berlin Heidelberg 
2008.

[24] D. Fudenberg and D. K. Levine. The Theory of Learning in Games. MIT Press Books. The

MIT Press  1998.

[25] A. D Jaggard  N. Lutz  M. Schapira  and R. N Wright. Dynamics at the boundary of game
theory and distributed computing. ACM Transactions on Economics and Computation (TEAC) 
2017.

[26] A. D Jaggard  M. Schapira  and R. N Wright. Distributed computing with adaptive heuristics.

In ICS  2011.

[27] R. Kleinberg  K. Ligett  G. Piliouras  and É. Tardos. Beyond the Nash equilibrium barrier. In

Symposium on Innovations in Computer Science (ICS)  2011.

[28] R. Kleinberg  G. Piliouras  and É. Tardos. Load balancing without regret in the bulletin board

model. Distributed Computing  24(1):21–29  2011.

[29] R. Kleinberg  G. Piliouras  and É. Tardos. Multiplicative updates outperform generic no-regret

learning in congestion games. In ACM Symposium on Theory of Computing (STOC)  2009.

[30] T. Li and J. A. Yorke. Period three implies chaos. The American Mathematical Monthly 

82(10):985–992  1975.

[31] P. Mertikopoulos and A. L. Moustakas. The emergence of rational behavior in the presence of

stochastic perturbations. The Annals of Applied Probability  20(4):1359–1388  2010.

[32] D. Monderer and L. S. Shapley. Potential games. Games and Economic Behavior  pages

124–143  1996.

[33] D. Monderer and L. S Shapley. Fictitious play property for games with identical interests.

Journal of economic theory  68(1):258–265  1996.

[34] N. Nisan  M. Schapira  and A. Zohar. Asynchronous best-reply dynamics. In International

Workshop on Internet and Network Economics  pages 531–538. Springer  2008.

[35] G. Piliouras and J. S. Shamma. Optimization despite chaos: Convex relaxations to complex

limit sets via Poincaré recurrence. In SODA  2014.

[36] R.W. Rosenthal. A class of games possessing pure-strategy Nash equilibria. International

Journal of Game Theory  2(1):65–67  1973.

[37] T. Roughgarden. Intrinsic robustness of the price of anarchy. In Proc. of STOC  pages 513–522 

2009.

[38] A.N. Sharkovskii. Co-existence of cycles of a continuous mapping of the line into itself.

Ukrainian Math. J.  16:61 – 71  1964.

[39] S. Strogatz. Nonlinear Dynamics and Chaos. Perseus Publishing  2000.

[40] V. Syrgkanis  A. Agarwal  H. Luo  and R. E. Schapire. Fast convergence of regularized
learning in games. In Proceedings of the 28th International Conference on Neural Information
Processing Systems  NIPS’15  pages 2989–2997  Cambridge  MA  USA  2015. MIT Press.

[41] L. R Welch. Hidden markov models and the baum-welch algorithm. IEEE Information Theory

Society Newsletter  53(4):10–13  2003.

11

,Gerasimos Palaiopanos
Ioannis Panageas
Georgios Piliouras