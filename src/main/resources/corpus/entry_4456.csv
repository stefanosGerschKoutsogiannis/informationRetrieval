2014,Projecting Markov Random Field Parameters for Fast Mixing,Markov chain Monte Carlo (MCMC) algorithms are simple and extremely powerful techniques to sample from almost arbitrary distributions. The flaw in practice is that it can take a large and/or unknown amount of time to converge to the stationary distribution. This paper gives sufficient conditions to guarantee that univariate Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing  in a precise sense. Further  an algorithm is given to project onto this set of fast-mixing parameters in the Euclidean norm. Following recent work  we give an example use of this to project in various divergence measures  comparing of univariate marginals obtained by sampling after projection to common variational methods and Gibbs sampling on the original parameters.,Projecting Markov Random Field Parameters for

Fast Mixing

Xianghang Liu

Justin Domke

NICTA  The University of New South Wales

NICTA  The Australian National University

xianghang.liu@nicta.com.au

justin.domke@nicta.com.au

Abstract

Markov chain Monte Carlo (MCMC) algorithms are simple and extremely power-
ful techniques to sample from almost arbitrary distributions. The ﬂaw in practice
is that it can take a large and/or unknown amount of time to converge to the station-
ary distribution. This paper gives sufﬁcient conditions to guarantee that univariate
Gibbs sampling on Markov Random Fields (MRFs) will be fast mixing  in a pre-
cise sense. Further  an algorithm is given to project onto this set of fast-mixing
parameters in the Euclidean norm. Following recent work  we give an example use
of this to project in various divergence measures  comparing univariate marginals
obtained by sampling after projection to common variational methods and Gibbs
sampling on the original parameters.

1 Introduction

Exact inference in Markov Random Fields (MRFs) is generally intractable  motivating approximate
algorithms. There are two main classes of approximate inference algorithms: variational methods
and Markov chain Monte Carlo (MCMC) algorithms [13].

Among variational methods  mean-ﬁeld approximations [9] are based on a “tractable” family of
distributions  such as the fully-factorized distributions. Inference ﬁnds a distribution in the tractable
set to minimize the KL-divergence from the true distribution. Other methods  such as loopy belief
propagation (LBP)  generalized belief propagation [14] and expectation propagation [10] use a less
restricted family of target distributions  but approximate the KL-divergence. Variational methods
are typically fast  and often produce high-quality approximations. However  when the variational
approximations are poor  estimates can be correspondingly worse.

MCMC strategies  such as Gibbs sampling  simulate a Markov chain whose stationary distribution is
the target distribution. Inference queries are then answered by the samples drawn from the Markov
chain. In principle  MCMC will be arbitrarily accurate if run long enough. The principal difﬁculty
is that the time for the Markov chain to converge to its stationary distribution  or the “mixing time” 
can be exponential in the number of variables.

This paper is inspired by a recent hybrid approach for Ising models [3]. This approach minimizes
the divergence from the true distribution to one in a tractable family. However  the tractable family
is a “fast mixing” family where Gibbs sampling is guaranteed to quickly converge to the stationary
distribution. They observe that an Ising model will be fast mixing if the spectral norm of a matrix
containing the absolute values of all interactions strengths is controlled. An algorithm projects
onto this fast mixing parameter set in the Euclidean norm  and projected gradient descent (PGD)
can minimize various divergence measures. This often leads to inference results that are better
than either simple variational methods or univariate Gibbs sampling (with a limited time budget).
However  this approach is limited to Ising models  and scales poorly in the size of the model  due to
the difﬁculty of projecting onto the spectral norm.

1

The principal contributions of this paper are  ﬁrst  a set of sufﬁcient conditions to guarantee that
univariate Gibbs sampling on an MRF will be fast-mixing (Section 4)  and an algorithm to project
onto this set in the Euclidean norm (Section 5). A secondary contribution of this paper is considering
an alternative matrix norm (the induced ∞-norm) that is somewhat looser than the spectral norm 
but more computationally efﬁcient. Following previous work [3]  these ideas are experimentally
validated via a projected gradient descent algorithm to minimize other divergences  and looking at
the accuracy of the resulting marginals. The ability to project onto a fast-mixing parameter set may
also be of independent interest. For example  it might be used during maximum likelihood learning
to ensure that the gradients estimated through sampling are more accurate.

2 Notation

We consider discrete pairwise MRFs with n variables  where the i-th variable takes values in
{1  ...  Li}  E is the set of edges  and θ are the potentials on each edge. Each edge in E is an ordered
pair (i  j) with i ≤ j. The parameters are a set of matrices θ := {θij|θij ∈ RLi×Lj   ∀(i  j) ∈ E}.
When i > j  and (j  i) ∈ E  we let θij denote the transpose of θji. The corresponding distribution is

p(x; θ) = exp⎛

⎝ #(i j)∈E

θij(xi  xj) − A(θ)⎞
⎠  

(1)

where A(θ) := log&x exp’&(i j)∈E θij(xi  xj)( is the log-partition function  and θij(xi  xj)

denotes the entry in the xi-th row and xj-th column of θij. It is easy to show that any parametrization
of a pairwise MRF can be converted into this form. “Self-edges” (i  i) can be included in E if one
wishes to explicitly represent univariate terms.

It is sometimes convenient to work with the exponential family representation

(2)
where f (x) is the sufﬁcient statistics for conﬁguration x. If these are indicator functions for all
conﬁgurations of all pairs in E  then the two representations are equivalent.

p(x; θ) = exp{f (x) · θ − A(θ)} 

3 Background Theory on Rapid Mixing

This section reviews background on mixing times that will be used later in the paper.
Deﬁnition 1. Given two ﬁnite distributions p and q  the total variation distance ∥ · ∥T V is deﬁned
as ∥p(X) − q(X)∥T V = 1

2&x |p(X = x) − q(X = x)|.

Next  one must deﬁne a measure of how fast a Markov chain converges to the stationary distribution.
Let the state of the Markov chain after t iterations be X t. Given a constant ϵ  this is done by ﬁnding
some number of iterations τ(ϵ) such that the induced distribution p(X t|X 0 = x) will always have a
distance of less than ϵ from the stationary distribution  irrespective of the starting state x.
Deﬁnition 2. Let {X t} be the sequence of random variables corresponding to running Gibbs sam-
pling on a distribution p. The mixing time τ(ϵ) is deﬁned as τ(ϵ) = min{t : d(t) < ϵ}  where
d(t) = maxx ∥P(X t|X 0 = x) − p(X)∥T V is the maximum distance at time t when considering all
possible starting states x.

Now  we are interested in when Gibbs sampling on a distribution p can be shown to have a fast
mixing time. The central property we use is the dependency of one variable on another  deﬁned
informally as how much the conditional distribution over Xi can be changed when all variables
other than Xj are the same.
Deﬁnition 3. Given a distribution p  the dependency matrix R is deﬁned by
−i)∥T V .

∥p(Xi|x−i) − p(Xi|x′

Rij =

max

x x′:x−j=x′

−j

Here  the constraint x−j = x′
−j indicates that all variables in x and x′ are identical except xj . The
central result on rapid mixing is given by the following Theorem  due to Dyer et al. [5]  generalizing
the work of Hayes [7]. Informally  it states that if ∥R∥ < 1 for any sub-multiplicative norm ∥ · ∥ 
then mixing will take on the order of n ln n iterations  where n is the number of variables.

2

1−∥R∥ ln! ∥1n∥ ∥1T

ϵ

" .

Theorem 4. [5  Lemma 17] If ∥ · ∥ is any sub-multiplicative matrix norm and ||R|| < 1  the mixing
time of univariate Gibbs sampling on a system with n variables with random updates is bounded by
τ(ϵ) ≤ n

n ∥

Here  ∥1n∥ denotes the same matrix norm applied to a matrix of ones of size n × 1  and similarly
for 1T

n . In particular  if ∥ · ∥ induced by a vector p-norm  then ∥1n∥ ∥1T

n ∥ = n.

Since this result is true for a variety of norms  it is natural to ask  for a given matrix R  which norm
will give the strongest result. It can be shown that for symmetric matrices (such as the dependency
matrix)  the spectral norm ∥ · ∥2 is always superior.
Theorem 5. [5  Lemma 13] If A is a symmetric matrix and ∥ · ∥ is any sub-multiplicative norm 
then ∥A∥2 ≤ ∥A∥.

Unfortunately  as will be discussed below  the spectral norm can be more computationally expensive
than other norms. As such  we will also consider the use of the ∞-norm ∥ · ∥∞. This leads to
additional looseness in the bound in general  but is limited in some cases. In particular if R = rG
where G is the adjacency matrix for some regular graph with degree d  then for all induced p-norms 
∥R∥ = rd  since ∥R∥ = maxx̸=0 ∥Rx∥/∥x| = r maxx̸=0 ∥Gx∥/∥x∥ = r∥Go∥/∥o∥ = rd  where
o is a vector of ones. Thus  the extra looseness from using  say  ∥ · ∥∞ instead of ∥ · ∥2 will tend to
be minimal when the graph is close to regular  and the dependency is close to a constant value. For
irregular graphs with highly variable dependency  the looseness can be much larger.

4 Dependency for Markov Random Fields

In order to establish that Gibbs sampling on a given MRF will be fast mixing  it is necessary to
compute (a bound on) the dependency matrix R  as done in the following result. The proof of this
result is fairly long  and so it is postponed to the Appendix. Note that it follows from several bounds
on the dependency that are tighter  but less computationally convenient.

Theorem 6. The dependency matrix for a pairwise Markov random ﬁeld is bounded by

Rij(θ) ≤ max
a b

1
2

∥θij

·a − θij

·b ∥∞.

Here  θij
·a indicates the a−th column of θij . Note that the MRF can include univariate terms as self-
edges with no impact on the dependency bound  regardless of the strength of the univariate terms. It
can be seen easily that from the deﬁnition of R (Deﬁnition 3)  for any i the entry Rii for self-edges
(i  i) should always be zero. One can  without loss of generality  set each column of θii to be the
same  meaning that Rii = 0 in the above bound.

5 Euclidean Projection Operator

#(i j)∈E ∥θij − ψij∥2

The Euclidean distance between two MRFs parameterized respectively by ψ and θ is ∥θ − ψ∥2 :=
F . This section considers projecting a given vector ψ onto the fast mixing set
or  formally  ﬁnding a vector θ with minimum Euclidean distance to ψ  subject to the constraint
that a norm ∥ · ∥∗ applied to the bound on the dependency matrix R is less than some constant c.
Euclidean projection is considered because  ﬁrst  it is a straightforward measure of the closeness
between two parameters and  second  it is the building block of the projected gradient descent for
projection in other distance measures. To begin with  we do not specify the matrix norm ∥ · ∥∗  as it
could be any sub-multiplicative norm (Section 3).

Thus  in principle  we would like to ﬁnd θ to solve

projc(ψ) := argmin

θ:∥R(θ)∥∗≤c

∥θ − ψ∥2.

(3)

Unfortunately  while convex  this optimization turns out to be somewhat expensive to solve  due to
a lack of smoothness Instead  we introduce a matrix Z  and constrain that Zij ≥ Rij(θ)  where
Rij(θ) is the bound on dependency in Thm 6 (as an equality). We add an extra quadratic term

3

α∥Z − Y ∥2
the smoothness and the closeness to original problem (3). The smoothed projection operator is

F to the objective  where Y is an arbitrarily given matrix and α > 0 is trade-off between

projC(ψ  Y ) := argmin
(θ Z)∈C

∥θ − ψ∥2 + α∥Z − Y ∥2

F   C = {(θ  Z) : Zij ≥ Rij(θ)  ∥Z∥∗ ≤ c}.

(4)

If α = 0  this yields a solution that is identical to that of Eq. 3. However  when α = 0  the objective
in Eq. 4 is not strongly convex as a function of Z  which results in a dual function which is non-
smooth  meaning it must be solved with a method like subgradient descent  with a slow convergence
rate.
In general  of course  the optimal point of Eq. 4 is different to that of Eq. 3. However 
the main usage of the Euclidean projection operator is the projection step in the projected gradient
descent algorithm for divergence minimization. In these tasks the smoothed projection operator can
be directly used in the place of the non-smoothed one without changing the ﬁnal result. In situations
when the exact Euclidean projection is required  it can be done by initializing Y1 arbitrarily and
repeating (θk+1  Yk+1) ← projC(ψ  Yk)  for k = 1  2  . . . until convergence.

5.1 Dual Representation

Theorem 7. Eq. 4 has the dual representation

maximize

g(σ  φ  ∆  Γ)

σ φ ∆ Γ
subject to σij(a  b  c) ≥ 0  φij(a  b  c) ≥ 0  ∀(i  j) ∈ E  a  b  c

 

(5)

where

g(σ  φ  ∆  Γ) = min

Z

h1(Z; σ  φ  ∆  Γ) + min

θ

h2(θ; σ  φ)

h1(Z; σ  φ  ∆  Γ) = −tr(ZΛT ) + I(∥Z∥∗ ≤ c) + α∥Z − Y ∥2
F

h2(θ; σ  φ) = ∥θ − ψ∥2 +

1

2 !i j∈E !a b c"σij(a  b  c) − φij(a  b  c)#(θij

c a − θij

c b) 

in which Λij

% Γij

:= ∆ijDij + ˆΓij + $a b c σij(a  b  c) + φij(a  b  c)  where ˆΓij

if (i  j) ∈ E
if (j  i) ∈ E   and D is an indicator matrix with Dij = 0 if (i  j) ∈ E or (j  i) ∈ E 
and Dij = 1 otherwise. The dual variables σij and φij are arrays of size Lj × Li × Li for all pairs
(i  j) ∈ E while ∆ and Γ are of size n × n.

−Γij

:=

The proof of this is in the Appendix. Here  I(·) is the indicator function with I(x) = 0 when x is
true and I(x) = ∞ otherwise.

Being a smooth optimization problem with simple bound constraints  Eq. 5 can be solved with
LBFGS-B [2]. For a gradient-based method like this to be practical  it must be possible to quickly
evaluate g and its gradient. This is complicated by the fact that g is deﬁned in terms of the mini-
mization of h1 with respect to Z and h2 with respect to θ. We discuss how to solve these problems
now. We ﬁrst consider the minimization of h2. This is a quadratic function of θ and can be solved
analytically via the condition that ∂

∂θ h2(θ; σ  φ) = 0. The closed form solution is

θij
c a = ψij

c a −

1

4&!b

σij(a  b  c) −!b

σij(b  a  c) −!b

φij(a  b  c) +!b

φij(b  a  c)’

∀(i  j) ∈ E  1 ≤ a  c ≤ m.. The time complexity is linear in the size of ψ.

Minimizing h1 is more involved. We assume to start that there exists an algorithm to quickly project
a matrix onto the set {Z : ∥Z∥∗ ≤ c}  i.e. to solve the optimization problem of

min

∥Z∥∗≤c

∥Z − A∥2
F .

(6)

Then  we observe that arg minZ h1 is equal to

arg min

Z

−tr(ZΛT ) + I(∥Z∥∗ ≤ c) + α∥Z − Y ∥2

F = arg min
∥Z∥∗≤c

∥Z − (Y +

1
2α

Λ)∥2
F .

4

For different norms ∥ · ∥∗  the projection algorithm will be different and can have a large impact on
efﬁciency. We will discuss in the followings sections the choices of ∥ · ∥∗ and an algorithm for the
∞-norm.

Finally  once h1 and h2 have been solved  the gradient of g is (by Danskin’s theorem [1])

∂g
∂∆ij

∂g

∂σij(a  b  c)

= − Dij ˆZij 

=

1
2

(ˆθij

c a − ˆθij

c b) − ˆZij 

∂g
∂Γij

∂g

∂φij(a  b  c)

= ˆZji − ˆZij 

= − ∂σij (a b c)g 

where ˆZ and ˆθ represent the solutions to the subproblems.

5.2 Spectral Norm

When ∥·∥∗ is set to the spectral norm  i.e. the largest singular value of a matrix  the projection in Eq.
6 can be performed by thresholding the singular values of A [3]. Theoretically  using spectral norm
will give a tighter bound on Z than other norms (Section 3). However  computing a full singular
value decomposition can be impractically slow for a graph with a large number of variables.

5.3 ∞-norm

Here  we consider setting ∥ · ∥∗ to the ∞-norm  ∥A∥∞ = maxi!j |Aij|  which measures the

maximum l1 norm of the rows of A. This norm has several computational advantages. Firstly  to
project a matrix onto a ∞-norm ball {A : ∥A∞∥ ≤ c}  we can simply project each row ai of the
matrix onto the l1-norm ball {a : ∥a∥1 ≤ c}. Duchi et al. [4] provide a method linear in the number
of nonzeros in a and logarithmic in the length of a. Thus  if Z is an n × n  matrix  Eq. 6 for the
∞-norm can be solved in time n2 and  for sufﬁciently sparse matrices  in time n log n.

A second advantage of the ∞-norm is that (unlike the spectral norm) projection in Eq. 6 preserves
the sparsity of the matrix. Thus  one can disregard the matrix D and dual variables ∆ when solving
the optimization in Theorem 7. This means that Z itself can be represented sparsely  i.e. we only
need variables for those (i  j) ∈ E. These simpliﬁcations signiﬁcantly improve the efﬁciency of
projection  with some tradeoff in accuracy.

6 Projection in Divergences

In this section  we want to ﬁnd a distribution p(x; θ) in the fast mixing family closest to a target
distribution p(x; ψ) in some divergence D(ψ  θ). The choice of divergence depends on convenience
of projection  the approximate family and the inference task. We will ﬁrst present a general algo-
rithmic framework based on projected gradient descent (Algorithm 1)  and then discuss the details
of several previously proposed divergences [11  3].

6.1 General algorithm framework for divergence minimization

The problem of projection in divergences is formulated as

D(·  ·) is some divergence measure  and ¯C := {θ : ∃Z  s.t.(θ  Z) ∈ C}  where C is the feasible set
in Eq. 4. Our general strategy for this is to use projected gradient descent to solve the optimization

D(ψ  θ) 

min
θ∈ ¯C

(7)

min

(θ Z)∈C

D(ψ  θ) 

(8)

using the joint operator to project onto C described in Section 5.

For different divergences  the only difference in projection algorithm is the evaluation of the gradient
∇θD(ψ  θ). It is clear that if (θ∗  Z ∗) is the solution of Eq. 8  then θ∗ is the solution of 7.

6.2 Divergences

5

Algorithm 1 Projected gradient descent for divergence projection

Initialize (θ1  Z1)  k ← 1.
repeat

θ′ ← θk − λ∇θD(ψ  θk)
(θk+1  Zk+1) ← projC(θ′  Zk)
k ← k + 1

until convergence

In this section  we will discuss the differ-
ent choices of divergences and correspond-
ing projection algorithms.

6.2.1 KL-divergence

is

p(x;θ)

arguably

The KL-divergence KL(ψ∥θ)

!x p(x; ψ) log p(x;ψ)

:=
the
optimal divergence for marginal inference
because it strives to preserve the marginals
of p(x; θ) and p(x; ψ). However  projection
in KL-divergence is intractable here because
the evaluation of the gradient ∇θKL(ψ∥θ)
requires the marginals of distribution ψ.

6.2.2 Piecewise KL-divergence

[3]

over

some

tractable

piecewise KL-divergence

One tractable surrogate of KL(ψ∥θ) is
the
de-
ﬁned
subgraphs.
Here  D(ψ  θ) := maxT ∈T KL(ψT ∥θT ) 
where T is a set of low-treewidth sub-
graphs. The gradient can be evaluated as
∇θD(ψ  θ) = ∇θKL(ψT ∗∥θT ∗) where
T ∗ = arg maxT ∈T KL(ψT ∥θT ). For any
T in T   KL(ψT ∥θT ) and its gradient can be
evaluated by the junction-tree algorithm.

 

4

 

Grid  Attractive only

LBP
TRW
Mean−Field
Original Parameters
Euclidean
Piecewise KL(ψ||θ) (TW 1)
Piecewise KL(ψ||θ) (TW 2)
KL(θ||ψ)

0.7

0.6

0.5

0.4

0.3

0.2

0.1

r
o
r
r

E

 
l

i

a
n
g
r
a
M

0
 
0

0.5

1

1.5
2.5
Interaction Strength

2

Edge density = 0.50  Mixed

3

3.5

LBP
TRW
Mean−Field
Original Parameters
Euclidean
Piecewise KL(ψ||θ)
KL(θ||ψ)

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

r
o
r
r

E

i

 
l
a
n
g
r
a
M

6.2.3 Reversed KL-divergence

0
 
0

0.5

1

1.5
2.5
Interaction Strength

2

3

3.5

4

The “reversed” KL-divergence KL(θ∥ψ) is
minimized by mean-ﬁeld methods.
In
general KL(θ∥ψ) is inferior to KL(ψ∥θ)
tends to
for marginal
underestimate the support of
the distri-
bution [11].
it often works well
in practice. ∇θKL(θ∥ψ) can computed

inference since it

Still 

as ∇θKL(θ∥ψ) = !x p(x; θ)(θ − ψ) ·
f (x)"f (x) − µ(θ)#   which can be approxi-

Figure 1: Mean univariate marginal error on 16 × 16
grids (top) with attractive interactions and median-
density random graphs (bottom) with mixed interac-
tions  comparing 30k iterations of Gibbs sampling af-
ter projection (onto the l∞ norm) to variational meth-
ods. The original parameters also show a lower curve
with 106 samples.

mated by samples generated from p(x; θ) [3]. In implementation  we maintain a “pool” of samples 
each of which is updated by a single Gibbs step after each iteration of Algorithm 1.

7 Experiments

The experiments below take two stages: ﬁrst  the parameters are projected (in some divergence) and
then we compare the accuracy of sampling with the resulting marginals. We focus on this second
aspect. However  we provide a comparison of the computation time for various projection algorithms
in Table 1  and when comparing the accuracy of sampling with a given amount of time  provide two

6

curves for sampling with the original parameters  where one curve has an extra amount of sampling
effort roughly approximating the time to perform projection in the reversed KL divergence.

7.1 Synthetic MRFs

Interaction strength = 2.00  Attractive Only

Our ﬁrst experiment follows that of [8  3]
in evaluating the accuracy of approximation
methods in marginal inference.
In the exper-
iments  we approximate randomly generated
MRF models with rapid-mixing distributions
using the projection algorithms described pre-
viously. Then  the marginals of fast mixing
approximate distributions are estimated by run-
ning a Gibbs chain on each distribution. These
are compared against exact marginals as com-
puted by the junction tree algorithm. We use
the mean absolute difference of the marginals
|p(Xi = 1) − q(Xi = 1)| as the accuracy mea-
sure. We compare to Naive mean-ﬁeld (MF) 
Gibbs sampling on original parameters (Gibbs) 
and Loopy belief propagation (LBP). Many
other methods have been compared against a
similar benchmark [6  8].

r
o
r
r

E

 
l

i

a
n
g
r
a
M

r
o
r
r

E

0.55

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

 
0
10

0.5

0.45

0.4

0.35

 

LBP
TRW
Mean−Field
Original Parameters
Euclidean
Piecewise KL(ψ||θ) (TW 1)
Piecewise KL(ψ||θ) (TW 2)
KL(θ||ψ)

1
10

2
10

3
10

4
10

5
10

6
10

Number of Samples

Edge density = 0.50  Interaction strength = 3.00  Mixed

 

LBP
TRW
Mean−Field
Original Parameters
Euclidean
Piecewise KL(ψ||θ)
KL(θ||ψ)

0.3

0.25

0.2

0.15

0.1

0.05

 
l

i

a
n
g
r
a
M

While our methods are for general MRFs  we
test on Ising potentials because this is a stan-
dard benchmark. Two graph topologies are
two-dimensional 16 × 16 grids and 10
used:
node random graphs  where each edge is in-
dependently present with probability pe ∈
{0.3  0.5  0.7}. Node parameters θi are uni-
form from [−dn  dn] with ﬁxed ﬁeld strength
dn = 1.0. Edge parameters θij are uniform
from [−de  de] or [0  de] to obtain mixed or at-
tractive interactions respectively  with interac-
tion strengths de ∈ {0  0.5  . . .   4}. Figure 1
shows the average marginal error at different
interaction strengths. Error bars show the stan-
dard error normalized by the number of samples  which can be interpreted as a 68.27% conﬁdence
interval. We also include time-accuracy comparisons in Figure 2. All results are averaged over 50
random trials. We run Gibbs long enough ( 106 samples) to get a fair comparison in terms of running
time.

Figure 2: Examples of the accuracy of obtained
marginals vs.
the number of samples. Top:
Grid graphs. Bottom: Median-Density Random
graphs.

2
10
Number of Samples

3
10

 
0
10

1
10

4
10

5
10

Except where otherwise stated  parameters are projected onto the ball {θ : ∥R(θ)∥∞ ≤ c}  where
c = 2.5 is larger than the value of c = 1 suggested by the proofs above. Better results are obtained
by using this larger constraint set  presumably because of looseness in the bound. For piecewise
projection  grids use simple vertical and horizontal chains of treewidth either one or two. For random
graphs  we randomly generate spanning trees until all edges are covered. Gradient descent uses a
ﬁxed step size of λ = 0.1. A Gibbs step is one “systematic-scan” pass over all variables between.
The reversed KL divergence maintains a pool of 500 samples  each of which is updated by a single
Gibbs step in each iteration.

We wish to compare the trade-off between computation time and accuracy represented by the choice
between the use of the ∞ and spectral norms. We measure the running time on 16 × 16 grids in
Table 1  and compare the accuracy in Figure 3.

The appendix contains results for a three-state Potts model on an 8×8 grid  as a test of the multivari-
ate setting. Here  the intractable divergence KL(ψ∥θ) is included for reference  with the projection
computed with the help of the junction tree algorithm for inference.

7

Table 1: Running times on 16×16 grids with attractive interactions. Euclidean projection converges
in around 5 LBFGS-B iterations. Piecewise projection (with a treewidth of 1) and reversed KL
projection use 60 gradient descent steps. All results use a single core of a Intel i7 860 processor.

Gibbs

Euclidean

Piecewise

Reversed-KL

de = 1.5
de = 3.0

30k Steps 106 Steps l∞ norm l2 norm l∞ norm l2 norm l∞ norm l2 norm
66.81s
254.25s

45.26s
13.13s
211.08s 20.12s

25.63s
12.87s
164.34s 20.73s

22.42s
22.42s

0.67s
0.67s

1.50s
3.26s

7.2 Berkeley binary image denoising

This experiment evaluates various methods
for denoising binary images from the Berke-
ley segmentation dataset downscaled from
300 × 200 to 120 × 80. The images are
binarized by setting Yi = 1 if pixel i is above
the average gray scale in the image  and
Yi = −1. The noisy image X is created by
setting: Xi = Yi+1
t1.25
 
i
in which ti is sampled uniformly from [0  1].
For
conditional
distribution Y is modeled as P (Y |X) ∝

i(1 − t1.25

) + 1−Yi

purposes 

inference

the

2

2

i

exp!β"ij YiYj + α

2 "i(2Xi − 1)Yi# 

where the pairwise strength β > 0 encourages
On this attractive-only Ising
smoothness.
potential 
the Swendsen-Wang method [12]
mixes rapidly  and so we use the resulting
samples to estimate the ground truth. The
parameters α and β are heuristically chosen to
be 0.5 and 0.7 respectively.

 

Grid  Mixed

Euclidean SP
Piecewise KL(ψ||θ) (TW 1) SP
Piecewise KL(ψ||θ) (TW 2) SP
KL(θ||ψ) SP
Euclidean Inf
Piecewise KL(ψ||θ) (TW 1) Inf
Piecewise KL(ψ||θ) (TW 2) Inf
KL(θ||ψ) Inf

0.35

0.3

0.25

0.2

0.15

0.1

0.05

r
o
r
r

E

 
l

i

a
n
g
r
a
M

0

 
0

0.5

1

1.5
2.5
Interaction Strength

2

3

3.5

4

Figure 3: The marginal error using ∞-norm pro-
jection (solid lines) and spectral-norm projection
(dotted lines) on 16x16 Ising grids.

Figure 4 shows
the decrease of average
marginal error. To compare running time  Eu-
clidean and K(θ∥ψ) projection cost approxi-
mately the same as sampling 105 and 4.8 × 105
samples respectively. Gibbs sampling on the
original parameter converges very slowly. Sam-
pling the approximate distributions from our
projection algorithms converge quickly in less
than 104 samples.

8 Conclusions

0.5

0.45

0.4

r
o
r
r

E

i

 
l
a
n
g
r
a
M

0.35

0.3

0.25

0.2

0.15

Marginal Error

 

LBP
Mean−Field
Original Parameter
Euclidean
Piecewise KL(ψ||θ) (TW 1)
KL(θ||ψ)

0.1

 
0
10

1
10

2
10

We derived sufﬁcient conditions on the parame-
ters of an MRF to ensure fast-mixing of univari-
ate Gibbs sampling  along with an algorithm to
project onto this set in the Euclidean norm. As
an example use  we explored the accuracy of
samples obtained by projecting parameters and
then sampling  which is competitive with simple variational methods as well as traditional Gibbs
sampling. Other possible applications of fast-mixing parameter sets include constraining parame-
ters during learning.

Figure 4: Average marginal error on the Berkeley
segmentation dataset.

Number of samples

3
10

4
10

5
10

6
10

Acknowledgments

NICTA is funded by the Australian Government through the Department of Communications and
the Australian Research Council through the ICT Centre of Excellence Program.

8

References

[1] Dimitri Bertsekas. Nonlinear Programming. Athena Scientiﬁc  2004. 5.1

[2] Richard H. Byrd  Peihuang Lu  Jorge Nocedal  and Ciyou Zhu. A limited memory algorithm

for bound constrained optimization. SIAM J. Sci. Comput.  16(5):1190–1208  1995. 5.1

[3] Justin Domke and Xianghang Liu. Projecting Ising model parameters for fast mixing. In NIPS 

2013. 1  5.2  6  6.2.2  6.2.3  7.1

[4] John C. Duchi  Shai Shalev-Shwartz  Yoram Singer  and Tushar Chandra. Efﬁcient projections

onto the l1-ball for learning in high dimensions. In ICML  2008. 5.3

[5] Martin E. Dyer  Leslie Ann Goldberg  and Mark Jerrum. Matrix norms and rapid mixing for

spin systems. Ann. Appl. Probab.  19:71–107  2009. 3  4  5

[6] Amir Globerson and Tommi Jaakkola. Approximate inference using conditional entropy de-

compositions. In UAI  2007. 7.1

[7] Thomas P. Hayes. A simple condition implying rapid mixing of single-site dynamics on spin

systems. In FOCS  pages 39–46  2006. 3

[8] Tamir Hazan and Amnon Shashua. Convergent message-passing algorithms for inference over

general graphs with convex free energies. In UAI  pages 264–273  2008. 7.1

[9] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT

Press  2009. 1

[10] Thomas Minka. Expectation propagation for approximate bayesian inference. In UAI  2001. 1

[11] Thomas Minka. Divergence measures and message passing. Technical report  2005. 6  6.2.3

[12] Robert H. Swendsen and Jian-Sheng Wang. Nonuniversal critical dynamics in monte carlo

simulations. Phys. Rev. Lett.  58:86–88  Jan 1987. 7.2

[13] Martin Wainwright and Michael Jordan. Graphical models  exponential families  and varia-

tional inference. Found. Trends Mach. Learn.  1(1-2):1–305  2008. 1

[14] Jonathan Yedidia  William Freeman  and Yair Weiss. Constructing free energy approximations
IEEE Transactions on Information Theory 

and generalized belief propagation algorithms.
51:2282–2312  2005. 1

9

,Xianghang Liu
Justin Domke
Alexandr Andoni
Piotr Indyk
Thijs Laarhoven
Ilya Razenshteyn
Ludwig Schmidt
Yiwen Guo
Anbang Yao
Yurong Chen