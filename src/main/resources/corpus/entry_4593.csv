2011,Recovering Intrinsic Images with a Global Sparsity Prior on Reflectance,We address the challenging task of decoupling material properties from lighting properties given a single image. In the last two decades virtually all works have concentrated on exploiting edge information to address this problem. We take a different route by introducing a new prior on reflectance  that models reflectance values as being drawn from a sparse set of basis colors. This results in a Random Field model with global  latent variables (basis colors) and pixel-accurate output reflectance values. We show that without edge information high-quality results can be achieved  that are on par with methods exploiting this source of information. Finally  we present competitive results by integrating an additional edge model. We believe that our approach is a solid starting point for future development in this domain.,Recovering Intrinsic Images with a Global Sparsity

Prior on Reﬂectance

Peter Vincent Gehler

Max Planck Institut for Informatics

pgehler@mpii.de

Carsten Rother

Microsoft Research Cambridge

carrot@microsoft.com

Martin Kiefel  Lumin Zhang  Bernhard Sch¨olkopf

Max Planck Institute for Intelligent Systems
{mkiefel lumin bs}@tuebingen.mpg.de

Abstract

We address the challenging task of decoupling material properties from lighting
properties given a single image. In the last two decades virtually all works have
concentrated on exploiting edge information to address this problem. We take a
different route by introducing a new prior on reﬂectance  that models reﬂectance
values as being drawn from a sparse set of basis colors. This results in a Random
Field model with global  latent variables (basis colors) and pixel-accurate output
reﬂectance values. We show that without edge information high-quality results
can be achieved  that are on par with methods exploiting this source of informa-
tion. Finally  we are able to improve on state-of-the-art results by integrating edge
information into our model. We believe that our new approach is an excellent
starting point for future developments in this ﬁeld.

1

Introduction

The task of recovering intrinsic images is to separate a given input image into its material-dependent
properties  known as reﬂectance or albedo  and its light-dependent properties  such as shading  shad-
ows  specular highlights  and inter-reﬂectance. A successful separation of these properties would be
beneﬁcial to a number of computer vision tasks. For example  an image which solely depends on
material-dependent properties is helpful for image segmentation and object recognition [11]  while
a clean image of shading is a valuable input to shape-from-shading algorithms.
As in most previous work in this ﬁeld  we cast the intrinsic image recovery problem into the follow-
ing simpliﬁed form  where each image pixel is the product of two components:

I = sR .

(1)
Here I ∈ R3 is the pixel’s color  in RGB space  R ∈ R3 is its reﬂectance and s ∈ R its “shading”.
Note  we use “shading” as a proxy for all light-dependent properties  e.g. shadows. The fact that
shading is only a 1D entity imposes some limitations. For example  shading effects stemming from
multiple light sources can only be modeled if all light sources have the same color.1 The goal of this
work is to estimate s and R given I. This problem is severely under-constraint  with 4 unknowns
and 3 constraints for each pixel. Hence  a trivial solution to (1) is  for instance  I = R  s = 1 for all
pixels. The main focus of this paper is on exploring sensible priors for both shading and reﬂectance.
Despite the importance of this problem surprisingly little research has been conducted in recent
years. Most of the inventions were done in the 70s and 80s. The recent comparative study [7] has
shown that the simple Retinex method [9] from the 70s is still the top performing approach. Given

1This problem can be overcome by utilizing a 3D vector for s  as done in [4]  which we however do not

consider in this work.

(a) Image I “paper1”

(b) I (in RGB)

(c) Reﬂectance R

(d) R (in RGB)

(e) Shading s

Figure 1: An image (a)  its color in RGB space (b)  the reﬂectance image (c)  its distribution in
RGB space (d)  and the shading image (e). Omer and Werman [12] have shown that an image of
a natural scene often contains only a few different “basis colorlines”. Figure (b) shows a dominant
gray-scale color-line and other color lines corresponding to the scribbles on the paper (a). These
colorlines are generated by taking a small set of “basis colors” which are then linearly “smeared”
out in RGB space. The basis colors are clearly visible in (d)  where the cluster for white (top 
right) is the dominant one. This “smearing effect” comes from properties of the scene (e.g. shading
or shadows)  and/or properties of the camera  e.g. motion blur. (Note  the few pixels in-between
clusters are due to anti-aliasing effects). In this work we approximate the basis colors by a simple
mixture of isotropic Gaussians.

the progress in the last two decades on probabilistic models  inference and learning techniques  as
well as the improved computational power  we believe that now is a good time to revisit this problem.
This work  together with the recent papers [14  4  7  15]  are a ﬁrst step in this direction.
The main motivation of our work is to develop a simple  yet powerful probabilistic model for shading
and reﬂectance estimation.
In total we use three different types of factors. The ﬁrst one is the
most commonly used factor and is key ingredient of all Retinex-based methods. The idea is to
extract those image edges which are (potentially) true reﬂectance edges and then to recover a new
reﬂectance image that contains only these edges  using a set of Poisson equations. This term on
its own is enough to recover a non-trivial decomposition  i.e. s (cid:54)= 1. The next factor is a simple
smoothness prior on shading between neighboring image pixels  and has been used by some previous
work e.g. [14]. Note  there are a few works  which we discuss in more detail later  that extend these
pairwise terms to become patch-based. The third prior term is the main contribution of our work and
is conceptually very different from the local (pairwise or patch-based) constraints of previous works.
We propose a new global (image-wide) sparsity prior on reﬂectance based on the ﬁndings of [12]
and discussed in Fig 1. In the absence of other factors this already produces non-trivial results. This
prior takes the form of a Mixture of Gaussians  and encodes the assumption that the reﬂectance value
for each pixel is drawn from some mixing components  which in this context we refer to as “basis
colors”. The complete model forms a latent variable Random Field model for which we perform
MAP estimation.
By combining the different terms we are able to outperform state-of-the art. If we use image optimal
parameter settings we perform on par with methods that use multiple images as input. To empirically
validate this we use the database introduced in the comparative study [7].

2 Related Work

There is a vast amount of literature on the problem of recovering intrinsic images. We refer the
reader to detailed surveys in [8  17  7]  and limit our attention to some few related works.
Barrow and Tenenbaum [2] were the ﬁrst to deﬁne the term “intrinsic image”. Around the same
time the ﬁrst solution to this problem was developed by Land and McCann [9] known as the Retinex
algorithm. After that the Retinex algorithm was extended to two dimensions by Blake [3] and
Horn [8]  and later applied to color images [6]. The basic Retinex algorithm is a 2-step procedure:
1) detect all image gradients which are caused by changes in reﬂectance; 2) recover a reﬂectance
image which preserves the detected reﬂectance gradients. The basic assumption of this approach
is that small image gradients are more likely caused by a shading effect and strong gradients by a
change in reﬂectance. For color images this rule can be extended by treating changes in the 1D
brightness domain differently to changes in the 2D chromaticity space.2 This method  which we
denote as “Color Retinex” was the top performing method in the recent comparison paper [7]. Note 

2Note  a gradient in chromaticity can only be caused by differently colored light sources  or inter-reﬂectance.

2

the only approach which could beat Retinex utilizes multiple images [19]. Surprisingly  the study
[7] also shows that more sophisticated methods for training the reﬂectance edge detector  using
e.g. images patches  did not perform better than the basic Retinex method. In particular the study
tested two methods of Tappen et al. [17  16]. A plausible explanation is offered  namely that these
methods may have over-ﬁtted the small amount of training data. The method [17] has an additional
intermediate step where a Markov Random Field (MRF) is used to “propagate” reﬂectance gradients
along contour lines.
The paper [15] implements the same intuition as done here  namely that there is a sparse set of re-
ﬂectances present in the scene. However both approaches bear the following differences. In [15] a
sparsity enforcing term is included  that is penalizing reﬂectance differences from some prototype
references. This term encourages all reﬂectances to take on the same value  while the model we
propose in this paper allows for a mixture of different material reﬂectances and thus keeps their
diversity. Also  in contrast to [15]  where a gradient aware wavelet transform is used as a new
representation  here we work directly in the RGB domain. By doing so we directly extend previ-
ous intrinsic image models which makes evident the gains that can be attributed to a global sparse
reﬂectance term alone.
Recently  Shen et al. [14] introduced an interesting extension of the Retinex method  which bears
some similarity with our approach. The key idea in their work is to perform a pre-processing step
where the (normalized) reﬂectance image is partitioned into a few clusters. Each cluster is treated
as a non-local “super-pixel”. Then a variant of the Retinex method is run on this super-pixel image.
The conceptual similarity to our approach is the idea of performing an image-wide clustering step.
However  the differences are that they do not formulate this idea as a joint probabilistic model over
latent reﬂectance “basis colors” and shading variables. Furthermore  every pixel in a super-pixel
must have the same intensity  which is not the case in our work. Also  they need a Retinex type of
edge term to avoid the trivial solution of s = 1.
Finally  let us brieﬂy mention techniques which use patch-based constraints  instead of pair-wise
terms. The seminal work of Freeman et al. on learning low-level vision [5] formulates a probabilistic
model for intrinsic images.
In essence  they build a patch-based prior jointly over shading and
reﬂectance.
In a new test image the best explanation for reﬂectance and shading is determined.
The key idea is that patches do overlap  and hence form an MRF  where long-range propagation
is possible. Since no large-scale ground database was available at that time  they only train and
test on computer generated images of blob-like textures. Another patch-based method was recently
suggested in [4]. They introduce a new energy term which is satisﬁed when all reﬂectance values
in a small  e.g. 3 × 3  patch lie on a plane in RGB space. This idea is derived from the Laplacian
matrix used for image matting [10]. On its own this term gives in practice often the trivial solution
s = 1. For that reason additional user scribbles are provided to achieve high-quality results.3

3 A Probabilistic Model for Intrinsic Images

The model outlined here falls into the class of Conditional Random Fields  specifying a conditional
probability distribution over reﬂectance R and shading S components for a given image I

p(s  R | I) ∝ exp (−E(s  R | I)) .

(2)
Before we describe the energy function E in detail  let us specify the notation. We will denote with
subscripts i the values at location i in the image. Thus Ii is an image pixel (vector of dimension 3) 
Ri a reﬂectance vector (a 3-vector)  si the shading (a scalar). The total number of pixels in an image
is N. With boldface we denote vectors of components  e.g. s = (s1  . . .   sN ).
There are two ways to use the relationship (1) to formulate a model for shading and reﬂectance 
corresponding to two different image likelihoods p(I | s  R). One possible way is to relax the
relation (1) and for example assume a Gaussian likelihood p(I | s  R) ∝ exp(−(cid:107)I − sR(cid:107)2) to
account for some noise in the image formation process. This yields an optimization problem with
4N unknowns. The second possibility is to assume a delta-prior around sR which results in the
i has to hold of all color channels c = {R  G  B} 
following complexity reduction. Since I c
the unknown variables are speciﬁed up to scalar multipliers  in other words the direction of Ri is
already known. We rewrite Ri = ri (cid:126)Ri  with (cid:126)Ri = Ii/(cid:107)Ii(cid:107)  leaving r = (r1  . . .   rN ) to be the
3We performed initial tests with this term. However  we found that it did not help to improve performance.

i = siRc

3

only unknown variable. The shading components can be computed using si = (cid:107)Ii(cid:107)/ri. Thus the
optimization problem is reduced to a search of N variables.
The latter reduction is commonly exploited by intrinsic image algorithms in order to simplify the
model [7  14  4] and in the remainder we will also make use of it. This allows us to write all model
parts in terms of r.
Note that there is a global scalar k by which the result s  R can be modiﬁed without effecting eq. (1) 
i.e. I = (sk)(1/kR). For visualization purpose k is chosen such that the results are visually closest
to the known ground truth.

3.1 Model
The energy function we describe here consists of three different terms that are linearly combined.
We will describe the three components and their inﬂuence in greater detail below  ﬁrst we write the
optimization problem that corresponds to a MAP solution in its most general form

min

ri αi;i=1 ... n

wsEs(r) + wrEret(r) + wclEcl(r  α).

(3)

Note  the global scale of the energy is not important  hence we can always ﬁx one non-zero weight
ws  wr  wcl to 1.
Shading Prior (Es) We expect the shading of an image to vary smoothly over the image and we
encode this in the following pairwise factors

Es(r) =(cid:88)

(cid:0)r−1

i∼j

j (cid:107)Ij(cid:107)(cid:1)2

i (cid:107)Ii(cid:107) − r−1

 

(4)

where we use a 4-connected pixel graph to encode the neighborhood relation which we denote with
i ∼ j. Because of the dependency on the inverse of r  this term is not jointly convex in r. Any
model that includes this smoothness prior thus has the (potential) problem of multiple local minima.
Empirically we have seen that  however  this function seems to be very well behaved  a large range of
different starting points for r resulted in the same minimum. Nevertheless  we use multiple restarts
with different starting points  see optimization selection 3.2.

Gradient Consistency (Eret) As discussed in the introduction  the main idea of the Retinex algo-
rithm is to disambiguate between edges that are due to shading variations from those that are caused
by material reﬂectance changes. This idea is then implemented as follows. Assume that we already
know  or have classiﬁed  that an edge at location i  j in the input image is caused by a change in re-
ﬂectance. Then we know the magnitude of the gradient that has to appear in the reﬂectance map by
noting that log(Ii)−log(Ij) = log(ri (cid:126)Ri)−log(rj (cid:126)Rj). Using the fact log((cid:107)Ii(cid:107)) = log(I c
i )−log( (cid:126)Rc
i )
(for all channels c) and assuming a squared deviation around the log gradient magnitude  this trans-
lates into the following Gaussian MRF term on the reﬂectances

(log(ri) − log(rj) − gij(I)(log((cid:107)Ii(cid:107)) − log((cid:107)Ij(cid:107))))2 .

(5)

Eret(r) =(cid:88)

i∼j

It remains to specify the classiﬁcation function g(I) for the image edges. In this work we adopt the
Color Retinex version that has been proposed in [7]. For each pixel i and a neighbor j we compute
the gradient of the intensity image and the gradient of the chromaticity change. If both gradients
exceed a certain threshold (θg and θc resp.)  the edge at i  j is classiﬁed as being a “reﬂectance edge”
and in this case gij(I) = 1. The two parameters which are the thresholds θg  θc for the intensity
and the chromaticity change are then estimated using leave-one-out-cross validation. It is worth
noting that this term is qualitatively different from the smoothness prior on shading (4) even for
pixels where gij(I) = 0. Here  the log-difference is penalized whereas the shading smoothness
does also depend on the intensity values (cid:107)Ii(cid:107) (cid:107)Ij(cid:107). By setting wcl  ws = 0 in Eq. (2) we recover
Color Retinex [7].
Global Sparse Reﬂectance Prior (Ecl ) Motivated by the ﬁndings of [12] we include a term
that acts as a global potential on the reﬂectances and favors the decomposition into some few
reﬂectance clusters. We assume C different reﬂectance clusters  each of which is denoted by
˜Rc  c ∈ {1  . . .   C}. Every reﬂectance component ri belongs to one of the clusters and we de-
note its cluster membership with the variable αi ∈ {1  . . .   C}. This is summarized in the following
energy term

4

Figure 2: A crop from the image “panther”. Left: input image I and true decomposition (R  s). Note 
the colors in reﬂectance image (True R) have been modiﬁed on purpose such that there are exactly 4
different colors. The second column shows a clustering (here from the solution with ws = 0)  where
each cluster has an arbitrary color. The remaining columns show results with various settings for C
and ws (left reﬂectance image  right shading image). Top row is the result for C = 4 and bottom
row for C = 50 clusters  columns are results for ws = 0  10−5  and 0.1. Below the images is the
corresponding LMSE score (described in Section 4.1). (Note  results are visually slightly different
since the unknown overall global scaling factor k is set differently  that is I = (sk)(1/kR).

n(cid:88)

Ecl(r  α) =

(cid:107)ri (cid:126)Ri − ˜Rαi(cid:107)2.

(6)

i=1

Here  both continuous r and discrete α variables are mixed. This represents a global potential  since
the cluster means depend on the assignment of all pixels in the image. For ﬁxed α  this term is
convex in r and for ﬁxed r the optimum of α is a simple assignment problem. The cluster means ˜Rc
are optimally determined given r and α: ˜Rc =

(cid:80)

1

i:αi=c ri (cid:126)Ri.

|{i:αi=c}|

Relationship between Ecl and Es The example in Figure 2 highlights the inﬂuence of the terms.
We use a simpliﬁed model (2)  namely Ecl + wsEs  and vary ws as well as the number of clusters.
Let us ﬁrst consider the case where ws = 0 (third column).
Independent of the clustering we
get an imperfect result. This is expected since there is no constraint across clusters. Hence the
shading within one cluster looks reasonable  but is not aligned across clusters. By adding a little
bit of smoothing (ws = 10−5; 4’th column)  this problem is cured for both clusterings. It is very
important to note that too many clusters (here C=50) do not affect the result very much. The reason
is that enough clustering constraints are present to recover the variation in shading. If we were to
give each pixel its own cluster this would no longer be true and we would get the trivial solution of
s = 1. Finally  results deteriorate when the smoothing term is too strong (last column ws = 0.1) 
since it prefers a constant shading. Note  that for this simple toy example the smoothness prior was
not important  however for real images the best results are achieved by using a non-zero ws.

3.2 Optimization of (3)
The MAP problem (3) consists of
both discrete and continuous vari-
ables and we solve it using coordinate
descent. The entire algorithm is sum-
marized in Algorithm 1. 4
Given an initial value for α we have
seen empirically that our function
tends to yield same solutions  irre-
spective of the starting point r. In or-
der to be also robust with respect to
this initial choice  we choose from a range of initial r values as described next. From these start-
ing points we choose the one with the lowest objective value (energy) and its corresponding result.

Algorithm 1 Coordinate Descent for solving (3)
1: Select r0 as described in the text
2: α0 ← K-Means clustering of {r0
3: t ← 0
i
4: repeat
5:
6:
7:
8:
9: until E(rt−1  αt−1) − E(rt  αt) < θ

rt+1 ← optimize (3) with αt ﬁxed
i:αi=c ri (cid:126)Ri/|{i : αi = c}|
αt+1 ← assign new cluster labels with rt+1 ﬁxed
t ← t + 1

˜Rc =(cid:80)

(cid:126)Ri  i = 1  . . .   N}

4Code available http://people.tuebingen.mpg.de/mkiefel/projects/intrinsic

5

comment
Color Retinex
no edge information
Col-Ret+ global term
full model

Es Ecl Eret
(cid:88)
-
-
(cid:88) (cid:88)
-
(cid:88)
(cid:88)
-
(cid:88)
(cid:88) (cid:88)

29.5
30.0
27.2
27.4

LOO-CV best single

29.5
30.6
24.4
24.4

image opt.

25.5
18.2
18.1
16.1

Table 1: Comparing the effect of including different terms. The column “best-single” is the pa-
rameter set that works best on all 16 images jointly  “image opt.” is the result when choosing the
parameters optimal for each image individually  based on ground truth information.
We have seen empirically that this procedure gives stable results. For instance  we virtually always
achieve a lower energy compared to using the ground truth r as initial start point.

for a given ﬁxed α this is implemented using a conjugate gradient descent solver [1].

It is reasonable to assume that the output has a ﬁxed range  i.e. 0 ≥ Rc

i   si ≥ 1
Initialization of r
(for all c  i).5 In particular  this is true for the data in [7]. From these constraints we can derive
that (cid:107)Ii(cid:107) ≥ ri ≥ 3. Given that  we use the following three starting points for r  by varying γ ∈
{0.3  0.5  0.7}: ri = γ(cid:107)Ii(cid:107) + 3(1 − γ). Additionally we choose the start point r = 1. From these
four different initial settings we choose the result which corresponds to the lowest ﬁnal energy.
Initialization of α Given an initial value for r we can compute the terms in Eq.(6) and use K-
Means clustering to optimize it. We use the best solution from ﬁve restarts.
Updating r
This typically converges in some few hundred iterations for the images used in the experiments.
Updating α for given r this is a simple assignment problem: αi = argminc=1 ... C(cid:107)ri (cid:126)Ri − ˜Rc(cid:107)2.
4 Experiments
For the empirical evaluation we use the intrinsic image database that has been introduced in [7].
This dataset consists of 16 different images for all of which the ground truth shading and reﬂectance
components are available. We refer to [7] for details on how this data was collected. Some of the
images can be seen in Figure 3. In all experiments we compare against Color Retinex which was
found to be the best performing method among those that take a single image as input. The method
from [19] yields better results but requires multiple input images from different light variations.
4.1 Error metric
We report the performance of the algorithms using the two different error metrics that have been
suggested by the creators of the database [7]. The ﬁrst metric is the average of the localized mean
squared error (LMSE) between the predicted and true shading and predicted and true reﬂectance
image. 6 Since the LMSE vary considerably we also use the average rank of the algorithm.
4.2 Experimental set-up and parameter learning
All free parameters of the models  e.g. the weights wcl  ws  wr and the gradient thresholds θc  θg
have been chosen using a leave-one-out estimate (LOO-CV). Due to the high variance of the scores
for the images we used the median error to score the parameters. Thus for image i the parameter
was chosen that leads to the lowest median error on all images except i. Additionally we record the
best single parameter set that works well on all images  and the score that is obtained when using
the optimal parameters on each image individually. Although the latter estimate involves knowing
ground truth estimates we are interested in the lower bound of the performance  in an interactive
scenario a user can provide additional information to achieve this  as in [4].
We select the parameters from the following ranges. Whenever used  we ﬁx wcl = 1 since it
sufﬁces to specify the relative difference between the parameters. For models using both the cluster
and shading smoothness terms  we select from ws ∈ {0.001  0.01  0.1}  for models that use the
cluster and Color Retinex term wr ∈ {0.001  0.01  0.1  1  10}. When all three terms are non-zero 
we vary ws as above paired with wr ∈ ×{0.1ws  ws  10ws}. The gradient thresholds are varied
in θg  θc ∈ {0.075  1} which yields four possible conﬁgurations. The reﬂectance cluster count is
varied in C ∈ {10  50  150}.

5This assumption is violated if there is no global scalar k such that 0 ≥ (1/kRc
6We multiply by 1000 for easier readability

i )  (ksi) ≥ 1.

6

-
-

-
-
n/a
-

56∗
39∗
n/a
n/a
72.6
40.7
29.5
27.4
21.5
16.4

4.3 Comparison - Model variations
In a ﬁrst set of experiments we investigate the inﬂuence of using combinations of the prior terms
described in Section 3.1. The numerical results are summarized in Table 1.
The ﬁrst observation is that the Color Retinex algorithm (1st row) performs about similar to the
system using a shading smoothness prior together with the global factor Ecl (2nd row). Note that
the latter system does not use any gradient information for estimation. This conﬁrms our intuition
that the term Ecl provides strong coupling information between reﬂectance components  as also
discussed in Figure 2. The lower value for the image optimal setting of 18.2 compared to 25.5 for
Color Retinex indicates that one would beneﬁt from a better parameter estimate  i.e. the ﬂexibility
of this algorithm is higher. Equipping Color Retinex with the global reﬂectance term improves all
recorded results (3rd vs 2nd row). Again it seems that the LOO-CV parameter estimation is more
stable in this case. Combining all three parts (4th row) does not improve the results over Color
Retinex with the reﬂectance prior. With knowledge about the optimal image parameter it yields a
lower LMSE score (16.1 vs 18.1).
4.4 Comparison to Literature

LOO-CV rank

best single

im. opt.

-
-
n/a
n/a
5.1
4.9
3.7
3.0
2.7
1.7

TAP05 [17]
TAP06 [16]
SHE [14]+
SHE [15]×
BAS [7]
Gray-Ret [7]
Col-Ret
full model
Weiss [19]
Weiss+Ret [7]

36.6
28.9
25.5
16.1
21.5
15.0

56.2
(20.4)
60.3
40.7
29.5
24.4
21.5
16.4

In Table 2 we compare the numer-
ical results of our method to other
intrinsic image algorithms. We
again include the single best pa-
rameter and image dependent opti-
mal parameter set. Although those
are positively biased and obviously
decrease with model complexity
we believe that they are informa-
tive  given the parameter estimation
Table 2: Method comparison with other intrinsic image algo-
problems due to the diverse and
rithms also compared in [7]. Refer to Tab. 1 for a description
small database. The full model us-
of the quantities. Note that the last two methods from [19]
ing all terms Ecl  Es and Ecret im-
use multiple input images. For entries ’-’ we had no individ-
proves over all the compared meth-
ual results (and no code)  the two numbers marked ∗ are esti-
ods that use only a single image as
mated from Fig4.a [7]. SHE+ is our implementation. SHE×
input  but SHE× (see below). The
Note that in [15] results were only given for 13 of 16 images
difference in rank between (Col-
from [7]. The additional data was kindly provided by authors.
Ret) and (full model) indicates that
the latter model is almost always better (direct comparison: 13 out of 16 images) than Color Retinex
alone. The full model is even better on 6/16 images than the Weiss algorithm [19] that uses multiple
images. Regarding the results of SHE×  we could not resolve with certainty whether the reported
results should be compared as “best single” or “im.opt.” (most parameters in [15] are common to
all images  the strategy for setting λmax is not entirely speciﬁed). Assuming “best single” SHE× is
better in terms of LMSE  in direct comparison both models are better on 8/16 images. Comparing
as an “im.opt.” setting  our full model yields lower LMSE and is better on 12/16 images.
4.5 Visual Comparison
Additionally to the quantitative numbers we present some visual comparison in Figure 3  since the
numbers not always reﬂect a visually pleasing results. For example note that the method BAS that
either attributes all variations to shading (r = 1) or to reﬂectance alone (s = 1) already yields a
LMSE of 36.6  if for every image the optimal choice between the two is made. Numerically this
is better than [16  17] and “Gray-Ret” with proper model selection. However the results of those
algorithms are of course visually more pleasing. We have also tested our method on various other
real-world images and results are visually similar to [15  4]. Due to missing ground truth and lack
of space we do not show them.
Figure 3 shows results with various models and settings. The “turtle” example (top three rows)
shows the effect of the global term. Without the global term (Color Retinex with LOO-CV and
image optimal) the result is imperfect. The key problem of Retinex is highlighted in the two zoom-
in pictures with blue border (second column  left side). The upper one shows the detected edges in
black. As expected the Retinex result has discontinuities at these edges  but over-smooths otherwise
(lower picture). With a global term (remaining three results) the images look visually much better.

7

Figure 3: Various results obtained with different methods and settings (more in supplementary ma-
terial); For each result: left reﬂectance image  right shading image

Note that the third row shows an extreme variation for the full model when switching from image
optimal setting to LOO-CV setting. The example “teabag2” illustrates nicely the point that Color
Retinex and our model without edge term (i.e. no Retinex term) achieve very complementary results.
Our model without edges is sensitive to edge transitions  while Color Retinex has problems with ﬁne
details  e.g. the small text below “TWININGS”. Combing all terms (full model) gives the best result
with lowest LMSE score (16.4). Note  in this case we chose for both methods the image optimal
settings to illustrate the potential of each model.

5 Discussion and Conclusion

We have introduced a new probabilistic model for intrinsic images that explicitly models the re-
ﬂectance formation process. Several extensions are conceivable  e.g. one can relax the condition
I = sR to allow deviations. Another reﬁnement would be to replace the Gaussian cluster term
with a color line term [12]. Building on the work of [5  4] one can investigate various higher-order
(patch-based) priors for both reﬂectance and shading.
A main concern is that in order to develop more advanced methods a larger and even more diverse
database than the one of [7] is needed. This is especially true to enable learning of richer models
such as Fields of Experts [13] or Gaussian CRFs [18]. We acknowledge the complexity of collecting
ground truth data  but do believe that the creation of a new  much enlarged dataset  is a necessity for
future progress in this ﬁeld.

8

References
[1] www.gatsby.ucl.ac.uk/˜edward/code/minimize.
[2] H. G. Barrow and J. M. Tenenbaum. Recovering intrinsic scene characteristics from images. Computer

Vision Systems  1978.

[3] A. Blake. Boundary conditions for lightness computation in mondrian world. Computer Vision  Graphics 

and Image Processing  1985.

[4] A. Bousseau  S. Paris  and F. Durand. User assisted intrinsic images. SIGGRAPH Asia  2009.
[5] W. T. Freeman  E. C. Pasztor  and O. T. Carmichael. Learning low-level vision. International Journal of

Computer Vision (IJCV)  2000.

[6] B. V. Funt  M. S. Drew  and M. Brockington. Recovering shading from color images.

Conference on Computer Vision (ECCV)  1992.

In European

[7] R. Grosse  M. K. Johnson  E. H. Adelson  and W. T. Freeman. Ground-truth dataset and baseline evalua-

tions for intrinsic image algorithms. In International Conference on Computer Vision (ICCV)  2009.

[8] B. K. Horn. Robot Vision. MIT press  1986.
[9] E. Land and J. McCann. Lightness and retinex theory. Journal of the Optical Society of America  1971.
[10] A. Levin  D. Lischinski  and Y. Weiss. A closed form solution to natural image matting. IEEE Transac-

tions on Pattern Analysis and Machine Intelligence (PAMI)  30(2)  2008.

[11] Y.-H. W. Ming Shao. Recovering facial intrinsic images from a single input. Lecture Notes in Computer

Science  2009.

[12] I. Omer and M. Werman. Color lines: Image speciﬁc color representation.

Computer Vision and Pattern Recognition (CVPR)  2004.

In IEEE Conference on

[13] S. Roth and M. J. Black. Fields of experts. International Journal of Computer Vision (IJCV)  82(2):205–

229  2009.

[14] L. Shen  P. Tan  and S. Lin. Intrinsic image decomposition with non-local texture cues. In IEEE Confer-

ence on Computer Vision and Pattern Recognition (CVPR)  2008.

[15] L. Shen and C. Yeo. Intrinsic images decomposition using a local and global sparse representation of

reﬂectance. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  2011.

[16] M. Tappen  E. Adelson  and W. Freeman. Estimating intrinsic component images using non-linear regres-

sion. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  2006.

[17] M. Tappen  W. Freeman  and E. Adelson. Recovering intrinsic images from a single image. IEEE Trans-

actions on Pattern Analysis and Machine Intelligence (PAMI)  2005.

[18] M. Tappen  C. Liu  E. H. Adelson  and W. T.Freeman. Learning gaussian conditional random ﬁelds for

low-level vision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  2007.

[19] Y. Weiss. Deriving intrinsic images from image sequences. In International Conference on Computer

Vision (ICCV)  2001.

9

,Mohsen Bayati
Murat Erdogdu
Andrea Montanari
Jan Drugowitsch
Ruben Moreno-Bote
Alexandre Pouget
Megasthenis Asteris
Dimitris Papailiopoulos
Anastasios Kyrillidis
Alexandros Dimakis