2015,Efficient Output Kernel Learning for Multiple Tasks,The paradigm of multi-task learning is that one can achieve better generalization by learning tasks jointly and thus exploiting the similarity between the tasks rather than learning them independently of each other. While previously the relationship between tasks had to be user-defined in the form of an output kernel  recent  approaches jointly learn the tasks and the output kernel. As the output kernel is a positive semidefinite matrix  the resulting optimization problems are not scalable in the  number of tasks as an eigendecomposition is required in each step. Using the theory of positive semidefinite kernels we show in this paper that for a certain class of regularizers on the output kernel  the constraint of being positive semidefinite can be dropped as it is automatically satisfied for the relaxed problem. This leads to an unconstrained dual problem which can be solved efficiently. Experiments on several multi-task and multi-class data sets illustrate the efficacy of our approach in terms of computational efficiency as well as generalization performance.,Efﬁcient Output Kernel Learning for Multiple Tasks

Pratik Jawanpuria1  Maksim Lapin2  Matthias Hein1 and Bernt Schiele2

1Saarland University  Saarbr¨ucken  Germany

2Max Planck Institute for Informatics  Saarbr¨ucken  Germany

Abstract

The paradigm of multi-task learning is that one can achieve better generalization
by learning tasks jointly and thus exploiting the similarity between the tasks rather
than learning them independently of each other. While previously the relationship
between tasks had to be user-deﬁned in the form of an output kernel  recent ap-
proaches jointly learn the tasks and the output kernel. As the output kernel is a
positive semideﬁnite matrix  the resulting optimization problems are not scalable
in the number of tasks as an eigendecomposition is required in each step. Using
the theory of positive semideﬁnite kernels we show in this paper that for a certain
class of regularizers on the output kernel  the constraint of being positive semidef-
inite can be dropped as it is automatically satisﬁed for the relaxed problem. This
leads to an unconstrained dual problem which can be solved efﬁciently. Experi-
ments on several multi-task and multi-class data sets illustrate the efﬁcacy of our
approach in terms of computational efﬁciency as well as generalization perfor-
mance.

1

Introduction

Multi-task learning (MTL) advocates sharing relevant information among several related tasks dur-
ing the training stage. The advantage of MTL over learning tasks independently has been shown
theoretically as well as empirically [1  2  3  4  5  6  7].
The focus of this paper is the question how the task relationships can be inferred from the data.
It has been noted that naively grouping all the tasks together may be detrimental [8  9  10  11].
In particular  outlier tasks may lead to worse performance. Hence  clustered multi-task learning
algorithms [10  12] aim to learn groups of closely related tasks. The information is then shared only
within these clusters of tasks. This corresponds to learning the task covariance matrix  which we
denote as the output kernel in this paper. Most of these approaches lead to non-convex problems.
In this work  we focus on the problem of directly learning the output kernel in the multi-task learning
framework. The multi-task kernel on input and output is assumed to be decoupled as the product
of a scalar kernel and the output kernel  which is a positive semideﬁnite matrix [1  13  14  15]. In
classical multi-task learning algorithms [1  16]  the degree of relatedness between distinct tasks is
set to a constant and is optimized as a hyperparameter. However  constant similarity between tasks
is a strong assumption and is unlikely to hold in practice. Thus recent approaches have tackled the
problem of directly learning the output kernel. [17] solves a multi-task formulation in the framework
of vector-valued reproducing kernel Hilbert spaces involving squared loss where they penalize the
Frobenius norm of the output kernel as a regularizer. They formulate an invex optimization prob-
lem that they solve optimally. In comparison  [18] recently proposed an efﬁcient barrier method
to optimize a generic convex output kernel learning formulation. On the other hand  [9] proposes a
convex formulation to learn low rank output kernel matrix by enforcing a trace constraint. The above
approaches [9  17  18] solve the resulting optimization problem via alternate minimization between
task parameters and the output kernel. Each step of the alternate minimization requires an eigen-

1

value decomposition of a matrix having as size the number of tasks and a problem corresponding to
learning all tasks independently.
In this paper we study a similar formulation as [17]. However  we allow arbitrary convex loss
functions and employ general p-norms for p ∈ (1  2] (including the Frobenius norm) as regularizer
for the output kernel. Our problem is jointly convex over the task parameters and the output kernel.
Small p leads to sparse output kernels which allows for an easier interpretation of the learned task
relationships in the output kernel. Under certain conditions on p we show that one can drop the
constraint that the output kernel should be positive deﬁnite as it is automatically satisﬁed for the
unconstrained problem. This signiﬁcantly simpliﬁes the optimization and our result could also be of
interest in other areas where one optimizes over the cone of positive deﬁnite matrices. The resulting
unconstrained dual problem is amenable to efﬁcient optimization methods such as stochastic dual
coordinate ascent [19]  which scale well to large data sets. Overall we do not require any eigenvalue
decomposition operation at any stage of our algorithm and no alternate minimization is necessary 
leading to a highly efﬁcient methodology. Furthermore  we show that this trick not only applies to
p-norms but also applies to a large class of regularizers for which we provide a characterization.
Our contributions are as follows: (a) we propose a generic p-norm regularized output kernel matrix
learning formulation  which can be extended to a large class of regularizers; (b) we show that the
constraint on the output kernel to be positive deﬁnite can be dropped as it is automatically satisﬁed 
leading to an unconstrained dual problem; (c) we propose an efﬁcient stochastic dual coordinate
ascent based method for solving the dual formulation; (d) we empirically demonstrate the superiority
of our approach in terms of generalization performance as well as signiﬁcant reduction in training
time compared to other methods learning the output kernel.
The paper is organized as follows. We introduce our formulation in Section 2. Our main technical
result is discussed in Section 3. The proposed optimization algorithm is described in Section 4. In
Section 5  we report the empirical results. All the proofs can be found in the supplementary material.

2 The Output Kernel Learning Formulation

We ﬁrst introduce the setting considered in this paper. We denote the number of tasks by T . We
assume that all tasks have a common input space X and a common positive deﬁnite kernel function
k : X × X → R. We denote by ψ(·) the feature map and by Hk the reproducing kernel Hilbert
i=1  where xi ∈ X   ti is the
space (RKHS) [20] associated with k. The training data is (xi  yi  ti)n
task the i-th instance belongs to and yi is the corresponding label. Moreover  we have a positive
deﬁnite matrix Θ ∈ ST
+ is the set of T × T symmetric and
positive semideﬁnite (p.s.d.) matrices.
If one arranges the predictions of all tasks in a vector one can see multi-task learning as learning a
vector-valued function in a RKHS [see 1  13  14  15  18  and references therein]. However  in this
paper we use the one-to-one correspondence between real-valued and matrix-valued kernels  see
[21]  in order to limit the technical overhead. In this framework we deﬁne the joint kernel of input
space and the set of tasks M : (X × {1  . . .   T}) × (X × {1  . . .   T}) → R as

+ on the set of tasks {1  . . .   T}  where ST

We denote the corresponding RKHS of functions on X × {1  . . .   T} as HM and by (cid:107)·(cid:107)HM
corresponding norm. We formulate the output kernel learning problem for multiple tasks as

(1)
the

M(cid:0)(x  s)  (z  t)(cid:1) = k(x  z)Θ(s  t) 
n(cid:88)

L(cid:0)yi  F (xi  ti)(cid:1) +

(cid:107)F(cid:107)2

C

1
2

i=1

Θ∈ST

min
+  F∈HM

(2)
where L : R × R → R is the convex loss function (convex in the second argument)  V (Θ) is a
convex regularizer penalizing the complexity of the output kernel Θ and λ ∈ R+ is the regularization
parameter. Note that (cid:107)F(cid:107)2
implicitly depends also on Θ. In the following we show that (2) can
be reformulated into a jointly convex problem in the parameters of the prediction function and the
output kernel Θ. Using the standard representer theorem [20] (see the supplementary material) for
ﬁxed output kernel Θ  one can show that the optimal solution F ∗ ∈ HM of (2) can be written as

+ λ V (Θ)

HM

HM

F ∗(x  t) =

γisk(xi  x)Θ(s  t).

(3)

T(cid:88)

n(cid:88)

γisM(cid:0)(xi  s)  (x  t)(cid:1) =

T(cid:88)

n(cid:88)

s=1

i=1

s=1

i=1

2

With the explicit form of the prediction function one can rewrite the main problem (2) as

n(cid:88)

L(cid:0)yi 

T(cid:88)

n(cid:88)

i=1

s=1

j=1

Θ∈ST

min
+  γ∈Rn×T

C

(cid:1) +

1
2

T(cid:88)

n(cid:88)

r s=1

i j=1

γjskjiΘs ti

γirγjskijΘrs + λ V (Θ) 

(4)

where Θrs = Θ(r  s) and kij = k(xi  xj). Unfortunately  problem (4) is not jointly convex in Θ
and γ due to the product in the second term. A similar problem has been analyzed in [17]. They
could show that for the squared loss and V (Θ) = (cid:107)Θ(cid:107)2
F the corresponding optimization problem is
invex and directly optimize it. For an invex function every stationary point is globally optimal [22].
We follow a different path which leads to a formulation similar to the one of [2] used for learning
an input mapping (see also [9]). Our formulation for the output kernel learning problem is jointly
convex in the task kernel Θ and the task parameters. We present a derivation for the general RKHS
Hk  analogous to the linear case presented in [2  9]. We use the following variable transformation 

βit =

Θtsγis  i = 1  . . .   n  s = 1  . . .   T 

resp.

γis =

In the last expression Θ−1 has to be understood as the pseudo-inverse if Θ is not invertible. Note
that this causes no problems as in case Θ is not invertible  we can without loss of generality restrict
γ in (4) to the range of Θ. The transformation leads to our ﬁnal problem formulation  where the
prediction function F and its squared norm (cid:107)F(cid:107)2

can be written as

(cid:0)Θ−1(cid:1)

T(cid:88)

t=1

stβit.

T(cid:88)

s=1

srβisβjrk(xi  xj).

srβisβjrkij + λ V (Θ)

(5)

(6)

i=1

HM

(cid:107)F(cid:107)2

F (x  t) =

βitk(xi  x) 

We get our ﬁnal primal optimization problem

n(cid:88)
n(cid:88)

n(cid:88)
T(cid:88)
(cid:0)Θ−1(cid:1)
T(cid:88)
n(cid:88)
(cid:0)Θ−1(cid:1)
lations in [9  17]. With the task weight vectors wt =(cid:80)n

L(cid:0)yi 

min
+  β∈Rn×T

(cid:1) +

n(cid:88)

βjtikji

r s=1

i j=1

r s=1

i j=1

Θ∈ST

1
2

=

HM

i=1

j=1

C

(cid:107)F(cid:107)2

HM

=

r s=1

i j=1

T(cid:88)

n(cid:88)
(cid:0)Θ−1(cid:1)
=(cid:80)T

Before we analyze the convexity of this problem  we want to illustrate the connection to the formu-
j=1 βjtψ(xj) ∈ Hk we get predictions as
F (x  t) = (cid:104)wt  ψ(x)(cid:105) and one can rewrite

srβisβjrk(xi  xj) =

T(cid:88)

(cid:0)Θ−1(cid:1)

r s=1

sr (cid:104)ws  wt(cid:105) .

This identity is known for vector-valued RKHS  see [15] and references therein. When Θ is κ times
the identity matrix  then (cid:107)F(cid:107)2
and thus (2) is learning the tasks independently. As
mentioned before the convexity of the expression of (cid:107)F(cid:107)2
is crucial for the convexity of the full
problem (6). The following result has been shown in [2] (see also [9]).
Lemma 1 Let R(Θ) denote the range of Θ ∈ ST
+ × Rn×T → R ∪ {∞} deﬁned as
function f : ST

+ and let Θ† be the pseudoinverse. The extended

(cid:107)wt(cid:107)2

HM

HM

t=1

κ

(cid:80)n

(cid:0)Θ†(cid:1)

r s=1

i j=1

(cid:40)(cid:80)T

∞

f (Θ  β) =

is jointly convex.

srβisβjrk(xi  xj) 

if βi· ∈ R(Θ) ∀ i = 1  . . .   n 
else .

 

[9] uses the constraint Trace(Θ) ≤ 1 instead
The formulation in (6) is similar to [9  17  18].
of a regularizer V (Θ) enforcing low rank of the output kernel. On the other hand  [17] employs
squared Frobenius norm for V (Θ) with squared loss function. [18] proposed an efﬁcient algorithm
for convex V (Θ). Instead we think that sparsity of Θ is better to avoid the emergence of spurious
relations between tasks and also leads to output kernels which are easier to interpret. Thus we
propose to use the following regularization functional for the output kernel Θ:

T(cid:88)

t t(cid:48)=1

V (Θ) =

|Θtt(cid:48)|p = (cid:107)Θ(cid:107)p
p  

3

for p ∈ [1  2]. Several approaches [9  17  18] employ alternate minimization scheme  involving
costly eigendecompositions of T × T matrix per iteration (as Θ ∈ ST
+). In the next section we show
that for a certain set of values of p one can derive an unconstrained dual optimization problem which
+ cone. The resulting unconstrained dual problem
thus avoids the explicit minimization over the ST
can then be easily optimized by stochastic coordinate ascent. Having explicit expressions of the
primal variables Θ and β in terms of the dual variables allows us to get back to the original problem.

3 Unconstrained Dual Problem Avoiding Optimization over ST
+

The primal formulation (6) is a convex multi-task output kernel learning problem. The next lemma
derives the Fenchel dual function of (6). This still involves the optimization over the primal variable
Θ ∈ ST
+. A main contribution of this paper is to show that this optimization problem over the
+ cone can be solved with an analytical solution for a certain class of regularizers V (Θ). In the
ST
following we denote by αr := {αi | ti = r} the dual variables corresponding to task r and by Krs
the kernel matrix (k(xi  xj)| ti = r  tj = s) corresponding to the dual variables of tasks r and s.
Lemma 2 Let L∗

i be the conjugate function of the loss Li : R → R  u (cid:55)→ L(yi  u)  then

q : Rn → R  q(α) = −C

Θrs (cid:104)αr  Krsαs(cid:105) − V (Θ)

(7)

n(cid:88)

i=1

L∗

i

(cid:16) − αi

(cid:17) − λ max

(cid:16) 1

T(cid:88)

C

Θ∈ST

+

2λ

r s=1

(cid:17)

F (x  s) =(cid:80)n

is the dual function of (6)  where α ∈ Rn are the dual variables. The primal variable β ∈ Rn×T
in (6) and the prediction function F can be expressed in terms of Θ and α as βis = αiΘsti and

j=1 αjΘstj k(xj  x) respectively  where tj is the task of the j-th training example.

We now focus on the remaining maximization problem in the dual function in (7)

Θrs (cid:104)αr  Krsαs(cid:105) − V (Θ).

(8)

T(cid:88)

r s=1

1
2λ

max
Θ∈ST
+

This is a semideﬁnite program which is computationally expensive to solve and thus prohibits to
(cid:80)T
scale the output kernel learning problem to a large number of tasks. However  we show in the
following that this problem has an analytical solution for a subset of the regularizers V (Θ) =
r s=1 |Θrs|p for p ≥ 1. For better readability we defer a more general result towards the end
1
2
of the section. The basic idea is to relax the constraint on Θ ∈ RT×T in (8) so that it is equivalent
to the computation of the conjugate V ∗ of V . If the maximizer of the relaxed problem is positive
semi-deﬁnite  one has found the solution of the original problem.
Theorem 3 Let k ∈ N and p = 2k

T(cid:88)

max
Θ∈ST
+

r s=1

Θrsρrs − 1
2

|Θrs|p =

(cid:17)2k T(cid:88)

2k−1   then with ρrs = 1

2λ (cid:104)αr  Krsαs(cid:105) we have
(cid:16) 2k − 1
T(cid:88)
(cid:16) 2k − 1
(cid:17)2k−1 (cid:104)αr  Krsαs(cid:105)2k−1  

r  s = 1  . . .   T.

4k − 2

2kλ

r s=1

r s=1

1

Θ∗
rs =

2kλ

and the maximizer is given by the positive semi-deﬁnite matrix

(cid:104)αr  Krsαs(cid:105)2k  

(9)

(10)

Plugging the result of the previous theorem into the dual function of Lemma 2 we get for k ∈ N and
p = 2k

p the following unconstrained dual of our main problem (6):

2k−1 with V (Θ) = (cid:107)Θ(cid:107)p
n(cid:88)

−C

max
α∈Rn

L∗

i

(cid:16) − αi

(cid:17) − λ

C

4k − 2

i=1

(cid:16) 2k − 1

(cid:17)2k T(cid:88)

2kλ

r s=1

(cid:104)αr  Krsαs(cid:105)2k .

(11)

C we effectively have only one hyper-
Note that by doing the variable transformation κi
parameter in (11). This allows us to cross-validate more efﬁciently. The range of admissible values
for p in Theorem 3 lies in the interval (1  2]  where we get for k = 1 the value p = 2 and as k → ∞

:= αi

4

Table 1: Examples of regularizers V (Θ) together with their generating function φ and the explicit
2λ (cid:104)αr  Krsαs(cid:105). The optimal value of (8) is given
form of Θ∗ in terms of the dual variables  ρrs = 1
in terms of φ as max
Θ∈RT×T

r s=1 φ(ρrs).

(cid:104)ρ  Θ(cid:105) − V (Θ) =(cid:80)T
T(cid:80)

|Θrs| 2k

2k−1

r s=1

φ(z)

z2k

2k   k ∈ N

ez =(cid:80)∞
cosh(z) − 1 =(cid:80)∞

zk
k!

k=0

k=1

z2k
(2k)!

V (Θ)
2k−1
2k

 T(cid:80)
(cid:16)
T(cid:80)

∞

r s=1

r s=1

rs

Θ∗
ρ2k−1

rs

eρrs

Θrs log(Θrs) − Θrs

Θrs arcsinh(Θrs) −(cid:112)1 + Θ2

rs

if Θrs > 0∀r  s
else .

(cid:17)

+ T 2

arcsinh(ρrs)

we have p → 1. The regularizer for p = 2 together with the squared loss has been considered in the
primal in [17  18]. Our analytical expression of the dual is novel and allows us to employ stochastic
dual coordinate ascent to solve the involved primal optimization problem. Please also note that by
optimizing the dual  we have access to the duality gap and thus a well-deﬁned stopping criterion.
This is in contrast to the alternating scheme of [17  18] for the primal problem which involves costly
matrix operations. Our runtime experiments show that our solver for (11) outperforms the solvers
of [17  18]. Finally  note that even for suboptimal dual variables α  the corresponding Θ matrix in
(10) is positive semideﬁnite. Thus we always get a feasible set of primal variables.

Characterizing the set of convex regularizers V which allow an analytic expression for the
dual function The previous theorem raises the question for which class of convex  separable reg-
ularizers we can get an analytical expression of the dual function by explicitly solving the opti-
mization problem (8) over the positive semideﬁnite cone. A key element in the proof of the pre-
vious theorem is the characterization of functions f : R → R which when applied elementwise
+ result in a p.s.d. matrix  that is
f (A) = (f (aij))T
f (A) ∈ ST
Theorem 4 ([23]) Let f : R → R and A ∈ ST
wise application of f to A. It holds ∀ T ≥ 2  A ∈ ST

i j=1 to a positive semideﬁnite matrix A ∈ ST

+. This set of functions has been characterized by Hiai [23].

i j=1 the element-
+ if and only if f is analytic

+. We denote by f (A) = (f (aij))T

+ =⇒ f (A) ∈ ST

and f (x) =(cid:80)∞

k=0 akxk with ak ≥ 0 for all k ≥ 0.

Note that in the previous theorem the condition on f is only necessary when we require the implica-
tion to hold for all T . If T is ﬁxed  the set of functions is larger and includes even (large) fractional
powers  see [24]. We use the stronger formulation as we want that the result holds without any
restriction on the number of tasks T . Theorem 4 is the key element used in our following charac-
terization of separable regularizers of Θ which allow an analytical expression of the dual function.
k+1 zk+1 where ak ≥
r s=1 φ∗(Θrs)  is a convex function V : RT×T → R and

Theorem 5 Let φ : R → R be analytic on R and given as φ(z) = (cid:80)∞
0 ∀k ≥ 0. If φ is convex  then  V (Θ) :=(cid:80)T
T(cid:88)
(cid:1) 
φ(cid:0)ρrs
rs =(cid:80)∞

where the global maximizer fulﬁlls Θ∗ ∈ ST
Table 1 summarizes e.g. of functions φ  the corresponding V (Θ) and the maximizer Θ∗ in (12).

(cid:104)ρ  Θ(cid:105) − V (Θ) = V ∗(ρ) =

+ if ρ ∈ ST

+ and Θ∗

k=0 akρk
rs.

max
Θ∈RT ×T

(12)

r s=1

k=0

ak

4 Optimization Algorithm

The dual problem (11) can be efﬁciently solved via decomposition based methods like stochastic
dual coordinate ascent algorithm (SDCA) [19]. SDCA enjoys low computational complexity per
iteration and has been shown to scale effortlessly to large scale optimization problems.

5

Algorithm 1 Fast MTL-SDCA

Input: Gram matrix K  label vector y  regularization parameter and relative duality gap parameter 
Output: α (Θ is computed from α using our result in 10)
Initialize α = α(0)
repeat

Randomly choose a dual variable αi
Solve for ∆ in (13) corresponding to αi
αi ← αi + ∆

until Relative duality gap is below 

i

s(cid:54)=r

Our algorithm for learning the output kernel matrix and task parameters is summarized in Algo-
rithm 1 (refer to the supplementary material for more details). At each step of the iteration we opti-
mize the dual objective over a randomly chosen αi variable. Let ti = r be the task corresponding to
αi. We apply the update αi ← αi + ∆. The optimization problem of solving (11) with respect to ∆
is as follows:
∆∈R L∗
where a = kii  brs = (cid:80)

(cid:0)(−αi − ∆)/C(cid:1) + η(cid:0)(a∆2 + 2brr∆ + crr)2k + 2

(cid:1)  (13)
(cid:17)2k
(cid:16) 2k−1

(brs∆ + crs)2k +

(cid:88)

(cid:88)

s z(cid:54)=r

c2k
sz

min

j:tj =s kijαj ∀s  csz = (cid:104)αs  Kszαz(cid:105) ∀s  z and η =

.
This one-dimensional convex optimization problem is solved efﬁciently via Newton method. The
complexity of the proposed algorithm is O(T ) per iteration . The proposed algorithm can also be
employed for learning output kernels regularized by generic V (Θ)  discussed in the previous section.
Special case p = 2(k = 1): For certain loss functions such as the hinge loss  the squared loss  etc. 
L∗
ﬁnding the roots of a cubic equation  which has a closed form expression. Hence  our algorithm is
highly efﬁcient with the above loss functions when Θ is regularized by the squared Frobenius norm.

(cid:1) yields a linear or a quadratic expression in ∆. In such cases problem (13) reduces to

(cid:0) − αti+∆

C(4k−2)

2kλ

ti

C

λ

5 Empirical Results

In this section  we present our results on benchmark data sets comparing our algorithm with existing
approaches in terms of generalization accuracy as well as computational efﬁciency. Please refer to
the supplementary material for additional results and details.

5.1 Multi-Task Data Sets

We begin with the generalization results in multi-task setups. The data sets are as follows: a) Sarcos:
a regression data set  aim is to predict 7 degrees of freedom of a robotic arm  b) Parkinson: a
regression data set  aim is to predict the Parkinson’s disease symptom score for 42 patients  c) Yale:
a face recognition data with 28 binary classiﬁcation tasks  d) Landmine: a data set containing binary
classiﬁcations from 19 different landmines  e) MHC-I: a bioinformatics data set having 10 binary
classiﬁcation tasks  f) Letter: a handwritten letters data set with 9 binary classiﬁcation tasks.
We compare the following algorithms: Single task learning (STL)  multi-task methods learning the
output kernel matrix (MTL [16]  CMTL [12]  MTRL [9]) and approaches that learn both input and
output kernel matrices (MTFL [11]  GMTL [10]). Our proposed formulation (11) is denoted by
FMTLp. We consider three different values for the p-norm: p = 2 (k = 1)  p = 4/3 (k = 2) and
p = 8/7 (k = 4). Hinge and -SVR loss functions were employed for classiﬁcation and regression
problems respectively. We follow the experimental protocol1 described in [11].
Table 2 reports the performance of the algorithms averaged over ten random train-test splits. The
proposed FMTLp attains the best generalization accuracy in general. It outperforms the baseline
MTL as well as MTRL and CMTL  which solely learns the output kernel matrix. Moreover  it
achieves an overall better performance than GMTL and MTFL. The FMTLp=4/3 8/7 give compa-
rable generalization to p = 2 case  with the additional beneﬁt of learning sparser and more inter-
pretable output kernel matrix (see Figure 1).

1The performance of STL  MTL  CMTL and MTFL are reported from [11].

6

Table 2: Mean generalization performance and the standard deviation over ten train-test splits.

Data set

STL

MTL

CMTL

MTFL

GMTL

MTRL

p = 2

FMTLp
p = 4/3

p = 8/7

Regression data sets: Explained Variance (%)
Sarcos
Parkinson

40.5±7.6 34.5±10.2 33.0±13.4
2.8±7.5
2.7±3.6

4.9±20.0

49.9±6.3
16.8±10.8 33.6±9.4 12.0±6.8 27.0±4.4

45.8±10.6 41.6±7.1 46.7±6.9 50.3±5.8 48.4±5.8
27.0±4.4 27.0±4.4

Classiﬁcation data sets: AUC (%)
93.4±2.3
Yale
Landmine 74.6±1.6
69.3±2.1
MHC-I
61.2±0.8
Letter

96.4±1.6
76.4±1.0
76.4±0.8
72.3±1.9 72.6±1.4 71.7±2.2
60.5±1.8
61.0±1.6

95.2±2.1 97.0±1.6 91.9±3.2
75.9±0.7
76.7±1.2
72.5±2.7
61.2±0.9
60.5±1.1

96.1±2.1 97.0±1.2 97.0±1.4 96.8±1.4
76.1±1.0 76.8±0.8 76.7±1.0 76.4±0.9
71.5±1.7 71.7±1.9
70.8±2.1 70.7±1.9
60.3±1.4 61.4±0.7 61.5±1.0 61.4±1.0

(p = 2)

(p = 4/3)

(p = 8/7)

Figure 1: Plots of |Θ| matrices (rescaled to [0 1] and averaged over ten splits) computed by our
solver FMTLp for the Landmine data set for different p-norms  with cross-validated hyper-parameter
values. The darker regions indicate higher value. Tasks (landmines) numbered 1-10 correspond to
highly foliated regions and those numbered 11-19 correspond to bare earth or desert regions. Hence 
we expect two groups of tasks (indicated by the red squares). We can observe that the learned Θ
matrix at p = 2 depicts much more spurious task relationships than the ones at p = 4/3 and p = 8/7.
Thus  our sparsifying regularizer improves interpretability.

Table 3: Mean accuracy and the standard deviation over ﬁve train-test splits.

Data set

STL

MTL-SDCA GMTL

MTRL

FMTLp-H
p = 4/3

FMTLp-S
p = 4/3

MNIST 84.1±0.3
90.5±0.3
USPS

86.0±0.2
90.6±0.2

p = 8/7
84.8±0.3 85.6±0.4 86.1±0.4 85.8±0.4 86.2±0.4 82.2±0.6 82.5±0.4 82.4±0.3
91.6±0.3 92.4±0.2 92.4±0.2 92.6±0.2 92.6±0.1 87.2±0.4 87.7±0.3 87.5±0.3

p = 8/7

p = 2

p = 2

5.2 Multi-Class Data Sets

The multi-class setup is cast as T one-vs-all binary classiﬁcation tasks  corresponding to T classes.
In this section we experimented with two loss functions: a) FMTLp-H – the hinge loss employed in
SVMs  and b) FMTLp-S – the squared loss employed in OKL [17]. In these experiments  we also
compare our results with MTL-SDCA  a state-of-the-art multi-task feature learning method [25].
USPS & MNIST Experiments: We followed the experimental protocol detailed in [10]. Results
are tabulated in Table 3. Our approach FMTLp-H obtains better accuracy than GMTL  MTRL and
MTL-SDCA [25] on both data sets.
MIT Indoor67 Experiments: We report results on the MIT Indoor67 benchmark [26] which covers
67 indoor scene categories. We use the train/test split (80/20 images per class) provided by the
authors. FMTLp-S achieved the accuracy of 73.3% with p = 8/7. Note that this is better than the
ones reported in [27] (70.1%) and [26] (68.24%).
SUN397 Experiments: SUN397 [28] is a challenging scene classiﬁcation benchmark [26] with 397
classes. We use m = 5  50 images per class for training  50 images per class for testing and report
the average accuracy over the 10 standard splits. We employed the CNN features extracted with the

7

246810121416182468101214161824681012141618246810121416182468101214161824681012141618Table 4: Mean accuracy and the standard deviation over ten train-test splits on SUN397.

m

5
50

STL

MTL

MTL-SDCA

40.5±0.9
55.0±0.4

42.0±1.4
57.0±0.2

41.2±1.3
54.8±0.3

p = 2
41.5±1.1
55.1±0.2

FMTLp-H
p = 4/3
41.6±1.3
55.6±0.3

FMTLp-S
p = 8/7
p = 4/3
41.6±1.2 44.1±1.3 44.1±1.1
58.5±0.1
55.1±0.3 58.6±0.1

p = 2

p = 8/7
44.0±1.2
58.6±0.2

(a)

(b)

Figure 2:
(a) Plot compares the runtime of various algorithms with varying number of tasks on
SUN397. Our approach FMTL2-S is 7 times faster that OKL [17] and 4.3 times faster than Convex-
OKL [18] when the number of tasks is maximum. (b) Plot showing the factor by which FMTL2-
S outperforms OKL and ConvexOKL over the hyper-parameter range on various data sets. On
SUN397  we outperform OKL and ConvexOKL by factors of 5.2 and 7 respectively. On MIT In-
door67  we are better than OKL and ConvexOKL by factors of 8.4 and 2.4 respectively.

convolutional neural network (CNN) [26] using Places 205 database. The results are tabulated in
Table 4. The Θ matrices computed by FMTLp-S are discussed in the supplementary material.

5.3 Scaling Experiment

We compare the runtime of our solver for FMTL2-S with the OKL solver of [17] and the Convex-
OKL solver of [18] on several data sets. All the three methods solve the same optimization problem.
Figure 2a shows the result of the scaling experiment where we vary the number of tasks (classes).
The parameters employed are the ones obtained via cross-validation. Note that both OKL and Con-
vexOKL algorithms do not have a well deﬁned stopping criterion whereas our approach can easily
compute the relative duality gap (set as 10−3). We terminate them when they reach the primal ob-
jective value achieved by FMTL2-S . Our optimization approach is 7 times and 4.3 times faster than
the alternate minimization based OKL and ConvexOKL  respectively  when the number of tasks is
maximal. The generic FMTLp=4/3 8/7 are also considerably faster than OKL and ConvexOKL.
Figure 2b compares the average runtime of our FMTLp-S with OKL and ConvexOKL on the cross-
validated range of hyper-parameter values. FMTLp-S outperform them on both MIT Indoor67 and
SUN397 data sets. On MNIST and USPS data sets  FMTLp-S is more than 25 times faster than
OKL  and more than 6 times faster than ConvexOKL. Additional details of the above experiments
are discussed in the supplementary material.

6 Conclusion

We proposed a novel formulation for learning the positive semi-deﬁnite output kernel matrix for
multiple tasks. Our main technical contribution is our analysis of a certain class of regularizers on the
output kernel matrix where one may drop the positive semi-deﬁnite constraint from the optimization
problem  but still solve the problem optimally. This leads to a dual formulation that can be efﬁciently
solved using stochastic dual coordinate ascent algorithm. Results on benchmark multi-task and
multi-class data sets demonstrates the effectiveness of the proposed multi-task algorithm in terms of
runtime as well as generalization accuracy.
Acknowledgments. P.J. and M.H. acknowledge the support by the Cluster of Excellence (MMCI).

8

5010015020025030035040010−210−1100101102103Number of TasksTime (log10 scale)  s FMTL2−SConvexOKLOKL33.544.555.566.5702468101214161820Log10(η)(Time by baseline) / (Time by FMTL2−S) MIT Indoor67  OKLSUN397  OKLMIT Indoor67  ConvexOKL .SUN397  ConvexOKLReferences
[1] T. Evgeniou  C. A. Micchelli  and M. Pontil. Learning multiple tasks with kernel methods. JMLR 

6:615–637  2005.

[2] A. Argyriou  T. Evgeniou  and M. Pontil. Convex multi-task feature learning. ML  73:243–272  2008.
[3] K. Lounici  M. Pontil  A. B. Tsybakov  and S. van de Geer. Taking advantage of sparsity in multi-task

learning. In COLT  2009.

[4] A. Jalali  P. Ravikumar  S. Sanghavi  and C. Ruan. A dirty model for multi-task learning. In NIPS  2010.
[5] P. Jawanpuria and J. S. Nath. Multi-task multiple kernel learning. In SDM  2011.
[6] A. Maurer  M. Pontil  and B. Romera-paredes. Sparse coding for multitask and transfer learning.

In

ICML  2013.

[7] P. Jawanpuria  J. S. Nath  and G. Ramakrishnan. Generalized hierarchical kernel learning. JMLR  16:617–

652  2015.

[8] R. Caruana. Multitask learning. ML  28:41–75  1997.
[9] Y. Zhang and D. Y. Yeung. A convex formulation for learning task relationships in multi-task learning.

In UAI  2010.

[10] Z. Kang  K. Grauman  and F. Sha. Learning with whom to share in multi-task feature learning. In ICML 

2011.

[11] P. Jawanpuria and J. S. Nath. A convex feature learning formulation for latent task structure discovery. In

ICML  2012.

[12] L. Jacob  F. Bach  and J. P. Vert. Clustered multi-task learning: A convex formulation. In NIPS  2008.
[13] C. A. Micchelli and M. Pontil. Kernels for multitask learning. In NIPS  2005.
[14] A. Caponnetto  C. A. Micchelli  M. Pontil  and Y. Ying. Universal multi-task kernels. JMLR  9:1615–

1646  2008.

[15] M. A. ´Alvarez  L. Rosasco  and N. D. Lawrence. Kernels for vector-valued functions: a review. Founda-

tions and Trends in Machine Learning  4:195–266  2012.

[16] T. Evgeniou and M. Pontil. Regularized multi–task learning. In KDD  2004.
[17] F. Dinuzzo  C. S. Ong  P. Gehler  and G. Pillonetto. Learning output kernels with block coordinate descent.

In ICML  2011.

[18] C. Ciliberto  Y. Mroueh  T. Poggio  and L. Rosasco. Convex learning of multiple tasks and their structure.

In ICML  2015.

[19] S. Shalev-Shwartz and T. Zhang. Stochastic dual coordinate ascent methods for regularized loss. JMLR 

14(1):567–599  2013.

[20] B. Sch¨olkopf and A. Smola. Learning with Kernels. MIT Press  2002.
[21] M. Hein and O. Bousquet. Kernels  associated structures and generalizations. Technical Report TR-127 

Max Planck Institute for Biological Cybernetics  2004.

[22] A. Ben-Israel and B. Mond. What is invexity ? J. Austral. Math. Soc. Ser. B  28:1–9  1986.
[23] F. Hiai. Monotonicity for entrywise functions of matrices. Linear Algebra and its Applications 

431(8):1125 – 1146  2009.

[24] R. A. Horn. The theory of inﬁnitely divisible matrices and kernels. Trans. Amer. Math. Soc.  136:269–286 

1969.

[25] M. Lapin  B. Schiele  and M. Hein. Scalable multitask representation learning for scene classiﬁcation. In

CVPR  2014.

[26] B. Zhou  A. Lapedriza  J. Xiao  A. Torralba  and A. Oliva. Learning deep features for scene recognition

using places database. In NIPS  2014.

[27] M. Koskela and J. Laaksonen. Convolutional network features for scene recognition. In Proceedings of

the ACM International Conference on Multimedia  2014.

[28] J. Xiao  J. Hays  K. A. Ehinger  A. Oliva  and A. Torralba. SUN database: Large-scale scene recognition

from abbey to zoo. In CVPR  2010.

9

,Harish Ramaswamy
Shivani Agarwal
Ambuj Tewari
Mehryar Mohri
Scott Yang
Pratik Kumar Jawanpuria
Maksim Lapin
Matthias Hein
Bernt Schiele