2012,High-Order Multi-Task Feature Learning to Identify Longitudinal Phenotypic Markers for Alzheimer's Disease Progression Prediction,Alzheimer disease (AD) is a neurodegenerative disorder characterized by progressive impairment of memory and other cognitive functions. Regression analysis has been studied to relate neuroimaging measures to cognitive status. However  whether these measures have further predictive power to infer a trajectory of cognitive performance over time is still an under-explored but important topic in AD research. We propose a novel high-order multi-task learning model to address this issue. The proposed model explores the temporal correlations existing in data features and regression tasks by the structured sparsity-inducing norms. In addition  the sparsity of the model enables the selection of a small number of MRI measures while maintaining high prediction accuracy. The empirical studies  using the baseline MRI and serial cognitive data of the ADNI cohort  have yielded promising results.,High-Order Multi-Task Feature Learning to Identify
Longitudinal Phenotypic Markers for Alzheimer’s

Disease Progression Prediction

Hua Wang  Feiping Nie  Heng Huang 

Department of Computer Science and Engineering 

University of Texas at Arlington  Arlington  TX 76019

{huawangcs  feipingnie}@gmail.com  heng@uta.edu

Jingwen Yan  Sungeun Kim  Shannon L. Risacher  Andrew J. Saykin  Li Shen  for the ADNI∗

Department of Radiology and Imaging Sciences 

Indiana University School of Medicine  Indianapolis  IN 46202

{jingyan  sk31  srisache  asaykin  shenli}@iupui.edu

Abstract

Alzheimer’s disease (AD) is a neurodegenerative disorder characterized by pro-
gressive impairment of memory and other cognitive functions. Regression analy-
sis has been studied to relate neuroimaging measures to cognitive status. However 
whether these measures have further predictive power to infer a trajectory of cog-
nitive performance over time is still an under-explored but important topic in AD
research. We propose a novel high-order multi-task learning model to address this
issue. The proposed model explores the temporal correlations existing in imag-
ing and cognitive data by structured sparsity-inducing norms. The sparsity of the
model enables the selection of a small number of imaging measures while main-
taining high prediction accuracy. The empirical studies  using the longitudinal
imaging and cognitive data of the ADNI cohort  have yielded promising results.

1 Introduction

Neuroimaging is a powerful tool for characterizing neurodegenerative process in the progression
of Alzheimer’s disease (AD). Neuroimaging measures have been widely studied to predict disease
status and/or cognitive performance [1  2  3  4  5  6  7]. However  whether these measures have
further predictive power to infer a trajectory of cognitive performance over time is still an under-
explored yet important topic in AD research. A simple strategy typically used in longitudinal studies
(e.g.  [8]) is to analyze a single summarized value such as average change  rate of change  or slope.
This approach may be inadequate to distinguish the complete dynamics of cognitive trajectories
and thus become unable to identify underlying neurodegenerative mechanism. Figure 1 shows a
schematic example. Let us look at the plot of Cognitive Score 2. The red and blue groups can be
easily separated by their complete trajectories. However  given very similar score values at the time
points of t0 and t3  any of the aforementioned summarized values may not be sufﬁcient to identify the
group difference. Therefore  if longitudinal cognitive outcomes are available  it would be beneﬁcial
to use the complete information for the identiﬁcation of relevant imaging markers [9  10].

∗Data used in preparation of this article were obtained from the Alzheimer’s Disease Neuroimaging Ini-
tiative (ADNI) database (adni.loni.ucla.edu). As such  the investigators within the ADNI contributed to
the design and implementation of ADNI and/or provided data but did not participate in analysis or writ-
ing of this report. A complete listing of ADNI investigators can be found at: http://adni.loni.ucla.edu/wp-
content/uploads/how to apply/ADNI Acknowledgement List.pdf.

1

Figure 1: Longitudinal multi-task regression of cognitive trajectories on MRI measures.

However  how to identify the temporal imaging features that predict longitudinal outcomes is a chal-
lenging machine learning problem. First  the input data and response measures often are high-order
tensors  not regular data/label matrix. For example  both input neuroimaging measures (samples ×
features × time) and output cognitive scores (samples × scores × time) are 3D tensors. Thus  it is
not trivial to build the longitudinal learning model for tensor data. Second  the associations between
features and a speciﬁc task (e.g. cognitive score) at two consecutive time points are often correlated.
How to efﬁciently include such correlations of associations cross time is unclear. Third  some longi-
tudinal learning tasks are often interrelated to each other. For example  it is well known that [3  4] in
RAVLT assessment  the total number of words remembered by the participants in the ﬁrst 5 learning
trials heavily impacts the total number of words which can be recalled in the 6th learning trial  and
the results of these two measures both partially determines the ﬁnal recognition rate after 30 minutes
delay. How to integrate such tasks correlations into longitudinal learning model is under-explored.

In this paper  we focus on the problem of predicting longitudinal cognitive trajectories using neu-
roimaging measures. We propose a novel high-order multi-task feature learning approach to iden-
tify longitudinal neuroimaging markers that can accurately predict cognitive scores over all the time
points. The sparsity-inducing norms are introduced to integrate the correlations existing in both
features and tasks. As a result  the selected imaging markers can fully differentiate the entire lon-
gitudinal trajectory of relevant scores and better capture the associations between imaging markers
and cognitive changes over time. Because the structured sparsity-inducing norms enforce the cor-
relations along two directions of the learned coefﬁcient tensor  the parameters in different sparsity
norms are tangled together by distinct structures and lead to a difﬁcult optimization problem. We
derive an efﬁcient algorithm to solve the proposed high-order multi-task feature learning objective
with closed form solution in each iteration. We further prove the global convergence of our algo-
rithm. We apply the proposed longitudinal multi-task regression method to the ADNI cohort. In
our experiments  the proposed method not only achieves competitive prediction accuracy but also
identiﬁes a small number of imaging markers that are consistent with prior knowledge.

2 High-Order Multi-Task Feature Learning Using Sparsity-Inducing Norms

For AD progression prediction using longitudinal phenotypic markers  the input imaging features
are a set of matrices X = {X1  X2  . . .   XT } ∈ Rd×n×T corresponding to the measurements at
T consecutive time points  where Xt is the phenotypic measurements for a certain type of imaging
markers  such as voxel-based morphometry (VBM) markers (see details in Section 3) used in this
study  at time t (1 ≤ t ≤ T ). Obviously  X is a tensor data with d imaging features  n subject
samples and T time points. The output cognitive assessments for the same set of subjects are a set of
matrices Y = {Y1  Y2  . . .   YT } ∈ Rn×c×T for a certain type of the cognitive measurements  such
as RAVLT memory scores (see details in Section 3)  at the same T consecutive time points. Again 
Y is a tensor data with n samples  c scores  and T time points. Our goal is to learn from {X   Y} a
model that can reveal the longitudinal associations between the imaging and cognitive trajectories 
by which we expect to better understand how the variations of different regions of human brains
affect the AD progression  such that we can improve the diagnosis and treatment to the disease.

Prior regression analyses typically study the associations between imaging features and cognitive
measures at each time point separately  which is equivalent to assume that the learning tasks  i.e. 
cognitive measures  at different time points are independent. Although this assumption can sim-
plify the problem and make the solution easier to obtain  it overlooks the temporal correlations of
imaging and cognitive measures. To address this  we propose to jointly learn a single longitudinal
regression model for the all time points to identify imaging markers which are associated to cog-

2

T i m e

T

BT
BT

…

s
e
r
u
t
a
e
F

d

B1

Tasks

c

B = fB1; : : : ; BT g

d

B1

B2

… …

BT

c

TB

1

TB

2

… …

B

T

T

B(1) = unfold(1) (B) = [B1; : : : ; BT ]

c x T

B(2) = unfold(2) (B) = #BT

T $
1 ; : : : ; BT

d x T

Figure 2: Left: visualization of the coefﬁcient tensor B learned for the association study on longi-
tudinal data. Middle: the matrix unfolded from B along the ﬁrst mode (feature dimension). Right:
the matrix unfolded from B along the second mode (task dimension).

nitive patterns. As a result  we aim to learn a coefﬁcient tensor (a stack of coefﬁcient matrices)
B = {B1  · · ·   Bn} ∈ Rd×c×T   as illustrated in the left panel of Figure 2  to reveal the temporal
changes of the coefﬁcient matrices. Given the additional time dimension  our problem becomes a
difﬁcult high-order data analysis problem  which we call as high-order multi-task learning.

2.1 Longitudinal Multi-Task Feature Learning

In order to associate the imaging markers and the cognitive measures  the multivariate regression
model was used in traditional association studies  which minimizes the following objective:

min

B

2

F

+ α kBk2
2

=

T

Xt=1

||X T

t Bt − Yt||2

F + α

T

d

Xt=1

Xk=1

||bk

t ||2

2 .

(1)

J0 = (cid:13)(cid:13)(cid:13)

B ⊗1 X T − Y(cid:13)(cid:13)(cid:13)

where bk
t denotes the k-th row of coefﬁcient matrix Bt at time t. Apparently  the objective J0 in
Eq. (1) can be decoupled for each individual time point. Therefore it does not take into account the
longitudinal correlations between imaging features and cognitive measures. Because our goal in the
association study is to select the imaging markers which are connected to the temporal changes of
all the cognitive measures  the T groups of regression tasks at different time points should not be
decoupled and have to be performed simultaneously. To achieve this  we select imaging markers
correlated to all the cognitive measures at all time points by introducing the sparse regularization
[11  12  13] into the longitudinal data regression and feature selection model as follows:

min

B

J1 =

T

Xt=1

||X T

t Bt − Yt||2

F + α

d

Xk=1

vuut

T

Xt=1

||bk

t ||2

2 =

T

Xt=1

||X T

t Bt − Yt||2

F + α(cid:13)(cid:13)B(1)(cid:13)(cid:13)2 1

 

(2)

where we denote unfoldk (B) = B(k) ∈ RIk×(I1...Ik−1Ik+1...In) as the unfolding operation to a gen-
eral n-mode tensor B along the k-th mode  and B(1) = unfold1 (B) = [B1  . . .   BT ] as illustrated
in the middle panel of Figure 2. By solving the objective J1  the imaging features with common
inﬂuences across all the time points for all the cognitive measures will be selected due to the second
term in Eq. (2)  which is a tensor extension of the widely used ℓ2 1-norm for matrix.

2.2 High-Order Multi-Task Correlations

The objective J1 in Eq. (2) couples all the learning tasks together  which  though  still does not ad-
dress the correlations among different learning tasks at different time points. As discussed earlier 
during the AD progression  many cognitive measures are interrelated together and their effects dur-
ing the process could overlap  thus it is necessary to further develop the objective J1 in Eq. (2) to
leverage the useful information conveyed by the correlations among different cognitive measures.
In order to capture the longitudinal patterns of the AD data  we consider two types of tasks corre-
lations. First  for an individual cognitive measure  although its association to the imaging features
at different stages of the disease could be different  its associations patterns at two consecutive time
points tend to be similar [9]. Second  we know that [4  14] during the AD progression  different
cognitive measures are interrelated to each other. Mathematically speaking  the above two types of
correlations can both be described by the low ranks of the coefﬁcient matrices unfolded from the

3

coefﬁcient tensor along different modes. Thus we further develop our learning model in Eq. (2) to
impose additional low rank regularizations to exploit these task correlations.
Let B(2) = unfold2 (B) = (cid:2)BT
T (cid:3) as illustrated in the right panel of Figure 2  we minimize
the ranks of B(1) and B(2) to capture the two types of task correlations  one for each type  as follows:

1   . . .   BT

min

B

J2 =

T

Xt=1

||X T

t Bt − Yt||2

F + α(cid:13)(cid:13)B(1)(cid:13)(cid:13)2 1

+ β(cid:0)(cid:13)(cid:13)B(1)(cid:13)(cid:13)∗

+(cid:13)(cid:13)B(2)(cid:13)(cid:13)∗(cid:1)  

(3)

1

where k·k∗ denote the trace norm of a matrix. Given a matrix M ∈ Rn×m and its singular
values σi (1 ≤ i ≤ min (n  m))  the trace norm of M is deﬁned as kM k∗ = Pmin (n m)
σi =
Tr(cid:0)M M T(cid:1)
2 . It has been shown that [15  16  17] the trace-norm is the best convex approximation
of the rank-norm. Therefore  the third and fourth terms of J2 in Eq. (3) indeed minimize the rank of
the unfolded learning model B  such that the two types of correlations among the learning tasks at
different time points can be utilized. Due to its capabilities for both imaging marker selection and
task correlation integration on longitudinal data  we call J2 deﬁned in Eq. (3) as the proposed High-
Order Multi-Task Feature Learning model  by which we will study the problem of longitudinal data
analysis to predict cognitive trajectories and identify relevant imaging markers.

i=1

2.3 New Optimization Algorithm and Its Global Convergence

Despite its nice properties  our new objective J2 in Eq. (3) is a non-smooth convex problem. Some
existing methods can solve it  but not efﬁciently. Thus  in this subsection we will derive a new
efﬁcient algorithm to solve this optimization problem with global convergence proof  where we
employ an iteratively reweighted method [18] to deal with the non-smooth regularization terms.
Taking the derivative of the objective J2 in Eq. (3) with respect to Bt and set it as 0  we obtain1:

2XtX T

t Bt − 2XtYt + 2αDBt + 2β(cid:16) ¯DBt + Bt

ˆD(cid:17) = 0  
2 (cid:16)B(1)BT

(1)(cid:17)−1/2

(4)

and ˆD =

where D is a diagonal matrix with D (i  i) =

1

2 (cid:16)B(2)BT

(2)(cid:17)−1/2

. We can re-write Eq. (4) as following:
t + αD + β ¯D(cid:17) Bt + βBt

(cid:16)XtX T

1

t=1kbk

t k2

2

  ¯D = 1

2qPT

ˆD = XtYt  

(5)

which is a Sylvester equation and can be solved in closed form. When the time t changes from 1 to
T   we can calculate Bt (1 ≤ t ≤ T ) by solving Eq. (5). Because D  ¯D and ˆD are dependent on B
and can be seen as latent variables  we propose an iterative algorithm to obtain the global optimum
solutions of Bt (1 ≤ t ≤ T )  which is summarized in Algorithm 1.
Convergence analysis of the new algorithm. We ﬁrst prove the following two useful lemmas  by
which we will prove the convergence of Algorithm 1.

Lemma 1 Given a constant α > 0  for function f (x) = x − x2
x ∈ R. The equality holds if and only if x = α.

2α   we have f (x) ≤ f (α) for any

The proof of Lemma 1 is obvious and skipped due to space limit.

Lemma 2 Given two semi-positive deﬁnite matrices A and ˜A  the following inequality holds:

tr(cid:16) ˜A

1

2(cid:17) −

1

2

tr(cid:16) ˜AA− 1

2(cid:17) ≤ tr(cid:16)A

1

2(cid:17) −

1

2

tr(cid:16)AA− 1

2(cid:17) .

(6)

The equality holds if and only if A = ˜A.

1kM k2 1 is a non-smooth function of M and not differentiable when one of its row mi = 0. Following
[18]  we introduce a small perturbation ζ > 0 to replace kM k2 1 by Piqkmik2
+ ζ  which is smooth and
differentiable with respect to M. Apparently  Piqkmik2
+ ζ is reduced to kM k2 1 when ζ → 0. In the
sequel of this paper  we implicitly apply this replacement for all k·k2 1. Following the same idea  we also
introduce a small perturbation ξ > 0 to replace kM k∗ by tr(cid:0)M M T + ξI(cid:1)

2 for the same reason.

2

2

1

4

Algorithm 1: A new algorithm to solve the optimization problem in Eq. (3).
Data: X = [X1  X2  . . .   XT ] ∈ Rd×n×T   Y = [Y1  Y2  . . .   YT ] ∈ Rn×c×T .
1. Set g = 1. Initialize B(1)
repeat

t ∈ Rd×c (1 ≤ t ≤ T ) using the linear regression results at each individual time point.

2. Calculate the diagonal matrix D(g)  where the i-th diagonal element is computed as D(g) (i  i) =

calculate ¯D(g) = 1

3. Update B(g+1)
t
4. g = g + 1.

2 (cid:18)B(g)

(1) (cid:16)B(g)

(1)(cid:17)T(cid:19)− 1

2 ; calculate ˆD(g) = 1

2 (cid:18)B(g)

(2) (cid:16)B(g)

(2)(cid:17)T(cid:19)− 1

2 .

(1 ≤ t ≤ T ) by solving the Sylvester equation in Eq. (5).

until Converges
Result: B = [B1  B2  . . .   BT ] ∈ Rd×c×T .

;

1

b

(g) k
t

2sPT
t=1(cid:13)(cid:13)(cid:13)(cid:13)

2

2

(cid:13)(cid:13)(cid:13)(cid:13)

Proof : Because A and ˜A are two semi-positive deﬁnite matrices and we know that tr(cid:16)A ˜A(cid:17) =
tr(cid:16) ˜AA(cid:17)  we can derive:
2 − 2 ˜A

2 − ˜A

1
2 A

1

1

1

2(cid:17) A− 1

4(cid:17) =

(7)

1

tr(cid:16)A
tr(cid:18)A− 1

2(cid:17) = tr(cid:16)A− 1
4 (cid:16)A + ˜A − A
4(cid:19) = (cid:13)(cid:13)(cid:13)
2(cid:17)(cid:13)(cid:13)(cid:13)
A− 1
A− 1
4 (cid:16)A
2 tr(cid:16) ˜AA− 1
by which we have the following inequality tr(cid:16) ˜A
2(cid:17) − 1
alent to Eq. (6) and completes the proof of Lemma 2.

2 + ˜AA− 1
2(cid:17)2

4 (cid:16)A

2 − ˜A

2 − ˜A

2 ˜A

F

2

1

1

1

1

1

1

≥ 0  

2(cid:17) ≤ 1

2 tr(cid:16)A

1

2(cid:17)  which is equiv-

(cid:3)

Now we prove the convergence of Algorithm 1  which is summarized by the following theorem.

Theorem 1 Algorithm 1 monotonically decreases the objective of the problem in Eq. (3) in each
iteration  and converges to the globally optimal solution.

Proof : In Algorithm 1  we denote the updated Bt in each iteration as ˜Bt. We also denote the
least square loss in the g-th iteration as L(g) = PT
F . According to Step 3 of
Algorithm 1 we know that the following inequality holds:
tr(cid:16) ˜BT
Xt=1
tr(cid:16)BT
Xt=1

t D ˜Bt(cid:17) + β
t DBt(cid:17) + β

tr(cid:16) ˜BT
Xt=1
tr(cid:16)BT
Xt=1

¯D ˜Bt(cid:17) + β
¯DBt(cid:17) + β

tr(cid:16) ˜Bt
Xt=1
tr(cid:16)Bt
Xt=1

t (cid:17) ≤
t (cid:17) .

t − Yt||2

L(g+1) + α

t=1 ||X T

t B(g)

L(g) + α

ˆD ˜BT

ˆDBT

(8)

T

T

T

T

T

T

t

t

Denote the updated B(1) as ˜B(1)  and the updated B(2) as ˜B(1)  from Eq. (8) we can derive:

L(g+1) + α tr(cid:16) ˜BT
tr(cid:16)BT
L(g) + α

(1)D ˜B(1)(cid:17) + β tr(cid:16) ˜B(1)
(1)DB(1)(cid:17) + β

Xt=1

Xt=1

T

T

¯D(cid:17) + β tr(cid:16) ˜B(2)
Xt=1

¯D(cid:17) + β

(1)

T

˜BT
(2)

ˆD(cid:17) ≤
tr(cid:16)B(2)BT

(2)

tr(cid:16)B(1)BT

˜BT
(1)

(9)

ˆD(cid:17) .

According to the deﬁnitions of D  ¯D and ˆD  we have:

L(g+1) +

L(g) +

α
2

α
2

d

Xk=1

t

t

d

t=1 ||b(g+1) k
PT
Xk=1
qPT
t=1 ||b(g) k
PT
||2
t=1 ||b
2
qPT
t=1 ||b(g) k

(g) k
t

||2
2

t

+

β
2

tr(cid:18) ˜B(1)

||2
2

||2
2

+

β
2

tr(cid:18)B(1)BT

˜BT

(1)(cid:17)− 1
(1) (cid:16)B(1)BT
(1)(cid:17)− 1
2(cid:19) +

(1) (cid:16)B(1)BT

2(cid:19) +

β
2

tr(cid:18) ˜B(2)

β
2

tr(cid:18)B(1)BT

2(cid:19) ≤

˜BT

(2)(cid:17)− 1
(2)(cid:16)B(2)BT
(2)(cid:17)− 1
2(cid:19) .

(1) (cid:16)B(2)BT

Then according to Lemma 1 and Lemma 2  the following three inequalities hold:

vuut

T

Xt=1

(g+1) k
||b
t

||2

t

t=1 ||b(g+1) k
2 − PT
2qPT
t=1 ||b(g) k

t

||2
2

||2
2

≤ vuut

T

Xt=1

(g) k
||b
t

5

||2

2 − PT
2qPT

t

t=1 ||b(g) k

||2
2
t=1 ||b(g) k

t

||2
2

(10)

.

(11)

tr(cid:16) ˜B(1)

tr(cid:16) ˜B(2)

˜BT

˜BT

2

(1)(cid:17) − tr(cid:18) 1
(2)(cid:17) − tr(cid:18) 1

2

˜B(1)

˜B(2)

˜BT

(1)(cid:16)B(1)BT

˜BT

(2)(cid:16)B(2)BT

(1)(cid:17)− 1
(2)(cid:17)− 1

2(cid:19) ≤ tr(cid:16)B(1)BT
2(cid:19) ≤ tr(cid:16)B(2)BT

(1)(cid:17) − tr(cid:18) 1
(2)(cid:17) − tr(cid:18) 1

2

2

B(1)BT

(1)(cid:16)B(1)BT

B(2)BT

(2)(cid:16)B(2)BT

(1)(cid:17)− 1
(2)(cid:17)− 1

2(cid:19)  

(12)

2(cid:19) .

(13)

Adding the both sides of of Eqs. (10–13) together  we can obtain:

L(g+1) + α

L(g+1) + α

d

X

k=1

d

X

k=1

vuut
vuut

T

X

t=1

T

X

t=1

||b(g+1) k

t

2 + β tr(cid:16) ˜B(1)
||2

(1)(cid:17) + β tr(cid:16) ˜B(2)
˜BT

(2)(cid:17) ≤
˜BT

(14)

||b(g) k

t

2 + β tr(cid:16)B(1)BT
||2

(1)(cid:17) + β tr(cid:16)B(2)BT

(2)(cid:17)

Thus  our algorithm decreases the objective value of Eq. (3) in each iteration. When the objective
value keeps unchange  Eq. (4) is satisﬁed  i.e.  the K.K.T. condition of the objective is satisﬁed.
Thus  our algorithm reaches one of the optimal solutions. Because the objective in Eq. (3) is a
convex problem  Algorithm 1 will converge to one of the globally optimal solution.
(cid:3)

3 Experiments

We evaluate the proposed method by applying it to the Alzheimer’s Disease Neuroimaging Initiative
(ADNI) cohort to examine the association between a wide range of imaging measures and two types
of cognitive measures over a certain period of time. Our goal is to discover a compact set of imaging
markers that are closely related to cognitive trajectories.
Imaging markers and cognitive measures. Data used in this work were obtained from the ADNI
database (adni.loni.ucla.edu). One goal of ADNI has been to test whether serial MRI  PET 
other biological markers  and clinical and neuropsychological assessment can be combined to mea-
sure the progression of Mild Cognitive Impairment (MCI) and early AD. For up-to-date information 
see www.adni-info.org. We downloaded 1.5 T MRI scans and demographic information for
821 ADNI-1 participants. We performed voxel-based morphometry (VBM) on the MRI data by
following [8]  and extracted mean modulated gray matter (GM) measures for 90 target regions of
interest (ROIs) (see Figure 3 for the ROI list and detailed deﬁnitions of these ROIs in [3]). These
measures were adjusted for the baseline intracranial volume (ICV) using the regression weights de-
rived from the healthy control (HC) participants at the baseline. We also downloaded the longitudinal
scores of the participants in two independent cognitive assessments including Fluency Test and Rey’s
Auditory Verbal Learning Test (RAVLT). The details of these cognitive assessments can be found
in the ADNI procedure manuals2. The time points examined in this study for both imaging markers
and cognitive assessments included baseline (BL)  Month 6 (M6)  Month 12 (M12) and Month 24
(M24). All the participants with no missing BL/M6/M12/M24 MRI measurements and cognitive
measures were included in this study. A total of 417 subjects were involved in our study  including
84 AD  and 191 MCI and 142 HC participants. We examined 3 RAVLT scores RAVLT TOTAL 
RAVLT TOT6 and RAVLT RECOG  and 2 Fluency scores FLU ANIM and FLU VEG.

3.1 Improved Cognitive Score Prediction from Longitudinal Imaging Markers

We ﬁrst evaluate the proposed method by applying it to the ADNI cohort for predicting the two types
of cognitive scores using the VBM markers  tracked over four different time points. Our goal in this
experiment is to improve the prediction performance.
Experimental setting. We compare the proposed method against its two close counterparts includ-
ing multivariate linear regression (LR) and ridge regression (RR). LR is the simplest and widely
used regression model in statistical learning and brain image analysis. RR is a regularized version
of LR to avoid over-ﬁtting. Due to their mathematical nature  these two methods are performed for

2http://www.adni-info.org/Scientists/ProceduresManuals.aspx

6

Table 1: Performance comparison for memory score prediction measured by RMSE.

RAVLT
Fluency

LR
0.380
0.171

RR
0.341
0.165

TGL
0.318
0.155

Ours (ℓ2 1-norm only) Ours (trace norm only)

0.306
0.144

0.301
0.147

Ours
0.283
0.135

each cognitive measure at each time point separately  and thus they cannot make use of the temporal
correlation. We also compare our method to a recent longitudinal method  called as Temporal Group
Lasso Multi-Task Regression (TGL) [9]. TGL takes into account the longitudinal property of the
data  which  however  is designed to analyze only one single memory score at a time. In contrast 
besides imposing structured sparsity via tensor ℓ2 1-norm regularization for imaging marker selec-
tion  our new method also imposes two trace norm regularizations to capture the interrelationships
among different cognitive measures over the temporal dimension. Thus  the proposed method is
able to perform association study for all the relevant scores of a cognitive test at the same time  e.g. 
our method can simultaneously deal with the three RAVLT scores  or the two Fluency scores.

To evaluate the usefulness of each component of the proposed method  we implement three versions
of our method as follows. First  we only impose the ℓ2 1-norm regularization on the unfolded co-
efﬁcient tensor B along the feature mode  denoted as “ℓ2 1-norm only”. Second  we only impose
the trace norm regularizations on the two coefﬁcient matrices unfolded from the coefﬁcient tensor B
along the feature and task modes respectively  denoted as “trace norm only”. Finally  we implement
the full version of our new method that solves the proposed objective in Eq. (3). Note that  if no
regularization is imposed  our method is degenerated to the traditional LR method.

To measure prediction performance  we use standard 5-fold cross-validation strategy by computing
the root mean square error (RMSE) between the predicted and actual values of the cognitive scores
on the testing data only. Speciﬁcally  the whole set of subjects are equally and randomly partitioned
into ﬁve subsets  and each time the subjects within one subset are selected as the testing samples
and all other subjects in the remaining four subsets are used for training the regression models. This
process is repeated for ﬁve times and average results are reported in Table 1. To treat all regression
tasks equally  data for each response variable is normalized to have zero mean and unit variance.
Experimental results. From Table 1 we can see that the proposed method is consistently better than
the three competing methods  which can be attributed to the following reasons. First  because LR
and RR methods by nature can only deal with one individual cognitive measure at one single time
point at a time  they cannot beneﬁt from the correlations across different cognitive measures over the
entire time course. Second  although TGL method improves the previous two methods in that it does
take into account longitudinal data patterns  it still assumes all the test scores (i.e.  learning tasks)
from one cognitive assessment to be independent  which  though  is not true in reality. For example 
it is well known that [3  4] in RAVLT assessment  the total number of words remembered by the
participants in the ﬁrst 5 learning trials (RAVLT TOTAL) heavily impacts the total number of words
which can be recalled in the 6th learning trial (RAVLT TOT6)  and the results of these two measures
both partially determines the ﬁnal recognition rate after 30 minutes delay (RAVLT RECOG). In
contrast  our new method considers all c learning tasks (c = 3 for RAVLT assessment and c =
2 for Fluency assessment) as an integral learning object as formulated in Eq. (3)  such that their
correlations can be incorporated by the two imposed low-rank regularization terms.

Besides  we also observe that the two degenerated versions of the proposed method do not perform as
well as their full version counterpart  which provides a concrete evidence to support the necessities of
the component terms of our learning objective in Eq. (3) and justiﬁes our motivation to impose ℓ2 1-
norm regularization for feature selection and trace norm regularization to capture task correlations.

3.2 Identiﬁcation of Longitudinal Imaging Markers

Because one of the primary goals of our regression analysis is to identify a subset of imaging markers
which are highly correlated to the AD progression reﬂected by the cognitive changes over time.
Therefore  we examine the imaging markers identiﬁed by the proposed methods with respect to the
longitudinal changes encoded by the cognitive scores recorded at the four consecutive time points.

7

BL

M6

M12

M24

l

a
a
d
g
y
m
A
L

l

a
a
d
g
y
m
A
R

l

r
a
u
g
n
A
L

l

r
a
u
g
n
A
R

e
n
i
r
a
c
a
C
L

l

e
n
i
r
a
c
a
C
R

l

t

e
a
d
u
a
C
L

t

e
a
d
u
a
C
R

l

t

e
a
u
g
n
C
n
A
L

t

i

l

t

e
a
u
g
n
C
n
A
R

t

i

e

t

l

i

a
u
g
n
C
d
M
L

i

l

t

e
a
u
g
n
C
d
M
R

i

i

l

t

e
a
u
g
n
C
t
s
o
P
L

i

i

l

t

e
a
u
g
n
C
t
s
o
P
R

s
u
e
n
u
C
L

s
u
e
n
u
C
R

r
e
p
O
_
a

l

t

n
o
r
F
n

f

I

L

l

t

r
e
p
O
_
a
n
o
r
F
n
R

I

f

l

a

t

n
o
r
F
b
r
O
n

f

I

L

l

t

a
n
o
r
F
b
r
O
n
R

f

I

g
n
a
i
r
T
_
a

l

t

n
o
r
F
n

f

I

L

g
n
a
i
r
T
_
a

l

t

n
o
r
F
n
R

I

f

l

a

t

n
o
r
F
b
r
O
d
e
M
L

l

t

a
n
o
r
F
b
r
O
d
e
M
R

l

a

t

n
o
r
F
d
M
L

i

l

a

t

n
o
r
F
d
M
R

i

l

t

a
n
o
r
F
b
r
O
d
M
L

i

l

a

t

n
o
r
F
b
r
O
d
M
R

i

l

t

a
n
o
r
F
p
u
S
L

l

a

t

n
o
r
F
p
u
S
R

l

a

t

n
o
r
F
p
u
S
d
e
M
L

l

t

a
n
o
r
F
p
u
S
d
e
M
R

l

t

a
n
o
r
F
b
r
O
p
u
S
L

l

a

t

n
o
r
F
b
r
O
p
u
S
R

m
r
o

f
i
s
u
F
L

m
r
o

f
i
s
u
F
R

l

h
c
s
e
H
L

l

h
c
s
e
H
R

l

a
u
s
n

I

L

s
u
p
m
a
c
o
p
p
H
L

i

s
u
p
m
a
c
o
p
p
H
R

i

l

a
u
s
n
R

I

l

a
u
g
n
L
L

i

l

a
u
g
n
L
R

i

l

a

t
i

i

p
c
c
O
n

f

I

L

l

a

t
i

i

p
c
c
O
n
R

I

f

l

a

t
i

i

p
c
c
O
d
M
L

i

l

a

t
i

i

p
c
c
O
d
M
R

i

l

a

t
i

i

p
c
c
O
p
u
S
L

y
r
o

t
c
a

f
l

O
L

y
r
o

t
c
a

f
l

O
R

l

a

t
i

i

p
c
c
O
p
u
S
R

m
u
d

i
l
l

a
P
L

m
u
d

i
l
l

a
P
R

i

p
p
h
a
r
a
P
L

i

p
p
h
a
r
a
P
R

l

a
r
t
n
e
c
a
r
a
P
L

l

a
r
t

n
e
c
a
r
a
P
R

l

a

t

e
i
r
a
P
n
L

I

f

l

t

a
e
i
r
a
P
n
R

I

f

l

a

t

e
i
r
a
P
p
u
S
L

l

t

a
e
i
r
a
P
p
u
S
R

l

a
r
t

n
e
c
t
s
o
P
L

0.006

0.005

0.004

0.003

0.002

0.001

l

e
o
P
p
m
e
T
p
u
S
L

l

e
o
P
p
m
e
T
p
u
S
R

l

a
r
o
p
m
e
T
p
u
S
L

l

a
r
o
p
m
e
T
p
u
S
R

s
u
m
a
a
h
T
L

l

s
u
m
a
a
h
T
R

l

s
u
e
n
u
c
e
r
P
L

s
u
e
n
u
c
e
r
P
R

n
e
m
a
u
P
L

t

n
e
m
a

t

u
P
R

s
u

t
c
e
R
L

s
u
t
c
e
R
R

i

r
e
p
O
_
c
d
n
a
o
R
L

l

i

r
e
p
O
_
c
d
n
a
o
R
R

l

l

a
r
o
p
m
e
T
n

f

I

L

g
r
a
m
a
r
p
u
S
L

g
r
a
m
a
r
p
u
S
R

a
e
r

A
r
o

t

o
M
p
p
u
S
L

a
e
r

A
r
o

t

o
M
p
p
u
S
R

l

a
r
o
p
m
e
T
n
R

I

f

l

a
r
o
p
m
e
T
d
M
L

i

l

a
r
o
p
m
e
T
d
M
R

i

l

e
o
P
p
m
e
T
d
M
L

i

l

e
o
P
p
m
e
T
d
M
R

i

l

a
r
t
n
e
c
e
r
P
L

l

a
r
t
n
e
c
t
s
o
P
R

l

a
r
t

n
e
c
e
r
P
R

Figure 3: Top panel: Average regression weights of imaging markers for predicting three RAVLT
memory scores. Bottom panel: Top 10 average weights mapped onto the brain.

Shown in Figure 3 are (1) the heat map of the learned weights (magnitudes of the average regression
weights for all three RAVLT scores at each time point) of the VBM measures at different time points
calculated by our method; and (2) the top 10 weights mapped onto the brain anatomy. A ﬁrst glance
at the heat map in Figure 3 indicates that the selected imaging markers have clear patterns that span
across all the four studied time points  which demonstrates that these markers are longitudinally
stable and thereby can potentially serve as screening targets over the course of AD progression.

Moreover  we observe that the bilateral hippocampi and parahippocampal gyri are among the top
selected features. These ﬁndings are in accordance with the known knowledge that in the patho-
logical pathway of AD  medial temporal lobe is ﬁrstly affected  followed by progressive neocortical
damage [19  20]. Evidence of a signiﬁcant atrophy of middle temporal region in AD patients has
also been observed in previous studies [21  22  23].

In summary  the identiﬁed longitudinally stable imaging markers are highly suggestive and strongly
agree with the existing research ﬁndings  which warrants the correctness of the discovered imaging-
cognition associations to reveal the complex relationships between MRI measures and cognitive
scores. This is important for both theoretical research and clinical practices for a better understand-
ing of AD mechanism.

4 Conclusion

To reveal the relationship between longitudinal cognitive measures and neuroimaging markers  we
have proposed a novel high-order multi-task feature learning model  which selects the longitudinal
imaging markers that can accurately predict cognitive measures at all the time points. As a result 
these imaging markers could fully differentiate the entire longitudinal trajectory of relevant cognitive
measures and better capture the associations between imaging markers and cognitive changes over
time. To solve our new objective  which uses the non-smooth structured sparsity-inducing norms 
we have derived an iterative algorithm with a closed form solution in each iteration. We have further
proved our algorithm converges to the global optimal solution. The validations using ADNI imaging
and cognitive data have demonstrated the promise of our method.
Acknowledgement. This work was supported by NSF CCF-0830780  CCF-0917274  DMS-
0915228  and IIS-1117965 at UTA; and by NSF IIS-1117335  NIH R01 LM011360  UL1
RR025761  U01 AG024904  RC2 AG036535  R01 AG19771  and P30 AG10133-18S1 at IU. Data
used in the work were obtained from the ADNI database. ADNI funding information is available at
http://adni.loni.ucla.edu/wp-content/uploads/how to apply/ADNI DSP Policy.pdf.

8

References
[1] C Hinrichs  V Singh  G Xu  SC Johnson  and ADNI. Predictive markers for ad in a multi-modality

framework: an analysis of mci progression in the adni population. Neuroimage  55(2):574–89  2011.

[2] CM Stonnington  C Chu  S Kloppel  and et al. Predicting clinical scores from magnetic resonance scans

in alzheimer’s disease. Neuroimage  51(4):1405–13  2010.

[3] L. Shen  S. Kim  and et al. Whole genome association study of brain-wide imaging phenotypes for

identifying quantitative trait loci in MCI and AD: A study of the ADNI cohort. Neuroimage  2010.

[4] H. Wang  F. Nie  H. Huang  S. Risacher  C. Ding  A.J. Saykin  L. Shen  et al. Sparse multi-task regression

and feature selection to identify brain imaging predictors for memory performance. In ICCV  2011.

[5] D. Zhang and D. Shen. Multi-modal multi-task learning for joint prediction of multiple regression and

classiﬁcation variables in alzheimer’s disease. Neuroimage  2011.

[6] H. Wang  F. Nie  H. Huang  S. Kim  Nho K.  S. Risacher  A. Saykin  and L. Shen. Identifying Quantitative
Trait Loci via Group-Sparse Multi-Task Regression and Feature Selection: An Imaging Genetics Study
of the ADNI Cohort. Bioinformatics  28(2):229–237  2012.

[7] H. Wang  F. Nie  H. Huang  S. Risacher  A. Saykin  and L. Shen.

Identifying Disease Sensitive and
Quantitative Trait Relevant Biomarkers from Multi-Dimensional Heterogeneous Imaging Genetics Data
via Sparse Multi-Modal Multi-Task Learning. Bioinformatics  28(18):i127–i136  2012.

[8] S. L. Risacher  L. Shen  J. D. West  S. Kim  B. C. McDonald  L. A. Beckett  D. J. Harvey  Jr. Jack  C. R. 
M. W. Weiner  A. J. Saykin  and ADNI. Longitudinal MRI atrophy biomarkers: relationship to conversion
in the ADNI cohort. Neurobiol Aging  31(8):1401–18  2010.

[9] J. Zhou  L. Yuan  J. Liu  and J. Ye. A multi-task learning formulation for predicting disease progression.

In SIGKDD  2011.

[10] H. Wang  F. Nie  H. Huang  J. Yan  S. Kim  Nho K.  S. Risacher  A. Saykin  and L. Shen. From Phenotype
to Genotype: An Association Study of Candidate Phenotypic Markers to Alzheimer’s Disease Relevant
SNPs. Bioinformatics  28(12):i619–i625  2012.

[11] A. Argyriou  T. Evgeniou  and M. Pontil. Multi-task feature learning. NIPS  pages 41–48  2007.
[12] G. Obozinski  B. Taskar  and M. Jordan. Multi-task feature selection. Technical report  Department of

Statistics  University of California  Berkeley  2006.

[13] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of The

Royal Statistical Society Series B  68(1):49C–67  2006.

[14] H. Wang  F. Nie  H. Huang  S. Risacher  A. Saykin  and L. Shen. Identifying ad-sensitive and cognition-
relevant imaging biomarkers via joint classiﬁcation and regression. Medical Image Computing and
Computer-Assisted Intervention (MICCAI 2011)  pages 115–123  2011.

[15] B. Recht  M. Fazel  and P.A. Parrilo. Guaranteed minimum-rank solutions of linear matrix equations via

nuclear norm minimization. Arxiv preprint arxiv:0706.4138  2007.

[16] E.J. Cand`es and B. Recht. Exact matrix completion via convex optimization. Foundations of Computa-

tional Mathematics  9(6):717–772  2009.

[17] E.J. Candes and T. Tao. The power of convex relaxation: Near-optimal matrix completion. Information

Theory  IEEE Transactions on  56(5):2053–2080  2010.

[18] I.F. Gorodnitsky and B.D. Rao. Sparse signal reconstruction from limited data using focuss: A re-

weighted minimum norm algorithm. Signal Processing  IEEE Transactions on  45(3):600–616  1997.

[19] H. Braak and E. Braak. Neuropathological stageing of alzheimer-related changes. Acta neuropathologica 

82(4):239–259  1991.

[20] A. Delacourte  JP David  N. Sergeant  L. Buee  A. Wattez  P. Vermersch  F. Ghozali  C. Fallet-Bianco 
F. Pasquier  F. Lebert  et al. The biochemical pathway of neuroﬁbrillary degeneration in aging and
alzheimers disease. Neurology  52(6):1158–1158  1999.

[21] L.G. Apostolova  P.H. Lu  S. Rogers  R.A. Dutton  K.M. Hayashi  A.W. Toga  J.L. Cummings  and
P.M. Thompson. 3d mapping of mini-mental state examination performance in clinical and preclinical
alzheimer disease. Alzheimer Disease & Associated Disorders  20(4):224  2006.

[22] A. Convit  J. De Asis  MJ De Leon  CY Tarshish  S. De Santi  and H. Rusinek. Atrophy of the medial oc-
cipitotemporal  inferior  and middle temporal gyri in non-demented elderly predict decline to Alzheimer’s
disease. Neurobiol of aging  21(1):19–26  2000.

[23] V. Julkunen  E. Niskanen  S. Muehlboeck  M. Pihlajam¨aki  M. K¨on¨onen  M. Hallikainen  M. Kivipelto 
S. Tervo  R. Vanninen  A. Evans  et al. Cortical thickness analysis to detect progressive mild cognitive
impairment: a reference to alzheimer’s disease. Dementia and geriatric cognitive disorders  28(5):404–
412  2009.

9

,Shauharda Khadka
Kagan Tumer