2019,On the Value of Target Data in Transfer Learning,We aim to understand the value of additional labeled or unlabeled target data in transfer learning  for any given amount of source data; this is motivated by practical questions around minimizing sampling costs  whereby  target data is usually harder or costlier to acquire than source data  but can yield better accuracy. 

To this aim  we establish the first minimax-rates in terms of both source and target sample sizes  and show that performance limits are captured by new notions of discrepancy between source and target  which we refer to as transfer exponents. 

Interestingly  we find that attaining minimax performance is akin to ignoring one of the source or target samples  provided distributional parameters were known a priori. Moreover  we show that practical decisions -- w.r.t. minimizing sampling costs -- can be made in a minimax-optimal way without knowledge or estimation of distributional parameters nor of the discrepancy between source and target.,On the Value of Target Data in Transfer Learning

Steve Hanneke

Toyota Technological Institute at Chicago

steve.hanneke@gmail.com

Samory Kpotufe

Columbia University  Statistics

skk2175@columbia.edu

Abstract

We aim to understand the value of additional labeled or unlabeled target data in
transfer learning  for any given amount of source data; this is motivated by prac-
tical questions around minimizing sampling costs  whereby  target data is usually
harder or costlier to acquire than source data  but can yield better accuracy.
To this aim  we establish the ﬁrst minimax-rates in terms of both source and target
sample sizes  and show that performance limits are captured by new notions of
discrepancy between source and target  which we refer to as transfer exponents.
Interestingly  we ﬁnd that attaining minimax performance is akin to ignoring one
of the source or target samples  provided distributional parameters were known a
priori. Moreover  we show that practical decisions – w.r.t. minimizing sampling
costs – can be made in a minimax-optimal way without knowledge or estimation
of distributional parameters nor of the discrepancy between source and target.

1

Introduction

The practice of transfer-learning often involves acquiring some amount of target data  and involves
various practical decisions as to how to best combine source and target data; however much of the
theoretical literature on transfer only addresses the setting where no target labeled data is available.
We aim to understand the value of target labels  that is  given nP labeled data from some source
distribution P   and nQ labeled target labels from a target Q  what is the best Q error achievable by
any classiﬁer in terms of both nQ and nP   and which classiﬁers achieve such optimal transfer.
In
this ﬁrst analysis  we mostly restrict ourselves to a setting  similar to the traditional covariate-shift
assumption  where the best classiﬁer – from a ﬁxed VC class H – is the same under P and Q.
We establish the ﬁrst minimax-rates  for bounded-VC classes  in terms of both source and target
sample sizes nP and nQ  and show that performance limits are captured by new notions of discrep-
ancy between source and target  which we refer to as transfer exponents.
The ﬁrst notion of transfer-exponent  called ⇢  is deﬁned in terms of discrepancies in excess risk 
and is most reﬁned. Already here  our analysis reveals a surprising fact:
the best possible rate
(matching upper and lower-bounds) in terms of ⇢ and both sample sizes nP   nQ is - up to constants
- achievable by an oracle which simply ignores the least informative of the source or target datasets.
In other words  if ˆhP and ˆhQ denote the ERM on data from P   resp. from Q  one of the two achieves
the optimal Q rate over any classiﬁer having access to both P and Q datasets. However  which of
ˆhP or ˆhQ is optimal is not easily decided without prior knowledge: for instance  cross-validating on
a holdout target-sample would naively result in a rate of n1/2
which can be far from optimal given
large nP . Interestingly  we show that the optimal (nP   nQ)-rate is achieved by a generic approach 
akin to so-called hypothesis-transfer [1  2]  which optimizes Q-error under the constraint of low
P -error  and does so without knowledge of distributional parameters such as ⇢.
We then consider a related notion of marginal transfer-exponent  called   deﬁned w.r.t. marginals
PX  QX. This is motivated by the fact that practical decisions in transfer often involve the use of

Q

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

cheaper unlabeled data (i.e.  data drawn from PX  QX). We will show that  when practical decisions
are driven by observed changes in marginals PX  QX  the marginal notion  is then most suited to
capture performance as it does not require knowledge (or observations) of label distribution QY |X.
In particular  the marginal exponent  helps capture performance limits in the following scenarios
of current practical interest:
• Minimizing sampling cost. Given different costs of labeled source and target data  and a desired
target excess error at most ✏  how to use unlabeled data to decide on an optimal sampling scheme
that minimizes labeling costs while achieving target error at most ✏. (Section 6)
• Choice of transfer. Given two sources P1 and P2  each at some unknown distance from Q  given
unlabeled data and some or no labeled data from Q  how to decide which of P1  P2 transfers best to
the target Q. (Appendix A.2)
• Reweighting. Given some amount of unlabeled data from Q  and some or no labeled Q data 
how to optimally re-weight (out of a ﬁxed set of schemes) the source P data towards best target
performance. While differently motivated  this problem is related to the last one. (Appendix A.1)
Although optimal decisions in the above scenarios depend tightly on unknown distributional param-
eters such as different label noise in source and target data  and on unknown distance from source
to target (as captured by )  we show that such practical decisions can be made  near optimally 
with no knowledge of distributional parameters  and perhaps surprisingly  without ever estimating
. Furthermore  the unlabeled sampling complexity can be shown to remain low. Finally  the proce-
dures described in this work remain of a theoretical nature  but yield new insights into how various
practical decisions in transfer can be made near-optimally in a data-driven fashion.

Related Work. Much of the theoretical literature on transfer can be subdivided into a few main
lines of work. As mentioned above  the main distinction with the present work is in that they mostly
focus on situations with no labeled target data  and consider distinct notions of discrepancy between
P and Q. We contrast these various notions with the transfer-exponents ⇢ and  in Section 3.1.
A ﬁrst direction considers reﬁnements of total-variation that quantify changes in error over classiﬁers
in a ﬁxed class H. The most common such measures are the so-called dA-divergence [3  4  5] and
the Y-discrepancy [6  7  8]. In this line of work  the rates of transfer  largely expressed in terms
of nP alone  take the form op(1) + C · divergence(P  Q). In other words  transfer down to 0 error
seems impossible whenever these divergences are non-negligible; we will carefully argue that such
intuition can be overly pessimistic.
Another prominent line of work  which has led to many practical procedures  considers so-called
density ratios fQ/fP (importance weights) as a way to capture the similarity between P and Q
[9  10]. A related line of work considers information-theoretic measures such as KL-divergence or
Renyi divergence [11  12] but has received relatively less attention. Similar to these notions  the
transfer-exponents ⇢ and  are asymmetric measures of distance  attesting to the fact that it could be
easier to transfer from some P to Q than the other way around. However  a signiﬁcant downside to
these notions is that they do not account for the speciﬁc structure of a hypothesis class H as is the
case with the aforementionned divergences. As a result  they can be sensitive to issues such as minor
differences of support in P and Q  which may be irrelevant when learning with certain classes H.
On the algorithmic side  many approaches assign importance weights to source data from P so as
to minimize some prescribed metric between P and Q [13  14]; as we will argue  metrics  being
symmetric  can be inadequate as a measure of discrepancy given the inherent asymmetry in transfer.
The importance of unlabeled data in transfer-learning  given the cost of target labels  has always
been recognized  with various approaches developed over the years [15  16]  including more recent
research efforts into so-called semisupervised or active transfer  where  given unlabeled target data 
the goal is to request as few target labels as possible to improve classiﬁcation over using source data
alone [17  18  19  20  21].
More recently  [22  23  24] consider nonparametric transfer settings (unbounded VC) allowing for
changes in conditional distributions. Also recent  but more closely related  [25] proposed a nonpara-
metric measure of discrepancy which successfully captures the interaction between labeled source
and target under nonparametric conditions and 0-1 loss; these notions however ignore the additional
structure afforded by transfer in the context of a ﬁxed hypothesis class.

2

2 Setup and Deﬁnitions
We consider a classiﬁcation setting where the input X 2X   some measurable space  and the output
Y 2{ 0  1}. We let H⇢ 2X denote a ﬁxed hypothesis class over X   denote dH the VC dimension
.
[26]  and the goal is to return a classiﬁer h 2H with low error RQ(h)
= EQ[h(X) 6= Y ] under some
joint distribution Q on X  Y . The learner has access to two independent labeled samples SP ⇠ P nP
and SQ ⇠ QnQ  i.e.  drawn from source distributions P and target Q  of respective sizes nP   nQ.
Our aim is to bound the excess error  under Q  of any ˆh learned from both samples  in terms of
nP   nQ  and (suitable) notions of discrepancy between P and Q. We will let PX  QX  PY |X  QY |X
denote the corresponding marginal and conditional distributions under P and Q.
.
Deﬁnition 1. For D 2{ Q  P}  denote ED(h)
= RD(h)  inf h02H RD(h0)  the excess error of h.
Distributional Conditions. We consider various traditional assumptions in classiﬁcation and
transfer. The ﬁrst one is a so-called Bernstein Class Condition on noise [27  28  29  30  31].
(NC). Let h⇤P

RP (h) and h⇤Q

.
= argmin

.
= argmin

h2H

PX(h 6= h⇤P )  cp · E P

P (h) 

RQ(h) exist. 9P   Q 2 [0  1]  cP   cQ > 0 s.t.
(1)

h2H
and QX(h 6= h⇤Q)  cq · E Q

Q (h).

For instance  the usual Tsybakov noise condition  say on P   corresponds to the case where
.
h⇤P is the Bayes classiﬁer  with corresponding regression function ⌘P (x)
= E[Y |x] satisfying
PX(|⌘P (X)  1/2| ⌧ )  C⌧ P /(1P ). Classiﬁcation is easiest w.r.t. P (or Q) when P
(resp. Q) is largest. We will see that this is also the case in Transfer.
The next assumption is stronger  but can be viewed as a relaxed version of the usual Covariate-Shift
assumption which states that PY |X = QY |X.
(RCS). Let h⇤P   h⇤Q as deﬁned above. We have EQ(h⇤P ) = EQ(h⇤Q) = 0. We then deﬁne h⇤ .
= h⇤P .
Note that the above allows PY |X 6= QY |X. However  it is not strictly weaker than Covariate-Shift 
since the latter allows h⇤P 6= h⇤Q provided the Bayes /2H . The assumption is useful as it serves to
isolate the sources of hardness in transfer beyond just shifts in h⇤. We will in fact see later that it is
easily removed  but at the additive (necessary) cost of EQ(h⇤P ).
3 Transfer-Exponents from P to Q.

We consider various notions of discrepancy between P and Q  which will be shown to tightly capture
the complexity of transfer P to Q.
Deﬁnition 2. We call ⇢> 0 a transfer-exponent from P to Q  w.r.t. H  if there exists C⇢ such that
(2)

8h 2H   C⇢ · EP (h) E ⇢

Q(h).

We are interested in the smallest such ⇢ with small C⇢. We generally would think of ⇢ as at least 1 
although there are situations – which we refer to as super-transfer  to be discussed  where we have
⇢< 1; in such situations  data from P can yield faster EQ rates than data from Q.
While the transfer-exponent will be seen to tightly capture the two-samples minimax rates of trans-
fer  and can be adapted to  practical learning situations call for marginal versions that can capture
the rates achievable when one has access to unlabeled Q data.
Deﬁnition 3. We call > 0 a marginal transfer-exponent from P to Q if 9C such that

8h 2H   C · PX(h 6= h⇤P )  Q

X(h 6= h⇤P ).

(3)

The following simple proposition relates  to ⇢.
Proposition 1 (From  to ⇢). Suppose Assumptions (NC) and (RCS) hold  and that P has marginal
transfer-exponent (  C) w.r.t. Q. Then P has transfer-exponent ⇢  /P   where C⇢ = C/ P
.
Proof. 8h 2H   we have EQ(h)  QX(h 6= h⇤P )  C · PX(h 6= h⇤P )1/  C · EP (h)P /.



3

2 QX(ht 6= h⇤) = 1

.
= U[0  2] and QX

3.1 Examples and Relation to other notions of discrepancy.
In this section  we consider various examples that highlight interesting aspects of ⇢ and   and their
relations to other notions of distance P ! Q considered in the literature. Though our results cover
noisy cases  in all these examples we assume no noise for simplicity  and therefore  = ⇢.
Example 1. (Non-overlapping supports) This ﬁrst example emphasizes the fact that  unlike in much
of previous analyses of transfer  the exponents   ⇢ do not require that QX and PX have overlapping
support. This is a welcome property shared also by the dA and Y discrepancy.
In the example shown on the right  H is the class of homogeneous linear separa-
tors  while PX and QX are uniform on the surface of the spheres depicted (e.g. 
corresponding to different scalings of the data). We then have that  = ⇢ = 1
with C = 1  while notions such as density-ratios  KL-divergences  or the recent
nonparameteric notion of [25]  are ill-deﬁned or diverge to 1.
Example 2. (Large dA  dY) Let H be the class of one-sided thresholds on the line  but now we
.
= U[0  1]. Let h⇤ be thresholded at 1/2. We then see that for all ht
let PX
thresholded at t 2 [0  1]  2PX(ht 6= h⇤) = 1
2 QX(ht 6= h⇤)  where for t > 1  PX(ht 6= h⇤) =
4. Thus  the marginal transfer exponent  = 1 with C = 2  so
2 (t  1/2)  1
1
we have fast transfer at the same rate 1/nP as if we were sampling from Q (Theorem 3).
On the other hand  recall that the dA-divergence takes the form
.
= suph2H |PX(h 6= h⇤)  QX(h 6= h⇤)|  while the Y-
dA(P  Q)
.
discrepancy takes the form dY (P  Q)
= suph2H |EP (h) E Q(h)|.
The two coincide whenever there is no noise in Y .
Now  take ht as the threshold at t = 1/2  and dA = dY = 1
4 which
would wrongly imply that transfer is not feasible at a rate faster than
2 by letting h⇤ correspond to a
4; we can in fact make this situation worse  i.e.  let dA = dY ! 1
1
threshold close to 0. A ﬁrst issue is that these divergences get large in large disagreement regions;
this is somewhat mitigated by localization  as discussed in Example 4.
Example 3. (Minimum   ⇢  and the inherent asymmetry of transfer) Suppose H is the class of
one-sided thresholds on the line  h⇤ = h⇤P = h⇤Q is a threshold at 0. The marginal QX has uniform
density fQ (on an interval containing 0)  while  for some   1  PX has density fP (t) / t1 on
t > 0 (and uniform on the rest of the support of Q  not shown). Consider any ht at threshold t > 0 
we have PX(ht 6= h⇤) =R t
0 fP / t  while QX(ht 6= h⇤) / t. Notice that for any ﬁxed ✏> 0 
QX (ht6=h⇤)✏
PX (ht6=h⇤) = lim
t>0  t!0

t>0  t!0
We therefore see that  is the smallest possible marginal transfer-
exponent (similarly  ⇢ =  is the smallest possible transfer expo-
nent). Interestingly  now consider transferring instead from Q to P :
.
we would have (Q ! P ) = 1  
= (P ! Q)  i.e.  it could
be easier to transfer from Q to P than from P to Q  which is not
captured by symmetric notions of distance (dA  Wassertein  etc ...).
Finally note that the above example can be extended to more general hypothesis classes as it simply
plays on how fast fP decreases w.r.t. fQ in regions of space.
Example 4.
(Super-transfer and localization). We continue on the above Example 2. Now let
.
0 << 1  and let fP (t) /| t|1 on [1  1] \ {0}  with QX
= U[1  1]  h⇤ at 0. As before   is a
transfer-exponent P ! Q  and following from Theorem 3  we attain transfer rates of EQ . n1/
 
faster than the rates of n1
Q attainable with data from Q. We call these situations super-transfer  i.e. 
ones where the source data gets us faster to h⇤; here P concentrates more mass close to h⇤  while
more generally  such situations can also be constructed by letting PY |X be less noisy than QY |X
data  for instance corresponding to controlled lab data as source  vs noisy real-world data.
Now consider the following ✏-localization ﬁx to the dA = dY divergences over h’s with small P
.
error (assuming we only observe data from P ): d⇤
= suph2H: EP (h)✏ |EP (h) E Q(h)| . This is no
Y
longer worst-case over all h’s  yet it is still not a complete ﬁx. To see why  consider that  given nP
data from P   the best P -excess risk attainable is n1
P so we might set ✏ / n1
P . Now the subclass
{h 2H : EP (h)  ✏} corresponds to thresholds t 2 [±n1/
]  since EP (ht) = P ([0  t]) /| t|.

P

lim

C t✏

t = 1.

P

4

We therefore have d⇤
while the super-transfer rate n1/
localization  d⇤
Y

Y / n1

P

 / n1

P  n1/

P   wrongly suggesting a transfer rate EQ . n1
P  
P
is achievable as discussed above. The problem is that  even after

treats errors under P and Q symmetrically.

4 Lower-Bounds
Deﬁnition 4 ((NC) Class). Let F(NC)(⇢  P   Q  C) denote the class of pairs of distributions (P  Q)
with transfer-exponent ⇢  C⇢  C  satisfying (NC) with parameters P   Q  and cP   cQ  C.
The following lower-bound in terms of ⇢ is obtained via information theoretic-arguments. In effect 
given the VC class H  we construct a set of distribution pairs {(Pi  Qi)} supported on dH datapoints 
which all belong to F(NC)(⇢  P   Q  C). All the distributions share the same marginals PX  QX.
  are close
Any two pairs are close to each other in the sense that ⇧i  ⇧j  where ⇧i
in KL-divergence  while  however maintaining pairs (Pi  Qi)  (Pj  Qj) far in a pseudo-distance in-
duced by QX. All the proofs from this section are in Appendix B.
Theorem 1 (⇢ Lower-bound). Suppose the hypothesis class H has VC dimension dH  9. Let
ˆh = ˆh(SP   SQ) denote any (possibly improper) classiﬁer with access to two independent labeled
samples SP ⇠ P nP and SQ ⇠ QnQ. Fix any ⇢  1  0  P   Q < 1. Suppose either nP or nQ is
sufﬁciently large so that

i ⇥ QnQ

.
= P nP

i

✏(nP   nQ)

.

= min(✓ dH

nP◆1/(2P )⇢

nQ◆1/(2Q))  1/2.
 ✓ dH

Then  for any ˆh  there exists (P  Q) 2F (NC)(⇢  P   Q  1)  and a universal constant c such that 

P

SP  SQ⇣EQ(ˆh) > c · ✏(nP   nQ)⌘ 

3  2p2

.

8

As per Proposition 1 we can translate any upper-bound in terms of ⇢ to an upper-bound in terms of
 since ⇢  /P . We investigate whether such upper-bounds in terms of  are tight  i.e.  given a
class F(NC)(⇢  P   Q  C)  are there distributions with ⇢ = /P where the rate is realized.
The proof of the next result is similar to that of Theorem 1  however with the added difﬁculty that
we need the construction to yield two forms of rates ✏1(nP   nQ) ✏ 2(nP   nQ) over the data support
(again dH points). Combining these two rates matches the desired upper-bound. In effect  we follow
the intuition that  to have ⇢ = /P achieved on some subset X1 ⇢X   we need Q to behave as 1
locally on X1  while matching the rate requires larger Q on the rest of the suppport (on X \ X1).
Theorem 2 ( Lower-bound). Suppose the hypothesis class H has VC dimension dH  bdH/2c  9.
Let ˆh = ˆh(SP   SQ) denote any (possibly improper) classiﬁer with access to two independent labeled
samples SP ⇠ P nP and SQ ⇠ QnQ. Fix any 0 < P   Q < 1  ⇢  max{1/P   1/Q}. Suppose
either nP or nQ is sufﬁciently large so that

✏1(nP   nQ)

✏2(nP   nQ)

.

= min(✓ dH
= min(✓ dH

nQ◆1/(2Q))  1/2  and
nP◆1/(2P )⇢·Q
 ✓ dH
nQ◆)  1/2.
 ✓ dH
nP◆1/(2P )⇢

.

Then  for any ˆh  there exists (P  Q) 2F (NC)(⇢  P   Q  2)  with marginal-transfer-exponent  =
⇢ · P  1  with C  2  and a universal constant c such that 

SP  SQ EQ(ˆh)  c · max{✏1(nP   nQ) ✏ 2(np  nQ)} .
E

Remark 1 (Tightness with upper-bound). Write ✏1(nP   nQ) = min{✏1(nP ) ✏ 1(nQ)}  and simi-
.
larly  ✏2(nP   nQ) = min{✏2(nP ) ✏ 2(nQ)}. Deﬁne ✏L
= max{✏1(nP   nQ) ✏ 2(nP   nQ)} as in the
.
above lower-bound of Theorem 2. Next  deﬁne ✏H
= min{✏2(nP ) ✏ 1(nQ)}. It turns out that the

5

best upper-bound we can show (as a function of ) is in terms of ✏H so deﬁned. It is therefore natural
to ask whether or when ✏H and ✏L are of the same order.
Clearly  we have ✏1(nP )  ✏2(nP ) and ✏1(nQ)  ✏2(nQ) so that ✏L  ✏H (as to be expected).
Now  if Q = 1  we have ✏1(nP ) = ✏2(nP ) and ✏1(nQ) = ✏2(nQ)  so that ✏L = ✏H. More generally 
from the above inequalities  we see that ✏L = ✏H in the two regimes where either ✏1(nQ)  ✏1(nP )
(in which case ✏L = ✏H = ✏1(nQ))  or ✏2(nP )  ✏2(nQ) (in which case ✏L = ✏H = ✏2(nP )).
5 Upper-Bounds

The following lemma is due to [32].

Lemma 1. Let An = dHn log⇣ max{n dH}

. With probability at least 1 
R(h)  R(h0)  ˆR(h)  ˆR(h0) + cqmin{P (h 6= h0)  ˆP (h 6= h0)}An + cAn 

⌘+ 1
n log 1

dH

3  8h  h0 2H  
(4)

and

1
2

P (h 6= h0)  cAn  ˆP (h 6= h0)  2P (h 6= h0) + cAn 

(5)

for a universal numerical constant c 2 (0 1)  where ˆR denotes empirical risk on n iid samples.
Now consider the following algorithm. Let SP be a sequence of nP samples from P and
ˆRSP (h) and ˆhSQ =
SQ a sequence of nQ samples from Q. Also let ˆhSP = argminh2H
argminh2H

ˆRSQ(h). Choose ˆh as the solution to the following optimization problem.

Algorithm 1:

Minimize

subject to

ˆRSP (h)

h 2H .

ˆRSQ(h)  ˆRSQ(ˆhSQ)  cq ˆPSQ(h 6= ˆhSQ)AnQ + cAnQ

(6)

The intuition is that  effectively  the constraint guarantees we maintain a near-optimal guarantee
on EQ(ˆh) in terms of nQ and the (NC) parameters for Q  while (as we show) still allowing the
algorithm to select an h with a near-minimal value of ˆRSP (h). The latter guarantee plugs into the
transfer condition to obtain a term converging in nP   while the former provides a term converging in
nQ  and altogether the procedure achieves a rate speciﬁed by the min of these two guarantees (which
is in fact nearly minimax optimal  since it matches the lower bound up to logarithmic factors).
Formally  we have the following result for this learning rule; its proof is below.
Theorem 3 (Minimax Upper-Bounds). Assume (NC). Let ˆh be the solution from Algorithm 1. For
a constant C depending on ⇢  C⇢  P   cP   Q  cQ  with probability at least 1   
 ✓ dH
nQ◆ 1

nQ  = ˜O min(✓ dH

EQ(ˆh)  C min⇢A

2Q)! .

nP◆ 1

(2P )⇢

(2P )⇢
nP

  A

1

2Q

1

Note that  by the lower bound of Theorem 1  this bound is optimal up to log factors.
.
Remark 2 (Effective Source Sample Size). From the above  we might view (ignoring dH) ˜nP
=
n(2Q)/(2P )⇢
as the effective sample size contributed by P . In fact  the above minimax rate
P
is of order (˜nP + nQ)1/(2Q)  which yields added intuition into the combined effect of both
samples. We have that  the effective source sample size ˜nP is smallest for large ⇢  but also depends
on (2  Q)/(2  P )  i.e.  on whether P is noisier than Q.
Remark 3 (Rate in terms of ). Note that  by Proposition 1  this also immediately implies a bound
under the marginal transfer condition and RCS  simply taking ⇢  /P . Furthermore  by the lower
bound of Theorem 2  the resulting bound in terms of  is tight in certain regimes up to log factors.

6

Proof of Theorem 3. In all the lines below  we let C serve as a generic constant (possibly depending
on ⇢  C⇢  P   cP   Q  cQ) which may be different in different appearances. Consider the event
of probability at least 1  /3 from Lemma 1 for the SQ samples. In particular  on this event  if
EQ(h⇤P ) = 0  it holds that

ˆRSQ(h⇤P )  ˆRSQ(ˆhSQ)  cq ˆPSQ(h⇤P 6= ˆhSQ)AnQ + cAnQ.

This means  under the (RCS) condition  h⇤P satisﬁes the constraint in the above optimization problem
deﬁning ˆh. Also  on this same event from Lemma 1 we have

so that (NC) implies

which implies the well-known fact from [28  29] that

EQ(ˆhSQ)  cqQ(ˆhSQ 6= h⇤Q)AnQ + cAnQ 
EQ(ˆhSQ)  CqEQ(ˆhSQ)QAnQ + cAnQ 
log✓ 1
◆◆ 1
Furthermore  following the analogous argument for SP   it follows that for any set G✓H with
h⇤P 2G   with probability at least 1  /3  the ERM ˆh0SP = argminh2G
◆◆ 1
log✓ 1

EQ(ˆhSQ)  C✓ dH

EP (ˆh0SP )  C✓ dH

log✓ nQ

dH◆ +

log✓ nP

dH◆ +

ˆRSP (h) satisﬁes

In particular  conditioned on the SQ data  we can take the set G as the set of h 2H satisfying
the constraint in the optimization  and on the above event we have h⇤P 2G (assuming the (RCS)
condition); furthermore  if EQ(h⇤P ) = 0  then without loss we can simply deﬁne h⇤Q = h⇤P = h⇤
(and it is easy to see that this does not affect the NC condition). We thereby establish the above
inequality (8) for this choice of G  in which case by deﬁnition ˆh0SP = ˆh. Altogether  by the union
bound  all of these events hold simultaneously with probability at least 1  . In particular  on this
event  if the (RCS) condition holds then

1
nQ

1
nP

.

.

2Q

2P

(7)

(8)

nQ

nP

Applying the deﬁnition of ⇢  this has the further implication that (again if (RCS) holds)

1
nP

nP

EP (ˆh)  C✓ dH
EQ(ˆh)  C✓ dH

nP

log✓ nP
dH◆ +
dH◆ +
log✓ nP

1
nP

log✓ 1
◆◆ 1
◆◆ 1
log✓ 1

2P

.

(2P )⇢

.

Also note that  if ⇢ = 1 this inequality trivially holds  whereas if ⇢< 1 then (RCS) necessarily
holds so that the above implication is generally valid  without needing the (RCS) assumption explic-
itly. Moreover  again when the above events hold  using the event from Lemma 1 again  along with
the constraint from the optimization  we have that

RQ(ˆh)  RQ(ˆhSQ)  2cq ˆPSQ(ˆh 6= ˆhSQ)AnQ + 2cAnQ 

and (5) implies the right hand side is at most

CqQ(ˆh 6= ˆhSQ)AnQ + CAnQ  CqQ(ˆh 6= h⇤Q)AnQ + CqQ(ˆhSQ 6= h⇤Q)AnQ + CAnQ.

Using the Bernstein class condition and (7)  the second term is bounded by

C✓ dH

nQ

while the ﬁrst term is bounded by

2Q

◆◆ 1

1
nQ

log✓ nQ
log✓ 1
dH◆ +
CqEQ(ˆh)QAnQ.

 

7

Altogether  we have that

which implies

EQ(ˆh) = RQ(ˆh)  RQ(ˆhSQ) + EQ(ˆhSQ)
 CqEQ(ˆh)QAnQ + C✓ dH
EQ(ˆh)  C✓ dH
log✓ nQ
dH◆ +

nQ

nQ

log✓ nQ

1
nQ

dH◆ +
log✓ 1

log✓ 1
◆◆ 1

2Q

.

1
nQ

2Q

◆◆ 1

 

Remark 4. Note that the above Theorem 3 does not require (RCS): that is  it holds even when
EQ(h⇤P ) > 0  in which case ⇢ = 1. However  for a related method we can also show a stronger
result in terms of a modiﬁed deﬁnition of ⇢:
Speciﬁcally  deﬁne EQ(h  h⇤P ) = max{RQ(h)  RQ(h⇤P )  0}  and suppose ⇢0 > 0  C⇢0 > 0 satisfy

8h 2H   C⇢0 · EP (h) E ⇢0

Q (h  h⇤P ).

This is clearly equivalent to ⇢ (Deﬁnition 2) under (RCS); however  unlike ⇢  this ⇢0 can be ﬁnite
even in cases where (RCS) fails. With this deﬁnition  we have the following result.

Proposition 2 (Beyond (RCS)). If ˆRSQ(ˆhSP )  ˆRSQ(ˆhSQ)  cq ˆPSQ(ˆhSP 6= ˆhSQ)AnQ + cAnQ 
that is  if ˆhSP satisﬁes (6)  deﬁne ˆh = ˆhSP   and otherwise deﬁne ˆh = ˆhSQ. Assume (NC). For a
constant C depending on ⇢0  C⇢0  P   cP   Q  cQ  with probability at least 1   

EQ(ˆh)  min⇢EQ(h⇤P ) + CA

1

(2P )⇢0
nP

  CA

1

2Q

nQ  .

The proof of this result is similar to that of Theorem 3  and as such is deferred to Appendix C.

An alternative procedure. Similar results as in Theorem 3 can be obtained for a method that
swaps the roles of P and Q samples:

Algorithm 10 :

Minimize

subject to

ˆRSQ(h)

h 2H .

ˆRSP (h)  ˆRSP (ˆhSP )  cq ˆPSP (h 6= ˆhSP )AnP + cAnP

This version  more akin to so-called hypothesis transfer may have practical beneﬁts in scenarios
where the P data is accessible before the Q data  since then the feasible set might be calculated (or
approximated) in advance  so that the P data itself would no longer be needed in order to execute
the procedure. However this procedure presumes that h⇤P is not far from h⇤Q  i.e.  that data SP from
P is not misleading  since it conditions on doing well on SP . Hence we now require (RCS).
Proposition 3. Assume (NC) and (RCS). Let ˆh be the solution from Algorithm 10. For a constant C
depending on ⇢  C⇢  P   cP   Q  cQ  with probability at least 1   
nP◆ 1

nQ  = ˜O min(✓ dH

EQ(ˆh)  C min⇢A

 ✓ dH
nQ◆ 1

2Q)! .

(2P )⇢
nP

(2P )⇢

2Q

  A

1

1

The proof is very similar to that of Theorem 3  so is omitted for brevity.

6 Minimizing Sampling Cost

In this section (and continued in Appendix A.1)  we discuss the value of having access to unlabeled
data from Q. The idea is that unlabeled data can be obtained much more cheaply than labeled data 

8

so gaining access to unlabeled data can be realistic in many applications. Speciﬁcally  we begin
by discussing an adaptive sampling scenario  where we are able to draw samples from P or Q  at
different costs  and we are interested in optimizing the total cost of obtaining a given excess Q-risk.
Formally  consider the scenario where we have as input a value ✏  and are tasked with producing
a classiﬁer ˆh with EQ(ˆh)  ✏. We are then allowed to draw samples from either P or Q toward
achieving this goal  but at different costs. Suppose cP : N ! [0 1) and cQ : N ! [0 1) are cost
functions  where cP (n) indicates the cost of sampling a batch of size n from P   and similarly deﬁne
cQ(n). We suppose these functions are increasing  and concave  and unbounded.
Deﬁnition 5. Deﬁne n⇤Q = dH/✏2Q  n⇤P = dH/✏(2P )/ P   and c⇤ = mincQ(n⇤Q)  cP (n⇤P ) .

We call c⇤ = c⇤(✏; cP   cQ) the minimax optimal cost of sampling from P or Q to attain Q-error ✏.

Note that the cost c⇤ is effectively the smallest possible  up to log factors  in the range of parameters
given in Theorem 2. That is  in order to make the lower bound in Theorem 2 less than ✏  either
nQ = ˜⌦(n⇤Q) samples are needed from Q or nP = ˜⌦(n⇤P ) samples are needed from P . We show
that c⇤ is nearly achievable  adaptively with no knowledge of distributional parameters.

Procedure. We assume access to a large unlabeled data set UQ sampled from QX. For our pur-
poses  we will suppose this data set has size at least ⇥( dH✏ log 1
Let A0n = dHn log( max{n dH}
argminh2H

ˆRS(h)  and given an additional data set U (labeled or unlabeled) deﬁne a quantity

 ). Then for any labeled data set S  deﬁne ˆhS =

n log( 2n2

✏ log 1

✏ + 1

) + 1

 ).

dH

ˆ(S  U ) = sup⇢ ˆPU (h 6= ˆhS) : h 2H   ˆRS(h)  ˆRS(ˆhS)  cq ˆPS(h 6= ˆhS)A0

|S|

+ cA0

|S|  

where c is as in Lemma 1. Now we have the following procedure.

Algorithm 2:
0. SP {}  SQ {}
1. For t = 1  2  . . .
2. Let nt P be minimal such that cP (nt P )  2t1
3. Sample nt P samples from P and add them to SP
4. Let nt Q be minimal such that cQ(nt Q)  2t1
5. Sample nt Q samples from Q and add them to SQ
If cqˆ(SQ  SQ)A|SQ| + cA|SQ|  ✏  return ˆhSQ
6.
If ˆ(SP   UQ)  ✏/4  return ˆhSP
7.

The following theorem asserts that this procedure will ﬁnd a classiﬁer ˆh with EQ(ˆh)  ✏ while
adaptively using a near-minimal cost associated with achieving this. The proof is in Appendix D.
Theorem 4 (Adapting to Sampling Costs). Assume (NC) and (RCS). There exist a constant c0 
depending on parameters (C    cQ  Q  cP   P ) but not on ✏ or   such that the following holds.
.
Deﬁne sample sizes ˜nQ = c0
Algorithm 2 outputs a classiﬁer ˆh such that  with probability at least 1   we have EQ(ˆh)  ✏  and
the total sampling cost incurred is at most min{cQ(˜nQ)  cP (˜nP )} = ˜O(c⇤).
Thus  when c⇤ favors sampling from P   we end up sampling very few labeled Q data. These are sce-
narios where P samples are cheap relative to the cost of Q samples and w.r.t. parameters (Q P  )
which determine the effective source sample size contributed for every target sample. Furthermore 
we achieve this adaptively: without knowing (or even estimating) these relevant parameters.

✏(2P )/ P dH log 1

✏2Q dH log 1

  and ˜nP =

✏ + log 1

✏ + log 1

c0

Acknowledgments

We thank Mehryar Mohri for several very important discussions which helped crystallize many
essential questions and directions on this topic.

9

References
[1] Ilja Kuzborskij and Francesco Orabona. Stability and hypothesis transfer learning. In Pro-

ceedings of the 30th International Conference on Machine Learning  pages 942–950  2013.

[2] Simon S Du  Jayanth Koushik  Aarti Singh  and Barnabás Póczos. Hypothesis transfer learning
via transformation functions. In Advances in Neural Information Processing Systems  pages
574–584  2017.

[3] Shai Ben-David  John Blitzer  Koby Crammer  Alex Kulesza  Fernando Pereira  and Jen-
nifer Wortman Vaughan. A theory of learning from different domains. Machine learning 
79(1-2):151–175  2010.

[4] Shai Ben-David  Tyler Lu  Teresa Luu  and Dávid Pál.

Impossibility theorems for domain
adaptation. In Proceedings of the Thirteenth International Conference on Artiﬁcial Intelligence
and Statistics  pages 129–136  2010.

[5] Pascal Germain  Amaury Habrard  François Laviolette  and Emilie Morvant. A pac-bayesian
approach for domain adaptation with specialization to linear classiﬁers. In International Con-
ference on Machine Learning  pages 738–746  2013.

[6] Yishay Mansour  Mehryar Mohri  and Afshin Rostamizadeh. Domain adaptation: Learning

bounds and algorithms. arXiv preprint arXiv:0902.3430  2009.

[7] Mehryar Mohri and Andres Munoz Medina. New analysis and algorithm for learning with
In International Conference on Algorithmic Learning Theory  pages

drifting distributions.
124–138. Springer  2012.

[8] Corinna Cortes  Mehryar Mohri  and Andrés Munoz Medina. Adaptation based on general-
ized discrepancy. Machine Learning Research  forthcoming. URL http://www. cs. nyu. edu/˜
mohri/pub/daj. pdf.

[9] Joaquin Quionero-Candela  Masashi Sugiyama  Anton Schwaighofer  and Neil D Lawrence.

Dataset shift in machine learning. The MIT Press  2009.

[10] Masashi Sugiyama  Taiji Suzuki  and Takafumi Kanamori. Density ratio estimation in machine

learning. Cambridge University Press  2012.

[11] Masashi Sugiyama  Shinichi Nakajima  Hisashi Kashima  Paul V Buenau  and Motoaki
Kawanabe. Direct importance estimation with model selection and its application to covariate
shift adaptation.
In Advances in neural information processing systems  pages 1433–1440 
2008.

[12] Yishay Mansour  Mehryar Mohri  and Afshin Rostamizadeh. Multiple source adaptation and
the rényi divergence. In Proceedings of the Twenty-Fifth Conference on Uncertainty in Artiﬁ-
cial Intelligence  pages 367–374. AUAI Press  2009.

[13] Corinna Cortes  Mehryar Mohri  Michael Riley  and Afshin Rostamizadeh. Sample selection
bias correction theory. In International conference on algorithmic learning theory  pages 38–
53. Springer  2008.

[14] Arthur Gretton  Alex Smola  Jiayuan Huang  Marcel Schmittfull  Karsten Borgwardt  and
Bernhard Schölkopf. Covariate shift by kernel mean matching. Dataset shift in machine
learning  3(4):5  2009.

[15] Jiayuan Huang  Arthur Gretton  Karsten M Borgwardt  Bernhard Schölkopf  and Alex J Smola.
Correcting sample selection bias by unlabeled data. In Advances in neural information pro-
cessing systems  pages 601–608  2007.

[16] Shai Ben-David and Ruth Urner. On the hardness of domain adaptation and the utility of
unlabeled target samples. In International Conference on Algorithmic Learning Theory  pages
139–153. Springer  2012.

10

[17] Avishek Saha  Piyush Rai  Hal Daumé  Suresh Venkatasubramanian  and Scott L DuVall. Ac-
tive supervised domain adaptation. In Joint European Conference on Machine Learning and
Knowledge Discovery in Databases  pages 97–112. Springer  2011.

[18] Minmin Chen  Kilian Q Weinberger  and John Blitzer. Co-training for domain adaptation. In

Advances in neural information processing systems  pages 2456–2464  2011.

[19] Rita Chattopadhyay  Wei Fan  Ian Davidson  Sethuraman Panchanathan  and Jieping Ye. Joint
transfer and batch-mode active learning. In Sanjoy Dasgupta and David McAllester  editors 
Proceedings of the 30th International Conference on Machine Learning  volume 28 of Pro-
ceedings of Machine Learning Research  pages 253–261  2013.

[20] Liu Yang  Steve Hanneke  and Jaime Carbonell. A theory of transfer learning with applications

to active learning. Machine learning  90(2):161–189  2013.

[21] Christopher Berlind and Ruth Urner. Active nearest neighbors in changing environments. In

International Conference on Machine Learning  pages 1870–1879  2015.

[22] Gilles Blanchard  Aniket Anand Deshmukh  Urun Dogan  Gyemin Lee  and Clayton Scott.
Domain generalization by marginal transfer learning. arXiv preprint arXiv:1711.07910  2017.
In

[23] Clayton Scott. A generalized neyman-pearson criterion for optimal domain adaptation.

Algorithmic Learning Theory  pages 738–761  2019.

[24] T Tony Cai and Hongji Wei. Transfer learning for nonparametric classiﬁcation: Minimax rate

and adaptive classiﬁer. arXiv preprint arXiv:1906.02903  2019.

[25] Samory Kpotufe and Guillaume Martinet. Marginal singularity  and the beneﬁts of labels in

covariate-shift. arXiv preprint arXiv:1803.01833  2018.

[26] V. Vapnik and A. Chervonenkis. On the uniform convergence of relative frequencies of events

to their expectation. Theory of probability and its applications  16:264–280  1971.

[27] P. L. Bartlett and S. Mendelson. Empirical minimization. Probability Theory and Related

Fields  135(3):311–334  2006.

[28] P. Massart and É. Nédélec. Risk bounds for statistical learning. The Annals of Statistics 

34(5):2326–2366  2006.

[29] V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization.

The Annals of Statistics  34(6):2593–2656  2006.

[30] A. B. Tsybakov. Optimal aggregation of classiﬁers in statistical learning. The Annals of Statis-

tics  32(1):135–166  2004.

[31] E. Mammen and A. B. Tsybakov. Smooth discrimination analysis. The Annals of Statistics 

27(6):1808–1829  1999.

[32] V. Vapnik and A. Chervonenkis. Theory of Pattern Recognition. Nauka  1974.
[33] Alexandre B Tsybakov. Introduction to nonparametric estimation. Springer  2009.
[34] A. W. van der Vaart. Asymptotic Statistics. Cambridge University Press  1998.
[35] S. Hanneke and L. Yang. Surrogate losses in passive and active learning. arXiv:1207.3772 

2012.

11

,Fariborz Salehi
Ehsan Abbasi
Babak Hassibi
Steve Hanneke
Samory Kpotufe