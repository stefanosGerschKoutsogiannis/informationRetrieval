2010,Copula Bayesian Networks,We present the Copula Bayesian Network model for representing multivariate continuous distributions. Our approach builds on a novel copula-based parameterization of a conditional density that  joined with a graph that encodes independencies  offers great flexibility in modeling high-dimensional densities  while maintaining control over the form of the univariate marginals. We demonstrate the advantage of our framework for generalization over standard Bayesian networks as well as tree structured copula models for varied real-life domains that are of substantially higher dimension than those typically considered in the copula literature.,Copula Bayesian Networks

Gal Elidan

Department of Statistics

Hebrew University

Jerusalem  91905  Israel

galel@huji.ac.il

Abstract

We present the Copula Bayesian Network model for representing multivariate
continuous distributions  while taking advantage of the relative ease of estimat-
ing univariate distributions. Using a novel copula-based reparameterization of a
conditional density  joined with a graph that encodes independencies  our model
offers great ﬂexibility in modeling high-dimensional densities  while maintaining
control over the form of the univariate marginals. We demonstrate the advantage
of our framework for generalization over standard Bayesian networks as well as
tree structured copula models for varied real-life domains that are of substantially
higher dimension than those typically considered in the copula literature.

Introduction

1
Multivariate real-valued distributions are of paramount importance in a variety of ﬁelds ranging from
computational biology and neuro-science to economics to climatology. Choosing and estimating a
useful form for the marginal distribution of each variable in the domain is often a straightforward
task. In contrast  aside from the normal representation  few univariate distributions have a conve-
nient multivariate generalization. Indeed  modeling and estimation of ﬂexible (skewed  multi-modal 
heavy tailed) high-dimensional distributions is still a formidable challenge.
Copulas [23] offer a general framework for constructing multivariate distributions using any given
(or estimated) univariate marginals and a copula function C that links these marginals. The impor-
tance of copulas is rooted in Sklar’s theorem [29] that states that any multivariate distribution can
be represented as a copula function of its marginals. The constructive converse is important from a
modeling perspective as it allows us to separate the choice of the marginals and that of the depen-
dence structure which is expressed in C. We can  for example  robustly estimate marginals using
a non-parametric approach  and then use only few parameters to capture the dependence structure.
This can result in a model that is easier to estimate and less prone to over-ﬁtting than a fully non-
parametric one  while at the same time avoiding the limitations of a fully parameterized distribution.
In practice  copula constructions often lead to signiﬁcant improvement in density estimation. Ac-
cordingly  there has been a dramatic growth of academic and practical interest in copulas in recent
years  with applications ranging from mainstream ﬁnancial risk assessment and actuarial analysis
(e.g.  Embrechts et al. [7]) to off-shore engineering (e.g.  Accioly and Chiyoshi [2]).
Despite the generality of the framework  constructing high-dimensional copulas is difﬁcult  and
much of the research involves only the bivariate case. Several works have attempted to overcome
this difﬁculty by suggesting innovative ways in which bivariate copulas can be combined to form
workable copulas of higher dimensions. These attempts  however  are either limited to hierarchical
[26] or mixture of trees [14] compositions  or rely on a recursive construction of conditional bivariate
copulas [1  3  17] that is somewhat elaborate for high dimensions.
In practice  applications are
almost always limited to a modest (< 10) number of variables (see Section 6 for further discussion).
Bayesian networks (BNs) [25] offer a markedly different approach for representing multivariate
distributions. In this widely used framework  a graph structure encodes independencies which imply
a decomposition of the joint density into local terms (the density of each variable conditioned on its

1

parents). This decomposition in turn facilitates efﬁcient probabilistic computation and estimation 
making the framework amenable to high-dimensional domains. However  the expressiveness of
these models is hampered by practical considerations that almost always lead to the the reliance
on simple parametric forms. Speciﬁcally  non-parametric variants of BNs (e.g.  [9  27]) typically
involve elaborate training setups with a running time that grows unfavorably with the number of
samples and local graph connectivity. Furthermore  aside from the case of the normal distribution 
the form of the univariate marginal is neither under control nor is it typically known.
Our goal is to construct ﬂexible multivariate continuous distributions that maintain desired marginals
while accommodating tens and hundreds of variables  or more. We present Copula Bayesian Net-
works (CBNs)  an elegant marriage between the copula and the Bayesian network frameworks.1 As
in BNs  we make use of a graph to encode independencies that are assumed to hold. Differently 
we rely on local copula functions and an explicit globally shared parameterization of the univariate
densities. This allows us to retain the ﬂexibility of BNs  while offering control over the form of the
marginals  resulting in substantially improved multivariate densities (see Section 7 for a discussion
of the related works of Kirshner [14] and Liu et al. [20]).
At the heart of our approach is a novel reparameterization of a conditional density using a copula
quotient. With this construction  we prove a parallel to the BN factorization theorem: a decomposi-
tion of the joint density according to the structure of the graph implies a decomposition of the joint
copula. Conversely  a product of local copula-based quotient terms is a valid multivariate copula.
This result provides us with a ﬂexible modeling tool where joint densities are constructed via a com-
position of local copulas and marginal densities. Importantly  the construction also allows us to use
standard BN machinery for estimation and structure learning. Thus  our model opens the door for
ﬂexible explorative learning of high-dimensional models that retain desired marginal characteristics.
We learn the structure and parameters of a CBN for three varied real-life domains that are of a
signiﬁcantly higher dimension than typically reported in the copula literature. Using standard copula
functions  we show that in all cases our approach leads to consistent and signiﬁcant improvement in
generalization when compared to standard BN models as well as a tree-structured copula model.

2 Copulas
Let X = {X1  . . .   XN} be a ﬁnite set of real-valued random variables and let FX (x) ≡ P (X1 ≤
x1  . . .   Xn ≤ xN ) be a (cumulative) distribution function over X   with lower case letters denoting
assignment to variables. By slight abuse of notation  we use F(xi) ≡ F (Xi ≤ xi  XX /Xi = ∞)
and f(xi) ≡ fXi(xi)  and similarly for sets of variables f (y) ≡ fY(y). A copula function [23  29]
links marginal distributions to form a multivariate one. Formally 
Deﬁnition 2.1: Let U1  . . .   UN be real random variables marginally uniformly distributed on [0  1].
A copula function C : [0  1]N → [0  1] is a joint distribution function

C(u1  . . .   uN ) = P (U1 ≤ u1  . . .   UN ≤ uN )

Copulas are important because of the following seminal result
Theorem 2.2:
random variables  then there exists a copula function such that

[Sklar 1959] Let F (x1  . . .   xN ) be any multivariate distribution over real-valued

Furthermore  if each F(xi) is continuous then C is unique.

F (x1  . . .   xN ) = C(F(x1)  . . .   F(xN )).

The constructive converse which is of central interest from a modeling perspective is also true: since
for any random variable the cumulative distribution F(xi) is uniformly distributed on [0  1]  any
copula function taking the marginal distributions {F(xi)} as its arguments  deﬁnes a valid joint
distribution with marginals F(xi). Thus  copulas are “distribution-generating” functions that allow
us to separate the choice of the univariate marginals and that of the dependence structure expressed
in the copula function C  often resulting in an effective real-valued construction.2.

1A preliminary draft of this paper appeared as a technical report. A companion paper [6] addresses the

question of performing approximate inference in Copula Bayesian networks.

2Copulas can also be deﬁned given non-continuous marginals and for ordinal random variables. These

extensions are orthogonal to our work and to maintain clarity we focus here on the continuous case

2

Figure 1: Samples from the 2-
dimensional normal copula den-
sity using a correlation ma-
trix with a unit diagonal and
an off-diagonal coefﬁcient of
0.25. (left) with zero mean and
unit variance normal marginals;
(right) with a mixture of two
Gaussians marginals.

Normal(1  1) marginals

Mix of Gaussians marginals

To derive the joint density f (x) = ∂N F (x)
from the copula construction  assuming F has N-order
∂x1...∂xN
partial derivatives (true almost everywhere when F is continuous)  and using the chain rule  we have

(cid:89)

(cid:89)

f (x) =

∂N C(F(x1)  . . .   F(xN ))

∂F(x1) . . . ∂F(xN )

f(xi) = c(F(x1)  . . .   F(xN ))

f(xi) 

(1)

i

i

where c(F(x1)  . . .   F(xN ))  is called the copula density function. Eq. (1) will be of central use in
this paper as we will directly model joint densities.

Example 2.3: A simple copula widely explored in the ﬁnancial community is the Gaussian copula
constructed directly by inverting Sklar’s theorem [7]

(cid:0)Φ−1(F(x1))  . . .   Φ−1(F(xN ))(cid:1)  

C({F(xi)}) = ΦΣ

(2)
where Φ is the standard normal distribution and ΦΣ is the zero mean normal distribution with cor-
relation matrix Σ. To get a sense of the power of copulas  Figure 1 shows samples generated from
this copula using two different families of univariate marginals. More generally and without added
computational difﬁculty  we can also mix and match marginals of different forms.

3 Copula Bayesian Networks (CBNs)
As in the copula framework  our goal is to model real-valued multivariate distributions while taking
advantage of the relative ease of one dimensional estimation. To cope with high-dimensional do-
mains  as in BNs  we would also like to utilize independence assumptions encoded by a graph. To
achieve this goal  we will construct multivariate copulas that are a composition of local copulas that
follow the structure of the graph. We start with the building block of our construction.

3.1 Copula Parameterization of The Conditional Density
As in the BN framework  the building block of our model will be a local conditional density. We
start with a parameterization of such a density using copulas:
Lemma 3.1: Let f (x | y)  with y = {y1  . . .   yK}  be a conditional density function and let f (x) be
the marginal density of X. Then there exists a copula density function c(F(x)  F(y1)  . . .   F(yK))
such that

f (x | y) = Rc(F(x)  F(y1)  . . .   F(yK))f (x)

where Rc is the ratio
Rc(F(x)  F(y1)  . . .   F(yK)) ≡

(cid:82) c(F(x)  F(y1)  . . .   F(yK))f (x)dx

c(F(x)  F(y1)  . . .   F(yK))

=

c(F(x)  F(y1)  . . .   F(yK))

∂K C(1 F(y1) ... F(yK ))

 

∂F(y1)...∂F(yK )

and where Rc is deﬁned to be 1 when y = ∅. The converse is also true  for any copula density
function c  Rc(F(x)  F(y1)  . . .   F(yK))f (x) deﬁnes a valid conditional density function.

Before proving this result 
denominator

(right-most

it
term)

(cid:82) c(F(x)  F(y1)  . . .   F(yK))f (x)dx. Recall that c() is itself an N-order derivative of the cop-

to understand why the derivative form of
than the standard normalization integral

is important
is more useful

ula function so computing our denominator is no more difﬁcult than computing c(). Indeed  for
the majority of existing copula functions  both have an explicit form. In contrast  the integral term
depends both on the copula form and the univariate marginal  and is generally difﬁcult to compute.

3

(cid:239)1012345(cid:239)1012345(cid:239)202468(cid:239)4(cid:239)202468Proof: From the basic properties of cumulative distribution functions  we have that for any copula
function C(1  F(y1)  . . .   F(yK)) = F (y1  . . .   yk) and thus  using the derivative chain rule 

∂KC(1  F(y1)  . . .   F(yK))

f (y) =

c(F(x)  F(y1)  . . .   F(yK))f (x)(cid:81)

From Eq. (1) we have that

∂y1  . . .   yK

f (x | y) =

f (x  y1  . . .   yK)

f (y)

=

=

∂KC(1  F(y1)  . . .   F(yK))

(cid:89)
c(F(x)  F(y1)  . . .   F(yK))f (x)(cid:81)

∂F(y1) . . . ∂F(yK)

k

∂K C(1 F(y1) ... F(yK ))

∂F(y1)...∂F(yK )

k f (yk)

(cid:81)

f (yk).

k f (yk)

there exists a copula density for which f (x  y1  . . .   yK) =

k f (yk). It follows that there exists a copula for which

=

c(F(x)  F(y1)  . . .   F(yK))f (x)

∂K C(1 F(y1) ... F(yK ))

∂F(y1)...∂F(yK )

≡ Rc(F(x)  F(y1)  . . .   F(yK))f (x)

As in Sklar’s theorem and Eq. (1)  the converse follows easily by reversing the arguments.
The implications of this result will underlie our construction: any copula density function
c(x  y1  . . .   yK)  together with f (x)  can be used to parameterize a conditional density f (x | y).

conditional densities fX (x) = (cid:81)

3.2 Decomposition of The Joint Copula
Let G be a directed acyclic graph whose nodes correspond to the random variables X   and let Pai =
{Pai1  . . .   Paiki} be the parents of Xi in G. G encodes the independence statements I(G) =
{(Xi ⊥ NonDescendantsi | Pai)}  where NonDescendantsi are nodes that are non-descendants
of Xi in G. We say that fX (x) decomposes according to G if it can be written as a product of
i f (Xi | Pai). It can be shown that if f decomposes according
to G then I(G) hold in fX (x). The converse is also true: if I(G) hold in fX (x) then the density
decomposes according to G (see [16]  theorems 3.1 and 3.2). These results form the basis for the
BN model [25] where a joint density is constructed via a composition of local conditional densities.
We now show that similar results hold for a multivariate copula. This in turn will provide the basis
for our construction of the CBN model.
Theorem 3.2 : Decomposition. Let G be a directed acyclic graph over X   and let fX (x) be
i f(xi)  with fX (x)
strictly positive for all values of X . If fX (x) decomposes according to G then the copula density
c(F(x1)  . . .   F(xN )) also decomposes according to G

parameterized via a joint copula density fX (x) = c(F(x1)  . . .   F(xN ))(cid:81)

c(F(x1)  . . .   F(xN )) =

Rci(F(xi) {F(paik)}) 

where ci is a local copula that depends only on the value of Xi and its parents in G.
Proof: Using the positivity assumption  we can rearrange Eq. (1) to get c(F(x1)  . . .   F(xN )) =
f (x)(cid:81)
(cid:81)
i f(xi). From Lemma 3.1 and the decomposition of f (x) we have
(cid:81)
i f (xi | pai)
(cid:81)
(cid:89)
i Rci(F(xi) {F(paik)})f(xi)

c(F(x1)  . . .   F(xN )) =

f (x)(cid:81)

i f(xi)

i f(xi)

=

Rci (F(xi) {F(paik)})

=

(cid:81)

i f(xi)

=

i

(cid:89)

i

The constructive converse that is of central interest here is also true:

Composition. Let G be a directed acyclic graph over X .

Theorem 3.3 :
In addition  let
{ci(F(xi)  F(pai1)  . . .   F(paiki))} be a set of strictly positive copula densities associated with
the nodes of G that have at least one parent. If I(G) hold then the function
Rci(F(xi) {F(paik)}) 

g(F(x1)  . . .   F(xN )) =

(cid:89)

is a valid copula density c(F(x1)  . . .   F(xN )) over X .

i

4

This above theorem can be proved directly via induction or using our reparameterization lemma
and standard BN results. It is important to note that the local copulas do not need to agree on the
non-univariate marginals of overlapping variables. This is a result of the fact that each copula ci
only appears as part of a quotient term which is used to parameterize a conditional density. This
gives us the freedom to mix and match local copulas of different types. Equally important is the
fact that aside from the univariate densities  we do not need to concern ourselves with any marginal
constraints when estimating the parameters of these local copulas functions.

3.3 A Multivariate Copula Model
We are now ready to construct a joint density given univariate marginals by properly composing
local terms and without worrying about global coherence:
Deﬁnition 3.4: A Copula Bayesian Network (CBN) is a triplet C = (G  ΘC  Θf ) that encodes the
joint density fX (x). ΘC is a set of local copula densities functions ci(F(xi) {F(paik)}) that are
associated with the nodes of G that have at least one parent. Θf is the set of parameters representing
the marginal densities f(xi). fX (x) is parameterized as

(cid:89)

fX (x) =

Rci(F(xi) {F(paik)})f(xi).

Using our previous developments and applying Eq. (1) to fX (x)  we have:

i

Corollary 3.5: A Copula Bayesian Network deﬁnes a valid joint density fX (x) whose marginal
distributions are parameterized by Θf and where the independence statements I(G) hold.
The main difference between the CBN model and a regular BN  aside from a novel choice for the
local conditional parameterization  is in the shared global component that has the explicit semantics
of the univariate marginals. Concretely  the CBN model allows us to decompose the problem of
representing a multivariate distribution with given (or estimated) univariate marginals into many
local problems that  depending on the structure of G  can be substantially smaller in dimension.
For each family of Xi and its parents we are still faced with the problem of choosing an appropriate
local copula. In this work we simply limit ourselves to copulas that have convenient multivariate
form  but any of the recently suggested methods for constructing multivariate copulas functions (see
Section 6) can also be used.
In either case  limiting ourselves to a smaller number of variables
(a node and its parents) makes the construction of the local copula substantially easier than the
construction of the full copula over X . Importantly  as in the case of BNs  our construction of a
joint copula density that decomposes over the graph structure G also facilitates efﬁcient parameter
estimation and model selection (structure learning)  as we brieﬂy discuss in the next section.

4 Learning
As in the case of BNs  the product form of our CBN facilitates relatively efﬁcient estimation and
model selection. The machinery is standard and only brieﬂy described below.

Parameter Estimation
Given a complete dataset D of M instances where all of the variables X are observed in each
instance  the log-likelihood of the data given a CBN model C is

(cid:96)(D : C) =(cid:80)M

(cid:80)

i log f (xi[m]) +(cid:80)M

m=1

(cid:80)

m=1

i log Ri(F(xi)[m]  F(pai1[m])  . . .   F(paiki[m]))
While this objective appears to fully decompose according to the structure of G  each marginal
distribution F(xi) actually appears in several local copula terms (of Xi and its children in G). To
facilitate efﬁcient estimation  we adopt the common approach where the marginals are estimated
ﬁrst [13]. Given F(xi)  we can then estimate the parameters of each local copula independently of
the others. We estimate the univariate densities using a standard normal kernel-based approach [24].
In this work we consider two of the simplest and most commonly used copula functions. For Frank’s
Archimedean copula C(u1  . . .   uN ) = − 1
the Gaussian copula (see Section 2) with a uniform correlation parameter  we ﬁnd the maximum

i(e−θF(xi) − 1)/(e−θ − 1)N−1(cid:1)   and for

θ log(cid:0)1 +(cid:81)

5

Wine Train

Dow Jones Train

Crime Train

Wine Test

Dow Jones Test

Crime Test

Figure 2: Train and test set performance for the 12 variable Wine  28 variable Dow Jones and 100 variables
Crime datasets. Models compared: Sigmoid BN; CBN with a uniform correlation normal copula (single
parameter); CBN with a full normal copula (0.5 ∗ d(d − 1) parameters); CBN with Frank’s single parameter
copula. Shown is the 10-fold average log-probability per instance (y-axis) vs. the maximal number of parents
allowed in the network (x-axis). Error bars (slightly shifted for readability) show the 10 − 90% range. The
structure for all models was learned with the same search procedure using the BIC model selection score.

likelihood parameters using a standard conjugate gradient algorithm. For the Gaussian copula with
a full covariance matrix  a reasonably effective and substantially more efﬁcient method is based on
the relationship between the copula function and Kendall’s Tau dependence measure [19]. For lack
of space  further details for both of these copulas are provided in the supplementary material.

Model Selection
Very brieﬂy  to learn the structure of G  we use a standard score-based approach that starts
with the empty network  and greedily advances via local modiﬁcations to the current structure
(add/delete/reverse edge). The search is guided by the Bayesian information criterion [28] that bal-
2 log(M )|ΘG| 
ances the likelihood of the model and its complexity score(G : D) = (cid:96)(D : ˆθ G)− 1
where ˆθ are the maximum-likelihood parameters  and |ΘG| is the number of free parameters asso-
ciated with the graph structure G. During the search  we also use a TABU list and random restarts
[10] to mitigate the problem of local maxima. See Koller and Friedman [16] for more details.

5 Experimental Evaluation
We assess the effectiveness of our approach for density estimation by comparing CBNs and BNs
learned from training data in terms of log-probability performance on test data. For BNs  we use a
linear Gaussian conditional density and a non-linear Sigmoid one (see Koller and Friedman [16]).
For CBNs  to demonstrate the ﬂexibility of our framework  we consider the three local copula func-
tions discussed in Section 4: fully parametrized Normal copula; the same copula with a single cor-
relation parameter and unit diagonal (UnifCorr); Frank’s single parameter Archimedean copula.
We use standard normal kernel density estimation for the univariate densities. The structure of both
the BN and CBN models was learned using the same greedy structure search procedure described in
Section 4. We consider three datasets of a markedly different nature and dimensionality:
• Wine Quality (UCI repository). 11 physiochemical properties and a sensory quality variable for

the red Portuguese ”Vinho Verde” wine [4]. Included are measurements from 1599 tastings.

6

(cid:239)0.500.511.522.533.544.5(cid:239)11(cid:239)10(cid:239)9(cid:239)8(cid:239)7(cid:239)6(cid:239)5(cid:239)4(cid:239)3Maximum number of parents10(cid:239)fold train log(cid:239)probability / instance(cid:239)0.500.511.522.533.544.5(cid:239)32(cid:239)30(cid:239)28(cid:239)26(cid:239)24(cid:239)22(cid:239)20(cid:239)18(cid:239)16Maximum number of parents(cid:239)0.500.511.522.533.544.520406080100120140160180200Maximum number of parents  Sigmoid BNKernel(cid:239)Gaussian CBNKernel(cid:239)UnifCorr CBNKernel(cid:239)Frank’s CBNNormal(cid:239)UnifCorr CBN(cid:239)0.500.511.522.533.544.5(cid:239)11(cid:239)10(cid:239)9(cid:239)8(cid:239)7(cid:239)6(cid:239)5(cid:239)4(cid:239)3Maximum number of parents10(cid:239)fold test log(cid:239)probability / instance(cid:239)0.500.511.522.533.544.5(cid:239)32(cid:239)30(cid:239)28(cid:239)26(cid:239)24(cid:239)22(cid:239)20(cid:239)18Maximum number of parents(cid:239)0.500.511.522.533.544.520406080100120140160180200Maximum number of parents  Sigmoid BNKernel(cid:239)Gaussian CBNKernel(cid:239)UnifCorr CBNKernel(cid:239)Frank’s CBNNormal(cid:239)UnifCorr CBNComparison
Figure 3:
of
the number of edges
learned in the different
random run for different
models (y-axis) vs. the Sig-
moid BN model (x-axis) 
when the maximal number
of parents in the network
was limited to 4.

Wine dataset

Crime dataset

• Dow Jones. 2001-2005 (1508 trading days) daily adjusted changes of the 30 index stocks. To
avoid arbitrary imputation  two stocks not traded in all of these days were excluded (KFT TRV).
• Crime (UCI repository). 100 observed variables relating to crime ranging from household size to

fraction of children born outside of a marriage  for 1994 communities across the U.S.

Figure 2 compares average log-probability (y-axis) for 10 random equal train/test splits as a function
of the maximal number of parents allowed in the network (x-axis). Results for the linear Gaussian
BN were almost identical to those of the sigmoid BN for the Wine and Dow Jones datasets and
inferior for the Crime dataset  and are omitted for clarity. For all datasets  the copula based models
offer a clear gain in training performance as well as in generalization on unseen test instances.
Remarkably  the single parameter (for each local density) UnifCorr model is superior to the BN
model even when the latter utilizes up to 8 local parameters (with 4 parents). In fact  even Frank’s
single parameter Archimedean copula which is constrained by the fact that all of its K-marginals are
equal [23]  is superior to the BN model. Importantly  the advantage of the CBN model is signiﬁcant
as the units of improvement are in bits/instance. That is  an improvement of 2 bits/instance translates
into each test instance being  on average  four times as likely.3 It is also important to note the beneﬁt
that comes with structures that are richer than a tree. As the number of allowed parents (x-axis) is
increased  gains are relatively small when the dimensionality of the domain is limited (12 variables);
The gains are  however  quite substantial for the more complex domains.
To understand the role of the univariate marginals  we start with the no dependency network (0
on x-axis)  where the advantage of CBNs is solely due to the use of ﬂexible univariate marginals.
Surprisingly  even with single parameter copulas  although much simpler than the Sigmoid form
used for the BN model  we are able to maintain much of that advantage as the model becomes
more complex. As expected  this is not the case when we constrain the CBN model to have normal
marginals (Normal-UnifCorr) and when the domain is sufﬁciently complex (Crime).
To get a sense of the overall dependency structure  Figure 3 shows the number of edges learned for
the different models. For the Wine dataset  the linear BN attempts to compensate for its constrained
form by using substantially more edges than the non-linear Sigmoid BN. The Kernel-UnifCorr
CBN  in contrast  tends to use less edges while achieving higher test performance. Finally  the
Normal-UnifCorr CBN model  despite the forced normal marginals  does not lead to overly com-
plex structures as it is constrained by the simplicity of the copula function (single parameter). For
the challenging Crime dataset  the differences are more pronounced: both the linear and non-linear
BN models almost saturate the limit of 4 parents per variable  while the Kernel-UnifCorr copula
model requires  on average  less than half the number of parents to achieve superior performance.
Finally  in Figure 4  we demonstrate the qualitative advantage of CBNs by comparing empirical
values from the test data (left) with samples generated from the different models. For the ’physical
density’ and ’alcohol’ variables (top)  the CBN samples (middle) are better than the BN ones (right) 
but not dramatically so. However  for the ’residual sugar’ and ’physical density’ pair (bottom)  where
the empirical dependence is far from normal  the advantage of the CBN representation is clear. We
recall that the CBN model uses a simple normal copula so that the advantage is solely rooted in the
distortion of the input to the copula created by the kernel-based univariate representation. With more
expressive copulas we can expect further qualitative and quantitative advantages.

3Note that the performance for the crime domain is on an unusually high scale since some of the variables
are closely correlated  leading to peaked densities. We emphasize that this does not effect the relative merit of
a method - an advantage of a bit/instance still translates to each instance being  on average  twice as likely.

7

1416182022242628303214161820222426283032# edges in Sigmoid BN# edges in competitor180200220240260280300320340360180200220240260280300320340360# edges in Sigmoid BN# edges in competitor  Kernel(cid:239)UnifCorr CBNGaussian BNNormal(cid:239)UnifCorr CBNEmpirical

CBN Samples

BN Samples

Figure 4: Demonstration of the depen-
dency learned for the Wine dataset for
two variable pairs. Compared is the
empirical distribution in the test data
(left) with samples generated from the
learned CBN (middle) and BN (right)
models. To eliminate the effect of dif-
ferences in structure  the CBN model
was forced to use the structure learned
for the BN model which contains the
network fragment ’residual sugar’ →
’physical density’ → ’alcohol level’.

6 Related Work
For lack of space we do not discuss direct multivariate copula constructions (e.g.  [8  15  18  22]) that
are typically effective only for few dimensions  and focus on composite constructions that build on
smaller (bivariate) copulas. The Vine model [3] relies on a recursive construction of bivariate copulas
to parameterize a multivariate one. Although it uses a graphical representation  the framework is
inherently different from ours: conditional independence is replaced with a conditional dependence
whose parameters depend on the conditioning variable(s). Kurwicka and Cooke [17] reveal a direct
connection between vines and belief networks  but that is limited to the scenario of elliptical bivariate
copulas. Relying on the same representation  Aas et al. [1] suggest an alternative construction
methodology. While the vine representation is certainly general  the need to condition on many
variables using a somewhat elaborate construction limits practical applications to a modest number
of variables. Aas et al. [1] do note the simpliﬁcation that can result from making independence
assumptions  but do not provide a general framework for doing so. Savu and Trede [26] suggest an
alternative model that is limited to a hierarchical tree structure of bivariate Archimedean copulas.
Kirshner [14] uses the copula product operator of Darsow et al. [5] to suggest a mixture of trees
model that is directly motivated by the ﬁeld of graphical models. The relationship between our
model to theirs is the same as that of a general BN to a mixture of trees model [21]. Most recently 
Liu et al. [20] consider a general sparse undirected copula-based model that is focused on the semi
and non-parametric aspect of modeling  and is speciﬁc to the case of the normal copula.
Finally  it is important to put the dimension of the domains we consider in this work (up to 100
variables) in perspective. Copula applications are numerous yet most are limited to a relatively
small number (< 10) of variables. Heinen and Alfonso [11] are unique in that they consider 95
variables  but using an approach that is tailored to the speciﬁc details of the GARCH model.

7 Discussion and Future Work
We presented Copula Bayesian Networks  a marriage between the Bayesian network and copula
frameworks. Building on a novel reparameterization of the conditional density  our model offers
great ﬂexibility in modeling high-dimensional continuous distribution while offering control over
the form of the univariate marginals. We applied our approach to three markedly different real-life
datasets and  in all cases  demonstrated a consistent and signiﬁcant generalization advantage.
Our contribution is threefold. First  our framework allows us to ﬂexibly “mix and match” local
copulas and univariate densities of any form. Second  like BNs  we allow for independence as-
sumptions that are more expressive than those possible with tree-based constructions  leading to
generalization advantages. Third  we leverage on existing machinery to perform model selection in
signiﬁcantly higher dimensions than typically considered in the copula literature. Thus  our work
opens the door for numerous applications where the ﬂexibility of copulas is needed but could not
be previously utilized. In a companion paper [6]  we also show that CBNs give rise to an efﬁcient
inference procedure.
The gap between train and test performance for CBNs motivates the development of model selection
scores tailored to the copula framework (e.g.  based on rank correlation). It would also be interesting
to see if our framework can be adapted to the cumulative scenario  while allowing for independencies
quite different from the recently introduced cumulative network model [12].

8

0.990.99511.00589101112131415Physical densityAlcohol level0.990.99511.005891011121314Physical densityAlcohol level0.9850.990.99511.0051.017891011121314Physical densityAlcohol level02468101214160.990.99511.005Residual sugarPhysical density02468101214160.990.99511.005Residual sugarPhysical density(cid:239)1012345670.9850.990.99511.0051.01Residual sugarPhysical densityAcknowledgements
I am grateful to Ariel Jaimovich  Amir Globerson  Nir Friedman and Fabio Spizzichino for their
comments on earlier drafts of this manuscript. G. Elidan was supported by the Alon fellowship.
References
[1] K. Aas  C. Czado  A. Frigessi  and H. Bakken. Pair-copula constructions of multiple dependencies.

Insurance: Mathematics and Economics  44:182–198  2009.

[2] R. Accioly and F. Chiyoshi. Modeling dependence with copulas: a useful tool for ﬁeld development

decision process. Journal of Petroleum Science and Engineering  44:83–91  2004.

[3] T. Bedford and R. Cooke. Vines - a new graphical model for dependent random variables. Annals of

Statistics  30(4):1031–1068  2002.

[4] P. Cortez  A. Cerdeira  F. Almeida  T. Matos  and J. Reis. Modeling wine preferences by data mining

from physicochemical properties. Decision Support Systems  47(4):547–553  2009.

[5] W. Darsow  B. Nguyen  and E. Olsen. Copulas and Markov processes. Illinois J Math  36:600–642  1992.
[6] G. Elidan. Inference-less density estimation using Copula Bayesian Networks. In Uncertainty in Artiﬁcial

Intelligence (UAI)  2010.

[7] P. Embrechts  F. Lindskog  and A. McNeil. Modeling dependence with copulas and applications to risk

management. Handbook of Heavy Tailed Distributions in Finance  2003.

[8] M. Fischer and C. Kock. Constructing and generalizing given multivariate copulas. Technical report 

Working paper  University of Erlangen-Nurnberg  Nurnberg  2007.

[9] N. Friedman and I. Nachman. Gaussian Process Networks. In Uncertainty in AI (UAI)  2000.
[10] F. Glover and M. Laguna. Tabu search. In C. Reeves  editor  Modern Heuristic Techniques for Combina-

torial Problems  Oxford  England  1993. Blackwell Scientiﬁc Publishing.

[11] A. Heinen and A. Alfonso. Asymmetric CAPM dependence for large dimensions: The canonical vine

autoregressive copula model. ECORE Discussion Paper  2008.

[12] J. Huang and B. Frey. Cumulative distribution networks and the derivative-sum-product algorithm. In

Uncertainty in Artiﬁcial Intelligence (UAI)  2008.

[13] H. Joe and J. Xu. The estimation method of inference functions for margins for multivariate models.

Technical Report 166  Department of Statistics  University of British Columbia  1996.

[14] S. Kirshner. Learning with tree-averaged densities and distributions. In Neural Information Processing

Systems (NIPS)  2007.

[15] K. Koehler and J. Symanowski. Constructing multivariate distributions with speciﬁc marginal distribu-

tions. Journal of Multivariate Distributions  55:261–282  1995.

[16] D. Koller and N. Friedman. Probabilistic Graphical Models: Principles and Techniques. MIT  2009.
[17] D. Kurwicka and R. Cooke. The vine copula method for representing high dimensional dependent distri-

butions: Applications to continuous belief nets. In The Winter Simulation Conference  2002.

[18] E. Liebscher. Modelling and estimation of multivariate copulas. Technical report  Working paper  Uni-

versity of Applied Sciences  Merseburg  2006.

[19] F. Lindskog  A. McNeil  and U. Schmock. Kendall’s tau for elliptical distributions. Credit Risk - mea-

surement  evaluation and management  pages 149–156  2003.

[20] H. Liu  J. Lafferty  and L. Wasserman. The nonparanormal: Semiparametric estimation of high dimen-

sional undirected graphs. Journal of Machine Learning Research  10:22952328  2010.

[21] M. Meila and M. Jordan. Estimating dependency structure as a hidden variable. In Neural Information

Processing Systems (NIPS)  1998.

[22] P. Morillas. A method to obtain new copulas from a given one. Metrika  61:169–184  2005.
[23] R. Nelsen. An Introduction to Copulas. Springer  2007.
[24] E. Parzen. On estimation of a probability density function and mode. Annals of Mathematical Statistics 

33:1065–1076  1962.

[25] J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann  1988.
[26] C. Savu and M. Trede. Hierarchical archimedean copulas. In the Conf on High Frequency Finance  2006.
[27] A. Schwaighofer  M. Dejori  V. Tresp  and M. Stetter. Structure Learning with Nonparametric Decom-

posable Models. In the International Conference on Artiﬁcial Neural Networks  2007.

[28] G. Schwarz. Estimating the dimension of a model. Annals of Statistics  6:461–464  1978.
[29] A. Sklar. Fonctions de repartition a n dimensions et leurs marges. Publications de l’Institut de Statistique

de L’Universite de Paris  8:229–231  1959.

9

,Damek Davis
Brent Edmunds
Madeleine Udell