2019,ADDIS: an adaptive discarding algorithm for online FDR control with conservative nulls,Major internet companies routinely perform tens of thousands of A/B tests each year. Such large-scale sequential experimentation has resulted in a recent spurt of new algorithms that can provably control the false discovery rate (FDR) in a fully online fashion. However  current state-of-the-art adaptive algorithms can suffer from a significant loss in power if null p-values are conservative (stochastically larger than the uniform distribution)  a situation that occurs frequently in practice. In this work  we introduce a new adaptive discarding method called ADDIS that provably controls the FDR and achieves the best of both worlds: it enjoys appreciable power increase over all existing methods if nulls are conservative (the practical case)  and rarely loses power if nulls are exactly uniformly distributed (the ideal case). We provide several practical insights on robust choices of tuning parameters  and extend the idea to asynchronous and offline settings as well.,ADDIS: an adaptive discarding algorithm

for online FDR control with conservative nulls

Department of Statistics and Data Science

Department of Statistics and Data Science

Aaditya Ramdas

Carnegie Mellon University

Pittsburgh  PA 15213
aramdas@cmu.edu

Jinjin Tian

Carnegie Mellon University

Pittsburgh  PA 15213

jinjint@andrew.cmu.edu

Abstract

Major internet companies routinely perform tens of thousands of A/B tests each
year. Such large-scale sequential experimentation has resulted in a recent spurt of
new algorithms that can provably control the false discovery rate (FDR) in a fully
online fashion. However  current state-of-the-art adaptive algorithms can suffer
from a signiﬁcant loss in power if null p-values are conservative (stochastically
larger than the uniform distribution)  a situation that occurs frequently in practice.
In this work  we introduce a new adaptive discarding method called ADDIS
that provably controls the FDR and achieves the best of both worlds: it enjoys
appreciable power increase over all existing methods if nulls are conservative (the
practical case)  and rarely loses power if nulls are exactly uniformly distributed
(the ideal case). We provide several practical insights on robust choices of tuning
parameters  and extend the idea to asynchronous and ofﬂine settings as well.

1

Introduction

Rapid data collection is making the online testing of hypotheses increasingly essential  where a
stream of hypotheses H1  H2  . . . is tested sequentially one by one. On observing the data for the t-th
test which is usually summarized as a p-value Pt  and without knowing the outcomes of the future
tests  we must make the decision of whether to reject the corresponding null hypothesis Ht (thus
proclaiming a “discovery”). Typically  a decision takes the form I(Pt ≤ αt) for some αt ∈ (0  1) 
meaning that we reject the null hypothesis when the p-value is smaller than some threshold αt. An
incorrectly rejected null hypothesis is called a false discovery. Let R(T ) represent the set of rejected
null hypotheses until time T   and H0 be the unknown set of true null hypotheses; then  R(T ) ∩ H0
is the set of false discoveries. Then some natural error metrics are the false discovery rate (FDR) 
modiﬁed FDR (mFDR) and power  which are deﬁned as
FDR(T ) ≡ E

.
(1)
The typical aim is to maximize power  while have FDR(T ) ≤ α at any time T ∈ N  for some
prespeciﬁed constant α ∈ (0  1). It is well known that setting every αt ≡ α does not provide any
control of the FDR in general. Indeed  the FDR can be as large as one in this case  see [1  Section
1] for an example. This motivates the need for special methods for online FDR control (that is  for
determining αt in an online manner).

  mFDR(T ) ≡ E [|H0 ∩ R(T )|]
E [|R(T )| ∨ 1]

0 ∩ R(T )|
0|
|Hc

(cid:20)|H0 ∩ R(T )|

|R(T )| ∨ 1

(cid:21)

  power ≡ E

(cid:20)|Hc

(cid:21)

Past work. Foster and Stine [2] proposed the ﬁrst “alpha-investing” (AI) algorithm for online FDR
control  which was later extended to the generalized alpha-investing methods (GAI) by Aharoni and
Rosset [3]. A particularly powerful GAI algorithm called LORD was proposed by Javanmard and

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Montanari [4]. Soon after  Ramdas et al. [1] proposed a modiﬁcation called LORD++ that uniformly
improved the power of LORD. Most recently  Ramdas et al. [5] developed the “adaptive” SAFFRON
algorithm  and alpha-investing is shown to be a special case of the more general SAFFRON framework.
SAFFRON arguably represents the state-of-the-art  achieving signiﬁcant power gains over all other
algorithms including LORD++ in a range of experiments.
However  an important point is that SAFFRON is more powerful only when the p-values are exactly
uniformly distributed under the null hypothesis. In practice  one frequently encounters conservative
nulls (see below)  and in this case SAFFRON can have lower power than LORD++ (see Figure 1).

Uniformly conservative nulls. When performing hypothesis testing  we always assume that the
p-value P is valid  which means that if the null hypothesis is true  we have Pr{P ≤ x} ≤ x for all
x ∈ [0  1]. Ideally  a p-value is exactly uniformly distributed  which means that the inequality holds
with equality. However  we say a null p-value is conservative if the inequality is strict  and often the
nulls are uniformly conservative  which means that under the null hypothesis  we have

Pr{P/τ ≤ x | P ≤ τ} ≤ x

for all x  τ ∈ (0  1).

(2)
As an obvious ﬁrst example  the p-values being exactly uniform (the ideal setting) is a special case.
Indeed  for a uniform U ∼ U [0  1]  if you know that U is less than (say) τ = 0.4  then the conditional
distribution of U is just U [0  0.4]  which means that U/0.4 has a uniform distribution on [0  1]  and
hence Pr{U/0.4 ≤ x | U ≤ 0.4} ≤ x for any x ∈ (0  1). A mathematically equivalent deﬁnition of
uniformly conservative nulls is that the CDF F of a null p-value P satisﬁes the following property:
(3)
Hence  any null p-value with convex CDF is uniformly conservative. Particularly  when F is
differentiable  the convexity of F is equivalent to its density f being monotonically increasing. Here
are two tangible examples of tests with uniformly conservative nulls:

for all 0 ≤ x  τ ≤ 1.

F (τ x) ≤ xF (τ ) 

• A test of Gaussian mean: we test the null hypothesis H0 : µ ≤ 0 against the alternative
H1 : µ > 0; the observation is Z ∼ N (µ  1) and the p-value is computed as P = Φ(−Z) 
where Φ is the standard Gaussian CDF.
• A test of Gaussian variance: we observe Z ∼ N (0  σ) and we wish to test the null hypothesis
H0 : σ ≤ 1 against the H1 : σ > 1 and the p-value is P = 2Φ(−|Z|).

It is easy to verify that  if the true µ in the ﬁrst test is strictly smaller than zero  or the true σ in the
second test is strictly smaller than one  then the corresponding null p-values have monotonically
increasing density  thus being uniformly conservative. More generally  Zhao et al. [6] presented the
following sufﬁcient condition for a one-dimensional exponential family with true parameter θ: when
the true θ is strictly smaller than θ0  the uniformly most powerful (UMP) test of H0 : θ ≤ θ0 versus
H1 : θ > θ0 is uniformly conservative. Since the true underlying state of nature is rarely exactly at
the boundary of the null set (like µ = 0 or σ = 1 or θ = θ0 in the above examples)  it is common in
practice to encounter uniformly conservative nulls. In the context of A/B testing  this corresponds
to testing H0 : µB ≤ µA against H1 : µB > µA  when in reality  B (the new idea) is strictly worse
than A (the existing system)  a very likely scenario.

Our contribution The main contribution of this paper is a new method called ADDIS (an ADaptive
algorithm that DIScards conservative nulls)  that compensates for the power loss of SAFFRON with
conservative nulls. ADDIS is based on a new serial estimate of the false discovery proportion 
having adaptivity to both fraction of nulls (like SAFFRON) and the conservativeness of nulls (unlike
SAFFRON). As shown in Figure 1  ADDIS enjoys appreciable power increase over SAFFRON as
well as LORD++ under settings with many conservative nulls  and rarely loses power when the nulls
are exactly uniformly distributed (not conservative). Our work is motivated by recent work by Zhao
et al. [6] and Ellis et al. [7] who study nonadaptive ofﬂine multiple testing problems with conservative
nulls  and ADDIS can be regarded as extending their work to both online and adaptive settings. The
connection to the ofﬂine setting is that ADDIS effectively employs a “discarding” rule  which states
we should discard (that is  not test) a hypothesis with p-value exceeding certain threshold. Beyond
the online setting  we also incorporate this rule into several other existing FDR methods  and formally
prove that the resulting new methods still control the FDR  while demonstrating numerically they
have a consistent power advantage over the original methods. Figure 2 presents the relational chart of

2

historical FDR control methods together with some of the new methods we proposed. As far as we
know  we provide the ﬁrst method that adapts to the conservativeness of nulls in the online setting.

Figure 1: Statistical power and FDR versus fraction of non-null hypotheses πA for ADDIS  SAFFRON
and LORD++ at target FDR level α = 0.05 (solid black line). The curves above 0.05 line display
the power of each methods versus πA  while the lines below 0.05 display the FDR of each methods
versus πA. The experimental setting is described in Section 3: we set µA = 3 for both ﬁgures  but
µN = −1 for the left ﬁgure and µN = 0 for the right ﬁgure (hence the left nulls are conservative 
the right nulls are not). These ﬁgures show that (a) all considered methods do control the FDR at
level 0.05  (b) SAFFRON sometimes loses its superiority over its nonadaptive variant LORD++ with
conservative nulls (i.e. µN < 0); and (c) ADDIS is more powerful than SAFFRON and LORD++
with conservative nulls  while loses almost nothing under settings with uniform nulls (i.e. µN = 0).

Ofﬂine methods

BH [8]

adaptivity

online analog

Online methods

LORD [4]
LORD++ [1]

adaptivity

discarding

discarding

Storey-BH [9]

online analog

SAFFRON [5]

special case

Alpha-Investing [2]

D-StBH (Section S-2)

online analog

ADDIS (Section 2)

Figure 2: Historical context: ADDIS generalizes SAFFRON  which generalizes Alpha-Investing and
LORD++. Analogously  D-StBH (supplement) generalizes Storey-BH  which generalizes BH.

Paper outline.
In Section 2  we derive the ADDIS algorithm and state its guarantees (FDR and
mFDR control)  deferring proofs to the supplement. Speciﬁcally  in Section 2.4  we discuss how
to choose the hyperparameters in ADDIS to balance adaptivity and discarding for optimal power.
Section 3 shows simulations which demonstrate the advantage of ADDIS over non-discarding or
non-adaptive methods. We then generalize the “discarding” rule of ADDIS in Section 4 and use it to
obtain the “discarding” version of many other methods under various settings. We also show the error
control with formal proofs for those variants in the supplement. Finally  we present a short summary
in Section 5. The code to reproduce all ﬁgures in the paper is included in the supplement.

2 The ADDIS algorithm

Before deriving the ADDIS algorithm  it is useful to set up some notation. Recall that Pj is the
p-value for testing hypothesis Hj. For some sequences {αt}∞
t=1  where each
term is in the range [0  1]  deﬁne the indicator random variables

t=1 and {λt}∞

t=1  {τt}∞

Sj = 1{Pj ≤ τj}  Cj = 1{Pj ≤ λj}  Rj = 1{Pj ≤ αj}.

They respectively answer the questions: “was Hj selected for testing? (or was it discarded?)”  “was
Hj a candidate for rejection?” and “was Hj rejected  yielding a discovery?”. We call the sets
S(t) = {j ∈ [t] : Sj = 1}  C(t) = {j ∈ [t] : Cj = 1}  R(t) = {j ∈ [t] : Rj = 1}

as the “selected (not discarded) set”  “candidate set” and “rejection set” after t steps respectively.
Similarly  we deﬁne R1:t = {R1  . . .   Rt}  C1:t = {C1  . . .   Ct} and S1:t = {S1  . . .   St}. In what
follows in this section and the next section  we repeatedly encounter the ﬁltration

F t := σ(R1:t  C1:t  S1:t).

3

0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.20.40.60.8πA0.050.250.50.751.0FDR / PowerWe insist that αt  λt and τt are predictable  that is they are measurable with respect to F t−1. This
means that αt  λt  τt are really mappings from {R1:t−1  C1:t−1  S1:t−1} (cid:55)→ [0  1].
The presentation is cleanest if we assume that the p-values from the different hypotheses are indepen-
dent (which would be the case if each A/B test was based on fresh data  for example). However  we
can also prove mFDR control under a mild form of dependence: we call the null p-values conditionally
uniformly conservative if for any t ∈ H0  we have that

∀x  τ ∈ (0  1)  Pr(cid:8)Pt/τ ≤ x(cid:12)(cid:12) Pt ≤ τ F t−1(cid:9) ≤ x.

(4)
Note that the above condition is equivalent to the (marginally) uniformly conservative property (2) if
the p-values are independent  and hence Pt is independent of F t−1. For simplicity  we will refer this
“conditionally uniformly conservative” property still as “uniformly conservative”.

2.1 Deriving ADDIS algorithm
Denote the (unknown) false discovery proportion by FDP ≡ |H0∩R(T )|
can control the FDR at any time t by instead controlling an oracle estimate of the FDP  given by

|R(T )|∨1 . As mentioned in [5]  one

FDP∗(t) : =

αj
j≤t j∈H0
|R(t)| ∨ 1

(5)
This means that if we can keep FDP∗(t) ≤ α at all times t  then we can prove that FDR(t) ≤ α at all
times t. Since the set of nulls H0 is unknown  LORD++ [1] is based on the simple upper bound of

FDP∗(t)  deﬁned as (cid:100)FDPLORD++(t)  and SAFFRON [5] is based on a more nuanced adaptive bound
on FDP∗(t)  deﬁned as (cid:100)FDPSAFFRON(t)  obtained by choosing a predictable sequence {λj}∞

j=1; where

.

(cid:80)

(cid:100)FDPLORD++(t) : =

(cid:80)

j≤t αj
|R(t)| ∨ 1

(cid:80)

  (cid:100)FDPSAFFRON(t) : =

1{Pj >λj}

j≤t αj
1−λj
|R(t)| ∨ 1

.

(6)

It is easy to ﬁx α1 < α  and then update α2  α3  . . . in an online fashion to maintain the invariant

(cid:100)FDPLORD++(t) ≤ α at all times  which the authors prove sufﬁces for FDR control  while it is also
proved that keeping (cid:100)FDPSAFFRON(t) ≤ α at all times sufﬁces for FDR control at any time. However 
we expect (cid:100)FDPSAFFRON(t) to be closer 1 to FDP∗(t) than (cid:100)FDPLORD++(t)  and since SAFFRON better

uses its FDR budget  it is usually more powerful than LORD++. SAFFRON is called an “adaptive”
algorithm  because it is the online analog of the Storey-BH procedure [9]  which adapts to the
proportion of nulls in the ofﬂine setting.
However  in the case when there are many conservative null p-values (whose distribution is stochasti-
cally larger than uniform)  many terms in { 1{λj <Pj}
: j ∈ H0} may have expectations much larger

than one  making (cid:100)FDPSAFFRON(t) an overly conservative estimator of FDP∗(t)  and thus causing

a loss in power. In order to ﬁx this  we propose a new empirical estimator of FDP∗(t). We pick
two predictable sequences {λj}∞
j=1 such that λj < τj for all j  for example setting
λj = 1/4  τj = 1/2 for all j  and deﬁne

j=1 and {τj}∞

1−λj

(7)

1{λj <Pj≤τj}

j≤t αj

τj−λj
|R(t)| ∨ 1

θj : =

λj

τj≡

j≤t αj

1{Pj≤τj}1{Pj /τj >θj}
|R(t)| ∨ 1

τj (1−θj )

the idea that the numerator of (cid:100)FDPADDIS(t) is a much tighter estimator of(cid:80)
with that of (cid:100)FDPSAFFRON(t). In order to see why this is true  we provide the following lemma.

With many conservative nulls  the claim that ADDIS is more powerful than SAFFRON  is based on
αj  compared

Lemma 1. If a null p-value P has a differentiable convex CDF  then for any constants a  b ∈ (0  1) 
we have

j≤t j∈H0

b(1 − a)

(8)
1To see this intuitively  consider the case when (a) λj ≡ 1/2 for all j  (b) there is a signiﬁcant fraction
of non-nulls  and the non-null p-values are all smaller than 1/2 (strong signal)  and (c) the null p-values are
exactly uniformly distributed. Then  1{1/2<Pj}
evaluates to 0 for every non-null  and equals one for every null
1/2
1{λj <Pj}
j≤t αj

in expectation. Thus  in this case  E(cid:104)(cid:80)

(cid:105) (cid:28) E(cid:104)(cid:80)

j≤t αj

(cid:105)

αj

.

.

j≤t j∈H0

1−λj

≤ Pr{P > a}
(1 − a)
= E(cid:104)(cid:80)

(cid:105)

Pr{ab < P ≤ b}

(cid:80)

(cid:100)FDPADDIS(t) : =

(cid:80)

4

for t = 1  2  . . . do

Reject the t-th null hypothesis if Pt ≤ αt  where αt : = min{λ (cid:98)αt}  and
(cid:16)
(cid:98)αt : = (τ − λ)
Here  St =(cid:80)
i<t 1{Pi ≤ τ}  Cj+ =(cid:80)t−1
j =(cid:80)

κj = min{i ∈ [t − 1] :(cid:80)

W0γSt−C0+ + (α − W0)γSt−κ∗

1−C1+ + α(cid:80)

i=κj +1 1{Pi ≤ λ} 
κ∗

k≤i 1{Pk ≤ αk} ≥ j} 

i≤κj

(cid:17)

j≥2 γSt−κ∗

j −Cj+

.

1{Pi ≤ τ}.

j=1 and {τj}∞

The proof of Lemma 1 is presented in Section S-4. Recalling deﬁnition (3)  Lemma 1 implies that

for some uniformly conservative nulls  our estimator (cid:100)FDPADDIS will be tighter than (cid:100)FDPSAFFRON in
expectation  and thus an algorithm based on keeping (cid:100)FDPADDIS ≤ α is expected to have higher power.
“ADDIS algorithm” if it updates αt in a way such that it maintains the invariant (cid:100)FDPADDIS(t) ≤ α.

ADDIS algorithm We now present the general ADDIS algorithm. Given user-deﬁned sequences
{λj}∞
j=1 as described previously  we call an online FDR algorithm as an instance of the
We also enforce the constraint that τt > λt ≥ αt for all t  which is needed for correctness of the proof
of FDR control. This is not a major restriction since we often choose α = 0.05  and the algorithms set
αt ≤ α  in which case τt > λt ≥ 0.05 easily satisﬁes the needed constraint. Now  the main nontrivial
question is how to ensure the invariant in a fully online fashion. We address this by providing an
explicit instance of ADDIS algorithm  called ADDIS∗ (Algorithm 1)  in the following section. From

the form of the invariant (cid:100)FDPADDIS(t) ≤ α  we observe that any p-value Pj that is bigger than τj has

no inﬂuence on the invariant  as if it never existed in the sequence at all. This reveals that ADDIS
effectively implements a “discarding" rule: it discards p-values exceeded a certain threshold. If the
p-value is not discarded  then Pj/τj is a valid p-value and we resort to using adaptivity like (6).
2.2 ADDIS∗: an instance of ADDIS algorithm using constant λ and τ
Here we present an instance of ADDIS algorithm  with choice of λj ≡ λ and τj ≡ τ for all j. (We
consider constant λ and τ for simplicity  but these can be replaced by λj and τj at time j.)
Algorithm 1: The ADDIS∗ algorithm
Input: FDR level α  discarding threshold τ ∈ (0  1]  candidate threshold λ ∈ [0  τ )  sequence
j=0 which is nonnegative  nonincreasing and sums to one  initial wealth W0 ≤ α.

{γj}∞

end

In Section S-5.2  we verify that αt is a monotonic function of the past2. In Section S-10  we present
Algorithm S-3  which is an equivalent version of the above ADDIS∗ algorithm  but it explicitly
discards p-values larger than τ  thus justifying our use of the term “discarding” throughout this paper.

Note that if we choose λ ≥ α  then the constraint αt : = min{λ (cid:98)αt} is vacuous and reduces to
αt : =(cid:98)αt  because(cid:98)αt ≤ α by construction. The power of ADDIS varies with λ and τ  as discussed

further in Section 2.4.

2.3 Error control of ADDIS algorithm

Here we present error control guarantees for ADDIS  and defer proofs to Section S-5 and Section S-6.
Theorem 1. If the null p-values are uniformly conservative (4)  and suppose we choose αj  λj and
τj such that τj > λj ≥ αj for each j ∈ N  then we have:

(a) any algorithm with (cid:100)FDPADDIS(t) ≤ α for all t ∈ N also enjoys mFDR(t) ≤ α for all t ∈ N.
(b) any algorithm with (cid:100)FDPADDIS(t) ≤ α for all t ∈ N also enjoys FDR(t) ≤ α for all t ∈ N.

If we additionally assume that the null p-values are independent of each other and of the non-nulls 
and always choose αt  λt and 1 − τt to be monotonic functions of the past for all t  then we
additionally have:
As an immediate corollary  any ADDIS algorithm enjoys mFDR control  and ADDIS∗ (Algorithm 1)
additionally enjoys FDR control since it is a monotonic rule.

2We say that a function ft(R1:t−1  C1:t−1  S1:t−1) : {0  1}3(t−1) → [0  1] is a monotonic function of the
past  if ft is coordinatewise nondecreasing in Ri and Ci  and is coordinatewise nonincreasing in Si. This is a
generalization of the monotonicity of SAFFRON [5]  which is recovered by setting Si = 1 for all i  that is we
never discard any p-value.

5

The above result only holds for nonrandom times. Below  we also show that any ADDIS algorithm
controls mFDR at any stopping time with ﬁnite expectation.
Theorem 2. Assume that the null p-values are uniformly conservative  and that minj{τj − λj} > 
for some  > 0. Then  for any stopping time Tstop with ﬁnite expectation  any algorithm that maintains

the invariant (cid:100)FDPADDIS(t) ≤ α for all t enjoys mFDR(Tstop) ≤ α.

Once more  the conditions for the theorem are not restrictive because the sequences {λj}∞
{τj}∞

j=1 and
j=1 are user-chosen  and λj = 1/4  τj = 1/2 is a reasonable default choice  as we justify next.

2.4 Choosing τ and λ to balance adaptivity and discarding
As we mentioned before  the power of our ADDIS∗ algorithm is closely related to the hyper-
parameters λ and τ. In fact  there is also an interaction between the hyper-parameters λ and τ  which
means that one cannot decouple the effect of each on power. One can see this interaction clearly
in Figure 3 which displays a trade off between adaptivity (λ) and discarding (τ). Indeed  the right
sub-ﬁgure displays a “sweet spot” for choosing λ  τ  which should neither be too large nor too small.
Ideally  one would hope that there exists some universally optimal choice of λ  τ that yields maximum
power. Unfortunately  the relationship between power and these parameters changes with the
underlying distribution of the null and alternate p-values  as well as their relative frequency. Therefore 
below  we only provide a heuristic argument about how to tune these parameters for ADDIS∗.

Recall that the ADDIS∗ algorithm is derived by tracking the empirical estimator (cid:100)FDPADDIS (7) with
ﬁxed λ and τ  and keeping it bounded by α over time. Since (cid:100)FDPADDIS serves as an estimate of
(cid:100)FDPADDIS. One simple way to choose λ and τ is to minimize the expectation of the indicator term in

the oracle FDP∗ (5)  it is natural to expect higher power with a more reﬁned (i.e. tighter) estimator

the estimator. Speciﬁcally  if the CDF of all p-values is F   then an oracle would choose λ  τ as

(λ∗  τ∗) ∈ arg min

λ<τ∈(0 1)

F (τ ) − F (λ)

τ − λ

.

(9)

In order to remove the constraints between the two variables  we again deﬁne θ = λ/τ  then the
optimization problem (9) is equivalent to
(θ∗  τ∗) ∈ arg min
θ τ∈(0 1)

≡ (g ◦ F )(θ  τ ).

F (τ ) − F (θτ )

τ (1 − θ)

(10)

We provide some empirical evidence to show the quality of the above proposal. The left subﬁgure
in Figure 3 shows the heatmap of (g ◦ F ) and the right one shows the empirical power of ADDIS∗
with p-values generate from F versus different θ and τ (the left is simply evaluating a function  the
right requires repeated simulation). The same pattern is consistent across other reasonable choices
of F   as shown in Section S-11. We can see that the two subﬁgures in Figure 3 show basically the
same pattern  with similar optimal choices of parameters θ and τ. Therefore  we suggest choosing λ
and τ as deﬁned in (9)  if prior knowledge of F is available; otherwise it seems like θ ∈ [0.25  0.75]
and τ ∈ [0.15  0.55] are safe choices  and for simplicity we use τ = θ = 0.5 as defaults  that is
τ = 0.5  λ = 0.25  in similar experimental settings. We leave the study of time-varying λj and τj as
future work.

Figure 3: The left ﬁgure shows the heatmap of function g ◦ F   where F is the CDF of p-values drawn
as described in Section 3 with µN = −1  µA = 3  πA = 0.2. The right ﬁgure is the empirical power
of ADDIS∗ versus different choice of θ and τ  with p-values drawn from F . The ﬁgures are basically
of the same pattern  with similar optimal values of θ and τ.

6

0.050.150.250.350.450.550.650.750.850.95θ0.950.850.750.650.550.450.350.250.150.05τ0.40.81.21.62.0g◦F0.050.150.250.350.450.550.650.750.850.95θ0.950.850.750.650.550.450.350.250.150.05τ0.540.600.660.720.78power3 Numerical experiments

√

(j+1)e

1

In this section  we numerically compare the performance of ADDIS against the previous state-of-
the-art algorithm SAFFRON [5]  and other well-studied algorithms like LORD++ [4]  LOND [10]
and Alpha-investing [2]. Speciﬁcally  we use ADDIS∗ deﬁned in Algorithm 1 as the representative
of our ADDIS algorithm. Though as discussed in Section 2.4  there is no universally optimal
constants  given the minimal nature of our assumptions  we will use some reasonable default choices
in the numerical studies to have a glance at the advantage of ADDIS algorithm. The constants
λ = 0.25  τ = 0.5 and sequence {γj}∞
j=0 with γj ∝ 1/(j + 1)−1.6 were found to be particularly
successful  thus are our default choices for hyperparameters in ADDIS∗. We choose the inﬁnite
constant sequence γj ∝
(j+1)1.6   and λ = 0.5 for SAFFRON  which yielded its best performance.
We use γj ∝ log ((j+1)∧2)
log (j+1) for LORD++ and LOND  which is shown to maximize its power in the
Gaussian setting [4]. The proportionality constant of {γj}∞
i=0 is determined so that the sequence
{γj}∞
We consider the standard experimental setup of testing Gaussian means  with M = 1000 hypotheses.
More precisely  for each index i ∈ {1  2  . . .   M}  the null hypotheses take the form Hi : µi ≤ 0 
which are being tested against the alternative HiA : µi > 0. The observations are independent
Gaussians Zi ∼ N (µi  1)  where µi ≡ µN ≤ 0 with probability 1 − πA and µi ≡ µA > 0
with probability πA. The one-sided p-values are computed as Pi = Φ(−Zi)  which are uniformly
conservative if µN < 0 as discussed in the introduction (and the lower µN is  the more conservative
the p-value). In the rest of this section  for each algorithm  we use target FDR α = 0.05 and estimate
the empirical FDR and power by averaging over 200 independent trials. Figure 4 shows that ADDIS
has higher power than all other algorithms when the nulls are conservative (i.e. µN < 0)  and ADDIS
matches the power of SAFFRON without conservative nulls (i.e. µN = 0).

i=0 sums to one.

(c)

(a)

(d)

(b)

(e)

Figure 4: Statistical power and FDR versus fraction of non-null hypotheses πA for ADDIS  SAF-
FRON  LORD++  LOND  and Alpha-investing at target FDR level α = 0.05 (solid black line). The
lines above the solid black line are the power of each methods versus πA  and the lines below are the
FDR of each methods versus πA. The p-values are drawn using the Gaussian model as described
in the text  while we set µN = −0.5 in plot (a)  µN = −1 in plot (b)  µN = −1.5 in plot (c)  and
µN = 0 in plots (d) and (e). And we set µA = 3 in plots (a  b  c  d)  µA = 4 in plot (e). These plots
show that (1) FDR is under control for all methods in all settings; (2) ADDIS enjoys appreciable
power increase as compared to all the other four methods; (3) the more conservative the nulls are
(the more negative µN is)  the more signiﬁcant the power increase of ADDIS is; (4) ADDIS matches
SAFFRON and remains the best in the setting with uniform (not conservative) nulls.

7

0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.20.40.60.8πA0.050.250.50.751.0FDR / Power0.040.020.000.020.040.040.020.000.020.04ADDISSAFFRONLORD++LONDAlpha-investing4 Generalization of the discarding rule

As we discussed before in Section 2  one way to interpret what ADDIS is doing is that it is “dis-
carding” the large p-values. We say ADDIS may be regarded as applying the “discarding" rule to
SAFFRON. Naturally  we would like to see whether the general advantage of this simple rule can be
applied to other FDR control methods  and under more complex settings. We present the following
generalizations and leave the details (formal setup  proofs) to supplement for interested readers.
• Extension 1: non-adaptive methods with discarding

We derive the discarding version of LORD++   which we would refer as D-LORD  in Section S-1 
with proved FDR control.

• Extension 2: discarding with asynchronous p-values

In a recent preprint  Zrnic et al. [11] show how to generalize existing online FDR control methods
to what they call the asynchronous multiple testing setting. They consider a doubly-sequential
setup  where one is running a sequence of sequential experiments  many of which could be running
in parallel  starting and ending at different times arbitrarily. In Section S-3  we show how to unite
the discarding rule from this paper with the “principle of pessimism” of Zrnic et al. [11] to derive
even more powerful asynchronous online FDR algorithms  which we would refer as ADDISasync.

• Extension 3: Ofﬂine FDR control with discarding

In Section S-2  we provide a new ofﬂine FDR control method called D-StBH  to show how to
incorporate the discarding rule with the Storey-BH method  which is a common ofﬂine adaptive
testing procedure [12  13]. Note that in the ofﬂine setting  the discarding rule is fundamentally the
same as the idea of [6  7]  which were only applied to non-adaptive multiple testing.

The following simulation results in Figure 5  which are plotted in the same format as in Section 3 
show that those discarding variants (marked with green color) enjoys the same type of advantage
over their non-discarding counterparts: they are consistently more powerful under settings with many
conservative nulls and do not lose much power under settings without conservative nulls.

(a) Extension 1

(b) Extension 2

(c) Extension 3

(d) Extension 1

(e) Extension 2

(f) Extension 3

Figure 5: Statistical power and FDR versus fraction of non-null hypotheses πA for extended methods
mentioned above at target FDR level α = 0.05 (solid black line). The p-values are drawn using the
Gaussian model as described in the text  while we set µA = 3 for all the ﬁgures  but µN = −1
in plots (a  b  c)  µN = 0 in plots (d  e  f). We additionally set the ﬁnish time for the j-th test as
Ej ∼ j − 1 + Geom(0.5) in plots (b  e)  which means the duration time of each individual tests
independently follows Geometric distribution with succeed probability 0.5.

8

0.20.40.60.8πA0.050.250.50.751.0FDR / PowerD-LORDLORD++0.20.40.60.8πA0.050.250.50.751.0FDR / PowerADDISasyncSAFFRONasyncLORDasync0.20.40.60.8πA0.050.250.50.751.0FDR / PowerD-StBHStorey-BH0.20.40.60.8πA0.050.250.50.751.0FDR / PowerD-LORDLORD++0.20.40.60.8πA0.050.250.50.751.0FDR / PowerADDISasyncSAFFRONasyncLORDasync0.20.40.60.8πA0.050.250.50.751.0FDR / PowerD-StBHStorey-BH5 Conclusion

In this work  we propose a new online FDR control method  ADDIS  to compensate for the un-
necessary power loss of current online FDR control methods due to conservative nulls. Numerical
studies show that ADDIS is signiﬁcantly more powerful than current state of arts  under settings
with many conservative nulls  and rarely lose power under settings without conservative nulls. We
also discuss the trade-off between adaptivity and discarding in ADDIS  together with some good
heuristic of how to balance them to obtain higher power. In the end  we generalize the main idea of
ADDIS to a simple but powerful rule “discarding”  and incorporate the rule with many current online
FDR control methods under various settings to generate corresponding more powerful variants. For
now  we mainly examine the power advantage of ADDIS algorithm with constant λ and τ  though
for future work  how to choose time varying {λj}∞
j=1 in a data adaptive matter with
provable power increase is worthy of more attention.

j=1 and {τj}∞

References
[1] Aaditya Ramdas  Fanny Yang  Martin Wainwright  and Michael Jordan. Online control of the
false discovery rate with decaying memory. In Advances In Neural Information Processing
Systems  pages 5655–5664  2017.

[2] Dean Foster and Robert Stine. α-investing: a procedure for sequential control of expected false
discoveries. Journal of the Royal Statistical Society  Series B (Statistical Methodology)  70(2):
429–444  2008.

[3] Ehud Aharoni and Saharon Rosset. Generalized α-investing: deﬁnitions  optimality results and
application to public databases. Journal of the Royal Statistical Society  Series B (Statistical
Methodology)  76(4):771–794  2014.

[4] Adel Javanmard and Andrea Montanari. Online rules for control of false discovery rate and

false discovery exceedance. The Annals of Statistics  46(2):526–554  2018.

[5] Aaditya Ramdas  Tijana Zrnic  Martin Wainwright  and Michael Jordan. SAFFRON: an adaptive
algorithm for online control of the false discovery rate. In Proceedings of the 35th International
Conference on Machine Learning  volume 80  pages 4286–4294  2018.

[6] Qingyuan Zhao  Dylan S. Small  and Weijie Su. Multiple testing when many p-values are
uniformly conservative  with application to testing qualitative interaction in educational inter-
ventions. Journal of the American Statistical Association  0(0):1–14  2018.

[7] Jules L Ellis  Jakub Pecanka  and Jelle Goeman. Gaining power in multiple testing of interval

hypotheses via conditionalization. arXiv preprint arXiv:1801.00141  2017.

[8] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and
powerful approach to multiple testing. Journal of the Royal Statistical Society  Series B
(Statistical Methodology)  57(1):289–300  1995.

[9] John Storey. A direct approach to false discovery rates. Journal of the Royal Statistical Society 

Series B (Statistical Methodology)  64:479–498  2002.

[10] Adel Javanmard and Andrea Montanari. On online control of false discovery rate. arXiv preprint

arXiv:1502.06197  2015.

[11] Tijana Zrnic  Aaditya Ramdas  and Michael Jordan. Asynchronous online testing of multiple

hypotheses. 2018. arXiv:1812.05068.

[12] John Storey  Jonathan Taylor  and David Siegmund. Strong control  conservative point esti-
mation and simultaneous conservative consistency of false discovery rates: a uniﬁed approach.
Journal of the Royal Statistical Society  Series B (Statistical Methodology)  66(1):187–205 
2004.

[13] Aaditya K Ramdas  Rina F Barber  Martin J Wainwright  Michael I Jordan  et al. A uniﬁed
treatment of multiple testing with prior knowledge using the p-ﬁlter. The Annals of Statistics 
47(5):2790–2821  2019.

9

,James Thewlis
Hakan Bilen
Andrea Vedaldi
Jinjin Tian
Aaditya Ramdas