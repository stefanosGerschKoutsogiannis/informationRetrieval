2014,Graphical Models for Recovering Probabilistic and Causal Queries from Missing Data,We address the problem of deciding whether a causal or probabilistic query is estimable from data corrupted by missing entries  given a model of missingness process. We extend the results of Mohan et al  2013 by presenting more general conditions for recovering probabilistic queries of the form P(y|x) and P(y x) as well as causal queries of the form P(y|do(x)). We show that causal queries may be recoverable even when the factors in their identifying estimands are not recoverable. Specifically  we derive graphical conditions for recovering causal effects of the form P(y|do(x)) when Y and its missingness mechanism are not d-separable. Finally  we apply our results to problems of attrition and characterize the recovery of causal effects from data corrupted by attrition.,Graphical Models for Recovering Probabilistic

and Causal Queries from Missing Data

Karthika Mohan and Judea Pearl

Cognitive Systems Laboratory
Computer Science Department
{karthika judea}@cs.ucla.edu

University of California  Los Angeles  CA 90024

Abstract

We address the problem of deciding whether a causal or probabilistic query
is estimable from data corrupted by missing entries  given a model of miss-
ingness process. We extend the results of Mohan et al. [2013] by present-
ing more general conditions for recovering probabilistic queries of the form
P (y|x) and P (y  x) as well as causal queries of the form P (y|do(x)). We
show that causal queries may be recoverable even when the factors in their
identifying estimands are not recoverable. Speciﬁcally  we derive graphical
conditions for recovering causal eﬀects of the form P (y|do(x)) when Y and
its missingness mechanism are not d-separable. Finally  we apply our re-
sults to problems of attrition and characterize the recovery of causal eﬀects
from data corrupted by attrition.

1 Introduction

All branches of experimental science are plagued by missing data. Improper handling of
missing data can bias outcomes and potentially distort the conclusions drawn from a study.
Therefore  accurate diagnosis of the causes of missingness is crucial for the success of any re-
search. We employ a formal representation called ‘Missingness Graphs’ (m-graphs  for short)
to explicitly portray the missingness process as well as the dependencies among variables in
the available dataset (Mohan et al. [2013]). Apart from determining whether recoverabil-
ity is feasible namely  whether there exists any theoretical impediment to estimability of
queries of interest  m-graphs can also provide a means for communication and reﬁnement
of assumptions about the missingness process. Furthermore  m-graphs permit us to detect
violations in modeling assumptions even when the dataset is contaminated with missing
entries (Mohan and Pearl [2014]).

In this paper  we extend the results of Mohan et al. [2013] by presenting general conditions
under which probabilistic queries such as joint and conditional distributions can be recov-
ered. We show that causal queries of the type P (y|do(x)) can be recovered even when the
associated probabilistic relations such as P (y  x) and P (y|x) are not recoverable. In partic-
ular  causal eﬀects may be recoverable even when Y is not separable from its missingness
mechanism. Finally  we apply our results to recover causal eﬀects when the available dataset
is tainted by attrition.

This paper is organized as follows. Section 2 provides an overview of missingness graphs
and reviews the notion of recoverability i.e. obtaining consistent estimates of a query 
given a dataset and an m-graph. Section 3 reﬁnes the sequential factorization theorem
presented in Mohan et al. [2013] and extends its applicability to a wider range of problems
in which missingness mechanisms may inﬂuence each other. In section 4  we present general

1

Figure 1: Typical m-graph where Vo = {S  X}  Vm = {I  Q}  V ∗ = {I∗  Q∗}  R = {Ri  Rq}
and U is the latent common cause. Members of Vo and Vm are represented by full and hollow
circles respectively. The associated missingness process and assumptions are elaborated in
appendix 10.1.

algorithms to recover joint distributions from the class of problems for which sequential
factorization theorem fails. In section 5  we introduce new graphical criteria that preclude
recoverability of joint and conditional distributions. In section 6  we discuss recoverability
of causal queries and show that unlike probabilistic queries  P (y|do(x)) may be recovered
even when Y and its missingness mechanism (Ry) are not d-separable.
In section 7  we
demonstrate how we can apply our results to problems of attrition in which missingness is a
severe obstacle to sound inferences. Related works are discussed in section 8 and conclusions
are drawn in section 9. Proofs of all theoretical results in this paper are provided in the
appendix.

2 Missingness Graph and Recoverability

Missingness graphs as discussed below was ﬁrst deﬁned in Mohan et al. [2013] and we adopt
the same notations. Let G(V  E) be the causal DAG where V = V ∪ U ∪ V ∗ ∪ R. V is the
set of observable nodes. Nodes in the graph correspond to variables in the data set. U is
the set of unobserved nodes (also called latent variables). E is the set of edges in the DAG.
We use bi-directed edges as a shorthand notation to denote the existence of a U variable
as common parent of two variables in V ∪ R. V is partitioned into Vo and Vm such that
Vo ⊆ V is the set of variables that are observed in all records in the population and Vm ⊆ V
is the set of variables that are missing in at least one record. Variable X is termed as fully
observed if X ∈ Vo  partially observed if X ∈ Vm and substantive if X ∈ Vo∪ Vm. Associated
with every partially observed variable Vi ∈ Vm are two other variables Rvi and V ∗
i   where
V ∗
is a proxy variable that is actually observed  and Rvi represents the status of the causal
mechanism responsible for the missingness of V ∗

i

i ; formally 

(cid:26) vi

m

v∗
i = f (rvi  vi) =

if rvi = 0
if rvi = 1

(1)

V ∗ is the set of all proxy variables and R is the set of all causal mechanisms that are
responsible for missingness. R variables may not be parents of variables in V ∪ U . We
call this graphical representation Missingness Graph (or m-graph). An example of an
m-graph is given in Figure 1 (a).We use the following shorthand. For any variable X  let
X(cid:48) be a shorthand for X = 0. For any set W ⊆ Vm ∪ Vo ∪ R  let Wr  Wo and Wm be the
shorthand for W ∩ R  W ∩ Vo and W ∩ Vm respectively. Let Rw be a shorthand for RVm∩W
i.e. Rw is the set containing missingness mechanisms of all partially observed variables in
W . Note that Rw and Wr are not the same. GX and GX represent graphs formed by
removing from G all edges leaving and entering X  respectively.
A manifest distribution P (Vo  V ∗  R) is the distribution that governs the available dataset.
An underlying distribution P (Vo  Vm  R) is said to be compatible with a given manifest
distribution P (Vo  V ∗  R) if the latter can be obtained from the former using equation 1.
Manifest distribution Pm is compatible with a given underlying distribution Pu if ∀X  X ⊆

2

RQRII*Q*Experience (X)Income (I)Missingness Mechanismof IncomeProxy variable for IncomeULatent VariableSex (S)Qualifcation (Q)Figure 2: (a) m-graph in which P (V ) is recoverable by the sequential factorization (b) &
(c): m-graphs for which no admissible sequence exists.

Vm and Y = Vm \ X  the following equality holds true.
x  Ry  X∗  Y ∗  Vo) = Pu(R(cid:48)

Pm(R(cid:48)

x  Ry  X  Vo)

where R(cid:48)

x denotes Rx = 0 and Ry denotes Ry = 1. Refer Appendix 10.2 for an example.

2.1 Recoverability
Given a manifest distribution P (V ∗  Vo  R) and an m-graph G that depicts the missingness
process  query Q is recoverable if we can compute a consistent estimate of Q as if no data
were missing. Formally 

Deﬁnition 1 (Recoverability (Mohan et al. [2013])). Given a m-graph G  and a target
relation Q deﬁned on the variables in V   Q is said to be recoverable in G if there exists an
algorithm that produces a consistent estimate of Q for every dataset D such that P (D) is
(1) compatible with G and (2) strictly positive1 i.e. P (Vo  Vm  R) > 0.

For an introduction to the notion of recoverability see  Pearl and Mohan [2013] and Mohan
et al. [2013].

3 Recovering Probabilistic Queries by Sequential Factorization

Mohan et al. [2013] (theorem-4) presented a suﬃcient condition for recovering probabilistic
queries such as joint and conditional distributions by using ordered factorizations. However 
the theorem is not applicable to certain classes of problems such as those in longitudinal
studies in which edges exist between R variables. General ordered factorization deﬁned
below broadens the concept of ordered factorization (Mohan et al. [2013]) to include the set of
R variables. Subsequently  the modiﬁed theorem (stated below as theorem 1) will permit us
to handle cases in which R variables are contained in separating sets that d-separate partially
observed variables from their respective missingness mechanisms (example: X⊥⊥Rx|Ry in
ﬁgure 2 (a)).
Deﬁnition 2 (General Ordered factorization). Given a graph G and a set O of ordered V ∪R
variables Y1 < Y2 < . . . < Yk  a general ordered factorization relative to G  denoted by f (O) 
i P (Yi|Xi) where Xi ⊆ {Yi+1  . . .   Yn} is
a minimal set such that Yi⊥⊥({Yi+1  . . .   Yn} \ Xi)|Xi holds in G.

is a product of conditional probabilities f (O) =(cid:81)

Theorem 1 (Sequential Factorization ). A suﬃcient condition for recoverability of a rela-
tion Q deﬁned over substantive variables is that Q be decomposable into a general ordered
factorization  or a sum of such factorizations  such that every factor Qi = P (Yi|Xi) satis-
ﬁes  (1) Yi⊥⊥(Ryi  Rxi)|Xi \ {Ryi  Rxi}  if Yi ∈ (Vo ∪ Vm) and (2) Rz⊥⊥RXi|Xi if Yi = Rz
for any Z ∈ Vm  Z /∈ Xi and Xr ∩ RXm = ∅.
An ordered factorization that satisﬁes the condition in Theorem 1 is called an admissible
sequence.

The following example illustrates the use of theorem 1 for recovering the joint distribution.
Additionally  it sheds light on the need for the notion of minimality in deﬁnition 2.

1An extension to datasets that are not strictly positive is sometimes feasible(Mohan et al. [2013]).

3

RWRXRYRZXZWYRWRZRXRYRXRYRZXZWYYZX(a)(b)(c)Example 1. We are interested in recovering P (X  Y  Z) given the m-graph in Figure 2
(a). We discern from the graph that deﬁnition 2 is satisﬁed because: (1) P (Y |X  Z  Ry) =
P (Y |X  Z) and (X  Z) is a minimal set such that Y ⊥⊥({X  Z  Ry} \ (X  Z))|(X  Z)  (2)
P (X|Ry  Z) = P (X|Ry) and Ry is the minimal set such that X⊥⊥({Ry  Z} \ Ry)|Ry
and (3) P (Z|Ry) = P (Z) and ∅ is the minimal set such that Z⊥⊥Ry|∅. Therefore 
the order Y < X < Z < Ry induces a general ordered factorization P (X  Y  Z  Ry) =
P (Y |X  Z)P (X|Ry)P (Z)P (Ry). We now rewrite P (X  Y  Z) as follows:

P (X  Y  Z) =

P (Y  X  Z  Ry) = P (Y |X  Z)P (Z)

Ry

Ry

P (X|Ry)P (Ry)

(cid:88)

Since Y ⊥⊥Ry|X  Z  Z⊥⊥Rz  X⊥⊥Rx|Ry  by theorem 1 we have 

(cid:88)

(cid:88)

Ry

P (X  Y  Z) = P (Y |X  Z  R(cid:48)

x  R(cid:48)

y  R(cid:48)

z)P (Z|R(cid:48)
z)

P (X|R(cid:48)

x  Ry)P (Ry)

Indeed  equation 1 permits us to rewrite it as:
y  R(cid:48)

P (X  Y  Z) = P (Y ∗|X∗  Z∗  R(cid:48)

x  R(cid:48)

z)P (Z∗|R(cid:48)
z)

(cid:88)

Ry

P (X∗|R(cid:48)

x  Ry)P (Ry)

P (X  Y  Z) is recoverable because every term in the right hand side is consistently estimable
from the available dataset.

in deﬁnition 2 and chosen to factorize
Had we ignored the minimality requirement
Y < X < Z < Ry using the chain rule  we would have obtained: P (X  Y  Z  Ry) =
P (Y |X  Z  Ry)P (X|Z  Ry)P (Z|Ry)P (Ry) which is not admissible since X⊥⊥(Rz  Rx)|Z does
not hold in the graph. In other words  existence of one admissible sequence based on an order
O of variables does not guarantee that every factorization based on O is admissible; it is for
this reason that we need to impose the condition of minimality in deﬁnition 2.

The recovery procedure presented in example 1 requires that we introduce Ry into the order.
Indeed  there is no ordered factorization over the substantive variables {X  Y  Z} that will
permit recoverability of P (X  Y  Z) in ﬁgure 2 (a). This extension of Mohan et al. [2013]
thus permits the recovery of probabilistic queries from problems in which the missingness
mechanisms interact with one another.

4 Recoverability in the Absence of an Admissible Sequence

Mohan et al. [2013] presented a theorem (refer appendix 10.4) that stated the necessary and
suﬃcient condition for recovering the joint distribution for the class of problems in which the
parent set of every R variable is a subset of Vo∪Vm. In contrast to Theorem 1  their theorem
can handle problems for which no admissible sequence exists. The following theorem gives a
generalization and is applicable to any given semi-markovian model (for example  m-graphs
in ﬁgure 2 (b) & (c)). It relies on the notion of collider path and two new subsets  R(part):
the partitions of R variables and M b(R(i)): substantive variables related to R(i)  which we
will deﬁne after stating the theorem.
Theorem 2. Given an m-graph G in which no element in Vm is either a neighbor of its
missingness mechanism or connected to its missingness mechanism by a collider path  P (V )
is recoverable if no M b(R(i)) contains a partially observed variable X such that Rx ∈ R(i)
i.e. ∀i  R(i) ∩ RM b(R(i)) = ∅. Moreover  if recoverable  P (V ) is given by 

(cid:81)
i P (R(i) = 0|M b(R(i))  RM b(R(i)) = 0)

P (V  R = 0)

P (V ) =

In theorem 2:
(i) collider path p between any two nodes X and Y is a path in which every intermediate
node is a collider. Example  X → Z < −− > Y .
(ii) Rpart = {R(1)  R(2)  ...R(N )} are partitions of R variables such that for every element
Rx and Ry belonging to distinct partitions  the following conditions hold true: (i) Rx and

4

Ry are not neighbors and (ii) Rx and Ry are not connected by a collider path. In ﬁgure 2
(b): Rpart = {R(1)  R(2)} where R(1) = {Rw  Rz}  R(2) = {Rx  Ry}
(iii) M b(R(i)) is the markov blanket of R(i) comprising of all substantive variables that are
either neighbors or connected to variables in R(i) by a collider path (Richardson [2003]). In
ﬁgure 2 (b): M b(R(1)) = {X  Y } and M b(R(2)) = {Z  W}.
Appendix 10.6 demonstrates how theorem 2 leads to the recoverability of P (V ) in ﬁgure 2 
to which theorems in Mohan et al. [2013] do not apply.

The following corollary yields a suﬃcient condition for recovering the joint distribution from
the class of problems in which no bi-directed edge exists between variables in sets R and
Vo∪ Vm (for example  the m-graph described in Figure 2 (c)). These problems form a subset
of the class of problems covered in theorem 2. Subset P asub(R(i)) used in the corollary is
the set of all substantive variables that are parents of variables in R(i).
In ﬁgure 2 (b):
P asub(R(1)) = ∅ and P asub(R(2)) = {Z  W}.
Corollary 1. Let G be an m-graph such that (i) ∀X ∈ Vm ∪ Vo  no latent variable is a
common parent of X and any member of R  and (ii) ∀Y ∈ Vm  Y is not a parent of Ry. If
∀i  P asub(R(i)) does not contain a partially observed variables whose missing mechanism is
in R(i) i.e. R(i) ∩ RP asub(R(i)) = ∅  then P (V ) is recoverable and is given by 

P (v) =

(cid:81)
P (R=0 V )
i P (R(i)=0|P asub(R(i)) R

P asub (R(i) )

=0)

5 Non-recoverability Criteria for Joint and Conditional

Distributions

Up until now  we dealt with suﬃcient conditions for recoverability. It is important however
to supplement these results with criteria for non-recoverability in order to alert the user to
the fact that the available assumptions are insuﬃcient to produce a consistent estimate of
the target query. Such criteria have not been treated formally in the literature thus far. In
the following theorem we introduce two graphical conditions that preclude recoverability.

Theorem 3 (Non-recoverability of P (V )). Given a semi-markovian model G  the following
conditions are necessary for recoverability of the joint distribution:
(i) ∀X ∈ Vm  X and Rx are not neighbors and
(ii) ∀X ∈ Vm  there does not exist a path from X to Rx in which every intermediate node
is both a collider and a substantive variable.

In the following corollary  we leverage theorem 3 to yield necessary conditions for recovering
conditional distributions.
Corollary 2. [Non-recoverability of P (Y |X)] Let X and Y be disjoint subsets of substantive
variables. P (Y |X) is non-recoverable in m-graph G if one of the following conditions is true:
(1) Y and Ry are neighbors
(2) G contains a collider path p connecting Y and Ry such that all intermediate nodes in p
are in X.

6 Recovering Causal Queries

Given a causal query and a causal bayesian network a complete algorithm exists for deciding
whether the query is identiﬁable or not (Shpitser and Pearl [2006]). Obviously  a query that
is not identiﬁable in the substantive model is not recoverable from missing data. Therefore 
a necessary condition for recoverability of a causal query is its identiﬁability which we will
assume in the rest of our discussion.

Deﬁnition 3 (Trivially Recoverable Query). A causal query Q is said to be trivially recov-
erable given an m-graph G if it has an estimand (in terms of substantive variables) in which
every factor is recoverable.

5

Figure 3: m-graph in which Y and Ry are not separable but still P (Y |do(Z)) is recoverable.

Classes of problems that fall into the MCAR (Missing Completely At Random) and MAR
(Missing At Random) category are much discussed in the literature ((Rubin [1976])) be-
cause in such categories probabilistic queries are recoverable by graph-blind algorithms. An
immediate but important implication of trivial recoverability is that if data are MAR or
MCAR and the query is identiﬁable  then it is also recoverable by model-blind algorithms.

Example 2. In the gender wage-gap study example in Figure 1 (a)  the eﬀect of sex on
income  P (I|do(S))  is identiﬁable and is given by P (I|S). By theorem 2  P (S  X  Q  I) is
recoverable. Hence P (I|do(S)) is recoverable.
6.1 Recovering P (y|do(z)) when Y and Ry are inseparable

Example 3. Examine Figure 3. By backdoor criterion  P (y|do(z)) =(cid:80)

The recoverability of P (V ) hinges on the separability of a partially observed variable from its
missingness mechanism (a condition established in theorem 3). Remarkably  causal queries
may circumvent this requirement. The following example demonstrates that P (y|do(z)) is
recoverable even when Y and Ry are not separable.
w P (y|z  w)P (w).
One might be tempted to conclude that the causal relation is non-recoverable because
P (w  z  y) is non-recoverable (by theorem 2) and P (y|z  w) is not recoverable (by corollary
2). However  P (y|do(z)) is recoverable as demonstrated below:

(cid:88)

w

P (y|do(z)  w  R(cid:48)
P (w|do(z)  R(cid:48)

P (y|do(z)) = P (y|do(z)  R(cid:48)
y) = P (y|z  w  R(cid:48)
y) = P (w|R(cid:48)
(cid:88)

Substituting (3) and (4) in (2) we get:
P (y|z  w  R(cid:48)

P (y|do(z)) =

y) =

P (y|do(z)  w  R(cid:48)

y)P (w|do(z)  R(cid:48)
y)

y) (by Rule-2 of do-calculus (Pearl [2009]))

y) (by Rule-3 of do-calculus) )

(2)

(3)

(4)

(cid:88)

y)P (w|R(cid:48)

y) =

P (y∗|z  w  R(cid:48)

y)P (w|R(cid:48)
y)

w

w

The recoverability of P (y|do(z)) in the previous example follows from the notion of d*-
separability and dormant independence [Shpitser and Pearl  2008].
Deﬁnition 4 (d∗-separation (Shpitser and Pearl [2008])). Let G be a causal diagram. Vari-
able sets X  Y are d∗-separated in G given Z  W (written X ⊥w Y |Z)  if we can ﬁnd sets
Z  W   such that X ⊥ Y |Z in Gw  and P (y  x|z  do(w)) is identiﬁable.
Deﬁnition 5 (Inducing path (Verma and Pearl [1991])). An path p between X and Y is
called inducing path if every node on the path is a collider and an ancestor of either X or
Y .
Theorem 4. Given an m-graph in which |Vm| = 1 and Y and Ry are connected by an
inducing path  P (y|do(x)) is recoverable if there exists Z  W such that Y ⊥w Ry|Z and for
W = W \ X  the following conditions hold:
(1) Y ⊥⊥W1|X  Z in GX W1
P (y|do(x)) =(cid:80)
(2) P (W1  Z|do(X)) and P (Y |do(W1)  do(X)  Z  R(cid:48)y) are identiﬁable.
Moreover  if recoverable then 

W1 Z P (Y |do(W )  do(X)  Z  R(cid:48)

y)P (Z  W1|do(X))

and

We can quickly conclude that P (y|do(z)) is recoverable in the m-graph in ﬁgure 3 by verifying
that the conditions in theorem 4 hold in the m-graph.

6

RyW ZY(a) m-graphs in which P (y|do(x)) is not recoverable (b) m-graphs in which

Figure 4:
P (y|do(x)) is recoverable.

7 Attrition

Attrition (i.e. participants dropping out from a study/experiment)  is a ubiquitous phe-
nomenon  especially in longitudinal studies. In this section  we shall discuss a special case
of attrition called ‘Simple Attrition’ (for an in-depth treatment see Garcia [2013]). In this
problem  a researcher conducts a randomized trial  measures a set of variables (X Y Z) and
obtains a dataset where outcome (Y) is corrupted by missing values (due to attrition).
Clearly  due to randomization  the eﬀect of treatment (X) on outcome (Y)  P (y|do(x)) 
is identiﬁable and is given by P (Y |X). We shall now demonstrate the usefulness of our
previous discussion in recovering P (y|do(x)). Typical attrition problems are depicted in
In Figure 4 (b) we can apply theorem 1 to recover P (y|do(x)) as given below:
ﬁgure 4.
In Figure 4 (a)  we observe that Y and Ry are
connected by a collider path. Therefore by corollary 2  P (Y |X) is not recoverable; hence
P (y|do(x)) is also not recoverable.

P (Y |X) = (cid:80)

Z P (Y ∗|X  Z  R(cid:48)

y)P (Z|X).

7.1 Recovering Joint Distributions under simple attrition

The following theorem yields the necessary and suﬃcient condition for recovering joint dis-
tributions from semi-markovian models with a single partially observed variable i.e. |Vm| = 1
which includes models aﬄicted by simple attrition.
Theorem 5. Let Y ∈ Vm and |Vm| = 1. P (V ) is recoverable in m-graph G if and only
if Y and Ry are not neighbors and Y and Ry are not connected by a path in which all
intermediate nodes are colliders. If both conditions are satisﬁed  then P (V ) is given by 
P (V ) = P (Y |VO  Ry = 0)P (VO)

7.2 Recovering Causal Eﬀects under Simple Attrition
Theorem 6. P (y|do(x)) is recoverable in the simple attrition case (with one partially ob-
served variable) if and only if Y and Ry are neither neighbors nor connected by an inducing
path. Moreover  if recoverable 

(cid:88)

P (Y |X) =

P (Y ∗|X  Z  R(cid:48)

y)P (Z|X)

(5)

where Z is the separating set that d-separates Y from Ry.

z

8 Related Work

Deletion based methods such as listwise deletion that are easy to understand as well as
implement  guarantee consistent estimates only for certain categories of missingness such as
MCAR (Rubin [1976]). Maximum Likelihood method is known to yield consistent estimates
under MAR assumption; expectation maximization algorithm and gradient based algorithms
are widely used for searching for ML estimates under incomplete data (Lauritzen [1995] 
Dempster et al. [1977]  Darwiche [2009]  Koller and Friedman [2009]). Most work in machine
learning assumes MAR and proceeds with ML or Bayesian inference. However  there are
exceptions such as recent work on collaborative ﬁltering and recommender systems which
develop probabilistic models that explicitly incorporate missing data mechanism (Marlin
et al. [2011]  Marlin and Zemel [2009]  Marlin et al. [2007]).

7

RYYXZ(a)RYXYZ(b)Other methods for handling missing data can be classiﬁed into two: (a) Inverse Probability
Weighted Methods and (b) Imputation based methods (Rothman et al. [2008]).
Inverse
Probability Weighing methods analyze and assign weights to complete records based on
estimated probabilities of completeness (Van der Laan and Robins [2003]  Robins et al.
[1994]). Imputation based methods substitute a reasonable guess in the place of a missing
value (Allison [2002]) and Multiple Imputation (Little and Rubin [2002]) is a widely used
imputation method.

Missing data is a special case of coarsened data and data are said to be coarsened at
random (CAR) if the coarsening mechanism is only a function of the observed data (Heitjan
and Rubin [1991]). Robins and Rotnitzky [1992] introduced a methodology for parameter
estimation from data structures for which full data has a non-zero probability of being fully
observed and their methodology was later extended to deal with censored data in which
complete data on subjects are never observed (Van Der Laan and Robins [1998]).

The use of graphical models for handling missing data is a relatively new development.
Daniel et al. [2012] used graphical models for analyzing missing information in the form of
missing cases (due to sample selection bias). Attrition is a common occurrence in longitu-
dinal studies and arises when subjects drop out of the study (Twisk and de Vente [2002] 
Shadish [2002]) and Garcia [2013] analysed the problem of attrition using causal graphs.
Thoemmes and Rose [2013] and Thoemmes and Mohan [2015] cautioned the practitioner
that contrary to popular belief  not all auxiliary variables reduce bias. Both Garcia [2013]
and Thoemmes and Rose [2013] associate missingness with a single variable and interactions
among several missingness mechanisms are unexplored.

Mohan et al. [2013] employed a formal representation called Missingness Graphs to depict
the missingness process  deﬁned the notion of recoverability and derived conditions under
which queries would be recoverable when datasets are categorized as Missing Not At Random
(MNAR). Tests to detect misspeciﬁcations in the m-graph are discussed in Mohan and Pearl
[2014].

9 Conclusion

Graphical models play a critical role in portraying the missingness process  encoding and
communicating assumptions about missingness and deciding recoverability given a dataset
aﬄicted with missingness. We presented graphical conditions for recovering joint and con-
ditional distributions and suﬃcient conditions for recovering causal queries. We exempliﬁed
the recoverability of causal queries of the form P (y|do(x)) despite the existence of an in-
separable path between Y and Ry  which is an insurmountable obstacle to the recovery of
P(Y). We applied our results to problems of attrition and presented necessary and suﬃcient
graphical conditions for recovering causal eﬀects in such problems.

Acknowledgement

This paper has beneﬁted from discussions with Ilya Shpitser. This research was supported
in parts by grants from NSF #IIS1249822 and #IIS1302448  and ONR #N00014-13-1-0153
and #N00014-10-1-0933.

References

P.D. Allison. Missing data series: Quantitative applications in the social sciences  2002.

R.M. Daniel  M.G. Kenward  S.N. Cousens  and B.L. De Stavola. Using causal diagrams to guide
analysis in missing data problems. Statistical Methods in Medical Research  21(3):243–256  2012.

A Darwiche. Modeling and reasoning with Bayesian networks. Cambridge University Press  2009.

A.P. Dempster  N.M. Laird  and D.B. Rubin. Maximum likelihood from incomplete data via the
em algorithm. Journal of the Royal Statistical Society. Series B (Methodological)  pages 1–38 
1977.

F. M. Garcia. Deﬁnition and diagnosis of problematic attrition in randomized controlled experi-

ments. Working paper  April 2013. Available at SSRN: http://ssrn.com/abstract=2267120.

8

D.F. Heitjan and D.B. Rubin. Ignorability and coarse data. The Annals of Statistics  pages 2244–

2253  1991.

D Koller and N Friedman. Probabilistic graphical models: principles and techniques. 2009.

S L Lauritzen. The em algorithm for graphical association models with missing data. Computational

Statistics & Data Analysis  19(2):191–201  1995.

R.J.A. Little and D.B. Rubin. Statistical analysis with missing data. Wiley  2002.

B.M. Marlin and R.S. Zemel. Collaborative prediction and ranking with non-random missing data.
In Proceedings of the third ACM conference on Recommender systems  pages 5–12. ACM  2009.

B.M. Marlin  R.S. Zemel  S. Roweis  and M. Slaney. Collaborative ﬁltering and the missing at

random assumption. In UAI  2007.

B.M. Marlin  R.S. Zemel  S.T. Roweis  and M. Slaney. Recommender systems: missing data and

statistical model estimation. In IJCAI  2011.

K Mohan and J Pearl. On the testability of models with missing data. Proceedings of AISTAT 

2014.

K Mohan  J Pearl  and J Tian. Graphical models for inference with missing data. In Advances in

Neural Information Processing Systems 26  pages 1277–1285. 2013.

J. Pearl. Causality: models  reasoning and inference. Cambridge Univ Press  New York  2009.

J Pearl and K Mohan.

Recoverability and testability of missing data:

Introduc-
Available at

tion and summary of results.
http://ftp.cs.ucla.edu/pub/stat ser/r417.pdf.

Technical Report R-417  UCLA  2013.

T Richardson. Markov properties for acyclic directed mixed graphs. Scandinavian Journal of

Statistics  30(1):145–157  2003.

J M Robins and A Rotnitzky. Recovery of information and adjustment for dependent censoring

using surrogate markers. In AIDS Epidemiology  pages 297–331. Springer  1992.

J M Robins  A Rotnitzky  and L P Zhao. Estimation of regression coeﬃcients when some regressors
are not always observed. Journal of the American Statistical Association  89(427):846–866  1994.

K J Rothman  S Greenland  and T L Lash. Modern epidemiology. Lippincott Williams & Wilkins 

2008.

D.B. Rubin. Inference and missing data. Biometrika  63:581–592  1976.

W R Shadish. Revisiting ﬁeld experimentation: ﬁeld notes for the future. Psychological methods  7

(1):3  2002.

I Shpitser and J Pearl. Identiﬁcation of conditional interventional distributions. In Proceedings of

the Twenty-Second Conference on Uncertainty in Artiﬁcial Intelligence  pages 437–444. 2006.

I Shpitser and J Pearl. Dormant independence. In AAAI  pages 1081–1087  2008.

F Thoemmes and K Mohan. Graphical representation of missing data problems. Structural Equation

Modeling: A Multidisciplinary Journal  2015.

F. Thoemmes and N. Rose. Selection of auxiliary variables in missing data problems: Not all

auxiliary variables are created equal. Technical Report R-002  Cornell University  2013.

J Twisk and W de Vente. Attrition in longitudinal studies: how to deal with missing data. Journal

of clinical epidemiology  55(4):329–337  2002.

M J Van Der Laan and J M Robins. Locally eﬃcient estimation with current status data and
time-dependent covariates. Journal of the American Statistical Association  93(442):693–701 
1998.

M.J. Van der Laan and J.M. Robins. Uniﬁed methods for censored longitudinal data and causality.

Springer Verlag  2003.

T.S Verma and J Pearl. Equivalence and synthesis of causal models. In Proceedings of the Sixth

Conference in Artiﬁcial Intelligence  pages 220–227. Association for Uncertainty in AI  1991.

9

,Karthika Mohan
Judea Pearl
Victor Picheny
Robert Gramacy
Stefan Wild
Sebastien Le Digabel