2017,Sparse convolutional coding for neuronal assembly detection,Cell assemblies  originally proposed by Donald Hebb (1949)  are subsets of neurons firing in a temporally coordinated way that gives rise to repeated motifs supposed to underly neural representations and information processing. Although Hebb's original proposal dates back many decades  the detection of assemblies and their role in coding is still an open and current research topic  partly because simultaneous recordings from large populations of neurons became feasible only relatively recently. Most current and easy-to-apply computational techniques focus on the identification of strictly synchronously spiking neurons. In this paper we propose a new algorithm  based on sparse convolutional coding  for detecting recurrent motifs of arbitrary structure up to a given length. Testing of our algorithm on synthetically generated datasets shows that it outperforms established methods and accurately identifies the temporal structure of embedded assemblies  even when these contain overlapping neurons or when strong background noise is present. Moreover  exploratory analysis of experimental datasets from hippocampal slices and cortical neuron cultures have provided promising results.,Sparse convolutional coding for neuronal assembly

detection

Sven Peter1 ∗

Elke Kirschbaum1 ∗

{sven.peter elke.kirschbaum}@iwr.uni-heidelberg.de

Martin Both2

mboth@physiologie.uni-heidelberg.de

Lee A. Campbell3

lee.campbell@nih.gov

Brandon K. Harvey3

bharvey@mail.nih.gov

Conor Heins3 4 †

conor.heins@ds.mpg.de

Daniel Durstewitz5

daniel.durstewitz@zi-mannheim.de

Ferran Diego Andilla6 ‡

ferran.diegoandilla@de.bosch.com

Fred A. Hamprecht1

fred.hamprecht@iwr.uni-heidelberg.de

1Interdisciplinary Center for Scientiﬁc Computing (IWR)  Heidelberg  Germany

2Institute of Physiology and Pathophysiology  Heidelberg  Germany

3National Institute on Drug Abuse  Baltimore  USA

4Max Planck Institute for Dynamics and Self-Organization  Göttingen  Germany

5Dept. Theoretical Neuroscience  Central Institute of Mental Health  Mannheim  Germany

6Robert Bosch GmbH  Hildesheim  Germany

Abstract

Cell assemblies  originally proposed by Donald Hebb (1949)  are subsets of neurons
ﬁring in a temporally coordinated way that gives rise to repeated motifs supposed
to underly neural representations and information processing. Although Hebb’s
original proposal dates back many decades  the detection of assemblies and their
role in coding is still an open and current research topic  partly because simultane-
ous recordings from large populations of neurons became feasible only relatively
recently. Most current and easy-to-apply computational techniques focus on the
identiﬁcation of strictly synchronously spiking neurons. In this paper we propose
a new algorithm  based on sparse convolutional coding  for detecting recurrent
motifs of arbitrary structure up to a given length. Testing of our algorithm on
synthetically generated datasets shows that it outperforms established methods and
accurately identiﬁes the temporal structure of embedded assemblies  even when
these contain overlapping neurons or when strong background noise is present.
Moreover  exploratory analysis of experimental datasets from hippocampal slices
and cortical neuron cultures have provided promising results.

∗Both authors contributed equally.
†Majority of this work was done while co-author was at 3.
‡Majority of this work was done while co-author was at 1.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

(b) Synﬁre chain

(a) Synchronously ﬁring neu-
rons
Figure 1: Temporal motifs in neuronal spike trains. All three illustrations show the activity of four
different neurons over time. The spikes highlighted in red are part of a repeating motif. In (a) the
motif is deﬁned by the synchronous activity of all neurons  while the synﬁre chain in (b) exhibits
sequential spiking patterns. (c) shows a more complex motif with non-sequential temporal structure.
(Figure adapted from [23].)

(c) Temporal motif

1

Introduction

The concept of a cell assembly (or cortical motif or neuronal ensemble) was originally introduced by
Donald Hebb [1] and denotes subsets of neurons that by ﬁring coherently represent mental objects
and form the building blocks of cortical information processing. Numerous experimental studies
within the past 30 years have attempted to address the neural assembly hypothesis from various
angles in different brain areas and species  but the concept remains debated  and recent massively
parallel single-unit recording techniques have opened up new opportunities for studying the role of
spatio-temporal coordination in the nervous system [2–12].
A number of methods have been proposed to identify motifs in neuronal spike train data  but most
of them are only designed for strictly synchronously ﬁring neurons (see ﬁgure 1a)  i.e. with zero
phase-lag [13–17]  or strictly sequential patterns as in synﬁre chains [18–21] (see ﬁgure 1b). However 
some experimental studies have suggested that cortical spiking activity may harbor motifs with more
complex structure [5  22] (see ﬁgure 1c). Only quite recently statistical algorithms were introduced
that can efﬁciently deal with arbitrary lag constellations among the units participating in an assembly
[23]  but the identiﬁcation and validation of motifs with complex temporal structure remains an area
of current research interest.
In this paper we present a novel approach to identify motifs with any of the temporal structures shown
in ﬁgure 1 in a completely unsupervised manner. Based on the idea of convolutive Non-Negative
Matrix Factorization (NMF) [24  25] our algorithm reconstructs the neuronal spike matrix as a
convolution of motifs and their activation time points. In contrast to convolutive NMF  we introduce
an (cid:96)0 and (cid:96)1 prior on the motif activation and appearance  respectively  instead of a single (cid:96)1 penalty.
This (cid:96)0 regularization enforces more sparsity in the temporal domain; thus performing better in
extracting motifs from neuronal spike data by reducing false positive activations. Adding the (cid:96)0
and (cid:96)1 penalty terms requires a novel optimization scheme. This replaces the multiplicative update
rules by a combination of discrete and continuous optimizations  which are matching pursuit and
LASSO regression. Additionally we added a sorting and non-parametric threshold estimation method
to distinguish between real and spurious results of the optimization problem. We benchmark our
approach on synthetic data against Principal Component Analysis (PCA) and Independent Component
Analysis (ICA) as the most widely used methods for motif detection  and against convolutive NMF
as the method most closely related to the proposed approach. Our algorithm outperforms the other
methods especially when identifying long motifs with complex temporal structure. We close with
results of our approach on two real-world datasets from hippocampal slices and cortical neuron
cultures.

2 Related work

PCA is one of the simplest methods that has been used for a long time to track cell motifs [26]. Its
biggest limitations are that different assembly patterns can easily be merged into a single ’large’
component  and that neurons shared between motifs are assigned lower weights than they should
have. Moreover  recovering individual neurons which belong to a single assembly is not reliably
possible [27  17]  and the detected assemblies are not very robust to noise and rate ﬂuctuations [23].
ICA with its assumption of non-Gaussian and statistically independent subcomponents [28] is able
to recover individual neuron-assembly membership  and neurons belonging to multiple motifs are

2

Y

=

=

+

noise

+

(cid:126)

(cid:126)

a1

a2

s1

s2

Figure 2: Sketch of convolutional coding. In this example the raw data matrix Y is described by a
matrix which is an additive mixture of two motifs a1 (cyan) and a2 (salmon) convolved with their
activities s1 and s2  respectively  plus background noise.

also correctly identiﬁed [17]. ICA provides a better estimate for synchronous motifs than PCA [17] 
but motifs with more complicated temporal structure are not (directly) accommodated within this
framework. An overview of PCA and ICA for identifying motifs is provided in [17].
More sophisticated statistical approaches have been developed  like unitary event analysis [13  14]  for
detecting coincident  joint spike events across multiple cells. More advanced methods and statistical
tests were also designed for detecting higher-order correlations among neurons [15  16]  as well
as synﬁre chains [20]. However  none of these techniques is designed to detect more complex 
non-synchronous  non-sequential temporal structure. Only quite recently more elaborate statistical
schemes for capturing assemblies with arbitrary temporal structure  and also for dealing with issues
like non-stationarity and different time scales  were advanced [23]. The latter method works by
recursively merging sets of units into larger groups based on their joint spike count probabilities
evaluated across multiple different time lags. The method proposed in this paper  in contrast 
approaches the detection of complex assemblies in a very different manner  attempting to detect
complex patterns as a whole.
NMF techniques have been widely applied to recover spike trains from calcium ﬂuorescence record-
ings [29–35]. Building on these schemes  NMF has been used to decompose a binned spike matrix
into multiple levels of synchronous patterns which describe a hierarchical structuring of the motifs
[36]. But these previous applications of NMF considered only neurons ﬁring strictly synchronously.
In audio processing  convolutive NMF has been successfully used to detect motifs with temporal
structure [24  25  37]. However  as we will show later  the constraints used in audio processing are
too weak to extract motifs from neuronal spike data. For this reason we propose a novel optimization
approach using sparsity constraints adapted to neuronal spike data.

3 Sparse convolutional coding

We formulate the identiﬁcation of motifs with any of the temporal structures displayed in ﬁgure 1 as
a convolutional matrix decomposition into motifs and their activity in time  based on the idea behind
convolutive NMF [24  25]  and combined with the sparsity constraints used in [34]. We use a novel
optimization approach and minimize the reconstruction error while taking into account the sparsity
constraints for both motifs and their activation time points.
Let Y ∈ Rn×m
be a matrix whose n rows represent individual neurons with their spiking activity
binned to m columns. We assume that this raw signal is an additive mixture of l motifs ai ∈ Rn×τ
with temporal length τ  convolved with a sparse activity signal si ∈ R1×m
plus noise (see ﬁgure 2).
We address the unsupervised problem of simultaneously estimating both the coefﬁcients making up
the motifs ai and their activities si. To this end  we propose to solve the optimization problem

+

+

+

si (cid:126) ai

(cid:107)si(cid:107)0 + β

(cid:107)ai(cid:107)1

(1)

i=1

i=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)Y − l(cid:88)

i=1

min
a s

l(cid:88)

l(cid:88)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

F

+ α

3

τ(cid:88)

with α and β controlling the regularization strength of the (cid:96)0 norm of the activations and the (cid:96)1 norm
of the motifs  respectively. The convolution operator (cid:126) is deﬁned by

si (cid:126) ai =

ai j · S(j − 1)si

(2)

j=1

with ai j being the jth column of ai. The column shift operator S(j) moves a matrix j places to
the right while keeping the same size and ﬁlling missing values appropriately with zeros [24]. The
product on the right-hand side is an outer product.
In [25] the activity of the learned motifs is regularized only with a (cid:96)1 prior which is too weak to
recover motifs in neuronal spike trains. Instead we choose the (cid:96)0 prior for si since it has been
successfully used to learn spike trains of neurons [34]. For the motifs themselves a (cid:96)1 prior is used to
enforce only few non-zero coefﬁcients while still allowing exact optimization [38].

3.1 Optimization

This problem is non-convex in general but can be approached by initializing the activities si randomly
and using a block coordinate descent strategy [39  Section 2.7] to alternatingly optimize for the two
variables.
When keeping the activations si ﬁxed  the motif coefﬁcients ai are learned using LASSO regression
with non-negativity constraints [40] by transforming the convolution with si to a linear set of equations
by using modiﬁed Toeplitz matrices ˜si ∈ Rmn×nτ which are then stacked column-wise [41  38]:

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)vec(Y)

(cid:124) (cid:123)(cid:122) (cid:125)

b∈Rmn

min

a

− [˜s1

(cid:124)

(cid:123)(cid:122)

... ˜sl]
A∈Rmn×lnτ

(cid:34)vec(a1)
(cid:124)
(cid:123)(cid:122)

vec(al)
x∈Rlnτ

...

(cid:125)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)

(cid:35)
(cid:125)

2

2

l(cid:88)

i=1

+ β

(cid:107)ai(cid:107)1

(3)

The matrices ˜si are constructed from the si with ˜si j k = ˜si j+1 k+1 = si j−k for j ≥ k and ˜si j k = 0
for j < k and ˜si j k = 0 for j > p · m and k < p · τ for p = 1  . . .   n (where i denotes the ith matrix
with element indices j and k).
When keeping the currently found motifs ai ﬁxed  their activation in time is learned using a con-
volutional matching pursuit algorithm [42–44] to approximate the (cid:96)0 norm. The greedy algorithm
iteratively includes an assembly appearance that most reduces the reconstruction error.All details of
the algorithm are outlined in the supplementary material for this paper.

3.2 Motif sorting and non-parametric threshold estimation

The list of identiﬁed motifs is expected to also contain false positives which do not appear repeatedly
in the data. The main non-biological reason for this is that our algorithm only ﬁnds local minima of
the optimization problem given by equation (1). Experiments on various synthetic datasets showed
that motifs present at the global optimum should always have the same appearance  independent of
the random initialization of the activities. The false positives which are only present in particular
local minima  however  look differently every time the initialization is changed. We therefore propose
to run our algorithm multiple times on the same data with the same parameter settings but with
different random initializations  and use the following sorting and non-parametric threshold estimation
algorithm in order to distinguish between true (reproducible) and spurious motifs. The following is
only a brief description. More details are given in the supplementary material.
In the ﬁrst step  the motifs found in each run are sorted using pairwise matching. The sorting is
necessary because the order of the motifs after learning is arbitrary and it has to be assured that the
motifs with the smallest difference between different runs are compared. Sorting the sets of motifs
from all runs at the same time is an NP hard multidimensional assignment problem [45]. Therefore  a
greedy algorithm is used instead. It starts by sorting the two sets of motifs with the lowest assignment
cost. Thereafter  the remaining sets of motifs are sorted one by one according to the order of motifs
given by the already sorted sets.
Inspired by permutation tests  we estimate a threshold T by creating a shufﬂed spike matrix to
determine which motifs are only spurious. In the shufﬂed matrix all temporal correlations between

4

and within neurons have been destroyed. Hence  there are no real motifs in the shufﬂed matrix and
the motifs learned from this matrix will likely be different with each new initialization. We take the
minimal difference of any two motifs from different runs of the algorithm on the shufﬂed matrix as
the threshold. We assume that motifs that show a difference between different runs larger than this
threshold are spurious and discard them.

3.3 Parameter selection

The sparse convolutional coding algorithm has only three parameters that have to be speciﬁed by
the user: the maximal number of assemblies  the maximal temporal length of a motif  and the
penalty β on the (cid:96)1 norm of the motifs. The number of assemblies to be learned can be set to a
generous upper limit since the sorting method assures that only the true motifs remain while all false
positives are deleted. The temporal length of a motif can also be set to a generous upper bound.
To ﬁnd an adequate (cid:96)1 penalty for the assemblies  different values need to be tested  and it should
be set to a value where neither the motifs are completely empty nor all neurons are active over the
whole possible length of the motifs. In the tested cases the appearance of the found motifs did not
change drastically while varying the (cid:96)1 penalty within one order of magnitude  so ﬁne-tuning it is not
necessary. Instead of specifying the penalty α on the (cid:96)0 norm of the activations directly  we chose to
stop the matching pursuit algorithm when adding an additional assembly appearance increases the
reconstruction error or when the difference of reconstruction errors from two consecutive steps falls
below a small threshold.
All code for
Sparse-convolutional-coding-for-neuronal-assembly-detection

the proposed method is available at:

https://github.com/sccfnad/

4 Results

4.1 Synthetic data

Since ground truth datasets are not available  we have simulated different synthetic datasets to
establish the accuracy of the proposed method  and compare it to existing work.
For PCA and ICA based methods the number of motifs is estimated using the Marchenko-Pastur
eigenvalue distribution [17]. The sparsity parameter in the sparse convolutive NMF (scNMF) that
resulted in the best performance was chosen empirically [25].
An illustrative example dataset with twenty neurons  one hundred spurious spikes per neuron and
three temporal motifs can be seen in ﬁgure 3. Consecutive activation times between motifs were
modeled as Poisson renewal processes with a mean inter-event-distance of twenty frames. When
running our method from two different random initial states to identify a total of ﬁve motifs  all three
original motifs were among those extracted from the data (ﬁgure 3c and 3d; the motifs have been
sorted manually to match up with the ground truth; all parameters for the analysis can be found in
table 1). While the two spurious motifs change depending on the random initialization  the three true
motifs consistently show up in the search results. Neither PCA  ICA nor scNMF were able to extract
the true motifs (see ﬁgures 3e  3f and 3g).
For further analysis  various datasets consisting of ﬁfty neurons observed over one thousand time
frames were created. Details on the generation of these datasets can be found in the supplementary
material. For each of the different motif lenghts τ = 1  7 and 21 frames  twenty different datasets
were created  with different noise levels and numbers of neurons shared between assemblies.
To compare the performance of different methods  we use the functional association between neurons
as an indicator [27  46  12]. For this a neuron association matrix (NAM) is calculated from the
learned motifs. The NAM contains for each pair of neurons a 1 if the two neurons belong to the same
assembly and a 0 otherwise. The tested methods  however  do not make binary statements about
whether a neuron belongs to an assembly  but provide only the information to what degree the neuron
was associated with an assembly. We apply multiple thresholds to binarize the output of the tested
methods and compute true positive rate and false positive rate between the ground truth NAM and the
binarized NAM  leading to the ROC curves shown in ﬁgure 4. We chose this method since it works
without limitations for synchronous motifs and also allows for comparisons for the more complex
cases.

5

(a) Spike matrix

(b) Ground truth motifs

(c) Learned motifs (proposed
method  ﬁrst trial)

(d) Learned motifs (proposed
method  second trial)

(e) Learned component (PCA)
Figure 3: Results on a synthetic dataset. (a) shows a synthetic spike matrix. (b) shows the three motifs
present in the data. By running our algorithm with two different random initial states the motifs seen
in (c) and (d) are learned. (e)  (f) and (g) show the results from PCA  ICA and scNMF  respectively.

(f) Learned component (ICA)

(g) Learned motifs (scNMF)

(a) τ = 1

(b) τ = 7

(c) τ = 21

Figure 4: ROC curves of different methods on synthetic data for different temporal motif lengths. We
show the mean ROC curve and its standard deviation averaged over all trials on different synthetic
datasets. All methods were run ten times on each dataset with different random initializations.

In the synchronous case (i.e. τ = 1  ﬁgure 4a) our proposed method performs as good as the best
competitor. As expected PCA performance shows a huge variance since some of the datasets contain
neurons shared between multiple motifs and since extracting actual neuron-assembly assignments
is not always possible [27  17]. When temporal structure is introduced we are still able to identify
associations between neurons with very high accuracy. For short temporal motifs (τ = 7  ﬁgure 4b)
scNMF is able to identify associations  but only our method was able to accurately recover most
associations in long motifs (τ = 21  ﬁgure 4c).

6

0100200300400500frame1234567891011121314151617181920neuron135791113frame1234567891011121314151617181920neuronmotif 1135791113frame1234567891011121314151617181920motif 2135791113frame1234567891011121314151617181920motif 30.00.20.40.60.81.013579111315frame1234567891011121314151617181920neuronmotif 113579111315frame1234567891011121314151617181920motif 213579111315frame1234567891011121314151617181920motif 313579111315frame1234567891011121314151617181920motif 413579111315frame1234567891011121314151617181920motif 50.00.10.20.30.40.50.60.713579111315frame1234567891011121314151617181920neuronmotif 113579111315frame1234567891011121314151617181920motif 213579111315frame1234567891011121314151617181920motif 313579111315frame1234567891011121314151617181920motif 413579111315frame1234567891011121314151617181920motif 50.00.10.20.30.40.50.60.70.81234567891011121314151617181920neuronmotif 1−0.4−0.20.00.20.41234567891011121314151617181920neuronmotif 1−0.6−0.4−0.20.00.20.40.613579111315frame1234567891011121314151617181920neuronmotif 113579111315frame1234567891011121314151617181920motif 213579111315frame1234567891011121314151617181920motif 313579111315frame1234567891011121314151617181920motif 413579111315frame1234567891011121314151617181920motif 50.000.050.100.150.200.250.300.350.400.00.20.40.60.81.0False positive rate0.00.20.40.60.81.0True positive ratePCAICAour methodscNMF0.00.20.40.60.81.0False positive rate0.00.20.40.60.81.0True positive ratePCAICAour methodscNMF0.00.20.40.60.81.0False positive rate0.00.20.40.60.81.0True positive ratePCAICAour methodscNMFTable 1: Experimental parameters. We show the used maximal number of assemblies  maximal motif
length in frames  (cid:96)1 penalty value β  and number of runs of the algorithm with different initializations
for the performed experiments on synthetic and real datasets. We also display the estimated threshold
T used for distinguishing between real and spurious motifs.

Experiment
synthetic example data
hippocampal CA1 region
cortical neuron culture

#motifs motif length in frames

5
5
5

15
10
10

β

5 · 10−4
10−6
10−6

#runs

2
5
5

T
–

5.7 · 10−6
6.5 · 10−4

4.2 Real data

In vitro hippocampal CA1 region data. We analyzed spike trains of 91 cells from the hippocampal
CA1 region recorded at high temporal and multiple single cell resolution using CA2+ imaging. The
acute mouse hippocampal slices were recorded in a so-called interface chamber [47].
On this dataset  our algorithm identiﬁed three motifs as real motifs. They are shown in ﬁgure 5a. The
activity of each assembly has been calculated at every frame and is shown in ﬁgure 5b. In order to
qualitatively show that the proposed method appropriately eliminates false positives from the list of
found motifs also on real data  we plotted in ﬁgure 6 for each motif the difference to the best matching
motif from every other run. We did this for the motifs identiﬁed in the original spike matrix (ﬁgure
6a)  as well as for the motifs identiﬁed in the shufﬂed spike matrix (ﬁgure 6b). The motifs found in
the shufﬂed matrix show much higher variability between runs than those found in the original matrix.
For motifs 1 and 3 from the original matrix the difference between runs is in average about two to
three times higher than for the other motifs  but still smaller than the average difference between runs
for all of the motifs from the shufﬂed data. Nevertheless  these motifs are deleted as false positives 
since the threshold for discarding a motif is set to the minimum difference of motifs from different
runs on the shufﬂed matrix. This shows that the ﬁnal set of motifs is unlikely to contain spurious
motifs anymore.
The spontaneous hippocampal network activity is expected to appear under the applied recording
conditions as sharp wave-ripple (SPW-R) complexes that support memory consolidation [48–50  47].
Motif 5 in ﬁgure 5a shows the typical behavior of principal neurons ﬁring single or two consecutive
spikes at a low ﬁring rate ((cid:28) 1 Hz) during SPW-R in vitro [47]. This might be interpreted as the
re-activation of a formerly established neuronal assembly.

In vitro cortical neuron culture data. Primary cortical neurons were prepared from E15 embryos
of Sprague Dawley rats as described in [51] and approved by the NIH Animal Care and Usage
Committee. Cells were transduced with an adeno-associated virus expressing the genetically-encoded
calcium indicator GCaMP6f on DIV 7 (Addgene #51085). Wide-ﬁeld epiﬂuorescent videos of
spontaneous calcium activity from individual wells (6 × 104 cells/well) were recorded on DIV 14 or
18 at an acquisition rate of 31.2 frames per second. The data for the shown example contains 400
identiﬁed neurons imaged for 10 minutes on DIV 14.
Our algorithm identiﬁed two motifs in the used dataset  shown in ﬁgure 5c. Their activity is plotted
in ﬁgure 5d. For each column of the two motifs  ﬁgure 7 shows the percentage of active neurons
at every time frame. The motifs were thresholded such that only neurons with a motif coefﬁcient
above 50% of the maximum coefﬁcient of the motif were counted. We show those columns of the
motifs which contained more than one neuron after thresholding. The fact that ﬁgure 7 shows only
few motif activations that include all of the cells that are a part of the motif has less to do with the
actual algorithm  but more with how the nervous system works: Only rarely all cells of an assembly
will spike [23]  due to both the intrinsic stochasticity  like probabilistic synaptic release [52] and the
fact that synaptic connectivity and thus assembly membership will be graded and strongly ﬂuctuates
across time due to short-term synaptic plasticity [53]. Nevertheless  the plot shows that often several
columns are active in parallel and there are some time points where a high percentage of the neurons
in all columns is active together. This shows that the found motifs really contain temporal structure
and are repeated multiple times in the data.
All parameters for the analysis of the shown experiments can be found in table 1.

7

(a) Motifs from hippocampal CA1 region data

(b) Activity of motifs from hip-
pocampal CA1 region data

(c) Motifs from cortical neuron culture data

(d) Activity of motifs from cortical neuron culture data

Figure 5: Results from real data. We show the results of our algorithm for two different real datasets.
The datasets vary in temporal length as well as number of observed cells. For each dataset we show
the motifs that our algorithm identiﬁed as real motifs and their activity over time.

(a) Difference between runs for motifs learned on origi-
nal matrix
Figure 6: Differences between the ﬁve runs for all ﬁve learned motifs from hippocampal CA1 region
data. The plots show for each motif the difference to the best matching motif from every other run.
We did this for the motifs identiﬁed in the original hippocampal CA1 region data (a)  as well as for
the motifs identiﬁed in the shufﬂed spike matrix (b). The motifs found in the shufﬂed matrix show
much higher variability between runs than those found in the original matrix.

(b) Difference between runs for motifs learned on shuf-
ﬂed matrix

5 Discussion

We have presented a new approach for the identiﬁcation of motifs that is not limited to synchronous
activity. Our method leverages sparsity constraints on the activity and the motifs themselves to allow
a simple and elegant formulation that is able to learn motifs with temporal structure. Our algorithm
extends convolutional coding methods with a novel optimization approach to allow modeling of
interactions between neurons. The proposed algorithm is designed to identify motifs in data with
temporal stationarity. Non-stationarities in the data  which are expected to appear especially in

8

12345678910frame0102030405060708090neuronmotif 212345678910frame0102030405060708090motif 412345678910frame0102030405060708090motif 50.000.020.040.060.080.100.120.140100020003000400050000.000.250.500.75activitymotif 20100020003000400050000.001.002.003.00activitymotif 4010002000300040005000frame0.000.501.001.50activitymotif 512345678910frame0102030405060708090100110120130140150160170180190200210220230240250260270280290300310320330340350360370380390400neuronmotif 112345678910frame0102030405060708090100110120130140150160170180190200210220230240250260270280290300310320330340350360370380390400motif 30.000.020.040.060.080.100250050007500100001250015000175000.001.002.003.00activitymotif 1025005000750010000125001500017500frame0.001.002.003.00activitymotif 312345run12345runmotif 112345run12345runmotif 212345run12345runmotif 312345run12345runmotif 412345run12345runmotif 50e+003e-056e-059e-0512345run12345runmotif 112345run12345runmotif 212345run12345runmotif 312345run12345runmotif 412345run12345runmotif 50e+003e-056e-059e-05Figure 7: Percentage of active neurons per column over time  for all motifs identiﬁed in the cortical
neuron culture dataset. For each column of the two motifs displayed in ﬁgure 5c  we show the
percentage of active neurons at every time frame. Vertical grey bars indicate points in time at
which all signiﬁcantly populated columns of a motif ﬁre with at least 30% of their neurons. Their
reoccurence shows that the motifs really contain temporal structure and are repeated multiple times
in the dataset.

recordings from in vivo  are not yet taken into account.
In cases where non-stationarities are
expected to be strong  the method for stationarity-segmentation introduced in [54] could be used
before applying our algorithm to the data. Although our algorithm has some limitations in terms of
non-stationarities  results on simulated datasets show that the proposed method outperforms others
especially when identifying long motifs. Additionally  the algorithm shows stable performance on
real datasets. Moreover  the results found on the cortical neuron culture dataset show that our method
is able to detect assemblies within large sets of recorded neurons.

Acknowledgments

SP and EK thank Eleonora Russo for sharing her knowledge on generating synthetic data and Fynn
Bachmann for his support. LAC  BKH and CH thank Lowella Fortuno for technical assistance with
cortical cultures and acknowledge the support by the Intramural Research Program of the NIH  NIDA.
DD acknowledges partial ﬁnancial support by DFG Du 354/8-1. SP  EK  MB  DD  FD and FAH
gratefully acknowledge partial ﬁnancial support by DFG SFB 1134.

References
[1] D. Hebb  The Organization of Behaviour: A Neuropsychological Theory. Wiley  1949.
[2] D. Marr  D. Willshaw  and B. McNaughton  Simple memory: a theory for archicortex. Springer  1991.
[3] W. Singer  “Synchronization of cortical activity and its putative role in information processing and learning ”

Annual review of physiology  vol. 55  no. 1  pp. 349–374  1993.

[4] M. A. Nicolelis  E. E. Fanselow  and A. A. Ghazanfar  “Hebb’s dream: the resurgence of cell assemblies ”

Neuron  vol. 19  no. 2  pp. 219–221  1997.

[5] Y. Ikegaya  G. Aaron  R. Cossart  D. Aronov  I. Lampl  D. Ferster  and R. Yuste  “Synﬁre chains and

cortical songs: temporal modules of cortical activity ” Science  vol. 304  no. 5670  pp. 559–564  2004.

[6] P. Cossart and P. J. Sansonetti  “Bacterial invasion: The paradigms of enteroinvasive pathogens ” Science 

vol. 304  no. 5668  pp. 242–248  2004.

[7] G. Buzsáki  “Large-scale recording of neuronal ensembles ” Nature neuroscience  vol. 7  no. 5  pp. 446–451 

2004.

[8] A. Mokeichev  M. Okun  O. Barak  Y. Katz  O. Ben-Shahar  and I. Lampl  “Stochastic emergence of
repeating cortical motifs in spontaneous membrane potential ﬂuctuations in vivo ” Neuron  vol. 53  no. 3 
pp. 413–425  2007.

[9] E. Pastalkova  V. Itskov  A. Amarasingham  and G. Buzsáki  “Internally generated cell assembly sequences

in the rat hippocampus ” Science  vol. 321  no. 5894  pp. 1322–1327  2008.

[10] I. H. Stevenson and K. P. Kording  “How advances in neural recording affect data analysis ” Nature

neuroscience  vol. 14  no. 2  pp. 139–142  2011.

[11] M. B. Ahrens  M. B. Orger  D. N. Robson  J. M. Li  and P. J. Keller  “Whole-brain functional imaging at

cellular resolution using light-sheet microscopy ” Nature methods  vol. 10  no. 5  pp. 413–420  2013.

[12] L. Carrillo-Reid  J.-e. K. Miller  J. P. Hamm  J. Jackson  and R. Yuste  “Endogenous sequential cortical

activity evoked by visual stimuli ” Journal of Neuroscience  vol. 35  no. 23  pp. 8813–8828  2015.

[13] S. Grün  M. Diesmann  and A. Aertsen  “Unitary events in multiple single-neuron spiking activity: I.

detection and signiﬁcance ” Neural Computation  vol. 14  no. 1  pp. 43–80  2002.

[14] S. Grün  M. Diesmann  and A. Aertsen  “Unitary events in multiple single-neuron spiking activity: II.

nonstationary data ” Neural Computation  vol. 14  no. 1  pp. 81–119  2002.

9

0250050007500100001250015000175000100010001000100motif 14567column025005000750010000125001500017500frame010001000100motif 3345columnpercentage of active neurons[15] B. Staude  S. Rotter  and S. Grün  “Cubic: cumulant based inference of higher-order correlations in
massively parallel spike trains ” Journal of Computational Neuroscience  vol. 29  no. 1  pp. 327–350  2010.
[16] B. Staude  S. Grün  and S. Rotter  “Higher-order correlations in non-stationary parallel spike trains:

statistical modeling and inference ” Frontiers in Computational Neuroscience  vol. 4  p. 16  2010.

[17] V. Lopes-dos Santos  S. Ribeiro  and A. B. Tort  “Detecting cell assemblies in large neuronal populations ”

Journal of neuroscience methods  vol. 220  no. 2  pp. 149–166  2013.

[18] A. C. Smith and P. C. Smith  “A set probability technique for detecting relative time order across multiple

neurons ” Neural Comput.  vol. 18  no. 5  pp. 1197–1214  2006.

[19] A. C. Smith  V. K. Nguyen  M. P. Karlsson  L. M. Frank  and P. Smith  “Probability of repeating patterns

in simultaneous neural data ” Neural Comput.  vol. 22  no. 10  pp. 2522–2536  2010.

[20] G. L. Gerstein  E. R. Williams  M. Diesmann  S. Grün  and C. Trengove  “Detecting synﬁre chains in

parallel spike data ” Journal of Neuroscience Methods  vol. 206  no. 1  pp. 54 – 64  2012.

[21] E. Torre  P. Quaglio  M. Denker  T. Brochier  A. Riehle  and S. Grün  “Synchronous spike patterns in
macaque motor cortex during an instructed-delay reach-to-grasp task ” Journal of Neuroscience  vol. 36 
no. 32  pp. 8329–8340  2016.

[22] R. Yuste  J. N. MacLean  J. Smith  and A. Lansner  “The cortex as a central pattern generator ” Nature

Reviews Neuroscience  vol. 6  no. 6  pp. 477–483  2005.

[23] E. Russo and D. Durstewitz  “Cell assemblies at multiple time scales with arbitrary lag constellations ”

eLife  vol. 6  p. e19428  2017.

[24] P. Smaragdis  “Non-negative matrix factor deconvolution; extraction of multiple sound sources from
monophonic inputs ” Lecture Notes in Computer Science (including subseries Lecture Notes in Artiﬁcial
Intelligence and Lecture Notes in Bioinformatics)  vol. 3195  pp. 494–499  2004.

[25] P. D. O’Grady and B. A. Pearlmutter  “Convolutive non-negative matrix factorisation with a sparseness
constraint ” in 2006 16th IEEE Signal Processing Society Workshop on Machine Learning for Signal
Processing  pp. 427–432  2006.

[26] M. A. Nicolelis  L. A. Baccala  R. Lin  and J. K. Chapin  “Sensorimotor encoding by synchronous
neural ensemble activity at multiple levels of the somatosensory system ” Science  vol. 268  no. 5215 
pp. 1353–1358  1995.

[27] V. Lopes-dos Santos  S. Conde-Ocazionez  M. A. L. Nicolelis  S. T. Ribeiro  and A. B. L. Tort  “Neuronal
assembly detection and cell membership speciﬁcation by principal component analysis ” PLOS ONE 
vol. 6  no. 6  pp. 1–16  2011.

[28] P. Comon  “Independent component analysis  a new concept? ” Signal processing  vol. 36  no. 3  pp. 287–

[29] A. Cichocki and R. Zdunek  “Multilayer nonnegative matrix factorisation ” Electronics Letters  vol. 42 

314  1994.

no. 16  pp. 947–948  2006.

[30] J. T. Vogelstein  A. M. Packer  T. A. Machado  T. Sippy  B. Babadi  R. Yuste  and L. Paninski  “Fast
nonnegative deconvolution for spike train inference from population calcium imaging ” Journal of Neuro-
physiology  vol. 104  no. 6  pp. 3691–3704  2010.

[31] R. Rubinstein  M. Zibulevsky  and M. Elad  “Double sparsity: Learning sparse dictionaries for sparse

signal approximation ” IEEE Transactions on Signal Processing  vol. 58  no. 3  pp. 1553–1564  2010.

[32] E. A. Pnevmatikakis  T. A. Machado  L. Grosenick  B. Poole  J. T. Vogelstein  and L. Paninski  “Rank-
penalized nonnegative spatiotemporal deconvolution and demixing of calcium imaging data ” in Computa-
tional and Systems Neuroscience (Cosyne) 2013  2013.

[33] E. A. Pnevmatikakis and L. Paninski  “Sparse nonnegative deconvolution for compressive calcium imaging:

algorithms and phase transitions ” in NIPS  2013.

[34] F. Diego Andilla and F. A. Hamprecht  “Sparse space-time deconvolution for calcium image analysis ” in
Advances in Neural Information Processing Systems 27 (Z. Ghahramani  M. Welling  C. Cortes  N. D.
Lawrence  and K. Q. Weinberger  eds.)  pp. 64–72  Curran Associates  Inc.  2014.

[35] E. A. Pnevmatikakis  Y. Gao  D. Soudry  D. Pfau  C. Laceﬁeld  K. Poskanzer  R. Bruno  R. Yuste  and
L. Paninski  “A structured matrix factorization framework for large scale calcium imaging data analysis ”
arXiv:1409.2903 [q-bio  stat].

[36] F. Diego and F. A. Hamprecht  “Learning multi-level sparse representations ” in NIPS  2013.
[37] R. J. Weiss and J. P. Bello  “Identifying repeated patterns in music using sparse convolutive non-negative

matrix factorization ” in ISMIR  2010.

[38] H. Zou and T. Hastie  “Regularization and variable selection via the elastic net ” Journal of the Royal

Statistical Society  Series B (Statistical Methodology)  vol. 67  no. 2  pp. 301–320  2005.

[39] D. P. Bertsekas  Nonlinear Programming. Athena Scientiﬁc  1999.
[40] R. Tibshirani  “Regression shrinkage and selection via the lasso ” Journal of the Royal Statistical Society.

Series B (Methodological)  vol. 58  no. 1  pp. 267–288  1996.

[41] P. C. Hansen  “Deconvolution and regularization with Toeplitz matrices ” Numerical Algorithms  vol. 29 

no. 4  pp. 323–378  2002.

[42] S. G. Mallat and Z. Zhang  “Matching pursuits with time-frequency dictionaries ” IEEE Transactions on

Signal Processing  vol. 41  no. 12  pp. 3397–3415  1993.

[43] M. Protter and M. Elad  “Image sequence denoising via sparse and redundant representations ” IEEE

Transactions on Image Processing  vol. 18  no. 1  pp. 27–35  2009.

10

[44] A. Szlam  K. Kavukcuoglu  and Y. LeCun  “Convolutional matching pursuit and dictionary training ”

[45] W. P. Pierskalla  “Letter to the editor – the multidimensional assignment problem ” Operations Research 

Computer Research Repository (arXiv)  2010.

vol. 16  no. 2  pp. 422–431  1968.

[46] Y. N. Billeh  M. T. Schaub  C. A. Anastassiou  M. Barahona  and C. Koch  “Revealing cell assemblies at

multiple levels of granularity ” Journal of Neuroscience Methods  vol. 236  pp. 92 – 106  2014.

[47] T. Pfeiffer  A. Draguhn  S. Reichinnek  and M. Both  “Optimized temporally deconvolved Ca2+ imaging
allows identiﬁcation of spatiotemporal activity patterns of CA1 hippocampal ensembles ” NeuroImage 
vol. 94  pp. 239–249  2014.

[48] G. Buzsáki  “Memory consolidation during sleep: A neurophysiological perspective ” Journal of Sleep

Research  vol. 7 Suppl 1  pp. 17–23  1998.

[49] G. Girardeau  K. Benchenane  S. I. Wiener  G. Buzsáki  and M. B. Zugaro  “Selective suppression of
hippocampal ripples impairs spatial memory ” Nature Neuroscience  vol. 12  no. 10  pp. 1222–1223  2009.
[50] G. Girardeau and M. Zugaro  “Hippocampal ripples and memory consolidation ” Current Opinion in

Neurobiology  vol. 21  no. 3  pp. 452–459  2011.

[51] D. B. Howard  K. Powers  Y. Wang  and B. K. Harvey  “Tropism and toxicity of adeno-associated viral
vector serotypes 1  2  5  6  7  8  and 9 in rat neurons and glia in vitro ” Virology  vol. 372  no. 1  pp. 24 –
34  2008.

[52] C. F. Stevens  “Neurotransmitter release at central synapses ” Neuron  vol. 40  no. 2  pp. 381 – 388  2003.
[53] H. Markram  Y. Wang  and M. Tsodyks  “Differential signaling via the same axon of neocortical pyramidal

neurons ” Proceedings of the National Academy of Sciences  vol. 95  no. 9  pp. 5323–5328  1998.

[54] C. S. Quiroga-Lombard  J. Hass  and D. Durstewitz  “Method for stationarity-segmentation of spike
train data with application to the pearson cross-correlation ” Journal of Neurophysiology  vol. 110  no. 2 
pp. 562–572  2013.

11

,Sven Peter
Elke Kirschbaum
Martin Both
Lee Campbell
Brandon Harvey
Conor Heins
Daniel Durstewitz
Ferran Diego
Fred Hamprecht