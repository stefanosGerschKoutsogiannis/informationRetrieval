2018,Wasserstein Distributionally Robust Kalman Filtering,We study a distributionally robust mean square error estimation problem over a nonconvex Wasserstein ambiguity set containing only normal distributions. We show that the optimal estimator and the least favorable distribution form a Nash equilibrium. Despite the non-convex nature of the ambiguity set  we prove that the estimation problem is equivalent to a tractable convex program. We further devise a Frank-Wolfe algorithm for this convex program whose direction-searching subproblem can be solved in a quasi-closed form. Using these ingredients  we introduce a distributionally robust Kalman filter that hedges against model risk.,Wasserstein Distributionally Robust Kalman Filtering

Soroosh Shaﬁeezadeh-Abadeh
Daniel Kuhn
École Polytechnique Fédérale de Lausanne  CH-1015 Lausanne  Switzerland

Viet Anh Nguyen

{soroosh.shafiee viet-anh.nguyen daniel.kuhn} @epfl.ch

Peyman Mohajerin Esfahani

Delft Center for Systems and Control  TU Delft  The Netherlands

P.MohajerinEsfahani@tudelft.nl

Abstract

We study a distributionally robust mean square error estimation problem over a
nonconvex Wasserstein ambiguity set containing only normal distributions. We
show that the optimal estimator and the least favorable distribution form a Nash
equilibrium. Despite the non-convex nature of the ambiguity set  we prove that
the estimation problem is equivalent to a tractable convex program. We further
devise a Frank-Wolfe algorithm for this convex program whose direction-searching
subproblem can be solved in a quasi-closed form. Using these ingredients  we
introduce a distributionally robust Kalman ﬁlter that hedges against model risk.

1

Introduction

The Kalman ﬁlter is the workhorse for the online tracking and estimation of a dynamical system’s
internal state based on indirect observations [1]. It has been applied with remarkable success in
areas as diverse as automatic control  brain-computer interaction  macroeconomics  robotics  signal
processing  weather forecasting and many more. The classical Kalman ﬁlter critically relies on
the availability of an accurate state-space model and is therefore susceptible to model risk. This
observation has led to several attempts to robustify the Kalman ﬁlter against modeling errors.
The H∞-ﬁlter targets situations in which the statistics of the noise process is uncertain and where
one aims to minimize the worst case instead of the variance of the estimation error [3  26]. This ﬁlter
bounds the H∞-norm of the transfer function that maps the disturbances to the estimation errors.
However  in transient operation  the desired H∞-performance is lost  and the ﬁlter may diverge unless
some (typically restrictive) positivity condition holds in each iteration. In set-valued estimation the
disturbance vectors are modeled through bounded sets such as ellipsoids [4  22]. In this framework 
one attempts to construct the smallest ellipsoids around the state estimates that are consistent with the
observations and the exogenous disturbance ellipsoids. However  the resulting robust ﬁlters ignore
any distributional information and thus have a tendency to be over-conservative. A ﬁlter that is robust
against more general forms of (set-based) model uncertainty was ﬁrst studied in [19]. This ﬁlter
iteratively minimizes the worst-case mean square error across all models in the vicinity of a nominal
state space model. While performing well in the face of large uncertainties  this ﬁlter may be too
conservative under small uncertainties. A generalized Kalman ﬁlter that addresses this shortcoming
and strikes the balance between nominal and worst-case performance has been proposed in [25].
A risk-sensitive Kalman ﬁlter is obtained by minimizing the moment-generating function instead
of the mean of the squared estimation error [24]. This risk-sensitive Kalman ﬁlter is equivalent
to a distributionally robust ﬁlter proposed in [12]  which minimizes the worst-case mean square
error across all joint state-output distributions in a Kullback-Leibler (KL) ball around a nominal
distribution. Extensions to more general τ-divergence balls are investigated in [27].

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

In this paper we use ideas from distributionally robust optimization to design a Kalman-type ﬁlter
that is immunized against model risk. Speciﬁcally  we assume that the joint distribution of the states
and outputs is uncertain but known to reside in a given ambiguity set that contains all distributions in
the proximity of the nominal distribution generated by a nominal state-space model. The ambiguity
set thus reﬂects our level of (dis)trust in the nominal model. We then construct the most accurate
ﬁlter under the least favorable distribution in this set. The hope is that hedging against the worst-
case distribution has a regularizing effect and will lead to a ﬁlter that performs well under the
unknown true distribution. Distributionally robust ﬁlters of this type have been studied in [7  16]
using uncertainty sets for the covariance matrix of the state vector and in [12  27] using ambiguity sets
deﬁned via information divergences. Inspired by recent progress in data-driven distributionally robust
optimization [14]  we construct here the ambiguity set as a ball around the nominal distribution with
respect to the type-2 Wasserstein distance. The Wasserstein distance has seen widespread application
in machine learning [2  6  18]  and an intimate relation between regularization and Wasserstein
distributional robustness has been discovered in [21  20  23  15]. Also  the Wasserstein distance is
known to be more statistically robust than other information divergences [5].
We summarize our main contributions as follows:
• We introduce a distributionally robust mean square estimation problem over a nonconvex Wasser-
stein ambiguity set containing normal distributions only  and we demonstrate that the optimal
estimator and the least favorable distribution form a Nash equilibrium.
• Leveraging modern reformulation techniques from [15]  we prove that this problem is equivalent to
a tractable convex program—despite the nonconvex nature of the underlying ambiguity set—and
that the optimal estimator is an afﬁne function of the observations.
• We devise an efﬁcient Frank-Wolfe-type ﬁrst-order method inspired by [10] to solve the resulting
convex program. We show that the direction-ﬁnding subproblem can be solved in quasi-closed
form  and we derive the algorithm’s convergence rate.
• We introduce a Wasserstein distributionally robust Kalman ﬁlter that hedges against model risk.
The ﬁlter can be computed efﬁciently by solving a sequence of robust estimation problems via the
proposed Frank-Wolfe algorithm. Its performance is validated on standard test instances.

Id stands for the identity matrix in Rd×d. For any A  B ∈ Rd×d  we use(cid:10)A  B(cid:11) = Tr(cid:2)A(cid:62)B(cid:3) to

All proofs are relegated to Appendix A  and additional numerical results are reported in Appendix B.
Notation: For any A ∈ Rd×d we use Tr [A] to denote the trace and (cid:107)A(cid:107) to denote the spectral norm
of A. By slight abuse of notation  the Euclidean norm of v ∈ Rd is also denoted by (cid:107)v(cid:107). Moreover 
denote the trace inner product. The space of all symmetric matrices in Rd×d is denoted by Sd. We
use Sd
++) to represent the cone of symmetric positive semideﬁnite (positive deﬁnite) matrices
in Sd. For any A  B ∈ Sd  the relation A (cid:23) B (A (cid:31) B) means that A − B ∈ Sd
++).
Finally  the set of all normal distribution on Rd is denoted by Nd.

+ (A − B ∈ Sd

+ (Sd

2 Robust Estimation with Wasserstein Ambiguity Sets
Consider the problem of estimating a signal x ∈ Rn from a potentially noisy observation y ∈ Rm.
In practice  the joint distribution of x and y is never directly observable and thus fundamentally
uncertain. This distributional uncertainty should be taken into account in the estimation procedure.
In this paper  we model distributional uncertainty through an ambiguity set P  that is  a family of
distributions on Rd  d = n + m  that are sufﬁciently likely to govern x and y in view of the available
data or that are sufﬁciently close to a prescribed nominal distribution. We then seek a robust estimator
that minimizes the worst-case mean square error across all distributions in the ambiguity set. In the
following  we propose to use the Wasserstein distance in order to construct ambiguity sets.
Deﬁnition 2.1 (Wasserstein distance). The type-2 Wasserstein distance between two distributions
Q1 and Q2 on Rd is deﬁned as
W2(Q1  Q2) (cid:44)

(1)
where Π(Q1  Q2) is the set of all probability distributions on Rd × Rd with marginals Q1 and Q2.

(cid:107)z1 − z2(cid:107)2 π(d z1  d z2)

2(cid:41)
(cid:19) 1

(cid:40)(cid:18)(cid:90)

inf

π∈Π(Q1 Q2)

Rd×Rd

 

2

Proposition 2.2 ([9  Proposition 7]). The type-2 Wasserstein distance between two normal distribu-
tions Q1 = Nd(µ1  Σ1) and Q2 = Nd(µ2  Σ2) with µ1  µ2 ∈ Rd and Σ1  Σ2 ∈ Sd

+ equals

(cid:115)(cid:13)(cid:13)µ1 − µ2

(cid:13)(cid:13)2

(cid:20)

(cid:16)

2(cid:21)
(cid:17) 1

.

W2(Q1  Q2) =

+ Tr

Σ1 + Σ2 − 2

1
2

2 Σ1Σ

1
2
2

Σ

Consider now a d-dimensional random vector z = [x(cid:62)  y(cid:62)](cid:62) comprising the signal x ∈ Rn and the
observation y ∈ Rm  where d = n + m. For a given ambiguity set P  the distributionally robust
minimum mean square error estimator of x given y is a solution of the outer minimization problem in

EQ(cid:2)(cid:107)x − ψ(y)(cid:107)2(cid:3)  

ψ∈L sup
inf
Q∈P

(2)

where L denotes the family of all measurable functions from Rm to Rn. Problem (2) can be viewed
as a zero-sum game between a statistician choosing the estimator ψ and a ﬁctitious adversary (or
nature) choosing the distribution Q. By construction  the minimax estimator performs best under the
worst possible distribution Q ∈ P. From now on we assume that P is the Wasserstein ambiguity set

(cid:110)Q ∈ Nd : W2(Q  P) ≤ ρ

(cid:111)

P =

(3)
which can be interpreted as a ball of radius ρ ≥ 0 in the space of normal distributions. We will further
assume that P is centered at a normal distribution P = Nd(µ  Σ) with covariance matrix Σ (cid:31) 0.
Even though the Wasserstein ambiguity set P is nonconvex (as mixtures of normal distributions are
generically not normal)  we can prove a minimax theorem  which ensures that one may interchange
the inﬁmum and the supremum in (2) without affecting the problem’s optimal value.
Theorem 2.3 (Minimax theorem). If P is a Wasserstein ambiguity set of the form (3)  then

 

EQ(cid:2)(cid:107)x − ψ(y)(cid:107)2(cid:3) = sup

EQ(cid:2)(cid:107)x − ψ(y)(cid:107)2(cid:3) .

(4)

ψ∈L sup
inf
Q∈P

inf
ψ∈L

Q∈P

Remark 2.4 (Connection to Bayesian estimation). The optimal solutions ψ(cid:63) and Q(cid:63) of the two
dual problems in (4) represent the minimax strategies of the statistician and nature  respectively.
Theorem 2.3 implies that (ψ(cid:63)  Q(cid:63)) forms a saddle point (and thus a Nash equilibrium) of the
underlying zero-sum game. Hence  the robust estimator ψ(cid:63) is also the optimal Bayesian estimator for
the prior Q(cid:63). For this reason  Q(cid:63) is often referred to as the least favorable prior [11].

We now demonstrate that the minimax problem (2) is equivalent to a tractable convex program  whose
solution allows us to recover both the optimal estimator ψ(cid:63) as well as the least favorable prior Q(cid:63).
Theorem 2.5 (Tractable reformulation). The minimax problem (2) with the Wasserstein ambiguity
set (3) centered at P = Nd(µ  Σ) 

σ (cid:44) λmin(Σ) > 0  is equivalent to the ﬁnite convex program
¯

sup Tr(cid:2)Sxx − SxyS−1
(cid:20)Sxx Sxy
(cid:21)
(cid:16)

Syx Syy
S + Σ − 2

s. t. S =

(cid:20)

Tr

Σ

yy Syx
∈ Sd

(cid:3)
2(cid:21)
+  Sxx ∈ Sn
(cid:17) 1

1
2 SΣ

1
2

≤ ρ2  S (cid:23)

σId.
¯

+  Syy ∈ Sm

+   Sxy = S(cid:62)

yx ∈ Rn×m

(5)

xy(S(cid:63)

xx  S(cid:63)

x   µ(cid:62)

yy and S(cid:63)

xy is optimal in (5) and µ = [µ(cid:62)

y ](cid:62) for some µx ∈ Rn and µy ∈ Rm  then
yy)−1(y − µy) + µx is the distributionally robust minimum mean

If S(cid:63)  S(cid:63)
the afﬁne function ψ(cid:63)(y) = S(cid:63)
square error estimator  and the normal distribution Q(cid:63) = Nd(µ  S(cid:63)) is the least favorable prior.
Theorem 2.5 provides a tractable procedure for constructing a Nash equilibrium (ψ(cid:63)  S(cid:63)) for the
statistician’s game against nature. Note that if ρ = 0  then S(cid:63) = Σ is the unique solution to (5). In
this case the estimator ψ(cid:63) reduces to the Bayesian estimator corresponding to the nominal distribution
P = Nd(µ  Σ). We emphasize that the choice of the Wasserstein radius ρ may have a signiﬁcant
impact on the resulting estimator. In fact  this is a key distinguishing feature of the Wasserstein
ambiguity set (3) with respect to other popular divergence-based ambiguity sets.

3

Remark 2.6 (Divergence-based ambiguity sets). As a natural alternative  one could replace the
Wasserstein distance in (3) with an information divergence. For example  ambiguity sets deﬁned via
τ-divergences  which encapsulate the popular KL divergence as a special case  have been studied in
[12  27]. As shown in [12  Theorem 1] and [27  Theorem 2.1]  the optimal estimator corresponding
to any τ-divergence ambiguity set always coincides with the Bayesian estimator for the nominal
distribution P = Nd(µ  Σ) irrespective of ρ. Thus  in stark contrast to the setting considered here  the
size of a τ-divergence ambiguity set has no impact on the corresponding optimal estimator. Moreover 
the least favorable prior Q = Nd(µ  S(cid:63)) for a τ-divergence ambiguity set always satisﬁes

.

(6)

(cid:20)S(cid:63)

(cid:21)

S(cid:63) =

xx Σxy
Σyx Σyy

Thus  in order to harm the statistician  nature only perturbs the second moments of the signal but sets
all second moments of the observation as well as all cross moments to their nominal values.
Example 2.7 (Impact of ρ on the Nash equilibrium). We illustrate the dependence of the saddle
point (ψ(cid:63)  Q(cid:63)) on the size ρ of the ambiguity set in a 2-dimensional example. Suppose that the
nominal distribution P of [x  y] ∈ R2 satisﬁes µx = µy = 0  Σxx = Σxy = 1 and Σyy = 1.1 
implying that the noise w (cid:44) y − x and the signal x are independent (EP
[xw] = Σxy − Σxx = 0).
Figure 1 visualizes the canonical 90% conﬁdence ellipsoids of the the least favorable priors as well
as the graphs of the optimal estimators for different sizes of the Wasserstein and KL ambiguity sets.
As ρ increases  the least favorable prior for the Wasserstein ambiguity set displays the following
xx increases  (ii) the measurement variance S(cid:63)
interesting properties: (i) the signal variance S(cid:63)
yy
decreases  (iii) the signal-measurement covariance S(cid:63)
xy decreases towards 0  and (iv) the noise variance
xy−S(cid:63)
EQ(cid:63)
xx
decreases and is negative for all ρ > 0  and (vi) the optimal estimator ψ(cid:63) tends to the zero function.
Note that the optimal estimator and the measurement variance remain constant in ρ when working
with a KL ambiguity set.

xx increases. Hence  (v) the signal-noise covariance EQ(cid:63)

[xw] = S(cid:63)

[w2] = S(cid:63)

yy−2S(cid:63)

xy+S(cid:63)

Figure 1: Least favorable priors (solid ellipsoids) and optimal estimators (dashed lines) for Wasserstein
(left) and KL (right) ambiguity sets with different radii ρ. The Wasserstein estimators vary with ρ 
while the KL estimators remain unaffected by ρ.
Remark 2.8 (Ambiguity sets with non-normal distributions). Theorem 2.3 can be generalized to
Wasserstein ambiguity set of the form Q = {Q ∈ M(Rd) : W2(Q  P) ≤ ρ}  where M(Rd) denotes
the set of all (possibly non-normal) probability distributions on Rd with ﬁnite second moments  and
P = Nd(µ  Σ). In this case  the minimax result (4) remains valid provided that the set L of all
measurable estimators is restricted to the set A of all afﬁne estimators. Theorem 2.5 also remains
valid under this alternative setting.

3 Efﬁcient Frank-Wolfe Algorithm

The ﬁnite convex optimization problem (5) is numerically challenging as it constitutes a nonlinear
semi-deﬁnite program (SDP). In principle  it would be possible to eliminate all nonlinearities by using
Schur complements and to reformulate (5) as a linear SDP  which is formally tractable. However  it is
folklore knowledge that general-purpose SDP solvers are yet to be developed that can reliably solve
large-scale problem instances. We thus propose a tailored ﬁrst-order method to solve the nonlinear
SDP (5) directly  which exploits a covert structural property of the problem’s objective function

f (S) (cid:44) Tr(cid:2)Sxx − SxyS−1

yy Syx

(cid:3) .

4

-5-3-10135-3-2-10123-5-3-10135-3-2-10123Deﬁnition 3.1 (Unit total elasticity1). We say that a function ϕ : Sd

+ → R+ has unit total elasticity if
+.

ϕ(S) =(cid:10)S ∇ϕ(S)(cid:11) ∀S ∈ Sd
(cid:28)(cid:20)Sxx Sxy

(cid:21)

(cid:20)

In
−S−1
yy Syx S−1

−SxyS−1
yy SyxSxyS−1

yy

yy

 

Syx Syy

(cid:21)(cid:29)

= f (S).

It is clear that every linear function has unit total elasticity. Maybe surprisingly  however  the objective
function f (S) of problem (5) also enjoys unit total elasticity because

(cid:10)S ∇f (S)(cid:11) =

Moreover  as will be explained below  it turns out problem (5) can be solved highly efﬁciently if
its objective function is replaced with a linear approximation. These observations motivate us to
solve (5) with a Frank-Wolfe algorithm [8]  which starts at S(0) = Σ and constructs iterates

(7a)
where αk represents a judiciously chosen step-size  while the oracle mapping F : S+ → S+ returns
the unique solution of the direction-ﬁnding subproblem

S(k+1) = αkF(cid:0)S(k)(cid:1) + (1 − αk)S(k) ∀k ∈ N ∪ {0} 
 arg max

(cid:10)L ∇f (S)(cid:11)
(cid:20)

L + Σ − 2

L(cid:23)
σId
¯
s. t.

2(cid:21)
(cid:17) 1

2 LΣ 1

(cid:16)

Σ 1

Tr

2

≤ ρ2 .

F (S) (cid:44)

(7b)

In each iteration  the Frank-Wolfe algorithm thus maximizes a linearized objective function over
the original feasible set. In contrast to other commonly used ﬁrst-order methods  the Frank-Wolfe
algorithm thus obviates the need for a potentially expensive projection step to recover feasibility. It
is easy to convince oneself that any solution of the nonlinear SDP (5) is indeed a ﬁxed point of the
operator F . To make the Frank-Wolfe algorithm (7) work in practice  however  one needs

(i) an efﬁcient routine for solving the direction-ﬁnding subproblem (7b);
(ii) a step-size rule that offers rigorous guarantees on the algorithm’s convergence rate.

In the following  we propose an efﬁcient bisection algorithm to address (i). As for (ii)  we show
that the convergence analysis portrayed in [10] applies to the problem at hand. The procedure for
solving (7b) is outlined in Algorithm 1  which involves an auxiliary function h : R+ → R deﬁned via
(8)

h(γ) (cid:44) ρ2 −(cid:10)Σ (cid:0)Id − γ(γId − ∇f (S))−1(cid:1)2(cid:11).

++ and

+  Algorithm 1 outputs a feasible and ε-suboptimal solution to (7b).

Theorem 3.2 (Direction-ﬁnding subproblem). For any ﬁxed inputs ρ  ε ∈ R++  Σ ∈ Sd
S ∈ Sd
We emphasize that the most expensive operation in Algorithm 1 is the matrix inversion (γId − D)−1 
which needs to be evaluated repeatedly for different values of γ. These computations can be
accelerated by diagonalizing D only once at the beginning. The repeat loop in Algorithm 1 carries
out the actual bisection algorithm  and a suitable initial bisection interval is determined by a pair of a
priori bounds LB and U B  which are available in closed form (see Appendix A).
The overall structure of the proposed Frank-Wolfe method is summarized in Algorithm 2. We borrow
the step-size rule suggested in [10] to establish rigorous convergence guarantees. This is accomplished
by showing that the objective function f has a bounded curvature constant. Our convergence result is
formalized in the next theorem.
Theorem 3.3 (Convergence analysis). If Σ (cid:31) 0  ρ > 0  δ > 0 and αk = 2/(2 + k) for any k ∈ N 
then the k-th iterate S(k) computed by Algorithm 2 is feasible in (5) and satisﬁes

where S(cid:63) is an optimal solution of (5) 

¯

f (S(cid:63)) − f (S(k)) ≤

4¯σ4

σ is the smallest eigenvalue of Σ  and ¯σ (cid:44) (ρ +(cid:112)Tr [Σ])2.

σ3(k + 2)
¯

(1 + δ) 

1Our terminology is inspired by the deﬁnition of the elasticity of a univariate function ϕ(s) as dϕ(s)
ds

s

ϕ(s) .

5

Algorithm 1 Bisection algorithm to solve (7b)
Input: Covariance matrix Σ (cid:31) 0

Gradient matrix D (cid:44) ∇f (S) (cid:23) 0
Wasserstein radius ρ > 0
Tolerance ε > 0

Denote the largest eigenvalue of D by λ1
Let v1 be an eigenvector of λ1

Set LB ← λ1(1 +(cid:112)v(cid:62)
Set U B ← λ1(1 +(cid:112)Tr [Σ]/ρ)

1 Σv1/ρ)

repeat

Set γ ← (U B + LB)/2
Set L ← γ2(γId − D)−1Σ(γId − D)−1
if h(γ) < 0 then
Set LB ← γ
Set U B ← γ

Set ∆ ← γ(ρ2 − Tr [Σ]) −(cid:10)L  D(cid:11)
+γ2(cid:10)(γId − D)−1  Σ(cid:11)

end if

else

until h(γ) > 0 and ∆ < ε

Output: L

Algorithm 2 Frank-Wolfe algorithm to solve (5)
Input: Covariance matrix Σ (cid:31) 0
Wasserstein radius ρ > 0
Tolerance δ > 0

σ ← λmin(Σ)  ¯σ ← (ρ +(cid:112)Tr [Σ])2

Set
Set C ← 2¯σ4/
σ3
Set S(0) ← Σ  k ← 0
¯
while Stopping criterion is not met do

¯

Set αk ← 2
Set G ← S(k)
Compute gradient D ← ∇f (S(k)) by

k+2
xy (S(k)

yy )−1

D ← [In  − G](cid:62)[In  − G]

Set ε ← αkδC
Solve the subproblem (7b) by Algorithm 1

L ← Bisection(Σ  D  ρ  ε)

Set S(k+1) ← S(k) + αk(L − S(k))
Set k ← k + 1

end while
Output: S(k)

4 The Wasserstein Distributionally Robust Kalman Filter
Consider a discrete-time dynamical system whose (unobservable) state xt ∈ Rn and (observable)
output yt ∈ Rm evolve randomly over time. At any time t ∈ N  we aim to estimate the current
state xt based on the output history Yt (cid:44) (y1  . . .   yt). We assume that the joint state-output process
t ](cid:62)  t ∈ N  is governed by an unknown Gaussian distribution Q in the neighborhood of a
zt = [x(cid:62)
known nominal distribution P(cid:63). The distribution P(cid:63) is determined through the linear state-space model

t   y(cid:62)

xt = Atxt−1 + Btvt
yt = Ctxt + Dtvt

∀t ∈ N 

(9)

where At  Bt  Ct  and Dt are given matrices of appropriate dimensions  while vt ∈ Rd  t ∈ N 
denotes a Gaussian white noise process independent of x0 ∼ Nn(ˆx0  V0). Thus  vt ∼ Nd(0  Id) for
all t  while vt and vt(cid:48) are independent for all t (cid:54)= t(cid:48). Note that we may restrict the dimension of vt to
the dimension d = n + m of zt without loss of generality. Otherwise  all linearly dependent columns
of [B(cid:62)
By the law of total probability and the Markovian nature of the state-space model (9)  the nominal
= Nn(ˆx0  V0) of the initial
distribution P(cid:63) is uniquely determined by the marginal distribution P(cid:63)
state x0 and the conditional distributions

t ](cid:62) and the corresponding components of vt can be eliminated systematically.

t   D(cid:62)

x0

(cid:27)

(cid:32)(cid:20) At

(cid:21)

(cid:20)

(cid:21)(cid:20)

(cid:21)(cid:62)(cid:33)

P(cid:63)
zt|xt−1

= Nd

xt−1 

CtAt

Bt

Bt

CtBt + Dt

CtBt + Dt

of zt given xt−1 for all t ∈ N.
Unlike P(cid:63)  the true distribution Q governing zt  t ∈ N  is unknown  and thus the estimation problem
at hand is not well-deﬁned. We will therefore estimate the conditional mean ˆxt and covariance matrix
Vt of xt given Yt under some worst-case distribution Q(cid:63) to be constructed recursively. First  we
= Nn(ˆx0  V0).
assume that the marginal distribution Q(cid:63)
Next  ﬁx any t ∈ N and assume that the conditional distribution Q(cid:63)
of xt−1 given Yt−1
under Q(cid:63) has already been computed as Q(cid:63)
xt|Yt
is then split into a prediction step and an update step. The prediction step combines the previous
state estimate Q(cid:63)
to generate a pseudo-nominal

= Nn(ˆxt−1  Vt−1). The construction of Q(cid:63)

x0 of x0 under Q(cid:63) equals Px0  that is  Q(cid:63)

with the nominal transition kernel P(cid:63)

xt−1|Yt−1

xt−1|Yt−1

x0

xt−1|Yt−1

zt|xt−1

6

Algorithm 3 Robust Kalman ﬁlter at time t
Input: Covariance matrix Vt−1 (cid:23) 0

State estimate ˆxt−1
Wasserstein radius ρt > 0
Tolerance δ > 0

Prediction:

Form the pseudo-nominal distribution
Pzt|Yt−1= Nd(µt  Σt) using (10)
Observe the output yt

Observation:

Update:

Use Algorithm 2 to solve (11)

t ← Frank-Wolfe(Σt  µt  ρt  δ)
S(cid:63)
Output: Vt = St xx − St xy(St yy)−1St yx

ˆxt = S(cid:63)

t xy(S(cid:63)

t yy)−1(yt − µt y) + µt x

Figure 2: Wasserstein ball in the space S2
+ of
covariance matrices centered at I2 with radius 1.

distribution Pzt|Yt−1 of zt conditioned on Yt−1  which is deﬁned through

P(cid:63)
zt|xt−1

(B|xt−1)Q(cid:63)

xt−1|Yt−1

(dxt−1|Yt−1)

(cid:90)

Pzt|Yt−1(B|Yt−1) =
(cid:21)

Rn

(cid:20) At

(cid:21)

(cid:20) At

(cid:20) At

(cid:21)(cid:62)

(cid:20)

(cid:21)(cid:20)

(cid:21)(cid:62)

for every Borel set B ⊆ Rd and observation history Yt−1 ∈ Rm×(t−1). The well-known formula for
the convolution of two multivariate Gaussians reveals that Pzt|Yt−1= Nd(µt  Σt)  where

ˆxt−1

CtAt

CtAt

Vt−1

and Σt =

(10)
µt =
Note that the construction of Pzt|Yt−1 resembles the prediction step of the classical Kalman ﬁlter but
uses the least favorable distribution Q(cid:63)
In the update step  the pseudo-nominal a priori estimate Pzt|Yt−1 is updated by the measurement
yt and robustiﬁed against model uncertainty to yield a reﬁned a posteriori estimate Q(cid:63)
. This a
posteriori estimate is found by solving the minimax problem

instead of the nominal distribution P(cid:63)

CtBt + Dt

CtBt + Dt

xt−1|Yt−1

xt−1|Yt−1

CtAt

xt|Yt

.

.

+

Bt

Bt

EQ(cid:2)(cid:107)xt − ψt(yt)(cid:107)2(cid:3)
Pzt|Yt−1 =(cid:8)Q ∈ Nd : W2(Q  Pzt|Yt−1) ≤ ρt

Q∈Pzt|Yt−1

inf
ψt∈L

sup

(11)

(cid:9) .

equipped with the Wasserstein ambiguity set

Note that the Wasserstein radius ρt quantiﬁes our distrust in the pseudo-nominal a priori estimate and
can therefore be interpreted as a measure of model uncertainty. Practically  we reformulate (11) as an
equivalent ﬁnite convex program of the form (5)  which is amenable to efﬁcient computational solution
via the Frank-Wolfe algorithm detailed in Section 3. By Theorem 2.5  the optimal solution S(cid:63)
t of
problem (5) yields the least favorable conditional distribution Q(cid:63)
t ) of zt given Yt−1.
By using the well-known formulas for conditional normal distributions (see  e.g.  [17  page 522])  we
then obtain the least favorable conditional distribution Q(cid:63)

zt|Yt−1
= Nn(ˆxt  Vt) of xt given Yt  where

= Nd(µt  S(cid:63)

ˆxt = S(cid:63)

t xy(S(cid:63)

t yy)−1(yt − µt y) + µt x

and

t  xx − S(cid:63)

t  xy(S(cid:63)

t  yy)−1S(cid:63)

t  yx.

xt|Yt
Vt = S(cid:63)

The distributionally robust Kalman ﬁltering approach is summarized in Algorithm 3. Note that the
robust update step outlined above reduces to the usual update step of the classical Kalman ﬁlter
for ρ ↓ 0.

5 Numerical Results

We showcase the performance of the proposed Frank-Wolfe algorithm and the distributionally robust
Kalman ﬁlter in a suite of synthetic experiments. All optimization problems are implemented in
MATLAB and run on an Intel XEON CPU with 3.40GHz clock speed and 16GB of RAM  and the
corresponding codes are made publicly available at https://github.com/sorooshafiee/WKF.

7

(a) d = 10

(b) d = 50

(c) d = 100

Figure 3: Distribution of the difference between the errors of the robust MMSE (Bayesian MMSE)
and the ideal MMSE(cid:63) estimator.
5.1 Distributionally Robust Minimum Mean Square Error Estimation

We ﬁrst assess the distributionally robust minimum mean square error (robust MMSE) estimator 
which is obtained by solving (2)  against the classical Bayesian MMSE estimator  which can be
viewed as the solution of problem (2) over a singleton ambiguity set that contains only the nominal
distribution. Recall from Remark 2.6 that the optimal estimator corresponding to a KL or τ-divergence
ambiguity set of the type studied in [12  27] coincides with the Bayesian MMSE estimator irrespective
of ρ. Thus  we may restrict attention to Wasserstein ambiguity sets. In order to develop a geometric
intuition  Figure 2 visualizes the set of all bivariate normal distributions with zero mean that have a
Wasserstein distance of at most 1 from the standard normal distribution—projected to the space of
covariance matrices.
In the ﬁrst experiment we aim to predict a signal x ∈ R4d/5 from an observation y ∈ Rd/5  where
the random vector z = [x(cid:62)  y(cid:62)](cid:62) follows a d-variate Gaussian distribution with d ∈ {10  50  100}.
The experiment comprises 104 simulation runs. In each run we randomly generate two covariance
matrices Σ(cid:63) and Σ as follows. First  we draw two matrices A(cid:63) and A from the standard normal
distribution on Rd×d  and we denote by R(cid:63) and R the orthogonal matrices whose columns correspond
to the orthonormal eigenvectors of A(cid:63) + (A(cid:63))(cid:62) and A + A(cid:62)  respectively. Then  we deﬁne ∆(cid:63) =
R(cid:63)Λ(cid:63)(R(cid:63))(cid:62) and Σ = RΛR(cid:62)  where Λ(cid:63) and Λ are diagonal matrices whose main diagonals are
2 + (∆(cid:63)) 1
sampled uniformly from [0  1]d and [0.1  10]d  respectively. Finally  we set Σ(cid:63) = (Σ 1
2 )2
and deﬁne the normal distributions P(cid:63) = Nd(0  Σ(cid:63)) and P = Nd(0  Σ). By construction  we have

W2(P(cid:63)  P) ≤ (cid:107)(Σ(cid:63))

1

2 − Σ

1

2(cid:107)F ≤

√

d 

√

where (cid:107) · (cid:107)F stands for the Frobenius norm  and the ﬁrst inequality follows from [13  Proposition 3].
We assume that P(cid:63) is the true distribution and P our nominal prior. The robust MMSE estimator
is obtained by solving (5) for ρ =
d via the Frank-Wolfe algorithm from Section 3  while the
Bayesian MMSE estimator under P is calculated analytically. In order to provide a meaningful
comparison between these two approaches  we also compute the Bayesian MMSE estimator under
the true distribution P(cid:63) (denoted by MMSE(cid:63))  which is indeed the best possible estimator. Figure 3
visualizes the distribution of the difference between the mean square errors under P(cid:63) of the robust
MMSE (Bayesian MMSE) and MMSE(cid:63) estimators. We observe that the robust MMSE estimator
produces better results consistently across all experiments  and the effect is more pronounced for
larger dimensions d. Figures 4(a) and 4(b) report the execution time and the iteration complexity
of the Frank-Wolfe algorithm for d ∈ {10  . . .   100} when the algorithm is stopped as soon as the

relative duality gap(cid:10)F (Sk) − Sk ∇f (Sk)(cid:11)/f (Sk) drops below 0.01%. Note that the execution

time grows polynomially due to the matrix inversion in the bisection algorithm. Figure 4(c) shows
the relative duality gap of the current solution as a function of the iteration count.

5.2 Wasserstein Distributionally Robust Kalman Filtering

We assess the performance of the proposed Wasserstein distributionally robust Kalman ﬁlter against
that of the classical Kalman ﬁlter and the Kalman ﬁlter with the KL ambiguity set from [12]. To
this end  we borrow the standard test instance from [19  25  12] with n = 2 and m = 1. The system
matrices satisfy

0.0196 + 0.099∆t

0

0.9802

  BtB(cid:62)

t =

0.0195
1.9605

  Ct = [1  − 1]  DtD(cid:62)

t = 1 

(cid:20)0.9802

At =

(cid:21)

(cid:21)

(cid:20)1.9608

0.0195

8

(a) Scaling of iteration count

(b) Scaling of execution time

(c) Convergence for d = 100

Figure 4: Convergence behavior of the Frank-Wolfe algorithm (shown are the average (solid line)
and the range (shaded area) of the respective performance measures across 100 simulation runs)

(a) Small time-invariant
uncertainty

(d) Large time-varying
uncertainty
Figure 5: Empirical means square estimation error of different ﬁlters

(c) Large time-invariant
uncertainty

(b) Small time varying
uncertainty

1

500

t − ˆxj

(cid:80)500
j=1 (cid:107)xj

t = 0  where ∆t represents a scalar uncertainty  and the initial state satisﬁes x0 ∼ N2(0  I2).
and BtD(cid:62)
In all numerical experiments we simulate the different ﬁlters over 1000 periods starting from ˆx0 = 0
t(cid:107)2 across 500
and V0 = I2. Figure 5 shows the empirical mean square error
independent simulation runs  where ˆxj
t denotes the state estimate at time t in the jth run. We
distinguish four different scenarios: time-invariant uncertainty (∆j
t = ∆j sampled uniformly from
[− ¯∆  ¯∆] for each j) versus time-varying uncertainty (∆j
t sampled uniformly from [− ¯∆  ¯∆] for each
t and j)  and small uncertainty ( ¯∆ = 1) versus large uncertainty ( ¯∆ = 10). All results are reported in
decibel units (10 log10(·)). As for the ﬁlter design  the Wasserstein and KL radii are selected from
the search grids {a · 10−1 : a ∈ {1  1.1 ···   2}} and {a · 10−4 : a ∈ {1  1.1 ···   2}}  respectively.
Figure 5 reports the results with minimum steady state error across all candidate radii.
Under small time-invariant uncertainty (Figure 5(a))  the Wasserstein and KL distributionally robust
ﬁlters display a similar steady-state performance but outperform the classical Kalman ﬁlter. Note
that the KL distributionally robust ﬁlter starts from a different initial point as we use the delayed
implementation from [12]. Under small time-varying uncertainty (Figure 5(b))  both distributionally
robust ﬁlters display a similar performance as the classical Kalman ﬁlter. Figures 5(c) and (d)
corresponding to the case of large uncertainty are similar to Figures 5(a) and (b)  respectively.
However  the Wasserstein distributionally robust ﬁlter now signiﬁcantly outperforms the classical
Kalman ﬁlter and  to a lesser extent  the KL distributionally robust ﬁlter. Moreover  the Wasserstein
distributionally robust ﬁlter exhibits the best transient behavior.

Acknowledgments We gratefully acknowledge ﬁnancial support from the Swiss National Science
Foundation under grant BSCGI0_157733.

References
[1] B. D. Anderson and J. B. Moore. Optimal Filtering. Prentice Hall  1979.

[2] M. Arjovsky  S. Chintala  and L. Bottou. Wasserstein GAN. arXiv preprint arXiv:1701.07875 

2017.

[3] T. Ba¸sar and P. Bernhard. H∞-Optimal Control and Related Minimax Design Problems: A

Dynamic Game Approach. Springer  2008.

[4] D. Bertsekas and I. Rhodes. Recursive state estimation for a set-membership description of

uncertainty. IEEE Transactions on Automatic Control  16(2):117–128  1971.

9

[5] Y. Chen  J. Ye  and J. Li. A distance for HMMs based on aggregated Wasserstein metric and

state registration. In European Conference on Computer Vision  pages 451–466  2016.

[6] M. Cuturi and D. Avis. Ground metric learning. The Journal of Machine Learning Research 

15(1):533–564  2014.

[7] Y. C. Eldar and N. Merhav. A competitive minimax approach to robust estimation of random

parameters. IEEE Transactions on Signal Processing  52(7):1931–1946  2004.

[8] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics 

3(1-2):95–110  1956.

[9] C. R. Givens and R. M. Shortt. A class of Wasserstein metrics for probability distributions. The

Michigan Mathematical Journal  31(2):231–240  1984.

[10] M. Jaggi. Revisiting Frank-Wolfe: Projection-free sparse convex optimization. In International

Conference on Machine Learning  pages 427–435  2013.

[11] E. L. Lehmann and G. Casella. Theory of Point Estimation. Springer  2006.

[12] B. C. Levy and R. Nikoukhah. Robust state space ﬁltering under incremental model perturbations
subject to a relative entropy tolerance. IEEE Transactions on Automatic Control  58(3):682–695 
2013.

[13] V. Masarotto  V. M. Panaretos  and Y. Zemel. Procrustes metrics on covariance operators and

optimal transportation of Gaussian processes. preprint at arXiv:1801.01990  2018.

[14] P. Mohajerin Esfahani and D. Kuhn. Data-driven distributionally robust optimization using
the Wasserstein metric: performance guarantees and tractable reformulations. Mathematical
Programming  171(1):115–166  2018.

[15] V. A. Nguyen  D. Kuhn  and P. Mohajerin Esfahani. Distributionally robust inverse covariance

estimation: The Wasserstein shrinkage estimator. Optimization Online  2018.

[16] L. Ning  T. Georgiou  A. Tannenbaum  and S. Boyd. Linear models based on noisy data and the

Frisch scheme. SIAM Review  57(2):167–197  2015.

[17] C. R. Rao. Linear Statistical Inference and its Applications. Wiley  1973.

[18] A. Rolet  M. Cuturi  and G. Peyré. Fast dictionary learning with a smoothed Wasserstein loss.

In Artiﬁcial Intelligence and Statistics  pages 630–638  2016.

[19] A. H. Sayed. A framework for state-space estimation with uncertain models. IEEE Transactions

on Automatic Control  46(7):998–1013  2001.

[20] S. Shaﬁeezadeh-Abadeh  D. Kuhn  and P. Mohajerin Esfahani. Regularization via mass trans-

portation. preprint at arXiv:1710.10016  2017.

[21] S. Shaﬁeezadeh-Abadeh  P. Mohajerin Esfahani  and D. Kuhn. Distributionally robust logistic
regression. In Advances in Neural Information Processing Systems  pages 1576–1584  2015.

[22] S. Shtern and A. Ben-Tal. A semi-deﬁnite programming approach for robust tracking. Mathe-

matical Programming  156(1-2):615–656  2016.

[23] A. Sinha  H. Namkoong  and J. Duchi. Certiﬁable distributional robustness with principled

adversarial training. In International Conference on Learning Representations  2018.

[24] J. L. Speyer  C. Fan  and R. N. Banavar. Optimal stochastic estimation with exponential cost

criteria. In IEEE Conference on Decision and Control  pages 2293–2299  1992.

[25] H. Xu and S. Mannor. A Kalman ﬁlter design based on the performance/robustness tradeoff.

IEEE Transactions on Automatic Control  54(5):1171–1175  2009.

[26] K. Zhou  J. C. Doyle  and K. Glover. Robust and Optimal Control. Prentice Hall  1996.
[27] M. Zorzi. Robust Kalman ﬁltering under model perturbations. IEEE Transactions on Automatic

Control  62(6):2902–2907  2017.

10

,Soroosh Shafieezadeh Abadeh
Viet Anh Nguyen
Daniel Kuhn
Peyman Mohajerin Esfahani
Koosha Khalvati
Saghar Mirbagheri
Seongmin Park
Jean-Claude Dreher
Rajesh Rao