2012,Query Complexity of Derivative-Free Optimization,Derivative Free Optimization (DFO) is attractive when the objective function's derivatives are not available and evaluations are costly.   Moreover  if the function evaluations are noisy  then approximating gradients by finite differences is difficult.  This paper gives quantitative lower bounds on the performance of DFO with noisy function evaluations  exposing a fundamental and unavoidable gap between optimization performance based on noisy evaluations versus noisy gradients. This challenges the conventional wisdom that the method of finite differences is comparable to a stochastic gradient.  However  there are situations in which DFO is unavoidable  and for such situations we propose a new DFO algorithm that is proved to be near optimal for the class of strongly convex objective functions.  A distinctive feature of the algorithm is that it only uses Boolean-valued function comparisons  rather than evaluations.  This makes the algorithm useful in an even wider range of applications  including optimization based on paired comparisons from human subjects  for example.  Remarkably  we show that regardless of whether DFO is based on noisy function evaluations or Boolean-valued function comparisons  the convergence rate is the same.,Query Complexity of Derivative-Free Optimization

Kevin G. Jamieson

University of Wisconsin
Madison  WI 53706  USA
kgjamieson@wisc.edu

Robert D. Nowak

University of Wisconsin
Madison  WI 53706  USA
nowak@engr.wisc.edu

Benjamin Recht

University of Wisconsin
Madison  WI 53706  USA
brecht@cs.wisc.edu

Abstract

This paper provides lower bounds on the convergence rate of Derivative Free Op-
timization (DFO) with noisy function evaluations  exposing a fundamental and
unavoidable gap between the performance of algorithms with access to gradients
and those with access to only function evaluations. However  there are situations
in which DFO is unavoidable  and for such situations we propose a new DFO al-
gorithm that is proved to be near optimal for the class of strongly convex objective
functions. A distinctive feature of the algorithm is that it uses only Boolean-valued
function comparisons  rather than function evaluations. This makes the algorithm
useful in an even wider range of applications  such as optimization based on paired
comparisons from human subjects  for example. We also show that regardless of
whether DFO is based on noisy function evaluations or Boolean-valued function
comparisons  the convergence rate is the same.

1

Introduction

Optimizing large-scale complex systems often requires the tuning of many parameters. With train-
ing data or simulations one can evaluate the relative merit  or incurred loss  of different parameter
settings  but it may be unclear how each parameter inﬂuences the overall objective function. In such
cases  derivatives of the objective function with respect to the parameters are unavailable. Thus 
we have seen a resurgence of interest in Derivative Free Optimization (DFO) [1  2  3  4  5  6  7  8].
When function evaluations are noiseless  DFO methods can achieve the same rates of convergence
as noiseless gradient methods up to a small factor depending on a low-order polynomial of the di-
mension [9  5  10]. This leads one to wonder if the same equivalence can be extended to the case
when function evaluations and gradients are noisy.
Sadly  this paper proves otherwise. We show that when function evaluations are noisy  the opti-

mization error of any DFO is ⌦(p1/T )  where T is the number of evaluations. This lower bound

holds even for strongly convex functions. In contrast  noisy gradient methods exhibit ⇥(1/T ) error
scaling for strongly convex functions [9  11]. A consequence of our theory is that ﬁnite differencing
cannot achieve the rates of gradient methods when the function evaluations are noisy.
On the positive side  we also present a new derivative-free algorithm that achieves this lower bound
with near optimal dimension dependence. Moreover  the algorithm uses only boolean comparisons
of function values  not actual function values. This makes the algorithm applicable to situations in
which the optimization is only able to probably correctly decide if the value of one conﬁguration is
better than the value of another. This is especially interesting in optimization based on human subject
feedback  where paired comparisons are often used instead of numerical scoring. The convergence
rate of the new algorithm is optimal in terms of T and near-optimal in terms of its dependence
on the ambient dimension. Surprisingly  our lower bounds show that this new algorithm that uses
only function comparisons achieves the same rate in terms of T as any algorithm that has access to
function evaluations.

1

2 Problem formulation and background

We now formalize the notation and conventions for our analysis of DFO. A function f is strongly
convex with constant ⌧ on a convex set B⇢ Rd if there exists a constant ⌧> 0 such that

f (y)  f (x) + hrf (x)  y  xi +

⌧
2||x  y||2

for all x  y 2B . The gradient of f  if it exists  denoted rf  is Lipschitz with constant L if
||rf (x)  rf (y)||  L||x  y|| for some L > 0. The class of strongly convex functions with
Lipschitz gradients deﬁned on a nonempty  convex set B⇢ Rn which take their minimum in B with
parameters ⌧ and L is denoted by F⌧ L B.
The problem we consider is minimizing a function f 2F ⌧ L B. The function f is not explicitly
known. An optimization procedure may only query the function in one of the following two ways.
Function Evaluation Oracle: For any point x 2B an optimization procedure can observe

Ef (x) = f (x) + w

Function Comparison Oracle: For any pair of points x  y 2B an optimization procedure can

where w 2 R is a random variable with E[w] = 0 and E[w2] = 2.
observe a binary random variable Cf (x  y) satisfying

P (Cf (x  y) = sign{f (y)  f (x)}) 

(1)
for some 0 < 0  1/2  µ > 0 and   1. When  = 1  without loss of generality
assume µ  0  1/2. Note  = 1 implies that the comparison oracle is correct with
a probability that is greater than 1/2 and independent of x  y. If > 1  then the oracle’s
reliability decreases as the difference between f (x) and f (y) decreases.

1
2

+ min0  µ|f (y)  f (x)|1 

To illustrate how the function comparison oracle and function evaluation oracles relate to each other 
suppose Cf (x  y) = sign{Ef (y)  Ef (x)} where Ef (x) is a function evaluation oracle with ad-
If w is Gaussian distributed with mean zero and variance 2 then  = 2 and
ditive noise w.
µ 4⇡2e1/2 (see supplementary materials). In fact  this choice of w corresponds to Thurston’s
law of comparative judgment which is a popular model for outcomes of pairwise comparisons from
human subjects [12]. If w is a “spikier” distribution such as a two-sided Gamma distribution with
shape parameter in the range of (0  1] then all values of  2 (1  2] can be realized (see supplementary
materials).
Interest in the function comparison oracle is motivated by certain popular derivative-free optimiza-
tion procedures that use only comparisons of function evaluations (e.g. [7]) and by optimization
problems involving human subjects making paired comparisons (for instance  getting ﬁtted for pre-
scription lenses or a hearing aid where unknown parameters speciﬁc to each person are tuned with
the familiar queries “better or worse?”). Pairwise comparisons have also been suggested as a novel
way to tune web-search algorithms [13]. Pairwise comparison strategies have previously been an-
alyzed in the ﬁnite setting where the task is to identify the best alternative among a ﬁnite set of
alternatives (sometimes referred to as the dueling-bandit problem) [13  14]. The function compar-
ison oracle presented in this work and its analysis are novel. The main contributions of this work
and new art are as follows (i) lower bounds for the function evaluation oracle in the presence of
measurement noise (ii) lower bounds for the function comparison oracle in the presence of noise
and (iii) an algorithm for the function comparison oracle  which can also be applied to the function
evaluation oracle setting  that nearly matches both the lower bounds of (i) and (ii).
We prove our lower bounds for strongly convex functions with Lipschitz gradients deﬁned on a com-
pact  convex set B  and because these problems are a subset of those involving all convex functions
(and have non-empty intersection with problems where f is merely Lipschitz)  the lower bound also
applies to these larger classes. While there are known theoretical results for DFO in the noiseless
setting [15  5  10]  to the best of our knowledge we are the ﬁrst to characterize lower bounds for
DFO in the stochastic setting. Moreover  we believe we are the ﬁrst to show a novel upper bound for
stochastic DFO using a function comparison oracle (which also applies to the function evaluation
oracle). However  there are algorithms with upper bounds on the rates of convergence for stochastic

2

DFO with the function evaluation oracle [15  16]. We discuss the relevant results in the next section
following the lower bounds .
While there remains many open problems in stochastic DFO (see Section 6)  rates of convergence
with a stochastic gradient oracle are well known and were ﬁrst lower bounded by Nemirovski and
Yudin [15]. These classic results were recently tightened to show a dependence on the dimension
of the problem [17]. And then tightened again to show a better dependence on the noise [11] which
matches the upper bound achieved by stochastic gradient descent [9]. The aim of this work is to
start ﬁlling in the knowledge gaps of stochastic DFO so that it is as well understood as the stochastic
gradient oracle. Our bounds are based on simple techniques borrowed from the statistical learning
literature that use natural functions and oracles in the same spirit of [11].

3 Main results

The results below are presented with simplifying constants that encompass many factors to aid in
exposition. Explicit constants are given in the proofs in Sections 4 and 5. Throughout  we denote
the minimizer of f as x⇤f . The expectation in the bounds is with respect to the noise in the oracle
queries and (possible) optimization algorithm randomization.

3.1 Query complexity of the function comparison oracle
Theorem 1. For every f 2F ⌧ L B let Cf be a function comparison oracle with parameters
(  µ  0). Then for n  8 and sufﬁciently large T

sup

f2F⌧ L B

inf

bxT

E⇥f (bxT )  f (x⇤f )⇤ 8<:

c1 expc2
c3 n
T

2(1)

1

T

n 

if  = 1

if > 1

where the inﬁmum is over the collection of all possible estimators of x⇤f using at most T queries to
a function comparison oracle and the supremum is taken with respect to all problems in F⌧ L B and
function comparison oracles with parameters (  µ  0). The constants c1  c2  c3 depend the oracle
and function class parameters  as well as the geometry of B  but are independent of T and n.
For upper bounds we propose a speciﬁc algorithm based on coordinate-descent in Section 5 and
prove the following theorem for the case of unconstrained optimization  that is  B = Rn.
Theorem 2. For every f 2F ⌧ L B with B = Rn let Cf be a function comparison oracle with
parameters (  µ  0). Then there exists a coordinate-descent algorithm that is adaptive to unknown
  1 that outputs an estimatebxT after T function comparison queries such that with probability

1  

sup

f2F⌧ L B

E⇥f (bxT )  f (x⇤f )⇤ 8><>:

c1 expnc2q T
c3n n
T

2(1)

1

no if  = 1

if > 1

where c1  c2  c3 depend the oracle and function class parameters as well as T  n  and 1/  but only
poly-logarithmically.

3.2 Query complexity of the function evaluation oracle
Theorem 3. For every f 2F ⌧ L B let Ef be a function evaluation oracle with variance 2. Then
for n  8 and sufﬁciently large T

sup

f2F⌧ L B

inf

bxT

E⇥f (bxT )  f (x⇤f )⇤  c✓ n2
T ◆ 1

2

where the inﬁmum is taken with respect to the collection of all possible estimators of x⇤f using just
T queries to a function evaluation oracle and the supremum is taken with respect to all problems in
F⌧ L B and function evaluation oracles with variance 2. The constant c depends on the oracle and
function class parameters  as well as the geometry of B  but is independent of T and n.

3

Because a function evaluation oracle can always be turned into a function comparison oracle (see
discussion above)  the algorithm and upper bound in Theorem 2 with  = 2 applies to many typical

function evaluation oracles (e.g. additive Gaussian noise)  yielding an upper bound ofn32/T1/2

ignoring constants and log factors. This matches the rate of convergence as a function of T and 2 
but has worse dependence on the dimension n.
Alternatively  under a less restrictive setting  Nemirovski and Yudin proposed two algorithms for
the class of convex  Lipschitz functions that obtain rates of n1/2/T 1/4 and p(n)/T 1/2  respectively 
where p(n) was left as an unspeciﬁed polynomial of n [15]. While focusing on stochastic DFO with
bandit feedback  Agarwal et. al. built on the ideas developed in [15] to obtain a result that they
point out implies a convergence rate of n16/T 1/2 in the optimization setting considered here [16].
Whether or not these rates can be improved to those obtained under the more restrictive function
classes of above is an open question.
A related but fundamentally different problem that is somewhat related with the setting considered
in this paper is described as online (or stochastic) convex optimization with multi-point feedback
[18  5  19]. Essentially  this setting allows the algorithm to probe the value of the function f plus
noise at multiple locations where the noise changes at each time step  but each set of samples at each
time experiences the same noise. Because the noise model of that work is incompatible with the one
considered here  no comparisons should be made between the two.

4 Lower Bounds

The lower bounds in Theorems 1 and 3 are proved using a general minimax bound [20  Thm. 2.5].
Our proofs are most related to the approach developed in [21] for active learning  which like opti-
mization involves a Markovian sampling process. Roughly speaking  the lower bounds are estab-
lished by considering a simple case of the optimization problem in which the global minimum is
known a priori to belong to a ﬁnite set. Since the simple case is “easier” than the original optimiza-
tion  the minimum number of queries required for a desired level of accuracy in this case yields a
lower bound for the original problem.
The following theorem is used to prove the bounds. In the terms of the theorem  f is a function to
be minimized and Pf is the probability model governing the noise associated with queries when f
is the true function.
Theorem 4. [20  Thm. 2.5] Consider a class of functions F and an associated family of probability
measures {Pf}f2F. Let M  2 be an integer and f0  f1  . . .   fM be functions in F. Let d(· ·) :
F⇥F! R be a semi-distance and assume that:

1

1. d(fi  fj)  2s > 0  for all 0  i < j  M 
MPM
2.

j=1 KL(Pi||P0)  a log M 

dP0

pM

max

f2{f0 ... fM}

inf

sup
f2F

dPi is assumed to be well-deﬁned

(i.e.  P0 is a dominating measure) and 0 < a < 1/8 . Then

P(d(bf   f )  s)  inf
bf

1+pM⇣1  2a  2q a

where the Kullback-Leibler divergence KL(Pi||P0) :=R log dPi
log M⌘ > 0  
P(d(bf   f )  s) 
bf
where the inﬁmum is taken over all possible estimators based on a sample from Pf .
We are concerned with the functions in the class F := F⌧ L B. The volume of B will affect only
constant factors in our bounds  so we will simply denote the class of functions by F and refer
explicitly to B only when necessary. Let xf := arg minx f (x)  for all f 2F . The semi-distance we
use is d(f  g) := kxf  xg||  for all f  g 2F . Note that each point in B can be speciﬁed by one of
many f 2F . So the problem of selecting an f is equivalent to selecting a point x 2B . Indeed  the
semi-distance deﬁnes a collection of equivalence classes in F (i.e.  all functions having a minimum
at x 2B are equivalent). For every f 2F we have inf g2F f (xg) = inf x2B f (x)  which is a useful
identity to keep in mind.
We now construct the functions f0  f1  . . .   fM that will be used for our proofs. Let ⌦= {1  1}n so
that each ! 2 ⌦ is a vertex of the d-dimensional hypercube. Let V⇢ ⌦ with cardinality |V|  2n/8

4

such that for all ! 6= !0 2V   we have ⇢(!  !0)  n/8 where ⇢(· ·) is the Hamming distance. It is
known that such a set exists by the Varshamov-Gilbert bound [20  Lemma 2.9]. Denote the elements
of V by !0 ! 1  . . .  ! M. Next we state some elementary bounds on the functions that will be used
in our analysis.
Lemma 1. For ✏> 0 deﬁne the set B⇢ Rn to be the `1 ball of radius ✏ and deﬁne the functions
on B: fi(x) := ⌧
2||x  ✏!i||2  for i = 0  . . .   M  !i 2V   and xi := arg minx fi(x) = ✏!i. Then
for all 0  i < j  M and x 2B the functions fi(x) satisfy

1. fi is strongly convex-⌧ with Lipschitz-⌧ gradients and xi 2B
2. ||xi  xj||  ✏p n
3. |fi(x)  fj(x)| 2⌧n✏ 2 .

2

We are now ready to prove Theorems 1 and 3. Each proof uses the functions f0  . . .   fM a bit
differently  and since the noise model is also different in each case  the KL divergence is bounded
differently in each proof. We use the fact that if X and Y are random variables distributed according
to Bernoulli distributions PX and PY with parameters 1/2 + µ and 1/2  µ  then KL(PX||PY ) 
4µ2/(1/2  µ). Also  if X ⇠N (µX  2) =: PX and Y ⇠N (µY   2) =: Py then KL(PX||PY ) =
22||µX  µY ||2.
4.1 Proof of Theorem 1

1

First we will obtain the bound for the case > 1. Let the comparison oracle satisfy

1
2

with an a small enough so that we can apply the theorem. By setting a = 1/16 and equating the two
4(1) (note that this also implies a
sides of the equation we have ✏ = ✏T := 1

KL(Pi T|Pj T )  16T µ22⌧n✏ 22(1)  a
⌧1/2⇣ n log(2)

2pn 2

2048µ2T⌘ 1

n
8

log(2)  a log M

5

P (Cfi(x  y) = sign{fi(y)  fi(x)}) =

+ minµ|fi(y)  fi(x)|1  0 .
In words  Cfi(x  y) is correct with probability as large as the right-hand-side of above and is
monotonic increasing in fi(y)  fi(x). Let {xk  yk}T
k=1 be a sequence of T pairs in B and let
k=1 be the corresponding sequence of noisy comparisons. We allow the sequence
{Cfi(xk  yk)}T
k=1 to be generated in any way subject to the Markovian assumption that Cfi(xk  yk) given
{xk  yk}T
(xk  yk) is conditionally independent of {xi  yi}i<k. For i = 0  . . .   M  and ` = 1  . . .   T let Pi `
denote the joint probability distribution of {xk  yk  Cfi(xk  yk)}`
k=1  let Qi ` denote the conditional
distribution of Cfi(x`  y`) given (x`  y`)  and let S` denote the conditional distribution of (x`  y`)
given {xk  yk  Cfi(xk  yk)}`1
k=1. Note that S` is only a function of the underlying optimization al-
gorithm and does not depend on i.
KL(Pi T||Pj T ) = EPi Tlog
EPi TEPi Tlog

Pj T = EPi T"logQT
`=1 Qj `S`# = EPi T"logQT
`=1 Qj `#
QT
QT
Qj 1x1  y1
Qj `{xk  yk}T
EPi 1EPi 1log

k=1  T sup

By the second claim of Lemma 1  |fi(x)  fj(x)| 2⌧n✏ 2  and therefore the bound above is
less than or equal to the KL divergence between the Bernoulli distributions with parameters 1
2 ±
µ2⌧n✏ 2(1)  yielding the bound
KL(Pi T|Pj T ) 

4T µ22⌧n✏ 22(1)
1/2  µ (2⌧n✏ 2)(1)  16T µ22⌧n✏ 22(1)

provided ✏ is sufﬁciently small. We also assume ✏ (or  equivalently  B) is sufﬁciently small so that
|fi(x)  fj(x)|1  0. We are now ready to apply Theorem 4. Recalling that M  2n/8  we
want to choose ✏ such that

TX`=1

`=1 Qi `S`

`=1 Qi `

Pi T

Qi `

x1 y12B

Qi 1

=

1

inf

4(1)

sup
f2F

=: 2sT .

Applying Theorem 4 we have

sequence of sets BT by the deﬁnition of the functions in Lemma 1). Thus  the semi-distance satisﬁes

2048µ2T◆ 1

d(fj  fi) = ||xj  xi|| pn/2✏T 
P(d(bf   fi)  sT )
P(kxbf  xfk  sT )  inf
bf
bf
i2{0 ... M}
1+pM⇣1  2a  2q a
pM

where the ﬁnal inequality holds since M  2 and a = 1/16. Strong convexity implies that f (x) 
2||x  xf||2 for all f 2F and x 2B . Therefore
f (xf )  ⌧
max
sup
inf
f2F

2p2✓ 2
⌧◆1/2✓ n log(2)
P(kxbf  xik  sT ) = inf
bf
log M⌘ > 1/7  

P⇣f (xbf )  f (xf ) 

i2{0 ... M}

i2{0 ... M}

max

max

bf

s2

⌧
2

T⌘  inf
bf
 inf
bf
= inf
bf
Ehf (xbf )  f (xf )i 

s2

⌧
2

T⌘
P⇣fi(xbf )  fi(xi) 
T⌘
P⇣ ⌧
2kxbf  xik2 
P⇣kxbf  xik  sT⌘ > 1/7 .

⌧
2

s2

max

i2{0 ... M}

max

i2{0 ... M}

1

7✓ 1
32◆✓ n log(2)

2048µ2T

2(1)

.◆ 1

Finally  applying Markov’s inequality we have

sup
f2F

inf

bf

4.2 Proof of Theorem 1 for  = 1

To handle the case when  = 1 we use functions of the same form  but the construction is slightly
i=1 be a set of uniformly space points
different. Let ` be a positive integer and let M = `n. Let {⇠i}M
in B which we deﬁne to be the unit cube in Rn  so that k⇠i  ⇠jk  `1 for all i 6= j. Deﬁne
fi(x) := ||x  ⇠i||2  i = 1  . . .   M. Let s := 1
2` so that d(fi  fj) := ||x⇤i  x⇤j||  2s. Because
 = 1  we have P (Cfi(x  y) = sign{fi(y)  fi(x)})  µ for some µ > 0  all i 2{ 1  . . .   M}  and
all x  y 2B . We bound KL(Pi T||Pj T ) in exactly the same way as we bounded it in Section 4.1
except that now we have Cfi(xk  yk) ⇠ Bernoulli( 1
2  µ). It
then follows that if we wish to apply the theorem  we want to choose s so that

2 + µ) and Cfj (xk  yk) ⇠ Bernoulli( 1

for some a < 1/8. Using the same sequence of steps as in Section 4.1 we have

KL(Pi T|Pj T )  2T µ2/(1/2  µ)  a log M = an log 1
2s
n(1/2  µ) .

Ehf (xbf )  f (xf )i 

7✓ 1
2◆2

exp⇢

128T µ2

sup
f2F

1

inf

bf

4.3 Proof of Theorem 3

Let fi for all i = 0  . . .   M be the functions considered in Lemma 1. Recall that the evaluation oracle
is deﬁned to be Ef (x) := f (x) + w  where w is a random variable (independent of all other random
variables under consideration) with E[w] = 0 and E[w2] = 2 > 0. Let {xk}n
k=1 be a sequence
of points in B⇢ Rn and let {Ef (xk)}T
k=1 denote the corresponding sequence of noisy evaluations
of f 2F . For ` = 1  . . .   T let Pi ` denote the joint probability distribution of {xk  Efi(xk)}`
k=1 
let Qi ` denote the conditional distribution of Efi(xk) given xk  and let S` denote the conditional
distribution of x` given {xk  Ef (xk)}`1
k=1. S` is a function of the underlying optimization algorithm
and does not depend on i. We can now bound the KL divergence between any two hypotheses as in
Section 4.1:

KL(Pi T||Pj T )  T sup
x12B

EPi 1EPi 1log

Qi 1

Qj 1x1 .

6

To compute a bound  let us assume that w is Gaussian distributed. Then

=

KLN (fi(z)  2)||N (fj(z)  2)
KL(Pi T||Pj T )  T sup
z2B
222⌧n✏ 22
T
z2B |fi(z)  fj(z)|2 
22 sup
◆ 1

7✓ 1
32◆✓ n2 log(2)

Ehf (xbf )  f (xf )i 

sup
f2F

64T

inf

T

1

.

2

by the third claim of Lemma 1. We then repeat the same procedure as in Section 4.1 to attain

bf
5 Upper bounds

The algorithm that achieves the upper bound using a pairwise comparison oracle is a combination
of standard techniques and methods from the convex optimization and statistical learning literature.
The algorithm is explained in full detail in the supplementary materials  and is summarized as fol-
lows. At each iteration the algorithm picks a coordinate uniformly at random from the n possible
dimensions and then performs an approximate line search. By exploiting the fact that the func-
tion is strongly convex with Lipschitz gradients  one guarantees using standard arguments that the
approximate line search makes a sufﬁcient decrease in the objective function value in expectation
[22  Ch.9.3]. If the pairwise comparison oracle made no errors then the approximate line search
is accomplished by a binary-search-like scheme  essentially a golden section line-search algorithm
[23]. However  when responses from the oracle are only probably correct we make the line-search
robust to errors by repeating the same query until we can be conﬁdent about the true  uncorrupted
direction of the pairwise comparison using a standard procedure from the active learning literature
[24] (a similar technique was also implemented for the bandit setting of derivate-free optimization
[8]). Because the analysis of each component is either known or elementary  we only sketch the
proof here and leave the details to the supplementary materials.

5.1 Coordinate descent
Given a candidate solution xk after k  0 iterations  the algorithm deﬁnes a search direction dk = ei
where i is chosen uniformly at random from the possible n dimensions and ei is a vector of all zeros
except for a one in the ith coordinate. We note that while we only analyze the case where the search
direction dk is a coordinate direction  an analysis with the same result can be obtained with dk
chosen uniformly from the unit sphere. Given dk  a line search is then performed to ﬁnd an ↵k 2 R
such that f (xk+1)  f (xk) is sufﬁciently small where xk+1 = xk + ↵kdk. In fact  as we will see in
the next section  for some input parameter ⌘> 0  the line search is guaranteed to return an ↵k such
that |↵k  ↵⇤| ⌘ where ↵⇤ = min↵2R f (xk + dk↵⇤). Using the fact that the gradients of f are
Lipschitz (L) we have

f (xk + ↵kdk)  f (xk + ↵⇤dk) 
then we have

If we deﬁne ˆ↵k = hrf (xk) dki

L

L
2 ||(↵k  ↵⇤)dk||2 =

L
2 |↵k  ↵⇤|2 

L
2

⌘2.

f (xk + ↵kdk)  f (xk)  f (xk + ↵⇤dk)  f (xk) +
 f (xk + ˆ↵kdk)  f (xk) +

⌘2

L
2
L
2

⌘2  hrf (xk)  dki2

2L

+

L
2

⌘2

where the last line follows from applying the fact that the gradients are Lipschitz (L). Arranging the
bound and taking the expectation with respect to dk we get
E [f (xk+1)  f (x⇤)]  L
where the second inequality follows from the fact that f is strongly convex (⌧ ). If we deﬁne ⇢k :=
E [f (xk)  f (x⇤)] then we equivalently have

2 ⌘2  E [f (xk)  f (x⇤)]  E[||rf (xk)||2]
◆ ⇣1 
⇣1 

4nL⌘✓⇢k 

⇢k+1 

 E [f (xk)  f (x⇤)]1  ⌧
4nL
◆
4nL⌘k✓⇢0 

2nL2⌘2

2nL2⌘2

2nL2⌘2

2nL

⌧

⌧

⌧

⌧

⌧

which leads to the following result.

7

sup
f

E[f (xK)  f (x⇤)]  4nL2⌘2

Theorem 5. Let f 2F ⌧ L B with B = Rn. For any ⌘> 0 assume the line search returns an ↵k that
is within ⌘ of the optimal after at most T`(⌘) queries from the pairwise comparison oracle. If xK is
an estimate of x⇤ = arg minx f (x) after requesting no more than K pairwise comparisons  then
⌘22nL2/⌧ ⌘ T`(⌘)

log⇣ f (x0)f (x⇤)
This implies that if we wish supf E[f (xK)  f (x⇤)]  ✏ it sufﬁces to take ⌘ =p ✏⌧

where the expectation is with respect to the random choice of dk at each iteration.

4nL2 so that at

K  4nL

most 4nL
⌧

whenever

⌧

⌧

log⇣ f (x0)f (x⇤)

✏/2

⌘ T`p ✏⌧

4nL2 pairwise comparisons are requested.

5.2 Line search
This section is concerned with minimizing a function f (xk+↵kdk) over some ↵k 2 R. In particular 
we wish to ﬁnd an ↵k 2 R such that |↵k↵⇤| ⌘ where ↵⇤ = min↵2R f (xk +dk↵⇤). First assume
that the function comparison oracle makes no errors. The line search operates by maintaining a pair
of boundary points ↵+  ↵ such that if at some iterate we have ↵⇤ 2 [↵ ↵ +] then at the next iterate 
we are guaranteed that ↵⇤ is still contained inside the boundary points but |↵+↵| 1
2|↵+↵|.
An initial set of boundary points ↵+ > 0 and ↵ < 0 are found using simple binary search. Thus 
regardless of how far away or close ↵⇤ is  we converge to it exponentially fast. Exploiting the fact
that f is strongly convex (⌧ ) with Lipschitz (L) gradients we can bound how far away or close ↵⇤
is from our initial iterate.
Theorem 6. Let f 2F ⌧ L B with B = Rn and let Cf be a function comparison oracle that makes
no errors. Let x 2 Rn be an initial position and let d 2 Rn be a search direction with ||d|| = 1. If
↵K is an estimate of ↵⇤ = arg min↵ f (x + d↵) that is output from the line search after requesting
no more than K pairwise comparisons  then for any ⌘> 0

|↵K  ↵⇤| ⌘

whenever

5.3 Making the line search robust to errors

K  2 log2⇣ 256L(f (x)f (x+d↵ ⇤))

⌧ 2⌘2

⌘ .

Now assume that the responses from the pairwise comparison oracle are only probably correct in
accordance with the model introduced above. Essentially  the robust procedure runs the line search
as if the oracle made no errors except that each time a comparison is needed  the oracle is repeatedly
queried until we can be conﬁdent about the true direction of the comparison. This strategy applied
to active learning is well known because of its simplicity and its ability to adapt to unknown noise
conditions [24]. However  we mention that when used in this way  this sampling procedure is known
to be sub-optimal so in practice  one may want to implement a more efﬁcient approach like that of
[21]. Nevertheless  we have the following lemma.
Lemma 2. [24] For any x  y 2B with P (Cf (x  y) = sign{f (y)  f (x)}) = p  with probability
at least 1   the coin-tossing algorithm of [24] correctly identiﬁes the sign of E [Cf (x  y)] and
requests no more than log(2/)

4|1/2p|2 log2⇣ log(2/)

4|1/2p|2⌘ pairwise comparisons.

It would be convenient if we could simply apply the result of Lemma 2 to our line search procedure.
Unfortunately  if we do this there is no guarantee that |f (y)  f (x)| is bounded below so for the
case when > 1  it would be impossible to lower bound |1/2  p| in the lemma. To account
for this  we will sample at multiple locations per iteration as opposed to just two in the noiseless
algorithm to ensure that we can always lower bound |1/2  p|. Intuitively  strong convexity ensures
that f cannot be arbitrarily ﬂat so for any three equally spaced points x  y  z on the line dk  if
f (x) is equal to f (y)  then it follows that the absolute difference between f (x) and f (z) must be
bounded away from zero. Applying this idea and union bounding over the total number of times
one must call the coin-tossing algorithm  one ﬁnds that with probability at least 1    the total
number of calls to the pairwise comparison oracle over the course of the whole algorithm does
⌘ log(n/)⌘ . By ﬁnding a T > 0 that satisﬁes this
2(1)⌘ for > 1 and

not exceed eO⇣ nL
✏2(1) log2⇣ f (x0)f (x⇤)
⌧  n
bound for any ✏ we see that this is equivalent to a rate of O⇣n log(n/) n
T
n log(n/)o⌘ for  = 1  ignoring polylog factors.
O⇣expncq T

✏

1

8

References
[1] T. Eitrich and B. Lang. Efﬁcient optimization of support vector machine learning parameters
for unbalanced datasets. Journal of computational and applied mathematics  196(2):425–436 
2006.

[2] R. Oeuvray and M. Bierlaire. A new derivative-free algorithm for the medical image registra-

tion problem. International Journal of Modelling and Simulation  27(2):115–124  2007.

[3] A.R. Conn  K. Scheinberg  and L.N. Vicente.

Introduction to derivative-free optimization 

volume 8. Society for Industrial Mathematics  2009.

[4] Warren B. Powell and Ilya O. Ryzhov. Optimal Learning. John Wiley and Sons  2012.
[5] Y. Nesterov. Random gradient-free minimization of convex functions. CORE Discussion

Papers  2011.

[6] N. Srinivas  A. Krause  S.M. Kakade  and M. Seeger. Gaussian process optimization in the

bandit setting: No regret and experimental design. Arxiv preprint arXiv:0912.3995  2009.

[7] R. Storn and K. Price. Differential evolution–a simple and efﬁcient heuristic for global opti-

mization over continuous spaces. Journal of global optimization  11(4):341–359  1997.

[8] A. Agarwal  D.P. Foster  D. Hsu  S.M. Kakade  and A. Rakhlin. Stochastic convex optimization

with bandit feedback. Arxiv preprint arXiv:1107.1744  2011.

[9] A. Nemirovski  A. Juditsky  G. Lan  and A. Shapiro. Robust stochastic approximation approach

to stochastic programming. SIAM Journal on Optimization  19(4):1574  2009.

[10] V. Protasov. Algorithms for approximate calculation of the minimum of a convex function

from its values. Mathematical Notes  59:69–74  1996. 10.1007/BF02312467.

[11] M. Raginsky and A. Rakhlin. Information-based complexity  feedback  and dynamics in con-

vex programming. Information Theory  IEEE Transactions on  (99):1–1  2011.

[12] L.L. Thurstone. A law of comparative judgment. Psychological Review; Psychological Review 

34(4):273  1927.

[13] Y. Yue  J. Broder  R. Kleinberg  and T. Joachims. The k-armed dueling bandits problem.

Journal of Computer and System Sciences  2012.

[14] K.G. Jamieson and R.D. Nowak. Active ranking using pairwise comparisons. Neural Infor-

mation Processing Systems (NIPS)  2011.

[15] A.S. Nemirovsky and D.B. Yudin. Problem complexity and method efﬁciency in optimization.

1983.

[16] A. Agarwal  D.P. Foster  D. Hsu  S.M. Kakade  and A. Rakhlin. Stochastic convex optimization

with bandit feedback. Arxiv preprint arXiv:1107.1744  2011.

[17] A. Agarwal  P.L. Bartlett  P. Ravikumar  and M.J. Wainwright. Information-theoretic lower
bounds on the oracle complexity of stochastic convex optimization. Information Theory  IEEE
Transactions on  (99):1–1  2010.

[18] A. Agarwal  O. Dekel  and L. Xiao. Optimal algorithms for online convex optimization with

multi-point bandit feedback. In Conference on Learning Theory (COLT)  2010.

[19] S. Ghadimi and G. Lan. Stochastic ﬁrst-and zeroth-order methods for nonconvex stochastic

programming. 2012.

[20] A.B. Tsybakov. Introduction to nonparametric estimation. Springer Verlag  2009.
[21] R.M. Castro and R.D. Nowak. Minimax bounds for active learning. Information Theory  IEEE

Transactions on  54(5):2339–2353  2008.

[22] S.P. Boyd and L. Vandenberghe. Convex optimization. Cambridge Univ Pr  2004.
[23] R.P. Brent. Algorithms for minimization without derivatives. Dover Pubns  2002.
[24] M. K¨a¨ari¨ainen. Active learning in the non-realizable case. In Algorithmic Learning Theory 

pages 63–77. Springer  2006.

9

,Kamalika Chaudhuri
Staal Vinterbo
Alberto Maria Metelli
Matteo Pirotta
Marcello Restelli
Osbert Bastani
Yewen Pu
Armando Solar-Lezama
Su Young Lee
Choi Sungik
Sae-Young Chung