2019,Using Embeddings to Correct for Unobserved Confounding in Networks,We consider causal inference in the presence of unobserved confounding. We study the case where a proxy is available for the unobserved confounding in the form of a network connecting the units. For example  the link structure of a social network carries information about its members. We show how to effectively use the proxy to do causal inference. The main idea is to reduce the causal estimation problem to a semi-supervised prediction of both the treatments and outcomes. Networks admit high-quality embedding models that can be used for this semi-supervised prediction. We show that the method yields valid inferences under suitable (weak) conditions on the quality of the predictive model. We validate the method with experiments on a semi-synthetic social network dataset.,Using Embeddings to Correct for Unobserved

Confounding in Networks

Victor Veitch1  Yixin Wang1  and David M. Blei1 2

1Department of Statistics  Columbia University

2Department of Computer Science  Columbia University

Abstract

We consider causal inference in the presence of unobserved confounding. We
study the case where a proxy is available for the unobserved confounding in the
form of a network connecting the units. For example  the link structure of a social
network carries information about its members. We show how to effectively use
the proxy to do causal inference. The main idea is to reduce the causal estimation
problem to a semi-supervised prediction of both the treatments and outcomes.
Networks admit high-quality embedding models that can be used for this semi-
supervised prediction. We show that the method yields valid inferences under
suitable (weak) conditions on the quality of the predictive model. We validate
the method with experiments on a semi-synthetic social network dataset. Code at
github.com/vveitch/causal-network-embeddings.

1

Introduction

We consider causal inference in the presence of unobserved confounding  i.e.  where unobserved
variables may affect both the treatment and the outcome. We study the case where there is an observed
proxy for the unobserved confounders  but (i) the proxy has non-iid structure  and (ii) a well-speciﬁed
generative model for the data is not available.

Example 1.1. We want to infer the efﬁcacy of a drug based on observed outcomes of people who are
connected in a social network. Each unit i is a person. The treatment variable ti indicates whether
they took the drug  a response variable yi indicates their health outcome  and latent confounders zi
might affect the treatment or response. For example  zi might be unobserved age or sex. We would
like to compute the average treatment effect  controlling for these confounds. We assume the social
network itself is associated with z  e.g.  similar people are more likely to be friends. This means that
the network itself may implicitly contain confounding information that is not explicitly collected.

In this example  inference of the causal effect would be straightforward if the confounder z were
available. So  intuitively  we would like to infer substitutes for the latent zi from the underlying social
network structure. Once inferred  these estimates ˆzi could be used as a substitute for zi and we could
estimate the causal effect [SM16].

For this strategy to work  however  we need a well-speciﬁed generative model (i.e.  joint probability
distribution) for z and the full network structure. But typically no such model is available. For
example  generative models of networks with latent unit structure—such as stochastic block models
[WW87; Air+08] or latent space models [Hof+02]—miss properties of real-world networks [Dur06;
New09; OR15]. Causal estimates based on substitutes inferred from misspeciﬁed models are
inherently suspect.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Embedding methods offer an alternative to fully speciﬁed generative models. Informally  an embed-
ding method assigns a real-valued embedding vector ˆλi to each unit  with the aim that conditioning
on the embedding should decouple the properties of the unit and the network structure. For example 
ˆλi might be chosen to explain the local network structure of user i.
The embeddings are learned by minimizing an objective function over the network  with no re-
quirement that this objective correspond to any generative model. For pure predictive tasks  e.g. 
classiﬁcation of vertices in a graph  embedding-based approaches are state of the art for many real-
world datasets [e.g.  Per+14; Cha+17; Ham+17; Ham+17; Vei+19a]. This suggests that network
embeddings might be usefully adapted to the inference of causal effects.

The method we develop here stems from the following insight. Even if we knew the confounders
{zi} we would not actually use all the information they contain to infer the causal effect. Instead  if
we use estimator ˆψn to estimate the effect ψ  then we only require the part of zi that is actually used
by the estimator ˆψn. For example  if ˆψn is an inverse probability weighted estimator [CH08] then we
require only estimates for the propensity scores P(Ti = 1 | zi) for each unit.
What this means is that if we can build a good predictive model for the treatment then we can plug
the outputs into a causal effect estimate directly  without any need to learn the true zi. The same
idea applies generally by using a predictive model for both the treatment and outcome. Reducing
the causal inference problem to a predictive problem is the crux of this paper. It allows us to replace
the assumption of a well-speciﬁed model with the more palatable assumption that the black-box
embedding method produces a strong predictor.

The contributions of this paper are:

• a procedure for estimating treatment effects using network embeddings;
• an extension of robust estimation results to (non-iid) network data  showing the method
• and  an empirical study of the method on social network data.

yields valid estimates under weak conditions;

2 Related Work

Our results connect to a number of different areas.

Causal Inference in Networks. Causal inference in networks has attracted signiﬁcant attention
[e.g.  SM16; Tch+17; Ogb+17; OV17; Ogb18]. Much of this work is aimed at inferring the causal
effects of treatments applied using the network; e.g.  social inﬂuence or contagion. A major challenge
in this area is that homophily—the tendency of similar people to cluster in a network—is generally
confounded with contagion—the inﬂuence people have on their neighbors [ST11]. In this paper  we
assume that each person’s treatment and outcome are independent of the network once we know that
person’s latent attributes; i.e.  we assume pure homophily. This is a reasonable assumption in some
situations  but certainly not all. Our major motivation is simply that pure homophily is the simplest
case  and is thus the natural proving ground for the use of black-box methods in causal network
problems. It is an import future direction to extend the results developed here to the contagion case.

Shalizi and McFowland III [SM16] address the homophily/contagion issue with a two-stage estimation
procedure. They ﬁrst estimate latent confounders (node properties)  then use these in a regression
based estimator in the second stage. Their main result is a proof that if the network was actually
generated by either a stochastic block model or a latent space model then the estimation procedure is
valid. Our main motivation here is to avoid such well-speciﬁed model assumptions. Their work is
complementary to our approach: we impose a weaker assumption  but we only address homophily.

Causal Inference Using Proxy Confounders. Another line of connected research deals with causal
inference with hidden confounding when there is an observed proxy for the confounder [KM99;
Pea12; KP14; Mia+18; Lou+17]. This work assumes the data is generated independently and

identically as (Xi  Zi  Ti  Yi) iid∼ P for some data generating distribution P . The variable Zi causally
affects Ti  Yi  and Xi. The variable(s) Xi are interpreted as noisy versions of Zi. The main question
here is when the causal effect is (non-parametrically) identiﬁable. The typical ﬂavor of the results is:
if the proxy distribution satisﬁes certain conditions then the marginal distribution P (Zi  Ti  Yi) is
identiﬁable  and thus so too is the causal effect (though weaker identiﬁcation conditions are possible

2

[Mia+18]). The main differences with the problem we address here are that the network surrogate has
non-iid structure  we expect that the information content of the exact confounder can be recovered in
the inﬁnite-sample limit  and we do not demand recovery the true data generating distribution.

Double machine learning. Chernozhukov et al. [Che+17a] addresses robust estimation of causal
effects in the i.i.d. setting. Mathematically  our main estimation result  theorem 5.1  is a fairly
straightforward adaptation of their result. The important distinction is conceptual: we treat a different
data generating scenario.

Embedding methods. Veitch et al. [Vei+19b] use the strategy of reducing causal estimation to
prediction to harness text embedding methods for causal inference with text data. In particular  that
paper views the embeddings as a dimension reduction strategy and asks how the dimension reduction
can be achieved in a manner that preserves causal identiﬁcation.

3 Setup

We ﬁrst ﬁx some notation and recall some necessary ideas about the statistical estimation of causal
effects. We take each statistical unit to be a tuple Oi = (Yi  Ti  Zi)  where Yi is the response  Ti is
the treatment  and Zi are (possibly confounding) unobserved attributes of the units. We assume that
iid∼ P .
the units are drawn independently and identically at random from some distribution P   i.e.  Oi
We study the case where there is a network connecting the units. We assume that the treatments and
outcomes are independent of the network given the latent attributes {Zi}. This condition is implied
by the (ubiquitous) exchangeable network assumption [OR15; VR15; CD15]  though our requirement
is weaker than exchangeability.

The average treatment effect of a binary outcome is deﬁned as

ψ = E[Y | do(T = 1)] − E[Y | do(T = 0)].

The use of Pearl’s do notation indicates that the effect of interest is causal: what is the expected
outcome if we intervene by assigning the treatment to a given unit? If Zi contains all common
inﬂuencers (a.k.a. confounders) of Yi and Ti then the causal effect is identﬁable as a parameter of the
observational distribution:

ψ = E[E[Y | Z  T = 1] − E[Y | Z  T = 0]].

(3.1)

Before turning to the unobserved Z case  we recall some ideas from the case where Z is observed.
Let Q(t  z) = E[Y | t  z] be the conditional expected outcome  and ˆQn be an estimator for this
function. Following 3.1  a natural choice of estimator ˆψn is:

1

ˆψQ

n =

nXi h ˆQn(1  zi) − ˆQn(0  zi)i .

That is  ψ is estimated by a two-stage procedure: First  produce an estimate for ˆQn. Second  plug ˆQn
into a pre-determined statistic to compute the estimate.
Of course  ˆψQ
n is not the only possible choice of estimator. In principle  it is possible to do better by
incorporating estimates ˆgn of the propensity scores g(z) = P(T = 1 | z). The augmented inverse
probability of treatment weighted (A-IPTW) estimator ˆψA
n is an important example [Rob+00; Rob00]:

ˆψA

n =

1

nXi

ˆQn(1  zi) − ˆQn(0  zi) +

1

nXi (cid:18) I[ti = 1]
ˆgn(zi) −

I[ti = 0]

1 − ˆgn(zi)(cid:19) (yi − ˆQn(ti  zi)).

(3.2)

We call η(z) = (Q(0  z)  Q(1  z)  g(z)) the nuisance parameters. The main advantage of ˆψA
n is that
it is robust to misestimation of the nuisance parameters [Rob+94; vR11; Che+17a]. For example 
it has the double robustness property: ˆψn is consistent if either ˆgn or ˆQn is consistent. If both are
consistent  then ˆψA
n is the asymptotically most efﬁcient possible estimator [Bic+00]. We will show
below that the good theoretical properties of the suitably modiﬁed A-IPTW estimator persist for the
embedding method even in the non-iid setting of this paper.

There is a remaining complication. In the general case  if the same data On is used to estimate the
nuisance parameters ˆηn and to compute ˆψn(On; ˆηn) then the estimator is not guaranteed to maintain
good asymptotic properties. This problem can be solved by splitting the data  using one part to
estimate ˆηn and the other to compute the estimate [Che+17a]. We rely on this data splitting approach.

3

4 Estimation

We now return to the setting where the {zi} are unobserved  but a network proxy is available.
Following the previous section  we want to hold out a subset of the units i ∈ I0 and  for each of these
units  produce estimates of the propensity score g(zi) and the conditional expected outcome Q(ti  zi).
Our starting point is (an immediate corollary of) [RR83  Thm. 3]:

Theorem 4.1. Suppose λ(z) is some function of the latent attributes such that at least one of the
following is λ(Z)-measurable: (i) (Q(0  Z)  Q(1  Z))  or (ii) g(Z). If adjusting for Z sufﬁces to
render the average treatment effect identiﬁable then adjusting for only λ(Z) also sufﬁces. That is 
ψ = E[E[Y | λ(Z)  T = 1] − E[Y | λ(Z)  T = 0]]
The signiﬁcance of this result is that adjusting for the confounding effect of the latent attributes does
not actually require us to recover the latent attributes. Instead  it sufﬁces to recover only the aspects
λ(zi) that are relevant for the prediction of the propensity score or conditional expected outcome.

The idea is that we may view network embedding methods as black-box tools for extracting informa-
tion from the network that is relevant to solving prediction problems. We make use of embedding

based semi-supervised prediction models. What this means is that we assign an embedding λi ∈ Rp
to each unit  and deﬁne predictors ˜Q(ti  λi; γQ) mapping the embedding and treatment to a predic-
tion for yi  and predictor ˜g(λi; γg) mapping the embeddings to predictions for ti. In this context 
‘semi-supervised’ means that when training the model we do not use the labels of units in I0  but we
do use all other data—including the proxy structure on units in I0.

An example clariﬁes the general approach.

Example 4.2. We denote the network Gn. We assume a continuous valued outcome. Consider the
case where ˜Q(0 ·; γQ)  ˜Q(1 ·; γQ) and logit ˜g(·; γg) are all linear predictors. We train a model with

a relational empirical risk minimization procedure [Vei+19a]. We set:

ˆλn  ˆγQ

n   ˆγg

n = argmin
λ γQ γg

EGk=Sample(Gn k)[L(Gk; λ  γQ  γg)]

where Sample(Gn  k) is a randomized sampling algorithm that returns a random subgraph of size k
from Gn (e.g.  a random walk with k edges)  and

L(Gk; λ  γQ  γg) = Xi∈I\I0

(yi − ˜Q(ti  λi; γQ))2 + Xi∈I\I0
+ Xi j∈I×I

CrossEntropy(1[(i  j) ∈ Gk]  sigmoid(λT

i λj)).

CrossEntropy(ti  ˜g(λi; γg))

Here  I is the full set of units  and 1[(i  j) ∈ Gk] indicates whether units i and j are linked. Note that
the ﬁnal term of the model is the one that explains the relational structure. Intuitively  it says that
the logit probability of an edge is the inner product of the embeddings of the end points of the edge.
This loss term makes use of the entire dataset  including links that involve the heldout units. This is
important to ensure that the embeddings for the heldout data ‘match’ the rest of the embeddings.

Estimation. With a trained model in hand  computing the estimate of the treatment effect is
straightforward. Simply plug-in the estimated values of the nuisance parameters to a standard
estimator. For example  using the A-IPTW estimator eq. (3.2) 

ˆψA

n (I0) :=

1

˜Q(1  ˆλn i; ˆγQ

|I0| Xi∈I0
|I0| Xi∈I0(cid:18) I[ti = 1]
n) −

n ) − ˜Q(0  ˆλn i; ˆγQ
n )
I[ti = 0]
1 − ˜g(ˆλn i; ˆγg

˜g(ˆλn i; ˆγg

+

1

n)(cid:19)(yi − ˜Q(ti  ˆλn i; ˆγQ

n )).

(4.1)

We also allow for a more sophisticated variant. We split the data into K folds I0  . . .   IK−1 and
deﬁne our estimator as:

ˆψA

n =

ˆψA

n (Ij).

(4.2)

This variant is more data efﬁcient than just using a single fold. Finally  the same procedure applies to
estimators other than the A-IPTW. We consider the effect of the choice of estimator in section 6.

1

K Xj

4

5 Validity

When does the procedure outlined in the previous section yield valid inferences? We now present a
theorem establishing sufﬁcient conditions. The result is an adaption of the “double machine learning”
of Chernozhukov et al. [Che+17a; Che+17b] to the network setting. We ﬁrst give the technical
statement  and then discuss its signiﬁcance and interpretation.
Fix notation as in the previous section. We also deﬁne ˆγQ I c
calculated using all but the kth data fold.

to be the estimates for γQ  γg

and ˆγg I c

n

n

k

k

Assumption 1. The probability distributions P satisﬁes

Further  we requrie that T does not causally affect either Z or the network.

Y = Q(T  Z) + ζ 
T = g(Z) + ν 

E[ζ | Z  T ] = 0 
E[ν | Z] = 0.

The second part of the statement is necessary to rule out a linear-gaussian edge case.

Assumption 2. There is some function λ mapping features Z into Rp such that λ satisﬁes the
condition of theorem 4.1  and each of || ˜Qn(0  ˆλn i; ˆγQ I c
)−
Q(1  λ(Zi))||P 2  and ||˜gn(ˆλn i; ˆγg I c
) − g(λ(Zi))||P 2 goes to 0 as n → ∞. Additionally  λ must

)− Q(0  λ(Zi))||P 2  || ˜Qn(1  ˆλn i; ˆγQ I c

satisfy all of the following assumptions.

k

k

k

Assumption 3. The following moment conditions hold for some ﬁxed ε  C  c  some q > 4  and all
t ∈ {0  1}

||Q(t  λ(Z))||P q ≤ C 
||Y ||P q ≤ C 
P (ε ≤ g(λ(Z)) ≤ 1 − ε) = 1 
P (EP (cid:2)ζ 2 | λ(Z)(cid:3) ≤ C) = 1 
||ζ||P 2 ≥ c 
||ν||P 2 ≥ c.

Assumption 4. The estimators of nuisance parameters satisfy the following accuracy requirements.
There is some δn  ∆nK → 0 such that for all n ≥ 2K and d ∈ {0  1} it holds with probability no
less than 1 − ∆nK :
|| ˜Qn(d  ˆλn i; ˆγQ I c

) − Q(d  λ(Zi))||P 2 · ||˜gn(ˆλn i; ˆγg I c

) − g(λ(Zi))||P 2 ≤ δnK · n−1/2

(5.1)

K

k

k

And 

P (ε ≤ ˜gn(ˆλn i; ˆγg I c

k

) ≤ 1 − ε) = 1 

(5.2)

Assumption 5. We assume the dependence between the trained embeddings is not too strong: For
any i  j and all bounded continuous functions f with mean 0 

Ehf (ˆλn i) · f (ˆλn j)i = o(

1
n

).

(5.3)

Theorem 5.1. Denote the true ATE as ψ. Let ˆψn be the K-fold A-IPTW variant deﬁned in eq. (4.2).
Under Assumptions 1 to 5  ˆψn concentrates around ψ with the rate 1/√n and is approximately

unbiased and normally distributed:

σ−1√n( ˆψn − ψ) d→ N (0  1)
σ2 = EP (cid:2)ϕ2

0(Y  T  λ(Z); θ0  η(λ(Z)))(cid:3)  

where

ϕ0(Y  T  λ(Z); θ0  η(λ(Z))) =

T

g(λ(Z)){Y − Q(1  λ(Z))} −
+ {Q(1  λ(Z)) − Q(0  λ(Z))} − ψ.

1 − T

1 − g(λ(Z)){Y − Q(0  λ(Z))}

5

Proof. The proof follows Chernozhukov et al. [Che+17b]. The main changes are technical modiﬁ-
cations exploiting Assumption 5 to allow for the use of the full data in the embedding training. We
defer the proof to the appendix.

Interpretation and Signiﬁcance. Under suitable conditions  theorem 5.1 promises us that the
treatment effect is identiﬁable and can be estimated at a fast rate. It is not surprising that there
are some conditions under which this holds. The insight from theorem 5.1 lies with the particular
assumptions that are required.

Assumptions 1 and 3 are standard conditions. Assumption 1 posits a causal model that (i) restricts
the treatments and outcomes to a pure unit effect (i.e.  it forbids contagion effects)  and that (ii)
renders the causal effects identiﬁable when Z observed. Assumption 3 is technical conditions on the
data generating distribution. This assumption includes the standard positivity condition. Possible
violations of these conditions are important and must be considered carefully in practice. However 
such considerations are standard  independent of the non-iid  no-generative-model setting that is our
focus  so we do not comment further.

Our ﬁrst deviation from the standard causal inference setup is Assumption 2. This is the identiﬁcation
condition when Z is not observed. It requires that the learned embeddings are able to extract whatever
information is relevant to the prediction of the treatment and outcome. This assumption is the crux of
the method.

A more standard assumption would directly posit the relationship between Z and the proxy network;
e.g.  by assuming a stochastic block model or latent space model. The practitioner is then required
to assess whether the posited model is realistic. In practice  all generative models of networks
fail to capture the structure of real-world networks. Instead  we ask the practitioner to judge the
plausibility of the predictive embedding model. Such judgments are non-falsiﬁable  and must be
based on experience with the methods and trials on semi-synthetic data. This is a difﬁcult task  but
the assumption is at least not violated a priori.

In practice  we do not expect the identiﬁcation assumption to hold exactly. Instead  the hope is that
applying the method will adjust for whatever confounding information is present in the network. This
is useful even if there is confounding exogenous to the network. We study the behavior of the method
in the presence of exogenous confounding in section 6.

The condition in Assumption 4 addresses the statistical quality of the nuisance parameter estimation
procedure. For an estimator to be useful  it must produce accurate estimates with a reasonable
amount of data. It is intuitive that if accurately estimating the nuisance parameters requires an
enormous amount of data  then so too will estimation of ψ. eq. (5.1) shows that this is not so. It
sufﬁces  in principle  to estimate the nuisance parameters crudely  e.g.  a rate of o(n1/4) each. This is
important because the need to estimate the embeddings may rule out parametric-rate convergence of
the nuisance parameters; theorem 5.1 shows this is not damning.

Assumption 5 is the price we pay for training the embeddings with the full data. If the pairwise
dependence between the learned embeddings is very strong then the data splitting procedure does
not guarantee that the estimate is valid. However  the condition is weak and holds empirically.
The condition can also be removed by a two-stage procedure where the embeddings are trained in
an unsupervised manner and then used as a direct surrogate for the confounders. However  such
approaches have relatively poor predictive performance [Yan+16; Vei+19a]. We compare to the
two-stage approach in section 6.

6 Experiments

The main remaining questions are: Is the method able to adjust for confounding in practice? If so  is
the joint training of embeddings and classiﬁer important? And  what is the best choice of plug-in
estimator for the second stage of the procedure? Additionally  what happens in the (realistic) case
that the network does not carry all confounding information?

We investigate these questions with experiments on a semi-synthetic network dataset.1 We ﬁnd
that in realistic situations  the network adjustment improves the estimation of the average treatment

1Code and pre-processed data at github.com/vveitch/causal-network-embeddings

6

effect. The estimate is closer to the truth than estimates from either a parametric baseline  or a
two-stage embedding procedure. Further  we ﬁnd that network adjustment improves estimation
quality even in the presence of confounding that is exogenous to the network. That is  the method
still helps even when full identiﬁcation is not possible. Finally  as predicted by theory  we ﬁnd
that the robust estimators are best when the theoretical assumptions hold. However  the simple
conditional-outcome-only estimator has better performance in the presence of signiﬁcant exogenous
confounding.

Choice of estimator. We consider 4 options for the plug-in treatment effect estimator.

1. The conditional expected outcome based estimator 

ˆψQ

n =

1

nXi h ˜Qn(1  ˆλn i; ˆγn) − ˜Qn(0  ˆλn i; ˆγn)i  

which only makes use of the outcome model.

2. The inverse probability of treatment weighted estimator 

ˆψg

n =

1

nXi " 1[ti = 1]
˜g(ˆλn i; ˆγn) −

1[ti = 0]

1 − ˜g(ˆλn i; ˆγn)# Yi 

which only makes use of the treatment model.

3. The augmented inverse probability treatment estimator ˆψA
4. A targeted minimum loss based estimator (TMLE) [vR11].

n   deﬁned in eq. (4.1).

The later two estimators both make full use of the nuisance parameter estimates. The TMLE also
admits the asymptotic guarantees of theorem 5.1 (though we only state the theorem for the simpler
A-IPTW estimator). The TMLE is a variant designed for better ﬁnite sample performance.

Pokec. To study the properties of the procedure  we generate semi-synthetic data using a real-world
social network. We use a subset of the Pokec social network. Pokec is the most popular online social
network in Slovakia. For our purposes  the main advantages of Pokec are: the anonymized data are
freely and openly available [TZ12; LK14] 2  and the data includes signiﬁcant attribute information for
the users  which is necessary for our simulations. We pre-process the data to restrict to three districts
( ˇZilina  Cadca  Namestovo)  all within the same region ( ˇZilinsk´y). The pre-processed network has 79
thousand users connected by 1.3 million links.

Simulation. We make use of three user level attributes in our simulations: the district they live
in  the user’s age  and their Pokec join date. These attributes were selected because they have low
missingness and have some dependency with the the network structure. We discretize age and join
date to a 3-level categorical variable (to match district).

For the simulation  we take each of these attributes to be the hidden confounder. We will attempt to
adjust for the confounding using the Pokec network. We take the probability of treatment to be wholly
determined by the confounder z  with the three levels corresponding to g(z) ∈ {0.15  0.5  0.85}. The
treatment and outcome for user i is simulated from their confounding attribute zi as:

ti = Bern(g(zi)) 
yi = ti + β(g(zi) − 0.5) + εi

εi ∼ N (0  1).

(6.1)

(6.2)

In each case  the true treatment effect is 1.0. The parameter β controls the amount of confounding.

Estimation. For each simulated dataset  we estimate the nuisance parameters using the procedure
described in section 4 with K = 10 folds. We use a random-walk sampler with negative sampling with
the default relational ERM settings [Vei+19a]. We pre-train the embeddings using the unsupervised
objective only  run until convergence.

Baselines. We consider three baselines. The ﬁrst is the naive estimate that does not attempt to
control for confounding; i.e.  1
individuals. The second baseline is the two-stage procedure  where we ﬁrst train the embeddings
on the unsupervised objective  freeze them  and then use them as features for the same predictor
maps. The ﬁnal baseline is a parametric approach to controlling for the confounding. We ﬁt a

n−mPi:ti=0 yi  where m is the number of treated

mPi:ti=1 yi − 1

2snap.stanford.edu/data/soc-Pokec.html

7

Table 1: Adjusting using the network improves ATE estimate in all cases. Further  the single-stage method is
more accurate than baselines. Table entries are estimated ATE with 10-fold std. Ground truth is 1.0. Low and
high confounding correspond to β = 1.0 and 10.0.

Conf.

Low

High

Low

High

Low

High

age

district

join date

Unadjusted
Parametric
Two-stage
ˆψA
n

1.32 ± 0.02
1.30 ± 0.00
1.33 ± 0.02
1.24 ± 0.04

4.34 ± 0.05
4.06 ± 0.01
4.55 ± 0.05
3.40 ± 0.04

1.34 ± 0.03
1.21 ± 0.00
1.34 ± 0.02
1.09 ± 0.02

4.51 ± 0.05
3.22 ± 0.01
4.55 ± 0.05
2.03 ± 0.07

1.29 ± 0.03
1.26 ± 0.00
1.30 ± 0.03
1.21 ± 0.05

4.03 ± 0.06
3.73 ± 0.01
4.16 ± 0.06
3.26 ± 0.09

Table 2: The conditional-outcome-only estimator is usually most accurate. Table entries are estimated ATE
with 10-fold std. Ground truth is 1.0. Low and high confounding correspond to β = 1.0 and 10.0.
join date

district

age

Conf.

Low

High

Low

High

Low

High

ˆψQ
n
ˆψg
n
ˆψA
n
ˆψTMLE

n

1.05 ± 0.24
1.27 ± 0.03
1.24 ± 0.04
1.21 ± 0.03

2.77 ± 0.35
3.12 ± 0.06
3.40 ± 0.04
3.26 ± 0.07

1.03 ± 0.25
1.10 ± 0.03
1.09 ± 0.02
1.09 ± 0.04

1.75 ± 0.20
1.66 ± 0.07
2.03 ± 0.07
2.02 ± 0.05

1.17 ± 0.35
1.29 ± 0.05
1.21 ± 0.05
1.20 ± 0.05

2.41 ± 0.45
3.10 ± 0.07
3.26 ± 0.09
3.13 ± 0.09

mixed-membership stochastic block model [GB13] to the data  with 128 communities (chosen to
match the embedding dimension). We predict the outcome using a linear regression of the outcome
on the community identities and the treatment. The estimated treatment effect is the coefﬁcient of the
treatment.

6.1 Results

Comparison to baselines. We report comparisons to the baselines in table 1. As expected  adjusting
for the network improves estimation in every case. Further  the one-stage embedding procedure is
more accurate than baselines.

robust method.

information about

We report comparisons of downstream estimators in table 2.
substantially
This is likely because the network does not
the confounding factors  violating one of our assumptions.

Choice of estimator.
The conditional-outcome-only estimator usually yields the best estimates 
improving on either
carry all
We expect that district has the strongest de-
pendence with the network  and we see best per-
formance for this attribute. Poor performance of
robust estimators when assumptions are violated
has been observed in other contexts [KS07].

Confounding exogenous to the network. In
practice  the network may not carry information
about all sources of confounding. For instance 
in our simulation  the confounders may not be
wholly predictable from the network structure.
We study the effect of exogenous confounding
by a second simulation where the confounder
consists of a part that can be fully inferred from
the network and part that is wholly exogenous.

For the inferrable part  we use the estimated
propensity scores {ˆgi} from the district ex-
periment above. By construction  the network
carries all information about each ˆgi. We deﬁne
the (ground truth) propensity score for our new
simulation as logit gsim = (1 − p) logit ˆgi + pξi 

Figure 1: Adjusting for the network helps even when
the no exogenous confounding assumption is violated.
The robust TMLE estimator is the best estimator when
no assumptions are violated. The simple conditional-
outcome-only estimator (“Simple”) is better in the pres-
ence of moderate exogeneity. Plot shows estimates of
ATE from district simulation. Ground truth is 1.

8

0.00.20.40.60.81.0Exogeneity0.51.01.52.02.53.03.54.0ATE EstimateSimpleTMLEUnadjustedwith ξi
controls the level of exogeneity. We simulate treatments and outcomes as in eq. (6.1).

iid∼ N(0  1). The second term  ξi  is the exogenous part of the confounding. The parameter p

In ﬁg. 1 we plot the estimates at various levels of exogeneity. We observe that network adjustment
helps even when the no exogenous confounding assumption is violated. Further  we see that the
robust estimator has better performance when p = 0  i.e.  when the assumptions of theorem 5.1
are satisﬁed. However  the conditional-outcome-only estimator is better with substantial exogenous
confounding.

7 Discussion

We have seen how black-box embedding methods can be harnessed for causal inference in the
context of networks. The important conceptual points of the development are: First  the method
eliminates the need to precisely specify the properties that inﬂuence both network formation and
that are confounding. In particular  we need not specify a parametric model for how the network is
formed. And  second  identiﬁcation and estimation can be achieved even if the embedding method
extracts the necessary information at only a slow rate. That is  absence of a parametric model is not a
grevious problem from a sample-complexity perspective. These are substantial strengths. However 
there also signiﬁcant limitations and opportunity for future work.

Assumption 2 may be difﬁcult to reason about in practice. It requires the practitioner to assess
both whether (1) the network carries sufﬁcient information for identiﬁcation  and (2) the embedding
method is able to effectively extract this information. The ﬁrst part is an assessment based on
application-speciﬁc domain knowledge. The second part is based on past performance of embedding
methodse.g.  a method that reliably predicts political afﬁliation in datasets where afﬁliation is
labeled can be expected to effectively extract information relevant to political identity. This is an
improvement on the (impossible) requirement of ﬁnding a well-speciﬁed model describing how
the network was generated. While we do not expect that either condition is exactly satisﬁed  the
exogeneous-confounding experiments in section 6 suggest that applying the adjustment can still
improve estimation. An important direction for future work is to develop new methods for sensitivity
analysis—applicable in this black-box setting—and formal results about when Assumption 2 can be
expected to hold. As an example of the need for such results  partial adjustment for confounding is
known to hurt estimation in certain cases [e.g.  bias ampliﬁcation Mid+16; Din+17].

The pure-homophily assumption is restrictive. Many of the most interesting causal questions on
networks are explicitly about inﬂuence and contagion. We restricted to the homophily case here
for simplicity  but it does not appear to be fundamentally required. Extending the results to handle
contagion and inﬂuence is an important direction for future work.

References

[Air+08]

[Bic+00]

[Cha+17]

E. Airoldi  D. Blei  S. Fienberg  and E. Xing. “Mixed membership stochastic blockmod-
els”. In: Journal of Machine Learning Research (2008).
P. J. Bickel  C. A. J. Klaassen  Y. Ritov  and J. A. Wellner. “Efﬁcient and adaptive
estimation for semiparametric models”. In: Sankhy: The Indian Journal of Statistics 
Series A (2000).
B. P. Chamberlain  J. Clough  and M. P. Deisenroth. “Neural embeddings of graphs in
hyperbolic space”. In: arXiv e-prints  arXiv:1705.10359 (2017).

[Che+17a] V. Chernozhukov  D. Chetverikov  M. Demirer  E. Duﬂo  C. Hansen  W. Newey  and
J. Robins. “Double/debiased machine learning for treatment and structural parameters”.
In: The Econometrics Journal (2017).

[Che+17b] V. Chernozhukov  D. Chetverikov  M. Demirer  E. Duﬂo  C. Hansen  and W. Newey.
“Double/debiased/neyman machine learning of treatment effects”. In: American Eco-
nomic Review 5 (2017).
S. R. Cole and M. A. Hern´an. “Constructing inverse probability weights for marginal
structural models.” In: American Journal of Epidemiology (2008).
H. Crane and W. Dempsey. “A framework for statistical network modeling”. In: arXiv
e-prints  arXiv:1509.08185 (2015).

[CH08]

[CD15]

9

[Din+17]

[Dur06]
[GB13]

P. Ding  T. Vanderweele  and J. M. Robins. “Instrumental variables as bias ampliﬁers
with general outcome and confounding”. In: Biometrika 2 (2017).
R. Durrett. Random Graph Dynamics. 2006.
P. K. Gopalan and D. M. Blei. “Efﬁcient discovery of overlapping communities in
massive networks”. In: Proceedings of the National Academy of Sciences (2013).

[Ham+17] W. Hamilton  Z. Ying  and J. Leskovec. “Inductive representation learning on large

graphs”. In: Advances in neural information processing systems 30. 2017.

[Ham+17] W. L. Hamilton  R. Ying  and J. Leskovec. “Representation learning on graphs: methods

[Hof+02]

[KS07]

[KM99]

[KP14]

[LK14]

[Lou+17]

and applications”. In: arXiv e-prints  arXiv:1709.05584 (2017).
P. Hoff  A. Raftery  and M. Handcock. “Latent space approaches to social network
analysis”. In: Journal of the American Statistical Association 460 (2002).
J. D. Y. Kang and J. L. Schafer. “Demystifying double robustness: a comparison of
alternative strategies for estimating a population mean from incomplete data”. In: Statist.
Sci. 4 (2007).
M. Kuroki and M. Miyakawa. “Identiﬁability criteria for causal effects of joint interven-
tions”. In: Journal of the Japan Statistical Society 2 (1999).
M. Kuroki and J. Pearl. “Measurement bias and effect restoration in causal inference”.
In: Biometrika 2 (2014).
J. Leskovec and A. Krevl. SNAP Datasets: Stanford Large Network Dataset Collection.
http://snap.stanford.edu/data. 2014.
C. Louizos  U. Shalit  J. M. Mooij  D. Sontag  R. Zemel  and M. Welling. “Causal
effect inference with deep latent-variable models”. In: Advances in neural information
processing systems. 2017.

[Mia+18] W. Miao  Z. Geng  and E. J. Tchetgen Tchetgen. “Identifying causal effects with proxy

[Mid+16]

[New09]
[Ogb18]

[OV17]

[Ogb+17]

[OR15]

[Pea12]

[Per+14]

[Rob00]

[Rob+94]

[Rob+00]

[RR83]

[SM16]

variables of an unmeasured confounder”. In: Biometrika 4 (2018).
J. A. Middleton  M. A. Scott  R. Diakow  and J. L. Hill. “Bias ampliﬁcation and bias
unmasking”. In: Political Analysis 3 (2016).
M. Newman. Networks. An Introduction. 2009.
E. L. Ogburn. “Challenges to estimating contagion effects from observational data”. In:
Complex spreading phenomena in social systems: inﬂuence and contagion in real-world
social networks. 2018.
E. L. Ogburn and T. J. VanderWeele. “Vaccines  contagion  and social networks”. In:
Ann. Appl. Stat. 2 (2017).
E. L. Ogburn  O. Sofrygin  I. Diaz  and M. J. van der Laan. “Causal inference for social
network data”. In: arXiv e-prints  arXiv:1705.08527 (2017).
P. Orbanz and D. Roy. “Bayesian models of graphs  arrays and other exchangeable
random structures”. In: Pattern Analysis and Machine Intelligence  IEEE Transactions
on 2 (2015).
J. Pearl. “On measurement bias in causal inference”. In: arXiv e-prints  arXiv:1203.3504
(2012).
B. Perozzi  R. Al-Rfou  and S. Skiena. “Deepwalk: online learning of social represen-
tations”. In: Proc. 20th int. conference on knowledge discovery and data mining (kdd
’14). 2014.
J. M. Robins. “Robust estimation in sequentially ignorable missing data and causal
inference models”. In: ASA Proceedings of the Section on Bayesian Statistical Science
(2000).
J. M. Robins  A. Rotnitzky  and L. P. Zhao. “Estimation of regression coefﬁcients
when some regressors are not always observed”. In: Journal of the American Statistical
Association 427 (1994).
J. M. Robins  A. Rotnitzky  and M. van der Laan. “On proﬁle likelihood: comment”. In:
Journal of the American Statistical Association 450 (2000).
P. R. Rosenbaum and D. B. Rubin. “The central role of the propensity score in observa-
tional studies for causal effects”. In: Biometrika 1 (1983).
C. Shalizi and E. McFowland III. “Estimating causal peer inﬂuence in homophilous
social networks by inferring latent locations”. In: arXiv e-prints  arXiv:1607.06565
(2016).

10

[ST11]

[TZ12]

[Tch+17]

[vR11]

[VR15]

C. R. Shalizi and A. C. Thomas. “Homophily and contagion are generically confounded
in observational social network studies”. In: Sociol. Methods Res. 2 (2011).
L. Takac and M. Zabovsky. “Data analysis in public social networks”. In: International
Scientiﬁc Conference and International Workshop Present Day Trends of Innovations
(2012).
E. J. Tchetgen Tchetgen  I. Fulcher  and I. Shpitser. “Auto-g-computation of causal
effects on a network”. In: arXiv e-prints  arXiv:1709.01577 (2017).
M. van der Laan and S. Rose. Targeted Learning: Causal Inference for Observational
and Experimental Data. 2011.
V. Veitch and D. M. Roy. “The class of random graphs arising from exchangeable
random measures”. In: arXiv e-prints  arXiv:1512.03099 (2015).

[Vei+19a] V. Veitch  M. Austern  W. Zhou  D. M. Blei  and P. Orbanz. “Empirical risk minimiza-
tion and stochastic gradient descent for relational data”. In: Proceedings of the 22nd
international conference on artiﬁcial intelligence and statistics. 2019.

[Vei+19b] V. Veitch  D. Sridhar  and D. M. Blei. “Using text embeddings for causal inference”. In:

[WW87]

[Yan+16]

arXiv e-prints  arXiv:1905.12741 (2019).
Y. Wang and G. Wong. “Stochastic block models for directed graphs”. In: Journal of
the American Statistical Association 397 (1987).
Z. Yang  W. Cohen  and R. Salakhudinov. “Revisiting semi-supervised learning with
graph embeddings”. In: Proceedings of the 33rd international conference on machine
learning. 2016.

11

,Victor Veitch
Yixin Wang
David Blei