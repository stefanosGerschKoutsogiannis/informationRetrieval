2011,Crowdclustering,Is it possible to crowdsource categorization? Amongst the challenges: (a) each annotator has only a partial view of the data  (b) different annotators may have different clustering criteria and may produce different numbers of categories  (c) the underlying category structure may be hierarchical. We propose a Bayesian model of how annotators may approach clustering and show how one may infer clusters/categories  as well as annotator parameters  using this model. Our experiments  carried out on large collections of images  suggest that Bayesian crowdclustering works well and may be superior to single-expert annotations.,Crowdclustering

Ryan Gomes∗

Caltech

Peter Welinder

Caltech

Andreas Krause

ETH Zurich & Caltech

Pietro Perona

Caltech

Abstract

Is it possible to crowdsource categorization? Amongst the challenges: (a) each
worker has only a partial view of the data  (b) different workers may have differ-
ent clustering criteria and may produce different numbers of categories  (c) the
underlying category structure may be hierarchical. We propose a Bayesian model
of how workers may approach clustering and show how one may infer clusters
/ categories  as well as worker parameters  using this model. Our experiments 
carried out on large collections of images  suggest that Bayesian crowdclustering
works well and may be superior to single-expert annotations.

Introduction

1
Outsourcing information processing to large groups of anonymous workers has been made easier
by the internet. Crowdsourcing services  such as Amazon’s Mechanical Turk  provide a convenient
way to purchase Human Intelligence Tasks (HITs). Machine vision and machine learning researchers
have begun using crowdsourcing to label large sets of data (e.g.  images and video [1  2  3]) which
may then be used as training data for AI and computer vision systems.
In all the work so far
categories are deﬁned by a scientist  while categorical labels are provided by the workers.
Can we use crowdsourcing to discover categories? I.e.  is it possible to use crowdsourcing not only
to classify data instances into established categories  but also to deﬁne the categories in the ﬁrst
place? This question is motivated by practical considerations. If we have a large number of images 
perhaps several tens of thousands or more  it may not be realistic to expect a single person to look
at all images and form an opinion as to how to categorize them. Additionally  individuals  whether
untrained or expert  might not agree on the criteria used to deﬁne categories and may not even agree
on the number of categories that are present. In some domains unsupervised clustering by machine
may be of great help; however  unsupervised categorization of images and video is unfortunately a
problem that is far from solved. Thus  it is an interesting question whether it is possible to collect
and combine the opinion of multiple human operators  each one of which is able to view a (perhaps
small) subset of a large image collection.
We explore the question of crowdsourcing clustering in two steps: (a) Reduce the problem to a
number of independent HITs of reasonable size and assign them to a large pool of human workers
(Section 2). (b) Develop a model of the annotation process  and use the model to aggregate the
human data automatically (Section 3) yielding a partition of the dataset into categories. We explore
the properties of our approach and algorithms on a number of real world data sets  and compare
against existing methods in Section 4.
2 Eliciting Information from Workers
How shall we enable human operators to express their opinion on how to categorize a large collection
of images? Whatever method we choose  it should be easy to learn and it should be implementable
by means of a simple graphical user interface (GUI). Our approach (Figure 1) is based on displaying
small subsets of M images and asking workers to group them by means of mouse clicks. We
provide instructions that may cue workers to certain attributes but we do not provide the worker
with category deﬁnitions or examples. The worker groups the M items into clusters of his choosing 
as many as he sees ﬁt. An item may be placed in its own cluster if it is unlike the others in the
HIT. The choice of M trades off between the difﬁculty of the task (worker time required for a HIT

∗Corresponding author  e-mail: gomes@vision.caltech.edu

1

Figure 1: Schematic of Bayesian crowdclustering. A large image collection is explored by workers. In each
HIT (Section 2)  the worker views a small subset of images on a GUI. By associating (arbitrarily chosen)
colors with sets of images the worker proposes a (partial) local clustering. Each HIT thus produces multiple
binary pairwise labels: each pair of images shown in the same HIT is placed by the worker either in the same
category or in different categories. Each image is viewed by multiple workers in different contexts. A model
of the annotation process (Sec. 3.1) is used to compute the most likely set of categories from the binary labels.
Worker parameters are estimated as well.
increases super-linearly with the number of items)  the resolution of the images (more images on
the screen means that they will be smaller)  and contextual information that may guide the worker
to make more global category decisions (more images give a better context  see Section 4.1.) Partial
clusterings on many M-sized subsets of the data from many different workers are thus the raw data
on which we compute clustering.
An alternative would have been to use pairwise distance judgments or three-way comparisons. A
large body of work exists in the social sciences that makes use of human-provided similarity values
deﬁned between pairs of data items (e.g.  Multidimensional Scaling [4].) After obtaining pairwise
similarity ratings from workers  and producing a Euclidean embedding  one could conceivably pro-
ceed with unsupervised clustering of the data in the Euclidean space. However  accurate distance
judgments may be more laborious to specify than partial clusterings. We chose to explore what we
can achieve with partial clusterings alone.
We do not expect workers to agree on their deﬁnitions of categories  or to be consistent in catego-
rization when performing multiple HITs. Thus  we avoid explicitly associating categories across

HITs. Instead  we represent the results of each HIT as a series of(cid:0)M

(cid:1) binary labels (see Figure 1).

2

2

(cid:1).

labels is T = H(cid:0)M

We assume that there are N total items (indexed by i)  J workers (indexed by j)  and H HITs
(indexed by h). The information obtained from workers is a set of binary variables L  with ele-
ments lt ∈ {−1  +1} indexed by a positive integer t ∈ {1  . . .   T}. Associated with the t-th label
is a quadruple (at  bt  jt  ht)  where jt ∈ {1  . . .   J} indicates the worker that produced the label 
and at ∈ {1  . . .   N} and bt ∈ {1  . . .   N} indicate the two data items compared by the label.
ht ∈ {1  . . .   H} indicates the HIT from which the t-th pairwise label was derived. The number of
Sampling Procedure We have chosen to structure HITs as clustering tasks of M data items  so
we must specify them. If we simply seperate the items into disjoint sets  then it will be impossible to
infer a clustering over the entire data set. We will not know whether two items in different HITs are
in the same cluster or not. There must be some overlap or redundancy: data items must be members
of multiple HITs.
In the other extreme  we could construct HITs such that each pair of items may be found in at least
one HIT  so that every possible pairwise category relation is sampled. This would be quite expensive
for large number of items N  since the number of labels scales asymptotically as T ∈ Ω(N 2).
However  we expect a noisy transitive property to hold: if items a and b are likely to be in the same
cluster  and items b and c are (not) likely in the same cluster  then items a and c are (not) likely to
be in the same cluster as well. The transitive nature of binary cluster relations should allow sparse
sampling  especially when the number of clusters is relatively small.
As a baseline sampling method  we use the random sampling scheme outlined by Strehl and
Ghosh [5] developed for the problem of object distributed clustering  in which a partition of a com-
plete data set is learned from a number of clusterings restricted to subsets of the data. (We compare
our aggregation algorithm to this work in Section 4.) Their scheme controls the level of sampling
redundancy with a single parameter V   which in our problem is interpreted as the expected number
of HITs to which a data item belongs.

2

Image setAnnotatorsGUIPairwise labels⇡6=6=6=ltτjxiWjziatbtjtAnnotatorsData ItemsPairwise LabelsΦkVk“Atomic” clustersModel / inferenceCategories(cid:1)

2

(cid:0)M

The N items are ﬁrst distributed deterministically among the HITs  so that there are (cid:100) M
V (cid:101) items
V (cid:101) items in each HIT are ﬁlled by sampling without re-
in each HIT. Then the remaining M − (cid:100) M
V (cid:101) items that are not yet allocated to the HIT. There are a total of (cid:100) N V
placement from the N − (cid:100) M
M (cid:101)
unique HITs. We introduce an additional parameter R  which is the number of different workers that
perform each constructed HIT. The total number of HITs distributed to the crowdsourcing service is
therefore H = R(cid:100) N V
M (cid:101)  and we impose the constraint that a worker can not perform the same HIT
more than once. This sampling scheme generates T = R(cid:100) N V
∈ O(RN V M ) binary labels.
M (cid:101)
With this exception  we ﬁnd a dearth of ideas in the literature pertaining to sampling methods for
distributed clustering problems. Iterative schemes that adaptively choose maximally informative
HITs may be preferable to random sampling. We are currently exploring ideas in this direction.
3 Aggregation via Bayesian Crowdclustering
There is an extensive literature in machine learning on the problem of combining multiple alternative
clusterings of data. This problem is known as consensus clustering [6]  clustering aggregation [7] 
or cluster ensembles [5]. While some of these methods can work with partial input clusterings  most
have not been demonstrated in situations where the input clusterings involve only a small subset of
the total data items (M << N)  which is the case in our problem.
In addition  existing approaches focus on producing a single “average” clustering from a set of input
clusterings. In contrast  we are not merely interested in the average clustering produced by a crowd
of workers.
Instead  we are interested in understanding the ways in which different individuals
may categorize the data. We seek a master clustering of the data that may be combined in order to
describe the tendencies of individual workers. We refer to these groups of data as atomic clusters.
For example  suppose one worker groups objects into a cluster of tall objects and another of short
objects  while a different worker groups the same objects into a cluster of red objects and another
of blue objects. Then  our method should recover four atomic clusters: tall red objects  short red
objects  tall blue objects  and short blue objects. The behavior of the two workers may then be
summarized using a confusion table of the atomic clusters (see Section 3.3). The ﬁrst worker groups
the ﬁrst and third atomic cluster into one category and the second and fourth atomic cluster into
another category. The second worker groups the ﬁrst and second atomic clusters into a category and
the third and fourth atomic clusters into another category.
3.1 Generative Model
We propose an approach in which data items are represented as points in a Euclidean space and
workers are modeled as pairwise binary classiﬁers in this space. Atomic clusters are then obtained
by clustering these inferred points using a Dirichlet process mixture model  which estimates the
number of clusters [8]. The advantage of an intermediate Euclidean representation is that it provides
a compact way to capture the characteristics of each data item. Certain items may be inherently more
difﬁcult to categorize  in which case they may lie between clusters. Items may be similar along one
axis but different along another (e.g.  object height versus object color.) A similar approach was
proposed by Welinder et al. [3] for the analysis of classiﬁcation labels obtained from crowdsourcing
services. This method does not apply to our problem  since it involves binary labels applied to single
data items rather than to pairs  and therefore requires that categories be deﬁned a priori and agreed
upon by all workers  which is incompatible with the crowdclustering problem.
We propose a probabilistic latent variable model that relates pairwise binary labels to hidden vari-
ables associated with both workers and images. The graphical model is shown in Figure 1. xi
is a D dimensional vector  with components [xi]d that encodes item i’s location in the embed-
ding space RD. Symmetric matrix Wj ∈ RD×D with entries [Wj]d1d2 and bias τj ∈ R are
used to deﬁne a pairwise binary classiﬁer  explained in the next paragraph  that represents worker
j’s labeling behavior. Because Wj is symmetric  we need only specify its upper triangular por-
tion: vecp{Wj} which is a vector formed by “stacking” the partial columns of Wj according
to the ordering [vecp{Wj}]1 = [Wj]11  [vecp{Wj}]2 = [Wj]12  [vecp{Wj}]3 = [Wj]22  etc.
Φk = {µk  Σk} are the mean and covariance parameters associated with the k-th Gaussian atomic
cluster  and Uk are stick breaking weights associated with a Dirichlet process.
The key term is the pairwise quadratic logistic regression likelihood that captures worker j’s ten-
dency to label the pair of images at and bt with lt:

(1)

p(lt|xat  xbt  Wjt  τjt) =

3

1

1 + exp(−ltAt)

where we deﬁne the pairwise quadratic activity At = xT
Wjtxbt + τjt. Symmetry of Wj ensures
at
that p(lt|xat  xbt  Wjt  τjt ) = p(lt|xbt  xat  Wjt  τjt). This form of likelihood yields a compact
and tractable method of representing classiﬁers deﬁned over pairs of points in Euclidean space.
Pairs of vectors with large pairwise activity tend to be classiﬁed as being in the same category 
and in different categories otherwise. We ﬁnd that this form of likelihood leads to tightly grouped
clusters of points xi that are then easily discovered by mixture model clustering.
The joint distribution is

p(Φ  U  Z  X  W  τ L) =

p(Uk|α)p(Φk|m0  β0  J0  η0)

p(zi|U )p(xi|Φzi)

∞(cid:89)
J(cid:89)

k=1

j=1

N(cid:89)
T(cid:89)

i=1

t=1

(2)

(3)

p(vecp{Wj}|σw

0 )p(τj|στ
0 )

p(lt|xat  xbt  Wjt  τjt).

k−1(cid:89)

The conditional distributions are deﬁned as follows:

p(Uk|α) = Beta(Uk; 1  α)
(cid:89)
p(xi|Φzi) = Normal(xi; µzi  Σzi)
p(vecp{Wj}|σw
p(τj|στ
p(Φk|m0  β0  J0  η0) = Normal-Wishart(Φk; m0  β0  J0  η0)

Normal([Wj]d1d2; 0  σw
0 )

p(xi|σx

d1≤d2

0 ) =

0 ) =

(cid:89)

p(zi = k|U ) = Uk

(1 − Ul)
Normal([xi]d; 0  σx
0 )

l=1

d
0 ) = Normal(τj; 0  στ
0 )

∞(cid:89)

k=K+1

(cid:89)

0   στ

0   σw

where (σx
0   α  m0  β0  J0  η0) are ﬁxed hyper-parameters. Our model is similar to that
of [9]  which is used to model binary relational data. Salient differences include our use of a logistic
rather than a Gaussian likelihood  and our enforcement of the symmetry of Wj. In the next section 
we develop an efﬁcient deterministic inference algorithm to accomodate much larger data sets than
the sampling algorithm used in [9].
3.2 Approximate Inference
Exact posterior inference in this model is intractable  since computing it involves integrating over
variables with complex dependencies. We therefore develop an inference algorithm based on the
Variational Bayes method [10]. The high level idea is to work with a factorized proxy posterior
distribution that does not model the full complexity of interactions between variables; it instead
represents a single mode of the true posterior. Because this distribution is factorized  integrations
involving it become tractable. We deﬁne the proxy distribution q(Φ  U  Z  X  W  τ ) =

K(cid:89)

N(cid:89)

J(cid:89)

p(Uk|α)p(Φk|m0  β0  J0  η0)

q(Uk)q(Φk)

q(zi)q(xi)

k=1

i=1

j=1

q(vecp{Wj})q(τj)

(4)

using parametric distributions of the following form:

q(Uk) = Beta(Uk; ξk 1  ξk 2)

q(xi) =

Normal([xi]d; [µx

i ]d  [σx

i ]d)

d

q(zi = k) = qik

q(vecp{Wj}) =

q(Φk) = Normal-Wishart(mk  βk  Jk  ηk)

(5)

(cid:89)

d1≤d2

q(τj) = Normal(τj; µτ

j   στ
j )

Normal([Wj]d1d2 ; [µw

j ]d1d2  [σw

j ]d1d2)

To handle the inﬁnite number of mixture components  we follow the approach of [11] where we
deﬁne variational distributions for the ﬁrst K components  and ﬁx the remainder to their correspond-
ing priors. {ξk 1  ξk 2} and {mk  βk  Jk  ηk} are the variational parameters associated with the k-th
mixture component. q(zi = k) = qik form the factorized assignment distribution for item i. µx
i and
i are variational mean and variance parameters associated with data item i’s embedding location.
σx
j are symmetric matrix variational mean and variance parameters associated with worker
j and σw
µw
j  and µτ
j are variational mean and variance parameters for the bias τj of worker j. We use
diagonal covariance Normal distributions over Wj and xi to reduce the number of parameters that
must be estimated.

j and στ

4

Next  we deﬁne a utility function which allows us to determine the variational parameters. We use
Jensen’s inequality to develop a lower bound to the log evidence:

log p(L|σx

0   στ

0   σw

0   α  m0  β0  J0  η0)

≥Eq log p(Φ  U  Z  X  W  τ L) + H{q(Φ  U  Z  X  W  τ )} 

H{·} is the entropy of the proxy distribution  and the lower bound is known as the Free Energy.
However  the Free Energy still involves intractable integration  because the normal distributions over
variables Wj  xi  and τj are not conjugate [12] to the logistic likelihood term. We therefore locally
approximate the logistic likelihood with an unnormalized Gaussian function lower bound  which is
the left hand side of the following inequality:

g(∆t) exp{(ltAt − ∆t)/2 + λ(∆t)(A2

(7)
This was adapted from [13] to our case of quadratic pairwise logistic regression. Here g(x) =
(1 + e−x)−1 and λ(∆) = [1/2 − g(∆)]/(2∆). This expression introduces an additional variational
parameter ∆t for each label  which are optimized in order to tighten the lower bound. Our utility
function is therefore:

t )} ≤ p(lt|xat  xbt  Wjt  τjt).

t − ∆2

(6)

(8)

(cid:88)

t

F =Eq log p(Φ  U  Z  X  W  τ ) + H{q(Φ  U  Z  X  W  τ )}
+ λ(∆t)(Eq{A2

Eq{At} −

log g(∆t) +

∆t
2

lt
2

+

t} − ∆2
t )

(cid:111)

which is a tractable lower bound to the log evidence. Optimization of variational parameters is
carried out in a coordinate ascent procedure  which exactly maximizes each variational parameter in
turn while holding all others ﬁxed. This is guaranteed to converge to a local maximum of the utility
function. The update equations are given in an extended technical report [14]. We initialize the vari-
ational parameters by carrying out a layerwise procedure: ﬁrst  we substitute a zero mean isotropic
normal prior for the mixture model and perform variational updates over {µx
j }.
j   στ
Then we use µx
i as point estimates for xi and update {mk  βk  Jk  ηk  ξk 1  ξk 2} and determine the
initial number of clusters K as in [11]. Finally  full joint inference updates are performed. Their
computational complexity is O(D4T + D2KN ) = O(D4N V RM + D2KN ).
3.3 Worker Confusion Analysis
As discussed in Section 3  we propose to understand a worker’s behavior in terms of how he groups
atomic clusters into his own notion of categories. We are interested in the predicted confusion matrix
Cj for worker j  where

j   σw

i   µw

i   σx

j   µτ

(cid:110)(cid:90)

[Cj]k1k2 = Eq

p(l = 1|xa  xb  Wj  τj)p(xa|Φk1)p(xb|Φk2)dxadxb

(9)

which expresses the probability that worker j assigns data items sampled from atomic cluster k1
and k2 to the same cluster  as predicted by the variational posterior. This integration is intractable.
We use the expected values E{Φk1} = {mk1   Jk1 /ηk1} and E{Φk2} = {mk2  Jk2 /ηk2} as point
estimates in place of the variational distributions over Φk1 and Φk2. We then use Jensen’s inequality
and Eq. 7 again to yield a lower bound. Maximizing this bound over ∆ yields

k1

µw

(10)

j mk2 + µτ

[ ˆCj]k1k2 = g( ˆ∆k1k2j) exp{(mT

j − ˆ∆k1k2j)/2}
which we use as our approximate confusion matrix  where ˆ∆k1k2j is given in [14].
4 Experiments
We tested our method on four image data sets that have established “ground truth” categories  which
were provided by a single human expert. These categories do not necessarily reﬂect the uniquely
valid way to categorize the data set  however they form a convenient baseline for the purpose of
quantitative comparison. We used 1000 images from the Scenes data set from [15] to illustrate our
approach (Figures 2  3  and 4.) We used 1354 images of birds from 10 species in the CUB-200 data
set [16] (Table 1) and the 3845 images in the Stoneﬂy9 data set [17] (Table 1) in order to compare
our method quantitatively to other cluster aggregation methods. We used the 37794 images from the
Attribute Discovery data set [18] in order to demonstrate our method on a large scale problem.
We set the dimensionality of xi to D = 4 (since higher dimensionality yielded no additional clus-
ters) and we iterated the update equations 100 times  which was enough for convergence. Hyperpa-
rameters were tuned once on synthetic pairwise labels that simulated 100 data points drawn from 4
clusters  and ﬁxed during all experiments.

5

Figure 2: Scene Dataset. Left: Mean locations µx
i projected onto ﬁrst two Fisher discriminant vectors  along
with cluster labels superimposed at cluster means mk. Data items are colored according to their MAP label
argmaxk qik. Center: High conﬁdence example images from the largest ﬁve clusters (rows correspond to
clusters.) Right: Confusion table between ground truth scene categories and inferred clusters. The ﬁrst cluster
includes three indoor ground truth categories  the second includes forest and open country categories  and the
third includes two urban categories. See Section 4.1 for a discussion and potential solution of this issue.

Figure 3: (Left of line) Worker confusion matrices for the 40 most active workers. (Right of line) Selected
worker confusion matrices for Scenes experiment. Worker 9 (left) makes distinctions that correspond closely to
the atomic clustering. Worker 45 (center) makes coarser distinctions  often combining atomic clusters. Right:
Worker 29’s single HIT was largely random and does not align with the atomic clusters.

N

(cid:80)

Figure 2 (left) shows the mean locations of the data items µx
learned from the Scene data set 
i
visualized as points in Euclidean space. We ﬁnd well seperated clusters whose labels k are displayed
at their mean locations mk. The points are colored according to argmaxk qik  which is item i’s MAP
cluster assignment. The cluster labels are sorted according to the number of assigned items  with
cluster 1 being the largest. The axes are the ﬁrst two Fisher discriminant directions (derived from
the MAP cluster assignments) as axes. The clusters are well seperated in the four dimensionsal
ik qik log qik in the ﬁgure title  which shows
space (we give the average assignment entropy − 1
little cluster overlap.) Figure 2 (center) shows six high conﬁdence examples from clusters 1 through
5. Figure 2 (right) shows the confusion table between the ground truth categories and the MAP
clustering. We ﬁnd that the MAP clusters often correspond to single ground truth categories  but they
sometimes combine ground truth categories in reasonable ways. See Section 4.1 for a discussion and
potential solution of this issue.
Figure 3 (left of line) shows the predicted confusion matrices (Section 3.3) associated with the
40 workers that performed the most HITs. This matrix captures the worker’s tendency to label
items from different atomic clusters as being in the same or different category. Figure 3 (right of
line) shows in detail the predicted confusion matrices for three workers. We have sorted the MAP
cluster indices to yield approximately block diagonal matrices  for ease of interpretation. Worker 9
makes relatively ﬁne grained distinctions  including seperating clusters 1 and 9 that correspond to
the indoor categories and the bedroom scenes  respectively. Worker 45 combines clusters 5 and 8
which correspond to city street and highway scenes in addition to grouping together all indoor scene
categories. The ﬁner grained distinctions made by worker 9 may be a result of performing more
HITs (74) and seeing a larger number of images than worker 45  who performed 15 HITs. Finally
(far right)  we ﬁnd a worker whose labels do not align with the atomic clustering. Inspection of his
labels show that they were entered largely at random.
Figure 4 (top left) shows the number of HITs performed by each worker according to descending
rank. Figure 4 (bottom left) is a Pareto curve that indicates the percentage of the HITs performed
by the most active workers. The Pareto principle (i.e.  the law of the vital few) [19] roughly holds:
the top 20% most active workers perform nearly 80% of the work. We wish to understand the
extent to which the most active workers contribute to the results. For the purpose of quantitative
comparisons  we use Variation of Information (VI) [20] to measure the discrepancy between the

6

−1.5−1−0.500.511.5−2.5−2−1.5−1−0.500.51Average assignment entropy (bits): 0.0029653123456789101112354Ground TruthInferred Cluster 1234567891011bedroomsuburbkitchenliving roomcoastforesthighwayinside citymountainopen countrystreettall buildingoffice010203040506070Worker: 9  # of HITs: 74 1910735811426191073581142600.10.20.30.40.50.60.70.80.91Worker: 45  # of HITs: 15 1 9 7 103 5 8 114 6 2 1 9 7 103 5 8 114 6 2 00.10.20.30.40.50.60.70.80.91Worker: 29  # of HITs: 1 1910538711426191053871142600.10.20.30.40.50.60.70.80.91Figure 4: Scene Data set. Left Top: Number of completed HITs by worker rank. Left Bottom: Pareto curve.
Center: Variation of Information on the Scene data set as we incrementally remove top (blue) and bottom (red)
ranked workers. The top workers are removed one at a time  bottom ranked workers are removed in groups so
that both curves cover roughly the same domain. The most active workers do not dominate the results. Right:
Variation of Information between the inferred clustering and the ground truth categories on the Scene data set 
as a function of sampling parameter V . R is ﬁxed at 5.

Strehl & Ghosh [5]

Bayes Crowd
1.103 ± 0.082
2.448 ± 0.063

18.5 min

Bayes Consensus
1.721 ± 0.07
18.1 min
2.735 ± 0.037

98.5 min

NMF [21]
1.500 ± 0.26
27.9 min
4.571 ± 0.158
212.6 min

Birds [16] (VI)
Birds (time)
Stoneﬂy9 [17] (VI)
Stoneﬂy9 (time)

1.256 ± 0.001
3.836 ± 0.002
Table 1: Quantitative comparison on Bird and Stoneﬂy species categorization data sets. Quality is measured
using Variation of Information between the inferred clustering and ground truth. Bayesian Crowdclustering
outperforms the alternatives.

100.1 min

0.93 min

46.5 min

inferred MAP clustering and the ground truth categorization. VI is a metric with strong information
theoretic justiﬁcation that is deﬁned between two partitions (clusterings) of a data set; smaller values
indicate a closer match and a VI of 0 means that two clusterings are identical. In Figure 4 (center)
we incrementally remove the most active (blue) and least active (red) workers. Removal of workers
corresponds to moving from right to left on the x-axis  which indicates the number of HITs used to
learn the model. The results show that removing the large number of workers that do fewer HITs is
more detrimental to performance than removing the relatively few workers that do a large number
of HITs (given the same number of total HITs)  indicating that the atomic clustering is learned from
the crowd at large.
In Figure 4 (right)  we judge the impact of the sampling redundancy parameter V described in Sec-
tion 2. We compare our approach (Bayesian crowdclustering) to two existing clustering aggregation
methods from the literature: consensus clustering by nonnegative matrix factorization (NMF) [21]
and the cluster ensembles method of Strehl and Ghosh (S&G) [5]. NMF and S&G require the num-
ber of inferred clusters to be provided as a parameter  and we set this to the number of ground truth
categories. Even without the beneﬁt of this additional information  our method (which automati-
cally infers the number of clusters) outperforms the alternatives. To judge the beneﬁt of modeling
the characteristics of individual workers  we also compare against a variant of our model in which
all HITs are treated as if they are performed by a single worker (Bayesian consensus.) We ﬁnd a
signiﬁcant improvement. We ﬁx R = 5 in this experiment  but we ﬁnd a similar ranking of methods
at other values of R. However  the performance beneﬁt of the Bayesian methods over the existing
methods increases with R.
We compare the four methods quantitatively on two additional data sets  with the results summarized
in Table 1. In both cases  we instruct workers to categorize based on species. This is known to be
a difﬁcult task for non-experts. We set V = 6 and R = 5 for these experiments. Again  we ﬁnd
that Bayesian Crowdclustering outperforms the alternatives. A run time comparison is also given
in Table 1. Bayesian Crowdclustering results on the Bird and Stoneﬂy data sets are summarized
in [14].
Finally  we demonstrate Bayesian crowdclustering on the large scale Attribute Discovery data set.
This data set has four image categories: bags  earrings  ties  and women’s shoes. In addition  each
image is a member of one of 27 sub-categories (e.g.  the bags category includes backpacks and totes
as sub-categories.) See [14] for summary ﬁgures. We ﬁnd that our method easily discovers the four

7

0204060801001201400100200Worker RankCompleted HITs020406080100050100% of total workers% of total HITs20040060080010001200140016001.31.41.51.61.71.81.922.12.22.3Variation of InformationNumber of HITs Remaining Top workers excludedBottom workers excluded345678910111.522.533.54VVariation of InformationR=5 Bayes CrowdNMF ConsensusS&G Cluster EnsemblesBayes ConsensusOriginal Cluster 1

Original Cluster 4

Original Cluster 8

Figure 5: Divisive Clustering on the Scenes data set. Left: Confusion matrix and high conﬁdence examples
when running our method on images assigned to cluster one in the original experiment (Figure 2). The three
indoor scene categories are correctly recovered. Center: Workers are unable to subdivide mountain scenes
consistently and our method returns a single cluster. Right: Workers may ﬁnd perceptually relevant distinctions
not present in the ground truth categories. Here  the highway category is subdivided according to the number
of cars present.
categories. The subcategories are not discovered  likely due to limited context associated with HITs
with size M = 36 as discussed in the next section. Runtime was approximately 9.5 hours on a six
core Intel Xeon machine.
4.1 Divisive Clustering
As indicated by the confusion matrix in Figure 2 (right)  our method results in clusters that corre-
spond to reasonable categories. However  it is clear that the data often has ﬁner categorical distinc-
tions that go undiscovered. We conjecture that this is a result of the limited context presented to the
worker in each HIT. When shown a set of M = 36 images consisting mostly of different types of
outdoor scenes and a few indoor scenes  it is reasonable for a worker to consider the indoor scenes
as a uniﬁed category. However  if a HIT is composed purely of indoor scenes  a worker might draw
ﬁner distinctions between images of ofﬁces  kitchens  and living rooms. To test this conjecture 
we developed a hierarchical procedure in which we run Bayesian crowdclustering independently on
images that are MAP assigned to the same cluster in the original Scenes experiment.
Figure 5 (left) shows the results on the indoor scenes assigned to original cluster 1. We ﬁnd that when
restricted to indoor scenes  the workers do ﬁnd the relevant distinctions and our algorithm accurately
recovers the kitchen  living room  and ofﬁce ground truth categories. In Figure 5 (center) we ran the
procedure on images from original cluster 4  which is composed predominantly of mountain scenes.
The algorithm discovers one subcluster. In Figure 5 (right) the workers divide a cluster into three
subclusters that are perceptually relevant: they have organized them according to the number of cars
present.
5 Conclusions
We have proposed a method for clustering a large set of data by distributing small tasks to a large
group of workers. It is based on using a novel model of human clustering  as well as a novel ma-
chine learning method to aggregate worker annotations. Modeling both data item properties and the
workers’ annotation process and parameters appears to produce performance that is superior to ex-
isting clustering aggregation methods. Our study poses a number of interesting questions for further
research: Can adaptive sampling methods (as opposed to our random sampling) reduce the number
of HITs that are necessary to achieve high quality clustering? Is it possible to model the workers’
tendency to learn over time as they perform HITs  rather than treating HITs independently as we do
here? Can we model contextual effects  perhaps by modeling the way that humans “regularize” their
categorical decisions depending on the number and variety of items present in the task?
Acknowledgements This work was supported by ONR MURI grant 1015-G-NA-127  ARL grant
W911NF-10-2-0016  and NSF grants IIS-0953413 and CNS-0932392.

8

Ground TruthInferred Cluster 123bedroomsuburbkitchenliving roomcoastforesthighwayinside citymountainopen countrystreettall buildingoffice010203040506070Ground TruthInferred Cluster 1bedroomsuburbkitchenliving roomcoastforesthighwayinside citymountainopen countrystreettall buildingoffice010203040506070Ground TruthInferred Cluster 123bedroomsuburbkitchenliving roomcoastforesthighwayinside citymountainopen countrystreettall buildingoffice010203040501.11.21.34.18.18.28.3References
[1] A. Sorokin and D. A. Forsyth. Utility data annotation with Amazon Mechanical Turk.

Internet Vision  pages 1–8  2008.

In

[2] Sudheendra Vijayanarasimhan and Kristen Grauman. Large-Scale Live Active Learning:

Training Object Detectors with Crawled Data and Crowds. In CVPR  2011.

[3] Peter Welinder  Steve Branson  Serge Belongie  and Pietro Perona. The multidimensional

wisdom of crowds. In Neural Information Processing Systems Conference (NIPS)  2010.

[4] J. B. Kruskal. Multidimensional scaling by optimizing goodness-of-ﬁt to a nonmetric hypoth-

esis. PSym  29:1–29  1964.

[5] Alexander Strehl and Joydeep Ghosh. Cluster ensembles—A knowledge reuse framework for

combining multiple partitions. Journal of Machine Learning Research  3:583–617  2002.

[6] Stefano Monti  Pablo Tamayo  Jill Mesirov  and Todd Golub. Consensus clustering: A
resampling-based method for class discovery and visualization of gene expression microar-
ray data. Machine Learning  52(1–2):91–118  2003.

[7] Gionis  Mannila  and Tsaparas. Clustering aggregation. In ACM Transactions on Knowledge

Discovery from Data  volume 1. 2007.

[8] A.Y. Lo. On a class of bayesian nonparametric estimates: I. density estimates. The Annals of

Statistics  pages 351–357  1984.

[9] I. Sutskever  R. Salakhutdinov  and J.B. Tenenbaum. Modelling relational data using bayesian
clustered tensor factorization. Advances in Neural Information Processing Systems (NIPS) 
2009.

[10] Hagai Attias. A variational baysian framework for graphical models. In NIPS  pages 209–215 

1999.

[11] Kenichi Kurihara  Max Welling  and Nikos Vlassis. Accelerated variational dirichlet process
mixtures. In B. Sch¨olkopf  J. Platt  and T. Hoffman  editors  Advances in Neural Information
Processing Systems 19. MIT Press  Cambridge  MA  2007.

[12] J. M. Bernardo and A. F. M. Smith. Bayesian Theory. Wiley  1994.
[13] Tommi S. Jaakkola and Michael I. Jordan. A variational approach to Bayesian logistic regres-

sion models and their extensions  August 13 1996.

[14] Ryan Gomes  Peter Welinder  Andreas Krause  and Pietro Perona. Crowdclustering. Technical

Report CaltechAUTHORS:20110628-202526159  June 2011.

[15] Li Fei-Fei and Pietro Perona. A Bayesian hierarchical model for learning natural scene cate-

gories. In CVPR  pages 524–531. IEEE Computer Society  2005.

[16] P. Welinder  S. Branson  T. Mita  C. Wah  F. Schroff  S. Belongie  and P. Perona. Caltech-
UCSD Birds 200. Technical Report CNS-TR-2010-001  California Institute of Technology 
2010.

[17] G. Martinez-Munoz  N. Larios  E. Mortensen  W. Zhang  A. Yamamuro  R. Paasch  N. Payet 
D. Lytle  L. Shapiro  S. Todorovic  et al. Dictionary-free categorization of very similar objects
via stacked evidence trees. 2009.

[18] T. Berg  A. Berg  and J. Shih. Automatic attribute discovery and characterization from noisy

web data. Computer Vision–ECCV 2010  pages 663–676  2010.

[19] V. Pareto. Cours d’economie politique. 1896.
[20] M. Meila. Comparing clusterings by the variation of information.

In Learning theory and
Kernel machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop 
COLT/Kernel 2003  Washington  DC  USA  August 24-27  2003: proceedings  volume 2777 
page 173. Springer Verlag  2003.

[21] Tao Li  Chris H. Q. Ding  and Michael I. Jordan. Solving consensus and semi-supervised
clustering problems using nonnegative matrix factorization. In ICDM  pages 577–582. IEEE
Computer Society  2007.

9

,Conghui Tan
Shiqian Ma
Yuqiu Qian
Rizal Fathony
Mohammad Ali Bashiri
Brian Ziebart