2008,PSDBoost: Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning,In this work  we consider the problem of learning a positive semidefinite matrix. The critical issue is how to preserve positive semidefiniteness during the course of learning. Our algorithm is mainly inspired by LPBoost [1] and the general greedy convex optimization framework of Zhang [2]. We demonstrate the essence of the algorithm  termed PSDBoost (positive semidefinite Boosting)  by focusing on a few different applications in machine learning. The proposed PSDBoost algorithm extends traditional Boosting algorithms in that its parameter is a positive semidefinite matrix with trace being one instead of a classifier. PSDBoost is based on the observation that any trace-one positive semidefinitematrix can be decomposed into linear convex combinations of trace-one rank-one matrices  which serve as base learners of PSDBoost. Numerical experiments are presented.,PSDBoost: Matrix-Generation Linear Programming

for Positive Semideﬁnite Matrices Learning

Chunhua Shen†‡  Alan Welsh‡  Lei Wang‡

†NICTA Canberra Research Lab  Canberra  ACT 2601  Australia∗
‡Australian National University  Canberra  ACT 0200  Australia

Abstract

In this work  we consider the problem of learning a positive semideﬁnite matrix.
The critical issue is how to preserve positive semideﬁniteness during the course
of learning. Our algorithm is mainly inspired by LPBoost [1] and the general
greedy convex optimization framework of Zhang [2]. We demonstrate the essence
of the algorithm  termed PSDBoost (positive semideﬁnite Boosting)  by focus-
ing on a few different applications in machine learning. The proposed PSDBoost
algorithm extends traditional Boosting algorithms in that its parameter is a posi-
tive semideﬁnite matrix with trace being one instead of a classiﬁer. PSDBoost is
based on the observation that any trace-one positive semideﬁnite matrix can be de-
composed into linear convex combinations of trace-one rank-one matrices  which
serve as base learners of PSDBoost. Numerical experiments are presented.

1 Introduction

Column generation (CG) [3] is a technique widely used in linear programming (LP) for solving
large-sized problems. Thus far it has mainly been applied to solve problems with linear constraints.
The proposed work here—which we dub matrix generation (MG)—extends the column generation
technique to non-polyhedral semideﬁnite constraints. In particular  as an application we show how
to use it for solving a semideﬁnite metric learning problem. The fundamental idea is to rephrase a
bounded semideﬁnite constraint into a polyhedral one with inﬁnitely many variables. This construc-
tion opens possibilities for use of the highly developed linear programming technology. Given the
limitations of current semideﬁnite programming (SDP) solvers to deal with large-scale problems 
the work presented here is of importance for many real applications.

The choice of a metric has a direct effect on the performance of many algorithms such as the simplest
k-NN classiﬁer and some clustering algorithms. Much effort has been spent on learning a good
metric for pattern recognition and data mining. Clearly a good metric is task-dependent: different
applications should use different measures for (dis)similarity between objects. We show how a
Mahalanobis metric is learned from examples of proximity comparison among triples of training
data. For example  assuming that we are given triples of images ai  aj and ak (ai  aj have same
labels and ai  ak have different labels  ai ∈ RD)  we want to learn a metric between pairs of images
such that the distance from aj to ai (distij) is smaller than from ak to ai (distik). Triplets like this
are the input of our metric learning algorithm. By casting the problem as optimization of the inner
product of the linear transformation matrix and its transpose  the formulation is based on solving
a semideﬁnite program. The algorithm ﬁnds an optimal linear transformation that maximizes the
margin between distances distij and distik.

∗NICTA is funded by the Australian Government as represented by the Department of Broadband  Commu-
nications and the Digital Economy and the Australian Research Council through the ICT Center of Excellence
program.

A major drawback of this formulation is that current SDP solvers utilizing interior-point (IP) meth-
ods do not scale well to large problems with computation complexity roughly O(n4.5) (n is the
number of variables). On the other hand  linear programming is much better in terms of scalability.
State-of-the-art solvers like CPLEX [4] can solve large problems up to millions of variables and
constraints. This motivates us to develop an LP approach to solve our SDP metric learning problem.

2 Related Work

We overview some relevant work in this section.

Column generation was ﬁrst proposed by Dantzig and Wolfe [5] for solving some special structured
linear programs with extremely large number of variables. [3] has presented a comprehensive survey
on this technique. The general idea of CG is that  instead of solving the original large-scale prob-
lem (master problem)  one works on a restricted master problem with a reasonably small subset of
variables at each step. The dual of the restricted master problem is solved by the simplex method 
and the optimal dual solution is used to ﬁnd the new column to be included into the restricted master
problem. LPBoost [1] is a direct application of CG in Boosting. For the ﬁrst time  LPBoost shows
that in an LP framework  unknown weak hypotheses can be learned from the dual although the
space of all weak hypotheses is inﬁnitely large. This is the highlight of LPBoost  which has directly
inspired our work.

Metric learning using convex optimization has attracted a lot of attention recently [6–8]. These
work has made it possible to learn distance functions that are more appropriate for a speciﬁc task 
based on partially labeled data or proximity constraints. These techniques improve classiﬁcation
or clustering accuracy by taking advantage of prior information. There is plenty of work reported.
We list a few that are most relevant to ours. [6] learns a Mahalanobis metric for clustering using
convex optimization to minimize the distance between examples belonging to the same class  while
at the same time restricting examples in difference classes not to be too close. The work in [7] also
learns a Mahalanobis metric using SDP by optimizing a modiﬁed k-NN classiﬁer. They have used
ﬁrst-order alternating projection algorithms  which are faster than generic SDP solvers. The authors
in [8] learns a Mahalanobis by considering proximity relationships of training examples. The ﬁnal
formulation is also an SDP. They replace the positive semideﬁnite (PSD) conic constraint using a
sequence of linear constraints under the fact that a diagonal dominance matrix must be PSD (but not
vice versa). In other words the conic constraint is replaced by a more strict one. The feasibility set
shrinks and the solution obtained is not necessarily a solution of the original SDP.

3 Preliminaries

We begin with some notational conventions and basic deﬁnitions that will be useful.

Tr(·) is the trace of a square matrix and hX  Zi = Tr(XZ⊤) = Pij

A bold lower case letter x represents a column vector and an upper case letter X is a matrix. We
denote the space of D × D symmetric matrices by SD  and positive semideﬁnite matrices by SD
+.
Xij Zij calculates the inner
product of two matrices. An element-wise inequality between two vectors writes u ≤ v  which
means ui ≤ vi for all i.
We use X < 0 to indicate that matrix X is positive semideﬁnite. For a matrix X ∈ SD  the
following statements are equivalent: (1) X < 0 (X ∈ SD
+); (2) All eigenvalues of X are nonnegative
(λi(X) ≥ 0  i = 1  · · ·   D); and (3) ∀u ∈ RD  u⊤Xu ≥ 0.

3.1 Extreme Points of Trace-one Semideﬁnite Matrices

Before we present our main results  we prove an important theorem that serves the basis of the
proposed algorithm.

Deﬁnition 3.1 For any positive integer M  given a set of points {x1  ...  xM } in a real vector or
matrix space Sp  the convex hull of Sp spanned by M elements in Sp is deﬁned as:

convM (Sp) = (cid:26)XM

i=1

θixi(cid:12)(cid:12)(cid:12)

θi ≥ 0 XM

i=1

θi = 1  xi ∈ Sp(cid:27) .

Deﬁne the convex hull1 of Sp as:
conv(Sp) = [M
= (cid:26)XM
θixi(cid:12)(cid:12)(cid:12)

i=1

Here Z+ denotes the set of all positive integers.

convM (Sp)

θi ≥ 0 XM

i=1

θi = 1  xi ∈ Sp  M ∈ Z+(cid:27) .

Deﬁnition 3.2 Let us deﬁne Γ1 to be the space of all positive semideﬁnite matrices X ∈ SD
trace equaling one:

+ with

Γ1 = {X | X < 0  Tr(X) = 1 } ; 2

and Ω1 to be the space of all positive semideﬁnite matrices with both trace and rank equaling one:

We also deﬁne Γ2 as the convex hull of Ω1  i.e. 

Ω1 = {Z | Z < 0  Tr(Z) = 1  rank(Z) = 1 } .

Γ2 = conv(Ω1).

Lemma 3.3 Let Ω2 be a convex polytope deﬁned as Ω2 = {λ ∈ RD| λk ≥ 0  ∀k = 1  · · ·   D 
PD
k=1 λk = 1}  then the points with only one element equaling one and all the others being zeros

are the extreme points (vertexes) of Ω2. All the other points can not be extreme points.

Ω2: λ′ = PM

i=1 θiλi  θi > 0  PM

Proof: Without loss of generality  let us consider such a point λ′ = {1  0  · · ·   0}. If λ′ is not an
extreme point of Ω2  then it must be expressed as an convex combination of a few other points in
k = 0 
∀k = 2  · · ·   D. It follows that λi
1 = 1 ∀i. This is
inconsistent with λi 6= λ′. Therefore such a convex combination does not exist and λ′ must be
an extreme point. It is trivial to see that any λ that has more than one active element is an convex
combination of the above-deﬁned extreme points. So they can not be extreme points.
(cid:3)

i=1 θi = 1 and λi 6= λ′. Then we have equations: PM
k = 0  ∀i and k = 2  · · ·   D. That means  λi

i=1 θiλi

Theorem 3.4 Γ1 equals to Γ2; i.e.  Γ1 is also the convex hull of Ω1. In other words  all Z ∈ Ω1 
forms the set of extreme points of Γ1.

with the following two facts: (1) a convex combination of PSD matrices is still a PSD matrix; (2)

Proof: It is easy to check that any convex combination Pi θiZi  such that Zi ∈ Ω1  resides in Γ1 
Tr(cid:0)Pi θiZi(cid:1) = Pi(cid:0)θi Tr(Zi)(cid:1) = 1.
By denoting λ1 ≥ · · · ≥ λD ≥ 0 the eigenvalues of a Z ∈ Γ1  we know that λ1 ≤ 1 because
PD
i=1 λi = Tr(Z) = 1. Therefore  all eigenvalues of Z must satisfy: λi ∈ [0  1]  ∀i = 1  · · ·   D
andPD
i λi = 1. By looking at the eigenvalues of Z and using Lemma 3.3  it is immediate to see that
a matrix Z such that Z < 0  Tr(Z) = 1 and rank(Z) > 1 can not be an extreme point of Γ1. The
only candidates for extreme points are those rank-one matrices (λ1 = 1 and λ2 ···  D = 0). Moreover 
it is not possible that some rank-one matrices are extreme points and others are not because the other
two constraints Z < 0 and Tr(Z) = 1 do not distinguish between different rank-one matrices.
Hence  all Z ∈ Ω1 forms the set of extreme points of Γ1. Furthermore  Γ1 is a convex and compact
set  which must have extreme points. Krein-Milman Theorem [9] tells us that a convex and compact
set is equal to the convex hull of its extreme points.
(cid:3)

This theorem is a special case of the results from [10] in the context of eigenvalue optimization. A
different proof for the above theorem’s general version can also be found in [11]. In the context of
SDP optimization  what is of interest about Theorem 3.4 is as follows: it tells us that a bounded
PSD matrix constraint X ∈ Γ1 can be equivalently replaced with a set of constrains which belong to
Γ2. At the ﬁrst glance  this is a highly counterintuitive proposition because Γ2 involves many more
complicated constraints. Both θi and Zi (∀i = 1  · · ·   M) are unknown variables. Even worse  M
could be extremely (or even indeﬁnitely) large.

1Strictly speaking  the union of convex hulls may not be a convex hull in general. It is a linear convex span.
2Such a matrix X is called a density matrix  which is one of the main concepts in quantum physics. A
density matrix of rank one is called a pure state  and a density matrix of rank higher than one is called a mixed
state.

3.2 Boosting

Boosting is an example of ensemble learning  where multiple learners are trained to solve the same
problem. Typically a boosting algorithm [12] creates a single strong learner by incrementally adding
base (weak) learners to the ﬁnal strong learner. The base learner has an important impact on the
strong learner. In general  a boosting algorithm builds on a user-speciﬁed base learning procedure
and runs it repeatedly on modiﬁed data that are outputs from the previous iterations.

The inputs to a boosting algorithm are a set of training example x  and their corresponding class
labels y. The ﬁnal output strong classiﬁer takes the form

Here fi(·) is a base learner. From Theorem 3.4  we know that a matrix X ∈ Γ1 can be decomposed
as

θiZi  Zi ∈ Ω1.

(2)

θifi(x).

(1)

Fθ(x) = XM

i=1

X = XM

i=1

By observing the similarity between Equations (1) and (2)  we may view Zi as a weak classiﬁer
and the matrix X as the strong classiﬁer we want to learn. This is exactly the problem that boosting
methods have been designed to solve. This observation inspires us to solve a special type of SDPs
using boosting techniques.

A sparse greedy approximation algorithm proposed by Zhang [2] is an efﬁcient way of solving a
class of convex problems  which provides fast convergence rates. It is shown in [2] that boosting
algorithms can be interpreted within the general framework of [2]. The main idea of sequential
greedy approximation is as follows. Given an initialization u0 ∈ V  V can be a subset of a linear
vector space  a matrix space or a functional space. The algorithm ﬁnds ui ∈ V  i = 1  · · ·   and
0 ≤ λ ≤ 1 such that the cost function F ((1 − λ)ui−1 + λui) is approximately minimized; Then the
solution ui is updated as ui = (1 − λ)ui−1 + λui and the iteration goes on.

4 Large-margin Semideﬁnite Metric Learning

We consider the Mahalanobis metric learning problem as an example although the proposed tech-
nique can be applied to many other problems in machine learning such as nonparametric kernel
matrix learning [13].
We are given a set of training examples ai ∈ RD  i = 1  2  · · · . The task is to learn a distance metric
such that with the learned metric  classiﬁcation or clustering will achieve better performance on
testing data. The information available is a bunch of relative distance comparisons. Mathematically
we are given a set S which contains the training triplets: S = {(ai  aj  ak)| distij < distik} 
where distij measures distance between ai and aj with a certain metric. In this work we focus
on the case that dist calculates the Mahalanobis distance. Equivalently we are learning a linear
transformation P ∈ RD×d such that dist is the Euclidean distance in the projected space: distij =
2 = (ai − aj)⊤PP⊤(ai − aj). It is not difﬁcult to see that the inequalities in the set
S are non-convex because a difference of quadratic terms in P is involved. In order to convexify the
inequalities in S  a new variable X = PP⊤ is instead used. This is a typical technique for modeling
an SDP problem [14]. We wish to maximize the margin that is deﬁned as the distance between
distij and distik. That is  ρ = distik − distij = (ai − ak)⊤X(ai − ak) − (ai − aj)⊤X(ai − aj).
Also one may use soft margin to tolerate noisy data. Putting these thoughts together  the ﬁnal convex
program we want to optimize is:

(cid:13)(cid:13)
P⊤ai − P⊤aj(cid:13)(cid:13)

2

max
ρ X ξ

ρ − CX|S|

r=1

ξr

s.t. X < 0  Tr(X) = 1  ξ ≥ 0 

(3)

(ai − ak)⊤X(ai − ak) − (ai − aj)⊤X(ai − aj) ≥ ρ − ξr 
∀(ai  aj  ak) ∈ S.

Here r indexes the training set S. |S| denotes the size of S. C is a trade-off parameter that balances
the training error and the margin. Same as in support vector machine  the slack variable ξ ≥ 0

corresponds to the soft-margin hinge loss. Note that the constraint Tr(X) = 1 removes the scale
ambiguity because the distance inequalities are scale invariant.

To simplify our exposition  we write

Ar = (ai − ak)(ai − ak)⊤ − (ai − aj)(ai − aj)⊤.

The last constraint in (3) is then written

hAr  Xi ≥ ρ − ξr  ∀Ar built from S; r = 1  · · · |S|.

(4)

(5)

Problem (3) is a typical SDP since it has a linear cost function and linear constraints plus a PSD
conic constraint. Therefore it can be solved using off-the-shelf SDP solvers like CSDP [15]. As
mentioned general interior-point SDP solvers do not scale well to large-sized problems. Current
solvers can only solve problems up to a few thousand variables  which makes many applications
intractable. For example  in face recognition if the inputs are 30 × 30 images  then D = 900 and
there would be 0.41 million variables. Next we show how we reformulate the above SDP into an LP.

5 Boosting via Matrix-Generation Linear Programming

Using Theorem 3.4  we can replace the PSD conic constraint in (3) with a linear convex combination

of rank-one unitary PSD matrices: X = PM

i=1 θiZi. Substituting X in Problem (3)  we obtain

max
ρ θ ξ Z

ρ − CX|S|

r=1

ξr

s.t. ξ ≥ 0 

i=1 θiZi(cid:11) = PM

i=1(cid:10)Ar  Zi(cid:11)θi ≥ ρ − ξr 

∀Ar built from S; r = 1  · · · |S| 

(cid:10)Ar PM
PM

i=1 θi = 1  θ ≥ 0 

Zi ∈ Ω1  i = 1  · · ·   M.

(P1)

This above problem is still very hard to solve since it has non-convex rank constraints and an in-
deﬁnite number of variables (M is indeﬁnite because there are an indeﬁnite number of rank-one
matrices). However if we somehow know matrices Zi (i = 1  · · · ) a priori  we can then drop all the
constraints imposed on Zi (i = 1  · · · ) and the problem becomes a linear program; or more precisely
a semi-inﬁnite linear program (SILP) because it has an inﬁnitely large set of variables θ.

Column generation is a state-of-the-art method for optimally solving difﬁcult large-scale optimiza-
tion problems. It is a method to avoid considering all variables of a problem explicitly. If an LP
has extremely many variables (columns) but much fewer constraints  CG can be very beneﬁcial.
The crucial insight behind CG is: for an LP problem with many variables  the number of non-zero
variables of the optimal solution is equal to the number of constraints  hence although the number
of possible variables may be large  we only need a small subset of these in the optimal solution. It
works by only considering a small subset of the entire variable set. Once it is solved  we ask the
question: “Are there any other variables that can be included to improve the solution?”. So we must
be able to solve the subproblem: given a set of dual values  one either identiﬁes a variable that has
a favorable reduced cost  or indicates that such a variable does not exist. In essence  CG ﬁnds the
variables with negative reduced costs without explicitly enumerating all variables. For a general LP 
this may not be possible. But for some types of problems it is possible.

We now consider Problem (P1) as if all Zi  (i = 1  · · · ) were known. The dual of (P1) is easily
derived:

min
π w

π

s.t. P|S|
r=1(cid:10)Ar  Zi(cid:11)wr ≤ π  i = 1  · · ·   M 
P|S|
r=1 wr = 1 

0 ≤ wr ≤ C  r = 1  · · ·   |S|.

(D1)

For convex programs with strong duality  the dual gap is zeros  which means the optimal value of
the primal and dual problems coincide. For LPs and SDPs  strong duality holds under very mild
conditions (almost always satisﬁed by LPs and SDPs considered here).

We now only consider a small subset of the variables in the primal; i.e.  only a subset of Z (denoted
by ˜Z)3 is used. The LP solved using ˜Z is usually termed restricted master problem (RMP). Because
the primal variables correspond to the dual constraints  solving RMP is equivalent to solving a
relaxed version of the dual problem. With a ﬁnite ˜Z  the ﬁrst set of constraints in (D1) are ﬁnite  and
we can solve the LP that satisﬁes all the existing constraints.

If we can prove that among all the constraints that we have not added to the dual problem  no
single constraint is violated  then we can conclude that solving the restricted problem is equivalent
to solving the original problem. Otherwise  there exists at least one constraint that is violated. The
violated constraints correspond to variables in primal that are not in RMP. Adding these variables
to RMP leads to a new RMP that needs to be re-optimized. In our case  by ﬁnding the violated
constraint  we generate a rank-one matrix Z′. Hence  as in LPBoost [1] we have a base learning
algorithm as an oracle that either ﬁnds a new Z′ such that

where ˜π is the solution of the current restricted problem  or a guarantee that such a Z′ does not exist.
To make convergence fast  we ﬁnd the one that has largest deviation. That is 

P|S|
r=1(cid:10)Ar  Z′(cid:11)wr > ˜π 

Z′ = argmaxZnP|S|

r=1(cid:10)Ar  Z(cid:11) ˜wr  s.t. Z ∈ Ω1o .

(B1)

Again here ˜wr (r = 1  · · ·   |S|) are obtained by solving the current restricted dual problem (D1). Let
us denote Opt(B1) the optimal value of the optimization problem in (B1). We now have a criterion
that guarantees the optimal convex combination over all Z’s satisfying the constraints in Γ2 has been
found. If Opt(B1) ≤ ˜π  then we are done—we have solved the original problem.
The presented algorithm is a variant of the CG technique. At each iteration  a new matrix is gener-
ated  hence the name matrix generation.

5.1 Base Learning Algorithm

In this section  we show that the optimization problem (B1) can be exactly and efﬁciently solved
using eigen-decomposition.

From Z < 0 and rank(Z) = 1  we know that Z has the format: Z = uu⊤  u ∈ RD; and Tr(Z) = 1
means kuk2 = 1. We have

By denoting

P|S|
r=1(cid:10)Ar  Z(cid:11) ˜wr = (cid:10)P|S|

the optimization in (B1) equals:

max

u

r=1 ˜wrAr(cid:1)u⊤.

r=1 ˜wrAr  Z(cid:11) = u(cid:0)P|S|
˜H = P|S|
u⊤ ˜Hu  subject to kuk2 = 1.

r=1 ˜wrAr 

(6)

(7)

It is clear that the largest eigenvalue of ˜H  λmax( ˜H)  and its corresponding eigenvector u1 give the
solution to the above problem. Note that ˜H is symmetric. Therefore we have the solution of the
original problem (B1): Opt(B1) = λmax( ˜H) and Z′ = u1u⊤
1 .
There are approximate eigenvalue solvers  which guarantee that for a symmetric matrix U and any
ε > 0  a vector v is found such that v⊤Uv ≥ λmax −ε. To approximately ﬁnd the largest eigenvalue
and eigenvector can be very efﬁcient using Lanczos or power method. We use the MATLAB function
eigs to calculate the largest eigenvector  which calls mex ﬁles of ARPACK. ARPACK is a collection
of Fortran subroutines designed to solve large scale eigenvalue problems. When the input matrix is
symmetric  this software uses a variant of the Lanczos process called the implicitly restarted Lanczos
method [16].

3We also use ˜θ  ˜π and ˜w etc. to denote the solution of the current RMP and its dual.

Algorithm 1: PSDBoost for semideﬁnite metric learning.
Input: Training set triplets (ai  aj  ak) ∈ S; Calculate Ar  r = 1  · · · from S using Equation (4).
Initialization:

1. M = 1 (no bases selected);
2. θ = 0 (all primal coefﬁcients are zeros);
3. π = 0;
4. wr = 1

|S|   r = 1  · · ·   |S| (uniform dual weights).

while true do

1. Find a new base Z′ by solving Problem (B1)  i.e.  eigen-decomposition of ˜H in (6);
2. if Opt(B1) ≤ π then break (problem solved);
3. Add Z′ to the restricted master problem  which corresponds to a new constraint in

Problem (D1);

4. Solve the dual (D1) to obtain updated π and wr (r = 1  · · ·   |S|);
5. M = M + 1 (base count).

end
Output:

1. Calculate the primal variable θ from the optimality conditions and the last solved dual LP;

2. The learned PSD matrix X ∈ RD×D  X = PM

i=1 θiZi.

Putting all the above analysis together  we summarize our PSDBoost algorithm for metric learning
in Algorithm 1. Note that  in practice  we can relax the convergence criterion by setting a small
positive threshold ε′ > 0 in order to obtain a good approximation quickly. Namely the convergence
criterion is Opt(B1) ≤ π + ε′.
The algorithm has some appealing properties. Each iteration the solution is provably better than the
preceding one  and has rank at most one larger. Hence after M iterations the algorithm attains a
solution with rank at most M. The algorithm preserves CG’s property that each iteration improves
the quality of the solution. The bounded rank follows the fact that rank(A + B) ≤ rank(A) +
rank(B)  ∀ matrices A and B.
An advantage of the proposed PSDBoost algorithm over standard boosting schemes is the totally-
corrective weight update in each iteration  which leads faster convergence. The coordinate descent
optimization employed by standard boosting algorithms is known to have a slow convergence rate in
general. However  the price of this totally-corrective update is obvious. PSDBoost spans the space of
the parameter X incrementally. The computational cost for solving the subproblem grows with the
number of linear constraints  which increases by one at each iteration. Also it needs more and more
memory to store the generated base learner Zi as represented by a series of unit vectors. To alleviate
this problem  one can use a selection and compression mechanism as the aggregation step of bundle
methods [17]. When the size of of the bundle becomes too large  bundle methods select columns to
be discarded and the selected information is aggregated into a single one. It can be shown that as
long as the aggregated column is introduced in the bundle  the bundle algorithm remains convergent 
although different selection of discarded columns may lead to different convergence speeds. See [17]
for details.

6 Experiments

In the ﬁrst experiment  we have artiﬁcially generated 600 points in 24 dimensions. Therefore the
learned metric is of size 24 × 24. The triplets are obtained in this way: For a point ai  we ﬁnd its
nearest neighbor in the same class aj and its nearest neighbor in the different class ak. We subsample
to have 550 triplets for training. To show the convergence  we have plotted the optimal values of
the dual problem (D1) at each iteration in Figure 1. We see that PSDBoost quickly converges to

the near-optimal solution. We have observed the so-called tailing-off effect of CG on large datasets.
While a near-optimal solution is approached considerably fast  only little progress per iteration is
made close to the optimum. Stabilization techniques have been introduced to partially alleviate
this problem [3]. However  approximate solutions are sufﬁcient for most machine learning tasks.
Moreover  we usually are not interested in the numerical accuracy of the solution but the test error
for many problems such as metric and kernel learning.

The second experiment uses the Pendigits data from the UCI repository that contains handwritten
samples of digits 1  5  7  9. The data for each digits are 16-dimensional. 80 samples for each digit
are used for training and 500 for each digit for testing. The results show that PSDBoost converges
quickly and the learned metric is very similar to the results obtained by a standard SDP solver. The
classiﬁcation errors on testing data with a 1-nearest neighbor are identical using the metrics learned
by PSDBoost and a standard SDP solver. Both are 1.3%.

7 Conclusion

We have presented a new boosting algorithm  PSDBoost  for learning a positive semideﬁnite ma-
trix. In particular  as an example  we use PSDBoost to learn a distance metric for classiﬁcation.
PSDBoost can also be used to learn a kernel matrix  which is of interest in machine learning. We
are currently exploring new applications with PSDBoost. Also we want to know what kind of SDP
optimization problems can be approximately solved by PSDBoost.

References
[1] A. Demiriz  K.P. Bennett  and J. Shawe-Taylor. Linear programming boosting via column generation. Mach. Learn.  46(1-3):225–254 

2002.

[2] T. Zhang. Sequential greedy approximation for certain convex optimization problems. IEEE Trans. Inf. Theory  49(3):682–691  2003.
[3] M. E. L¨ubbecke and J. Desrosiers. Selected topics in column generation. Operation Res.  53(6):1007–1023  2005.
[4]
[5] G. B. Dantzig and P. Wolfe. Decomposition principle for linear programs. Operation Res.  8(1):101–111  1960.
[6] E. Xing  A. Ng  M. Jordan  and S. Russell. Distance metric learning  with application to clustering with side-information. In Proc. Adv.

ILOG  Inc. CPLEX 11.1  2008. http://www.ilog.com/products/cplex/.

Neural Inf. Process. Syst. MIT Press  2002.

[7] K. Q. Weinberger  J. Blitzer  and L. K. Saul. Distance metric learning for large margin nearest neighbor classiﬁcation. In Proc. Adv.

Neural Inf. Process. Syst.  pages 1473–1480  2005.

[8] R. Rosales and G. Fung. Learning sparse metrics via linear programming. In Proc. ACM Int. Conf. Knowledge Discovery & Data Mining 

pages 367–373  Philadelphia  PA  USA  2006.

[9] M. Krein and D. Milman. On extreme points of regular convex sets. Studia Mathematica  9:133–138  1940.
[10] M. L. Overton and R. S. Womersley. On the sum of the largest eigenvalues of a symmetric matrix. SIAM J. Matrix Anal. Appl. 

13(1):41–45  1992.

[11] P. A. Fillmore and J. P. Williams. Some convexity theorems for matrices. Glasgow Math. Journal  12:110–117  1971.
[12] R. E. Schapire. Theoretical views of boosting and applications. In Proc. Int. Conf. Algorithmic Learn. Theory  pages 13–25  London 

UK  1999. Springer-Verlag.

[13] B. Kulis  M. Sustik  and I. Dhillon. Learning low-rank kernel matrices. In Proc. Int. Conf. Mach. Learn.  pages 505–512  Pittsburgh 

Pennsylvania  2006.

[14] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.
[15] B. Borchers. CSDP  a C library for semideﬁnite programming. Optim. Methods and Softw.  11(1):613–623  1999.
[16] D. Calvetti  L. Reichel  and D. C. Sorensen. An implicitly restarted Lanczos method for large symmetric eigenvalue problems. Elec.

Trans. Numer. Anal  2:1–21  Mar 1994. http://etna.mcs.kent.edu.

[17] J. F. Bonnans  J. C. Gilbert  C. Lemar´echal  and C. A. Sagastiz´abal. Numerical Optimization: Theoretical and Practical Aspects (1st

edition). Springer-Verlag  Berlin  2003.

)

1

D

(
t
p
O

5

0

−5

−10

−15

−20

−25
0

50

100

iterations

150

200

)

1

D

(
t
p
O

300

200

100

0

−100

−200

−300
0

50

iterations

100

150

Figure 1: The objective value of the dual problem (D1) on the ﬁrst (left) and second (right) experiment. The dashed line shows the ground
truth obtained by directly solving the original primal SDP (3) using interior-point methods.

,Kirthevasan Kandasamy
Gautam Dasarathy
Junier Oliva
Jeff Schneider
Barnabas Poczos