2017,Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive Direct Search,Computational models in fields such as computational neuroscience  are often evaluated via stochastic simulation or numerical approximation. Fitting these models implies a difficult optimization problem over complex  possibly noisy parameter landscapes. Bayesian optimization (BO) has been successfully applied to solving expensive black-box problems in engineering and machine learning.  Here we explore whether BO can be applied as a general tool for model fitting. First  we present a novel hybrid BO algorithm  Bayesian adaptive direct search (BADS)  that achieves competitive performance with an affordable computational overhead for the running time of typical models. We then perform an extensive benchmark of BADS vs. many common and state-of-the-art nonconvex  derivative-free optimizers  on a set of model-fitting problems with real data and models from six studies in behavioral  cognitive  and computational neuroscience. With default settings  BADS consistently finds comparable or better solutions than other methods  including `vanilla' BO  showing great promise for advanced BO techniques  and BADS in particular  as a general model-fitting tool.,Practical Bayesian Optimization for Model Fitting

with Bayesian Adaptive Direct Search

Luigi Acerbi∗

Center for Neural Science

New York University

luigi.acerbi@nyu.edu

Abstract

Center for Neural Science & Dept. of Psychology

Wei Ji Ma

New York University
weijima@nyu.edu

Computational models in ﬁelds such as computational neuroscience are often
evaluated via stochastic simulation or numerical approximation. Fitting these
models implies a difﬁcult optimization problem over complex  possibly noisy
parameter landscapes. Bayesian optimization (BO) has been successfully applied
to solving expensive black-box problems in engineering and machine learning.
Here we explore whether BO can be applied as a general tool for model ﬁtting.
First  we present a novel hybrid BO algorithm  Bayesian adaptive direct search
(BADS)  that achieves competitive performance with an affordable computational
overhead for the running time of typical models. We then perform an extensive
benchmark of BADS vs. many common and state-of-the-art nonconvex  derivative-
free optimizers  on a set of model-ﬁtting problems with real data and models
from six studies in behavioral  cognitive  and computational neuroscience. With
default settings  BADS consistently ﬁnds comparable or better solutions than
other methods  including ‘vanilla’ BO  showing great promise for advanced BO
techniques  and BADS in particular  as a general model-ﬁtting tool.

1

Introduction

Many complex  nonlinear computational models in ﬁelds such as behaviorial  cognitive  and compu-
tational neuroscience cannot be evaluated analytically  but require moderately expensive numerical
approximations or simulations. In these cases  ﬁnding the maximum-likelihood (ML) solution –
for parameter estimation  or model selection – requires the costly exploration of a rough or noisy
nonconvex landscape  in which gradients are often unavailable to guide the search.
Here we consider the problem of ﬁnding the (global) optimum x∗ = argminx∈X E [f (x)] of a
possibly noisy objective f over a (bounded) domain X ⊆ RD  where the function f can be intended
as the (negative) log likelihood of a parameter vector x for a given dataset and model  but is generally
a black box. With many derivative-free optimization algorithms available to the researcher [1]  it is
unclear which one should be chosen. Crucially  an inadequate optimizer can hinder progress  limit
the complexity of the models that can be ﬁt  and even cast doubt on the reliability of one’s ﬁndings.
Bayesian optimization (BO) is a state-of-the-art machine learning framework for optimizing expensive
and possibly noisy black-box functions [2  3  4]. This makes it an ideal candidate for solving difﬁcult
model-ﬁtting problems. Yet there are several obstacles to a widespread usage of BO as a general tool
for model ﬁtting. First  traditional BO methods target very costly problems  such as hyperparameter
tuning [5]  whereas evaluating a typical behavioral model might only have a moderate computational
cost (e.g.  0.1-10 s per evaluation). This implies major differences in what is considered an acceptable
algorithmic overhead  and in the maximum number of allowed function evaluations (e.g.  hundreds vs.
∗Current address: Département des neurosciences fondamentales  Université de Genève  CMU  1 rue

Michel-Servet  1206 Genève  Switzerland. E-mail: luigi.acerbi@gmail.com.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

thousands). Second  it is unclear how BO methods would fare in this regime against commonly used
and state-of-the-art  non-Bayesian optimizers. Finally  BO might be perceived by non-practitioners
as an advanced tool that requires speciﬁc technical knowledge to be implemented or tuned.
We address these issues by developing a novel hybrid BO algorithm  Bayesian Adaptive Direct Search
(BADS)  that achieves competitive performance at a small computational cost. We tested BADS 
together with a wide array of commonly used optimizers  on a novel benchmark set of model-ﬁtting
problems with real data and models drawn from studies in cognitive  behaviorial and computational
neuroscience. Finally  we make BADS available as a free MATLAB package with the same user
interface as existing optimizers and that can be used out-of-the-box with no tuning.1
BADS is a hybrid BO method in that it combines the mesh adaptive direct search (MADS) framework
[6] (Section 2.1) with a BO search performed via a local Gaussian process (GP) surrogate (Section
2.2)  implemented via a number of heuristics for efﬁciency (Section 3). BADS proves to be highly
competitive on both artiﬁcial functions and real-world model-ﬁtting problems (Section 4)  showing
promise as a general tool for model ﬁtting in computational neuroscience and related ﬁelds.

Related work There is a large literature about (Bayesian) optimization of expensive  possibly
stochastic  computer simulations  mostly used in machine learning [3  4  5] or engineering (known
as kriging-based optimization) [7  8  9]. Recent work has combined MADS with treed GP models
for constrained optimization (TGP-MADS [9]). Crucially  these methods have large overheads and
may require problem-speciﬁc tuning  making them impractical as a generic tool for model ﬁtting.
Cheaper but less precise surrogate models than GPs have been proposed  such as random forests [10] 
Parzen estimators [11]  and dynamic trees [12]. In this paper  we focus on BO based on traditional
GP surrogates  leaving the analysis of alternative models for future work (see Conclusions).

2 Optimization frameworks

2.1 Mesh adaptive direct search (MADS)

The MADS algorithm is a directional direct search framework for nonlinear optimization [6  13].
Brieﬂy  MADS seeks to improve the current solution by testing points in the neighborhood of the
current point (the incumbent)  by moving one step in each direction on an iteration-dependent mesh.
In addition  the MADS framework can incorporate in the optimization any arbitrary search strategy
which proposes additional test points that lie on the mesh.

MADS deﬁnes the current mesh at the k-th iteration as Mk =(cid:83)

k Dz : z ∈ ND(cid:9) 

(cid:8)x + ∆mesh

∈ R+ is the
where Sk ⊂ Rn is the set of all points evaluated since the start of the iteration  ∆mesh
mesh size  and D is a ﬁxed matrix in RD×nD whose nD columns represent viable search directions.
We choose D = [ID −ID]  where ID is the identity matrix in dimension D.
Each iteration of MADS comprises of two stages  a SEARCH stage and an optional POLL stage. The
SEARCH stage evaluates a ﬁnite number of points proposed by a provided search strategy  with the
only restriction that the tested points lie on the current mesh. The search strategy is intended to inject
problem-speciﬁc information in the optimization. In BADS  we exploit the freedom of SEARCH to
perform Bayesian optimization in the neighborhood of the incumbent (see Section 2.2 and 3.3). The
POLL stage is performed if the SEARCH fails in ﬁnding a point with an improved objective value.

POLL constructs a poll set of candidate points  Pk  deﬁned as Pk = (cid:8)xk + ∆mesh

k v  for v ∈ Dk (typically  ∆poll

where xk is the incumbent and Dk is the set of polling directions constructed by taking discrete linear
combinations of the set of directions D. The poll size parameter ∆poll
deﬁnes the maximum
||v||). Points in the
length of poll displacement vectors ∆mesh
poll set can be evaluated in any order  and the POLL is opportunistic in that it can be stopped as soon
as a better solution is found. The POLL stage ensures theoretical convergence to a local stationary
point according to Clarke calculus for nonsmooth functions [6  14].
If either SEARCH or POLL are a success  ﬁnding a mesh point with an improved objective value  the
incumbent is updated and the mesh size remains the same or is multiplied by a factor τ > 1. If neither
SEARCH or POLL are successful  the incumbent does not move and the mesh size is divided by τ. The
algorithm proceeds until a stopping criterion is met (e.g.  maximum budget of function evaluations).

k v : v ∈ Dk

k ≥ ∆mesh

k

k ≈ ∆mesh

k

x∈Sk

k

(cid:9)  

1Code available at https://github.com/lacerbi/bads.

2

2.2 Bayesian optimization

X =(cid:8)x(i) ∈ X(cid:9)n
assume i.i.d. Gaussian observation noise such that f evaluated at x(i) returns y(i) ∼ N(cid:0)f (x(i))  σ2(cid:1) 

The typical form of Bayesian optimization (BO) [2] builds a Gaussian process (GP) approximation
of the objective f  which is used as a relatively inexpensive surrogate to guide the search towards
regions that are promising (low GP mean) and/or unknown (high GP uncertainty)  according to a rule 
the acquisition function  that formalizes the exploitation-exploration trade-off.
Gaussian processes GPs are a ﬂexible class of models for specifying prior distributions over
unknown functions f : X ⊆ RD → R [15]. GPs are speciﬁed by a mean function m : X → R and a
positive deﬁnite covariance  or kernel function k : X ×X → R. Given any ﬁnite collection of n points
i=1  the value of f at these points is assumed to be jointly Gaussian with mean
(m(x(1))  . . .   m(x(n)))(cid:62) and covariance matrix K  where Kij = k(x(i)  x(j)) for 1 ≤ i  j ≤ n. We
and y = (y(1)  . . .   y(n))(cid:62) is the vector of observed values. For a deterministic f  we still assume a
small σ > 0 to improve numerical stability of the GP [16]. Conveniently  observation of such (noisy)
function values will produce a GP posterior whose latent marginal conditional mean µ(x;{X  y}   θ)
and variance s2(x;{X  y}   θ) at a given point are available in closed form (see Supplementary
Material)  where θ is a hyperparameter vector for the mean  covariance  and likelihood. In the
following  we omit the dependency of µ and s2 from the data and GP parameters to reduce clutter.
Covariance functions Our main choice of stationary (translationally-invariant) covariance function
is the automatic relevance determination (ARD) rational quadratic (RQ) kernel 

(cid:20)

(cid:21)−α

D(cid:88)

d=1

kRQ (x  x(cid:48)) = σ2

f

1 +

1
2α

r2(x  x(cid:48))

 

with r2(x  x(cid:48)) =

(xd − x(cid:48)

d)2  

(1)

1
(cid:96)2
d

where σ2
f is the signal variance  (cid:96)1  . . .   (cid:96)D are the kernel length scales along each coordinate direction 
and α > 0 is the shape parameter. More common choices for Bayesian optimization include the
squared exponential (SE) kernel [9] or the twice-differentiable ARD Matérn 5/2 (M5/2) kernel [5] 
but we found the RQ kernel to work best in combination with our method (see Section 4.2). We also
consider composite periodic kernels for circular or periodic variables (see Supplementary Material).
Acquisition function For a given GP approximation of f  the acquisition function  a : X → R 
determines which point in X should be evaluated next via a proxy optimization xnext = argminxa(x).
We consider here the GP lower conﬁdence bound (LCB) metric [17] 

aLCB (x;{X  y}   θ) = µ (x) −(cid:112)νβts2 (x) 

(2)
where ν > 0 is a tunable parameter  t is the number of function evaluations so far  δ > 0 is a
probabilistic tolerance  and βt is a learning rate chosen to minimize cumulative regret under certain
assumptions. For BADS we use the recommended values ν = 0.2 and δ = 0.1 [17]. Another popular
choice is the (negative) expected improvement (EI) over the current best function value [18]  and an
historical  less used metric is the (negative) probability of improvement (PI) [19].

βt = 2 ln(cid:0)Dt2π2/(6δ)(cid:1)

3 Bayesian adaptive direct search (BADS)

We describe here the main steps of BADS (Algorithm 1). Brieﬂy  BADS alternates between a series
of fast  local BO steps (the SEARCH stage of MADS) and a systematic  slower exploration of the
mesh grid (POLL stage). The two stages complement each other  in that the SEARCH can explore
the space very effectively  provided an adequate surrogate model. When the SEARCH repeatedly
fails  meaning that the GP model is not helping the optimization (e.g.  due to a misspeciﬁed model 
or excess uncertainty)  BADS switches to POLL. The POLL stage performs a fail-safe  model-free
optimization  during which BADS gathers information about the local shape of the objective function 
so as to build a better surrogate for the next SEARCH. This alternation makes BADS able to deal
effectively and robustly with a variety of problems. See Supplementary Material for a full description.

3.1

Initial setup

Problem speciﬁcation The algorithm is initialized by providing a starting point x0  vectors of hard
lower/upper bounds LB  UB  and optional vectors of plausible lower/upper bounds PLB  PUB  with the

3

Algorithm 1 Bayesian Adaptive Direct Search
Input: objective function f  starting point x0  hard bounds LB  UB  (optional: plausible bounds PLB 

PUB  barrier function c  additional options)

0 ← 2−10  ∆poll

(cid:46) Section 3.1

if SEARCH is NOT successful then

(cid:46) Section 3.2
(cid:46) SEARCH stage  Section 3.3
(cid:46) local Bayesian optimization step

xsearch ← SEARCHORACLE
Evaluate f on xsearch  if improvement is sufﬁcient then break

0 ← 1  k ← 0  evaluate f on initial design
(update GP approximation at any step; reﬁt hyperparameters if necessary)
for 1 . . . nsearch do

1: Initialization: ∆mesh
2: repeat
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: until fevals > MaxFunEvals or ∆poll
(cid:46) stopping criteria
17: return xend = arg mink f (xk) (or xend = arg mink qβ(xk) for noisy objectives  Section 3.4)

compute poll set Pk
evaluate opportunistically f on Pk sorted by acquisition function

update incumbent xk+1
if POLL was successful then ∆mesh
else
k ← 1
2 ∆poll
∆mesh
k ← k + 1

k ← 1

2 ∆mesh

  ∆poll

k < 10−6 or stalling

(cid:46) optional POLL stage  Section 3.3

k ← 2∆mesh

k

  ∆poll

k ← 2∆poll

k

if iteration k is successful then

k

k

requirement that for each dimension 1 ≤ d ≤ D  LBd ≤ PLBd < PUBd ≤ UBd.2 Plausible bounds
identify a region in parameter space where most solutions are expected to lie. Hard upper/lower
bounds can be inﬁnite  but plausible bounds need to be ﬁnite. Problem variables whose hard bounds
are strictly positive and UBd ≥ 10 · LBd are automatically converted to log space. All variables
are then linearly rescaled to the standardized box [−1  1]D such that the box bounds correspond
to [PLB  PUB] in the original space. BADS supports bound or no constraints  and optionally other
constraints via a provided barrier function c (see Supplementary Material). The user can also specify
circular or periodic dimensions (such as angles); and whether the objective f is deterministic or noisy
(stochastic)  and in the latter case provide a coarse estimate of the noise (see Section 3.4).
Initial design The initial design consists of the provided starting point x0 and ninit = D additional
points chosen via a space-ﬁlling quasi-random Sobol sequence [20] in the standardized box  and
forced to lie on the mesh grid. If the user does not specify whether f is deterministic or stochastic 
the algorithm assesses it by performing two consecutive evaluations at x0.

3.2 GP model in BADS
The default GP model is speciﬁed by a constant mean function m ∈ R  a smooth ARD RQ kernel
(Eq. 1)  and we use aLCB (Eq. 2) as a default acquisition function.
Hyperparameters The default GP has hyperparameters θ = ((cid:96)1  . . .   (cid:96)D  σ2
f   α  σ2  m). We
impose an empirical Bayes prior on the GP hyperparameters based on the current training set
(see Supplementary Material)  and select θ via maximum a posteriori (MAP) estimation. We ﬁt θ
via a gradient-based nonlinear optimizer  starting from either the previous value of θ or a weighted
draw from the prior  as a means to escape local optima. We reﬁt the hyperparameters every 2D
to 5D function evaluations; more often earlier in the optimization  and whenever the current GP
is particularly inaccurate at predicting new points  according to a normality test on the residuals 

z(i) =(cid:0)y(i) − µ(x(i))(cid:1) /(cid:112)s2(x(i)) + σ2 (assumed independent  in ﬁrst approximation).

Training set The GP training set X consists of a subset of the points evaluated so far (the cache) 
selected to build a local approximation of the objective in the neighborhood of the incumbent xk 
constructed as follows. Each time X is rebuilt  points in the cache are sorted by their (cid:96)-scaled distance
r2 (Eq. 1) from xk. First  the closest nmin = 50 points are automatically added to X. Second 
up to 10D additional points with r ≤ 3ρ(α) are included in the set  where ρ(α) (cid:38) 1 is a radius
2A variable d can be ﬁxed by setting (x0)d = LBd = UBd = PLBd = PUBd. Fixed variables become

constants  and BADS runs on an optimization problem with reduced dimensionality.

4

e1/α − 1 (see
function that depends on the decay of the kernel. For the RQ kernel  ρRQ(α) =
Supplementary Material). Newly evaluated points are added incrementally to the set  using fast
rank-one updates of the GP posterior. The training set is rebuilt any time the incumbent is moved.

α

√

√

3.3

Implementation of the MADS framework

0 = 1 and ∆mesh

0 = 2−10 (in standardized space)  such that the initial poll steps can
We initialize ∆poll
span the plausible region  whereas the mesh grid is relatively ﬁne. We use τ = 2  and increase the
mesh size only after a successful POLL. We skip the POLL after a successful SEARCH.
Search stage We apply an aggressive  repeated SEARCH strategy that consists of up to nsearch =
max{D (cid:98)3 + D/2(cid:99)} unsuccessful SEARCH steps. In each step  we use a search oracle  based on a
local BO with the current GP  to produce a search point xsearch (see below). We evaluate f (xsearch)
and add it to the training set. If the improvement in objective value is none or insufﬁcient  that is less
than (∆poll
k )3/2  we continue searching  or switch to POLL after nsearch steps. Otherwise  we call it a
success and start a new SEARCH from scratch  centered on the updated incumbent.
Search oracle We choose xsearch via a fast  approximate optimization inspired by CMA-ES [21].
We sample batches of points in the neighborhood of the incumbent xk  drawn ∼ N (xs  λ2(∆poll
k )2Σ) 
where xs is the current search focus  Σ a search covariance matrix  and λ > 0 a scaling factor  and
we pick the point that optimizes the acquisition function (see Supplementary Material). We remove
from the SEARCH set candidate points that violate non-bound constraints (c(x) > 0)  and we project
candidate points that fall outside hard bounds to the closest mesh point inside the bounds. Across

SEARCH steps  we use both a diagonal matrix Σ(cid:96) with diagonal(cid:0)(cid:96)2

D/|(cid:96)|2(cid:1)  and a matrix

ΣWCM proportional to the weighted covariance matrix of points in X (each point weighted according
to a function of its ranking in terms of objective values yi). We choose between Σ(cid:96) and ΣWCM
probabilistically via a hedge strategy  based on their track record of cumulative improvement [22].
Poll stage We incorporate the GP approximation in the POLL in two ways: when constructing the
set of polling directions Dk  and when choosing the polling order. We generate Dk according to the
random LTMADS algorithm [6]  but then rescale each vector coordinate 1 ≤ d ≤ D proportionally
to the GP length scale (cid:96)d (see Supplementary Material). We discard poll vectors that do not satisfy
the given bound or nonbound constraints. Second  since the POLL is opportunistic  we evaluate points
in the poll set according to the ranking given by the acquisition function [9].
Stopping criteria We stop the optimization when the poll size ∆poll
k goes below a threshold (default
10−6); when reaching a maximum number of objective evaluations (default 500D); or if there is no
signiﬁcant improvement of the objective for more than 4 + (cid:98)D/2(cid:99) iterations. The algorithm returns
the optimum xend (transformed back to original coordinates) with the lowest objective value yend.

1/|(cid:96)|2  . . .   (cid:96)2

3.4 Noisy objective
In case of a noisy objective  we assume for the noise a hyperprior ln σ ∼ N (ln σest  1)  with σest
a base noise magnitude (default σest = 1  but the user can provide an estimate). To account for
additional uncertainty  we also make the following changes: double the minimum number of points
added to the training set  nmin = 100  and increase the maximum number to 200; increase the initial
design to ninit = 20; and double the number of allowed stalled iterations before stopping.
Uncertainty handling Due to noise  we cannot simply use the output values yi as ground truth in
the SEARCH and POLL stages. Instead  we replace yi with the GP latent quantile function [23]

qβ (x;{X  y}   θ) ≡ qβ(x) = µ (x) + Φ−1(β)s (x)  

(3)
where Φ−1(·) is the quantile function of the standard normal (plugin approach [24]). Moreover  we
modify the MADS procedure by keeping an incumbent set {xi}k
i=1  where xi is the incumbent at the
end of the i-th iteration. At the end of each POLL we re-evaluate qβ for all elements of the incumbent
set  in light of the new points added to the cache. We select as current (active) incumbent the point
with lowest qβ(xi). During optimization we set β = 0.5 (mean prediction only)  which promotes
exploration. We use a conservative βend = 0.999 for the last iteration  to select the optimum xend
returned by the algorithm in a robust manner. Instead of yend  we return either µ(xend) or an unbiased
estimate of E[f (xend)] obtained by averaging multiple evaluations (see Supplementary Material).

β ∈ [0.5  1) 

5

4 Experiments

We tested BADS and many optimizers with implementation available in MATLAB (R2015b  R2017a)
on a large set of artiﬁcial and real optimization problems (see Supplementary Material for details).

4.1 Design of the benchmark

Algorithms Besides BADS  we tested 16 optimization algorithms  including popular choices
such as Nelder-Mead (fminsearch [25])  several constrained nonlinear optimizers in the fmincon
function (default interior-point [26]  sequential quadratic programming sqp [27]  and active-set
actset [28])  genetic algorithms (ga [29])  random search (randsearch) as a baseline [30]; and
also less-known state-of-the-art methods for nonconvex derivative-free optimization [1]  such as
Multilevel Coordinate Search (MCS [31]) and CMA-ES [21  32] (cmaes  in different ﬂavors). For
noisy objectives  we included algorithms that explicitly handle uncertainty  such as snobfit [33]
and noisy CMA-ES [34]. Finally  to verify the advantage of BADS’ hybrid approach to BO  we also
tested a standard  ‘vanilla’ version of BO [5] (bayesopt  R2017a) on the set of real model-ﬁtting
problems (see below). For all algorithms  including BADS  we used default settings (no ﬁne-tuning).

Problem sets First  we considered a standard benchmark set of artiﬁcial  noiseless functions
(BBOB09 [35]  24 functions) in dimensions D ∈ {3  6  10  15}  for a total of 96 test functions. We
also created ‘noisy’ versions of the same set. Second  we collected model-ﬁtting problems from six
published or ongoing studies in cognitive and computational neuroscience (CCN17). The objectives
of the CCN17 set are negative log likelihood functions of an input parameter vector  for speciﬁed
datasets and models  and can be deterministic or stochastic. For each study in the CCN17 set we
asked its authors for six different real datasets (i.e.  subjects or neurons)  divided between one or two
main models of interest; collecting a total of 36 test functions with D ∈ {6  9  10  12  13}.
Procedure We ran 50 independent runs of each algorithm on each test function  with randomized
starting points and a budget of 500 × D function evaluations (200 × D for noisy problems). If an
algorithm terminated before depleting the budget  it was restarted from a new random point. We
consider a run successful if the current best (or returned  for noisy problems) function value is within a
given error tolerance ε > 0 from the true optimum fmin (or our best estimate thereof).3 For noiseless
problems  we compute the fraction of successful runs as a function of number of objective evaluations 
averaged over datasets/functions and over ε ∈ [0.01  10] (log spaced). This is a realistic range for ε 
as differences in log likelihood below 0.01 are irrelevant for model selection; an acceptable tolerance
is ε ∼ 0.5 (a difference in deviance  the metric used for AIC or BIC  less than 1); larger ε associate
with coarse solutions  but errors larger than 10 would induce excessive biases in model selection. For
noisy problems  what matters most is the solution xend that the algorithm actually returns  which 
depending on the algorithm  may not necessarily be the point with the lowest observed function value.
Since  unlike the noiseless case  we generally do not know the solutions that would be returned by any
algorithm at every time step  but only at the last step  we plot instead the fraction of successful runs
at 200 × D function evaluations as a function of ε  for ε ∈ [0.1  10] (noise makes higher precisions
moot)  and averaged over datasets/functions. In all plots we omit error bars for clarity (standard errors
would be about the size of the line markers or less).

4.2 Results on artiﬁcial functions (BBOB09)

The BBOB09 noiseless set [35] comprises of 24 functions divided in 5 groups with different properties:
separable; low or moderate conditioning; unimodal with high conditioning; multi-modal with adequate
/ with weak global structure. First  we use this benchmark to show the performance of different
conﬁgurations for BADS. Note that we selected the default conﬁguration (RQ kernel  aLCB) and
other algorithmic details by testing on a different benchmark set (see Supplementary Material). Fig 1
(left) shows aggregate results across all noiseless functions with D ∈ {3  6  10  15}  for alternative
choices of kernels and acquisition functions (only a subset is shown  such as the popular M5/2  EI
combination)  or by altering other features (such as setting nsearch = 1  or ﬁxing the search covariance
matrix to Σ(cid:96) or ΣWCM). Almost all changes from the default conﬁguration worsen performance.

3Note that the error tolerance ε is not a fractional error  as sometimes reported in optimization  because for

model comparison we typically care about (absolute) differences in log likelihoods.

6

Figure 1: Artiﬁcial test functions (BBOB09). Left & middle: Noiseless functions. Fraction of
successful runs (ε ∈ [0.01  10]) vs. # function evaluations per # dimensions  for D ∈ {3  6  10  15}
(96 test functions); for different BADS conﬁgurations (left) and all algorithms (middle). Right:
Heteroskedastic noise. Fraction of successful runs at 200 × D objective evaluations vs. tolerance ε.

Noiseless functions We then compared BADS to other algorithms (Fig 1 middle). Depending on
the number of function evaluations  the best optimizers are BADS  methods of the fmincon family 
and  for large budget of function evaluations  CMA-ES with active update of the covariance matrix.
Noisy functions We produce noisy versions of the BBOB09 set by adding i.i.d. Gaussian obser-
vation noise at each function evaluation  y(i) = f (x(i)) + σ(x(i))η(i)  with η(i) ∼ N (0  1). We
consider a variant with moderate homoskedastic (constant) noise (σ = 1)  and a variant with het-
eroskedastic noise with σ(x) = 1+0.1×(f (x)−fmin)  which follows the observation that variability
generally increases for solutions away from the optimum. For many functions in the BBOB09 set  this
heteroskedastic noise can become substantial (σ (cid:29) 10) away from the optimum. Fig 1 (right) shows
aggregate results for the heteroskedastic set (homoskedastic results are similar). BADS outperforms
all other optimizers  with CMA-ES (active  with or without the noisy option) coming second.
Notably  BADS performs well even on problems with non-stationary (location-dependent) features 
such as heteroskedastic noise  thanks to its local GP approximation.

4.3 Results on real model-ﬁtting problems (CCN17)

The objectives of the CCN17 set are deterministic (e.g.  computed via numerical approximation) for
three studies (Fig 2)  and noisy (e.g.  evaluated via simulation) for the other three (Fig 3).
The algorithmic cost of BADS is ∼ 0.03 s to 0.15 s per function evaluation  depending on D  mostly
due to the reﬁtting of the GP hyperparameters. This produces a non-negligible overhead  deﬁned as
100%× (total optimization time / total function time −1). For a fair comparison with other methods
with little or no overhead  for deterministic problems we also plot the effective performance of BADS
by accounting for the extra cost per function evaluation. In practice  this correction shifts rightward
the performance curve of BADS in log-iteration space  since each function evaluation with BADS has
an increased fractional time cost. For stochastic problems  we cannot compute effective performance
as easily  but there we found small overheads (< 5%)  due to more costly evaluations (more than 1 s).
For a direct comparison with standard BO  we also tested on the CCN17 set a ‘vanilla’ BO algorithm 
as implemented in MATLAB R2017a (bayesopt). This implementation closely follows [5]  with
optimization instead of marginalization over GP hyperparameters. Due to the fast-growing cost of
BO as a function of training set size  we allowed up to 300 training points for the GP  restarting the
BO algorithm from scratch with a different initial design every 300 BO iterations (until the total
budget of function evaluations was exhausted). The choice of 300 iterations already produced a large
average algorithmic overhead of ∼ 8 s per function evaluation. In showing the results of bayesopt 
we display raw performance without penalizing for the overhead.

Causal inference in visuo-vestibular perception Causal inference (CI) in perception is the pro-
cess whereby the brain decides whether to integrate or segregate multisensory cues that could arise
from the same or from different sources [39]. This study investigates CI in visuo-vestibular heading

7

Function evaluations / D1050100500Fraction solved00.250.50.751BBOB09 noiseless (BADS variants)bads (rq lcb default)bads (search-wcm)bads (m5/2 ei)bads (search-ℓ)bads (se pi)bads ( =1)Function evaluations / D1050100500Fraction solved00.250.50.751BBOB09 noiselessbadsfmincon (actset)fminconfmincon (sqp)cmaes (active)mcsfminsearchcmaesglobalpatternsearchsimulannealbndparticleswarmgarandsearchError tolerance ε0.10.31310Fraction solved at 200×D func. evals.00.250.50.751BBOB09 with heteroskedastic noisebadscmaes (noisy active)cmaes (noisy)snobfitparticleswarmpatternsearchmcsgasimulannealbndfmincon (actset)randsearchfminconfmincon (sqp)fminsearchglobalsearchnFigure 2: Real model-ﬁtting problems (CCN17  deterministic). Fraction of successful runs (ε ∈
[0.01  10]) vs. # function evaluations per # dimensions. Left: Causal inference in visuo-vestibular
perception [36] (6 subjects  D = 10). Middle: Bayesian conﬁdence in perceptual categorization [37]
(6 subjects  D = 13). Right: Neural model of orientation selectivity [38] (6 neurons  D = 12).

perception across tasks and under different levels of visual reliability  via a factorial model comparison
[36]. For our benchmark we ﬁt three subjects with a Bayesian CI model (D = 10)  and another three
with a ﬁxed-criterion CI model (D = 10) that disregards visual reliability. Both models include
heading-dependent likelihoods and marginalization of the decision variable over the latent space of
noisy sensory measurements (xvis  xvest)  solved via nested numerical integration in 1-D and 2-D.
Bayesian conﬁdence in perceptual categorization This study investigates the Bayesian conﬁ-
dence hypothesis that subjective judgments of conﬁdence are directly related to the posterior probabil-
ity the observer assigns to a learnt perceptual category [37] (e.g.  whether the orientation of a drifting
Gabor patch belongs to a ‘narrow’ or to a ‘wide’ category). For our benchmark we ﬁt six subjects
to the ‘Ultrastrong’ Bayesian conﬁdence model (D = 13)  which uses the same mapping between
posterior probability and conﬁdence across two tasks with different distributions of stimuli. This
model includes a latent noisy decision variable  marginalized over via 1-D numerical integration.
Neural model of orientation selectivity The authors of this study explore the origins of diversity of
neuronal orientation selectivity in visual cortex via novel stimuli (orientation mixtures) and modeling
[38]. We ﬁt the responses of ﬁve V1 and one V2 cells with the authors’ neuronal model (D = 12)
that combines effects of ﬁltering  suppression  and response nonlinearity [38]. The model has one
circular parameter  the preferred direction of motion of the neuron. The model is analytical but still
computationally expensive due to large datasets and a cascade of several nonlinear operations.
Word recognition memory This study models a word recognition task in which subjects rated their
conﬁdence that a presented word was in a previously studied list [40] (data from [41]). We consider
six subjects divided between two normative models  the ‘Retrieving Effectively from Memory’ model
[42] (D = 9) and a similar  novel model4 (D = 6). Both models use Monte Carlo methods to draw
random samples from a large space of latent noisy memories  yielding a stochastic log likelihood.
Target detection and localization This study looks at differences in observers’ decision making
strategies in target detection (‘was the target present?’) and localization (‘which one was the target?’)
with displays of 2  3  4  or 6 oriented Gabor patches.5 Here we ﬁt six subjects with a previously
derived ideal observer model [43  44] (D = 6) with variable-precision noise [45]  assuming shared
parameters between detection and localization. The log likelihood is evaluated via simulation due to
marginalization over latent noisy measurements of stimuli orientations with variable precision.
Combinatorial board game playing This study analyzes people’s strategies in a four-in-a-row
game played on a 4-by-9 board against human opponents ([46]  Experiment 1). We ﬁt the data of six
players with the main model (D = 10)  which is based on a Best-First exploration of a decision tree
guided by a feature-based value heuristic. The model also includes feature dropping  value noise  and
lapses  to better capture human variability. Model evaluation is computationally expensive due to the

4Unpublished; upcoming work from Aspen H. Yoo and Wei Ji Ma.
5Unpublished; upcoming work from Andra Mihali and Wei Ji Ma.

8

1050100500Function evaluations / D00.250.50.751Fraction solvedCCN17 causal inference[overhead-corrected  24%]badsbadscmaes (active)cmaesfminsearchpatternsearchparticleswarmglobalsimulannealbndfminconfmincon (sqp)mcsgafmincon (actset)randsearchbayesopt1050100500Function evaluations / D00.250.50.751Fraction solvedCCN17 Bayesian confidencebadsbadsfminconfmincon (sqp)fmincon (actset)cmaes (active)cmaesmcspatternsearchfminsearchparticleswarmglobalrandsearchsimulannealbndgabayesopt1050100500Function evaluations / D00.250.50.751Fraction solvedCCN17 neuronal selectivitybadsbadsfminconfmincon (sqp)fmincon (actset)cmaes (active)cmaesmcsfminsearchpatternsearchsimulannealbndgaglobalparticleswarmrandsearchbayesopt[overhead-corrected  68%][overhead-corrected  14%]Figure 3: Real model-ﬁtting problems (CCN17  noisy). Fraction of successful runs at 200 × D
objective evaluations vs. tolerance ε. Left: Conﬁdence in word recognition memory [40] (6 subjects 
D = 6  9). Middle: Target detection and localization [44] (6 subjects  D = 6). Right: Combinatorial
board game playing [46] (6 subjects  D = 10).

construction and evaluation of trees of future board states  and achieved via inverse binomial sampling 
an unbiased stochastic estimator of the log likelihood [46]. Due to prohibitive computational costs 
here we only test major algorithms (MCS is the method used in the paper [46]); see Fig 3 right.
In all problems  BADS consistently performs on par with or outperforms all other tested optimizers 
even when accounting for its extra algorithmic cost. The second best algorithm is either some ﬂavor
of CMA-ES or  for some deterministic problems  a member of the fmincon family. Crucially  their
ranking across problems is inconsistent  with both CMA-ES and fmincon performing occasionally
quite poorly (e.g.  fmincon does poorly in the causal inference set because of small ﬂuctuations
in the log likelihood landscape caused by coarse numerical integration). Interestingly  vanilla BO
(bayesopt) performs poorly on all problems  often at the level of random search  and always
substantially worse than BADS  even without accounting for the much larger overhead of bayesopt.
The solutions found by bayesopt are often hundreds (even thousands) points of log likelihood from
the optimum. This failure is possibly due to the difﬁculty of building a global GP surrogate for BO 
coupled with strong non-stationarity of the log likelihood functions; and might be ameliorated by more
complex forms of BO (e.g.  input warping to produce nonstationary kernels [47]  hyperparameter
marginalization [5]). However  these advanced approaches would substantially increase the already
large overhead. Importantly  we expect this poor perfomance to extend to any package which
implements vanilla BO (such as BayesOpt [48])  regardless of the efﬁciency of implementation.

5 Conclusions

We have developed a novel BO method and an associated toolbox  BADS  with the goal of ﬁtting
moderately expensive computational models out-of-the-box. We have shown on real model-ﬁtting
problems that BADS outperforms widely used and state-of-the-art methods for nonconvex  derivative-
free optimization  including ‘vanilla’ BO. We attribute the robust performance of BADS to the
alternation between the aggressive SEARCH strategy  based on local BO  and the failsafe POLL stage 
which protects against failures of the GP surrogate – whereas vanilla BO does not have such failsafe
mechanisms  and can be strongly affected by model misspeciﬁcation. Our results demonstrate that
a hybrid Bayesian approach to optimization can be beneﬁcial beyond the domain of very costly
black-box functions  in line with recent advancements in probabilistic numerics [49].
Like other surrogate-based methods  the performance of BADS is linked to its ability to obtain a fast
approximation of the objective  which generally deteriorates in high dimensions  or for functions
with pathological structure (often improvable via reparameterization). From our tests  we recommend
BADS  paired with some multi-start optimization strategy  for models with up to ∼ 15 variables 
a noisy or jagged log likelihood landscape  and when algorithmic overhead is (cid:46) 75% (e.g.  model
evaluation (cid:38) 0.1 s). Future work with BADS will focus on testing alternative statistical surrogates
instead of GPs [12]; combining it with a smart multi-start method for global optimization; providing
support for tunable precision of noisy observations [23]; improving the numerical implementation;
and recasting some of its heuristics in terms of approximate inference.

9

0.10.31310Error tolerance ε00.250.50.751Fraction solved at 200×D func. evals.CCN17 word recognition memorybadscmaes (noisy active)cmaes (noisy)fminsearchpatternsearchparticleswarmfmincon (actset)gamcssimulannealbndrandsearchsnobfitglobalbayesopt0.10.31310Error tolerance ε00.250.50.751Fraction solved at 200×D func. evals.CCN17 target detection/localizationbadscmaes ( )cmaes (noisy)snobfitbayesoptparticleswarmmcspatternsearchfminsearchsimulannealbndgaglobalfmincon (actset)randsearchnoisy active0.10.31310Error tolerance ε00.250.50.751Fraction solved at 200×D func. evals.CCN17 combinatorial game playingbadscmaes (noisy active)particleswarmbayesoptsnobfitmcspatternsearchfminsearchAcknowledgments

We thank Will Adler  Robbe Goris  Andra Mihali  Bas van Opheusden  and Aspen Yoo for sharing
data and model evaluation code that we used in the CCN17 benchmark set; Maija Honig  Andra
Mihali  Bas van Opheusden  and Aspen Yoo for providing user feedback on earlier versions of the
bads package for MATLAB; Will Adler  Andra Mihali  Bas van Opheusden  and Aspen Yoo for
helpful feedback on a previous version of this manuscript; John Wixted and colleagues for allowing us
to reuse their data for the CCN17 ‘word recognition memory’ problem set; and the three anonymous
reviewers for useful feedback. This work has utilized the NYU IT High Performance Computing
resources and services.

References
[1] Rios  L. M. & Sahinidis  N. V. (2013) Derivative-free optimization: A review of algorithms and comparison

of software implementations. Journal of Global Optimization 56  1247–1293.

[2] Jones  D. R.  Schonlau  M.  & Welch  W. J. (1998) Efﬁcient global optimization of expensive black-box

functions. Journal of Global Optimization 13  455–492.

[3] Brochu  E.  Cora  V. M.  & De Freitas  N. (2010) A tutorial on Bayesian optimization of expensive cost
functions  with application to active user modeling and hierarchical reinforcement learning. arXiv preprint
arXiv:1012.2599.

[4] Shahriari  B.  Swersky  K.  Wang  Z.  Adams  R. P.  & de Freitas  N. (2016) Taking the human out of the

loop: A review of Bayesian optimization. Proceedings of the IEEE 104  148–175.

[5] Snoek  J.  Larochelle  H.  & Adams  R. P. (2012) Practical Bayesian optimization of machine learning

algorithms. Advances in Neural Information Processing Systems 24  2951–2959.

[6] Audet  C. & Dennis Jr  J. E. (2006) Mesh adaptive direct search algorithms for constrained optimization.

SIAM Journal on optimization 17  188–217.

[7] Taddy  M. A.  Lee  H. K.  Gray  G. A.  & Grifﬁn  J. D. (2009) Bayesian guided pattern search for robust

local optimization. Technometrics 51  389–401.

[8] Picheny  V. & Ginsbourger  D. (2014) Noisy kriging-based optimization methods: A uniﬁed implementation

within the DiceOptim package. Computational Statistics & Data Analysis 71  1035–1053.

[9] Gramacy  R. B. & Le Digabel  S. (2015) The mesh adaptive direct search algorithm with treed Gaussian

process surrogates. Paciﬁc Journal of Optimization 11  419–447.

[10] Hutter  F.  Hoos  H. H.  & Leyton-Brown  K. (2011) Sequential model-based optimization for general

algorithm conﬁguration. LION 5  507–523.

[11] Bergstra  J. S.  Bardenet  R.  Bengio  Y.  & Kégl  B. (2011) Algorithms for hyper-parameter optimization.

pp. 2546–2554.

[12] Talgorn  B.  Le Digabel  S.  & Kokkolaras  M. (2015) Statistical surrogate formulations for simulation-

based design optimization. Journal of Mechanical Design 137  021405–1–021405–18.

[13] Audet  C.  Custódio  A.  & Dennis Jr  J. E. (2008) Erratum: Mesh adaptive direct search algorithms for

constrained optimization. SIAM Journal on Optimization 18  1501–1503.

[14] Clarke  F. H. (1983) Optimization and Nonsmooth Analysis. (John Wiley & Sons  New York).
[15] Rasmussen  C. & Williams  C. K. I. (2006) Gaussian Processes for Machine Learning. (MIT Press).
[16] Gramacy  R. B. & Lee  H. K. (2012) Cases for the nugget in modeling computer experiments. Statistics

and Computing 22  713–722.

[17] Srinivas  N.  Krause  A.  Seeger  M.  & Kakade  S. M. (2010) Gaussian process optimization in the bandit

setting: No regret and experimental design. ICML-10 pp. 1015–1022.

[18] Mockus  J.  Tiesis  V.  & Zilinskas  A. (1978) in Towards Global Optimisation. (North-Holland Amster-

dam)  pp. 117–129.

[19] Kushner  H. J. (1964) A new method of locating the maximum point of an arbitrary multipeak curve in the

presence of noise. Journal of Basic Engineering 86  97–106.

[20] Bratley  P. & Fox  B. L. (1988) Algorithm 659: Implementing Sobol’s quasirandom sequence generator.

ACM Transactions on Mathematical Software (TOMS) 14  88–100.

[21] Hansen  N.  Müller  S. D.  & Koumoutsakos  P. (2003) Reducing the time complexity of the derandomized

evolution strategy with covariance matrix adaptation (CMA-ES). Evolutionary Computation 11  1–18.

[22] Hoffman  M. D.  Brochu  E.  & de Freitas  N. (2011) Portfolio allocation for Bayesian optimization.

Proceedings of the Twenty-Seventh Conference on Uncertainty in Artiﬁcial Intelligence pp. 327–336.

10

[23] Picheny  V.  Ginsbourger  D.  Richet  Y.  & Caplin  G. (2013) Quantile-based optimization of noisy

computer experiments with tunable precision. Technometrics 55  2–13.

[24] Picheny  V.  Wagner  T.  & Ginsbourger  D. (2013) A benchmark of kriging-based inﬁll criteria for noisy

optimization. Structural and Multidisciplinary Optimization 48  607–626.

[25] Lagarias  J. C.  Reeds  J. A.  Wright  M. H.  & Wright  P. E. (1998) Convergence properties of the

Nelder–Mead simplex method in low dimensions. SIAM Journal on Optimization 9  112–147.

[26] Waltz  R. A.  Morales  J. L.  Nocedal  J.  & Orban  D.

(2006) An interior algorithm for nonlinear
optimization that combines line search and trust region steps. Mathematical Programming 107  391–408.
[27] Nocedal  J. & Wright  S. (2006) Numerical Optimization  Springer Series in Operations Research. (Springer

Verlag)  2nd edition.

[28] Gill  P. E.  Murray  W.  & Wright  M. H. (1981) Practical Optimization. (Academic press).
[29] Goldberg  D. E. (1989) Genetic Algorithms in Search  Optimization & Machine Learning. (Addison-

Wesley).

[30] Bergstra  J. & Bengio  Y. (2012) Random search for hyper-parameter optimization. Journal of Machine

Learning Research 13  281–305.

[31] Huyer  W. & Neumaier  A. (1999) Global optimization by multilevel coordinate search. Journal of Global

Optimization 14  331–355.

[32] Jastrebski  G. A. & Arnold  D. V. (2006) Improving evolution strategies through active covariance matrix

adaptation. IEEE Congress on Evolutionary Computation (CEC 2006). pp. 2814–2821.

[33] Csendes  T.  Pál  L.  Sendin  J. O. H.  & Banga  J. R. (2008) The GLOBAL optimization method revisited.

Optimization Letters 2  445–454.

[34] Hansen  N.  Niederberger  A. S.  Guzzella  L.  & Koumoutsakos  P.

(2009) A method for handling
uncertainty in evolutionary optimization with an application to feedback control of combustion. IEEE
Transactions on Evolutionary Computation 13  180–197.

[35] Hansen  N.  Finck  S.  Ros  R.  & Auger  A. (2009) Real-parameter black-box optimization benchmarking

2009: Noiseless functions deﬁnitions.

[36] Acerbi  L.  Dokka  K.  Angelaki  D. E.  & Ma  W. J. (2017) Bayesian comparison of explicit and implicit

causal inference strategies in multisensory heading perception. bioRxiv preprint bioRxiv:150052.

[37] Adler  W. T. & Ma  W. J. (2017) Human conﬁdence reports account for sensory uncertainty but in a

non-Bayesian way. bioRxiv preprint bioRxiv:093203.

[38] Goris  R. L.  Simoncelli  E. P.  & Movshon  J. A. (2015) Origin and function of tuning diversity in macaque

visual cortex. Neuron 88  819–831.

[39] Körding  K. P.  Beierholm  U.  Ma  W. J.  Quartz  S.  Tenenbaum  J. B.  & Shams  L. (2007) Causal

inference in multisensory perception. PLoS One 2  e943.

[40] van den Berg  R.  Yoo  A. H.  & Ma  W. J. (2017) Fechner’s law in metacognition: A quantitative model of

visual working memory conﬁdence. Psychological Review 124  197–214.

[41] Mickes  L.  Wixted  J. T.  & Wais  P. E. (2007) A direct test of the unequal-variance signal detection model

of recognition memory. Psychonomic Bulletin & Review 14  858–865.

[42] Shiffrin  R. M. & Steyvers  M. (1997) A model for recognition memory: REM—retrieving effectively

from memory. Psychonomic Bulletin & Review 4  145–166.

[43] Ma  W. J.  Navalpakkam  V.  Beck  J. M.  van Den Berg  R.  & Pouget  A. (2011) Behavior and neural

basis of near-optimal visual search. Nature Neuroscience 14  783–790.

[44] Mazyar  H.  van den Berg  R.  & Ma  W. J. (2012) Does precision decrease with set size? J Vis 12  1–10.
[45] van den Berg  R.  Shin  H.  Chou  W.-C.  George  R.  & Ma  W. J. (2012) Variability in encoding precision

accounts for visual short-term memory limitations. Proc Natl Acad Sci U S A 109  8780–8785.

[46] van Opheusden  B.  Bnaya  Z.  Galbiati  G.  & Ma  W. J.

(2016) Do people think like computers?

International Conference on Computers and Games pp. 212–224.

[47] Snoek  J.  Swersky  K.  Zemel  R.  & Adams  R. (2014) Input warping for Bayesian optimization of

non-stationary functions. pp. 1674–1682.

[48] Martinez-Cantin  R.

(2014) BayesOpt: A Bayesian optimization library for nonlinear optimization 

experimental design and bandits. Journal of Machine Learning Research 15  3735–3739.

[49] Hennig  P.  Osborne  M. A.  & Girolami  M. (2015) Probabilistic numerics and uncertainty in computations.

Proceedings of the Royal Society A 471  20150142.

11

,Xiangyu Wang
Peichao Peng
David Dunson
Djork-Arné Clevert
Andreas Mayr
Thomas Unterthiner
Sepp Hochreiter
Luigi Acerbi
Wei Ji Ma
Ofir Marom
Benjamin Rosman