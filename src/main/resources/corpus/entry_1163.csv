2012,Convergence Rate Analysis of MAP Coordinate Minimization Algorithms,Finding maximum aposteriori (MAP) assignments in graphical models is an important task in many applications. Since the problem is generally hard  linear programming (LP) relaxations are often used. Solving these relaxations efficiently is thus an important practical problem. In recent years  several authors have proposed message passing updates corresponding to coordinate descent in the dual LP. However these are generally not guaranteed to converge to a global optimum. One approach to remedy this is to smooth the LP  and perform coordinate descent on the smoothed dual. However  little is known about the convergence rate of this procedure. Here we perform a thorough rate analysis of such schemes and derive primal and dual convergence rates. We also provide a simple dual to primal mapping that yields feasible primal solutions with a guaranteed rate of convergence. Empirical evaluation supports our theoretical claims and shows that the method is highly competitive with state of the art approaches that yield global optima.,Convergence Rate Analysis of MAP Coordinate

Minimization Algorithms

Ofer Meshi ∗

Tommi Jaakkola †

Amir Globerson ∗

meshi@cs.huji.ac.il

tommi@csail.mit.edu

gamir@cs.huji.ac.il

Abstract

Finding maximum a posteriori (MAP) assignments in graphical models is an im-
portant task in many applications. Since the problem is generally hard  linear pro-
gramming (LP) relaxations are often used. Solving these relaxations efﬁciently
is thus an important practical problem. In recent years  several authors have pro-
posed message passing updates corresponding to coordinate descent in the dual
LP. However  these are generally not guaranteed to converge to a global optimum.
One approach to remedy this is to smooth the LP  and perform coordinate descent
on the smoothed dual. However  little is known about the convergence rate of this
procedure. Here we perform a thorough rate analysis of such schemes and derive
primal and dual convergence rates. We also provide a simple dual to primal map-
ping that yields feasible primal solutions with a guaranteed rate of convergence.
Empirical evaluation supports our theoretical claims and shows that the method is
highly competitive with state of the art approaches that yield global optima.

1

Introduction

Many applications involve simultaneous prediction of multiple variables. For example  we may seek
to label pixels in an image  infer amino acid residues in protein design  or ﬁnd the semantic role of
words in a sentence. These problems can be cast as maximizing a function over a set of labels (or
minimizing an energy function). The function typically decomposes into a sum of local functions
over overlapping subsets of variables.
Such maximization problems are nevertheless typically hard. Even for simple decompositions (e.g. 
subsets correspond to pairs of variables)  maximizing over the set of labels is often provably NP-
hard. One approach would be to reduce the problem to a tractable one  e.g.  by constraining the
model to a low tree-width graph. However  empirically  using more complex interactions together
with approximate inference methods is often advantageous. One popular family of approximate
methods is the linear programming (LP) relaxation approach. Although these LPs are generally
tractable  general purpose LP solvers typically do not exploit the problem structure [28]. Therefore
a great deal of effort has gone into designing solvers that are speciﬁcally tailored to typical MAP-
LP relaxations. These include  for example  cut based algorithms [2]  accelerated gradient methods
[8]  and augmented Lagrangian methods [10  12]. One class of particularly simple algorithms 
which we will focus on here  are coordinate minimization based approaches. Examples include
max-sum-diffusion [25]  MPLP [5] and TRW-S [9]. These work by ﬁrst taking the dual of the LP
and then optimizing the dual in a block coordinate fashion [21].
In many cases  the coordinate
block operations can be performed in closed form  resulting in updates quite similar to the max-
product message passing algorithm. By coordinate minimization we mean that at each step a set
of coordinates is chosen  all other coordinates are ﬁxed  and the chosen coordinates are set to their

∗School of Computer Science and Engineering  The Hebrew University of Jerusalem  Israel
†CSAIL  MIT  Cambridge  MA

1

optimal value given the rest. This is different from a coordinate descent strategy where instead a
gradient step is performed on the chosen coordinates (rather than full optimization).
A main caveat of the coordinate minimization approach is that it will not necessarily ﬁnd the global
optimum of the LP (although in practice it often does). This is a direct result of the LP objective
not being strictly convex. Several authors have proposed to smooth the LP with entropy terms
and employ variants of coordinate minimization [7  26]. However  the convergence rates of these
methods have not been analyzed. Moreover  since the algorithms work in the dual  there is no
simple procedure to map the result back into primal feasible variables. We seek to address all these
shortcomings: we present a convergence rate analysis of dual coordinate minimization algorithms 
provide a simple scheme for generating primal variables from dual ones  and analyze the resulting
primal convergence rates.
Convergence rates for coordinate minimization are not common in the literature. While asymptotic
convergence is relatively well understood [22]  ﬁnite rates have been harder to obtain. Recent work
[17] provides rates for rather limited settings which do not hold in our case. On the other hand 
for coordinate descent methods  some rates have been recently obtained for greedy and stochastic
update schemes [16  20]. These do not apply directly to the full coordinate minimization case which
we study. A related analysis of MAP-LP using smoothing appeared in [3]. However  their approach
is speciﬁc to LDPC codes  and does not apply to general MAP problems as we analyze here.

2 MAP and LP relaxations
Consider a set of n discrete variables x1  . . .   xn  and a set C of subsets of these variables (i.e.  c ∈ C
is a subset of {1  . . .   n}). We consider maximization problems over functions that decompose
according to these subsets. In particular  each subset c is associated with a local function or factor
θc(xc) and we also include factors θi(xi) for each individual variable.1 The MAP problem is to ﬁnd
an assignment x = (x1  . . .   xn) to all the variables which maximizes the sum of these factors:

MAP(θ) = max

x

θc(xc) +

θi(xi)

(1)

Linear programming relaxations are a popular approach to approximating combinatorial optimiza-
tion problems [6  23  25]. For example  we obtain a relaxation of the discrete optimization problem
given in Eq. (1) by replacing it with the following linear program:2

(cid:88)

c∈C

n(cid:88)

i=1

P M AP : max
µ∈ML

P (µ) = max
µ∈ML

θc(xc)µc(xc) +

θi(xi)µi(xi)

= max
µ∈ML

where P (µ) is the primal (linear) objective and the local marginal polytope ML enforces basic
consistency constraints on the marginals {µi(xi) ∀xi} and {µc(xc) ∀xc}. Speciﬁcally 

ML =

µ ≥ 0 :

µc(xc) = µi(xi) ∀c  i ∈ c  xi
µi(xi) = 1

∀i

xc\i

xi

µ · θ (2)

(3)

(cid:88)

(cid:88)

i

xi

(cid:27)

(cid:27)

(cid:26)(cid:88)

(cid:88)

c

xc

(cid:80)
(cid:80)

(cid:26)

If the maximizer of P M AP has only integral values (i.e.  0 or 1) it can be used to ﬁnd the MAP
assignment (e.g.  by taking the xi that maximizes µi(xi)). However  in the general case the solution
may be fractional [24] and the maximum of P M AP is an upper bound on MAP(θ).

2.1 Smoothing the LP

As mentioned earlier  several authors have considered a smoothed version of the LP in Eq. (2).
As we shall see  this offers several advantages over solving the LP directly. Given a smoothing
parameter τ > 0  we consider the following smoothed primal problem:

P M APτ : max
µ∈ML

Pτ (µ) = max
µ∈ML

µ · θ +

1
τ

H(µc) +

1
τ

H(µi)

(4)

(cid:26)

(cid:88)

c

(cid:27)

(cid:88)

i

1Although singleton factors are not needed for generality  we keep them for notational convenience.
2We use µ and θ to denote vectors consisting of all µ and θ values respectively.

2

where H(µc) and H(µi) are local entropy terms. Note that as τ → ∞ we obtain the original primal
problem. In fact  a stronger result can be shown. Namely  that the optimal value of P M AP is O( 1
τ )
close to the optimal value of P M APτ . This justiﬁes using the smoothed objective Pτ as a proxy to
P in Eq. (2). We express this in the following lemma (which appears in similar forms in [7  15]).
Lemma 2.1. Denote by µ∗ the optimum of problem P M AP in Eq. (2) and by ˆµ∗ the optimum of
problem P M APτ in Eq. (4). Then:

where Hmax =(cid:80)

c log |xc|+(cid:80)

ˆµ∗ · θ ≤ µ∗ · θ ≤ ˆµ∗ · θ +
i log |xi|. In other words  the smoothed optimum is an O( 1

Hmax

τ

(5)

τ )-optimal

solution of the original non-smoothed problem.

We shall be particularly interested in the dual of P M APτ since it facilitates simple coordinate
minimization updates. Our dual variables will be denoted by δci(xi)  which can be interpreted as
the messages from subset c to node i about the value of variable xi. The dual variables are therefore
indexed by (c  i  xi) and written as δci(xi). The dual objective can be shown to be:

(cid:32)

(cid:88)

c

(cid:88)

xc

1
τ

log

(cid:88)

i:i∈c

(cid:33)

(cid:88)

i

(cid:88)

xi

1
τ

log

(cid:32)

F (δ) =

exp

τ θc(xc) − τ

δci(xi)

+

exp

τ θi(xi) + τ

(cid:88)

c:i∈c

(cid:33)

δci(xi)

(6)

(7)

The dual problem is an unconstrained smooth minimization problem:

DM APτ : min

δ

F (δ)

Convex duality implies that the optima of DM APτ and P M APτ coincide.
Finally  we shall be interested in transformations between dual variables δ and primal variables µ
(see Section 5). The following are the transformations obtained from the Lagrangian derivation (i.e. 
they can be used to switch from optimal dual variables to optimal primal variables).
µc(xc; δ) ∝ exp

  µi(xi; δ) ∝ exp

τ θc(xc) − τ

(cid:88)

(cid:88)

τ θi(xi) + τ

δci(xi)

δci(xi)

(cid:32)

(cid:33)

(cid:33)

(cid:32)

i:i∈c

c:i∈c

(8)
We denote the vector of all such marginals by µ(δ). For the dual variables δ that minimize F (δ)
it holds that µ(δ) are feasible (i.e.  µ(δ) ∈ ML). However  we will also consider µ(δ) for non
optimal δ  and show how to obtain primal feasible approximations from µ(δ). These will be helpful
in obtaining primal convergence rates.
It is easy to see that: (∇F (δt))c i xi

= µi(xi; δt) − µc(xi; δt)  where (with some abuse of notation)
µc(xc\i  xi). The elements of the gradient thus correspond to inconsis-
tency between the marginals µ(δt) (i.e.  the degree to which they violate the constraints in Eq. (3)).
We shall make repeated use of this fact to link primal and dual variables.

we denote: µc(xi) =(cid:80)

xc\i

3 Coordinate Minimization Algorithms

In this section we propose several coordinate minimization procedures for solving DM APτ (Eq.
(7)). We ﬁrst set some notation to deﬁne block coordinate minimization algorithms. Denote the
objective we want to minimize by F (δ) where δ corresponds to a set of N variables. Now deﬁne
S = {S1  . . .   SM} as a set of subsets  where each subset Si ⊆ {1  . . .   N} describes a coordinate
block. We will assume that Si ∩ Sj = ∅ for all i  j and that ∪iSi = {1  . . .   N}.
Block coordinate minimization algorithms work as follows: at each iteration  ﬁrst set δt+1 = δt.
Next choose a block Si and set:

δt+1
Si

= arg min
δSi

Fi(δSi; δt)

(9)

where we use Fi(δSi; δt) to denote the function F restricted to the variables δSi and where all other
variables are set to their value in δt. In other words  at each iteration we fully optimize only over the
variables δSi while ﬁxing all other variables. We assume that the minimization step in Eq. (9) can
be solved in closed form  which is indeed the case for the updates we consider.
Regarding the choice of an update schedule  several options are available:

3

• Cyclic: Decide on a ﬁxed order (e.g.  S1  . . .   SM ) and cycle through it.
• Stochastic: Draw an index i uniformly at random3 at each iteration and use the block Si.
• Greedy: Denote by ∇SiF (δt) the gradient ∇F (δt) evaluated at coordinates Si only. The
greedy scheme is to choose Si that maximizes (cid:107)∇SiF (δt)(cid:107)∞. In other words  choose the
set of coordinates that correspond to maximum gradient of the function F . Intuitively this
corresponds to choosing the block that promises the maximal (local) decrease in objective.
Note that to ﬁnd the best coordinate we presumably must process all sets Si to ﬁnd the best
one. We will show later that this can be done rather efﬁciently in our case.

In our analysis  we shall focus on the Stochastic and Greedy cases  and analyze their rate of con-
vergence. The cyclic case is typically hard to analyze  with results only under multiple conditions
which do not hold here (e.g.  see [17]).
Another consideration when designing coordinate minimization algorithms is the choice of block
size. One possible choice is all variables δci(·) (for a speciﬁc pair ci). This is the block chosen in the
max-sum-diffusion (MSD) algorithm (see [25] and [26] for non-smooth and smooth MSD). A larger
block that also facilitates closed form updates is the set of variables δ·i(·). Namely  all messages
into a variable i from c such that i ∈ c. We call this a star update. The update is used in [13] for the
non-smoothed dual (but the possibility of applying it to the smoothed version is mentioned).
For simplicity  we focus here only on the star update  but the derivation is similar for other choices.
To derive the star update around variable i  one needs to ﬁx all variables except δ·i(·) and then set
the latter to minimize F (δ). Since F (δ) is differentiable this is pretty straightforward. The update
turns out to be:4

δt+1
ci (xi) = δt

ci(xi) +

1
τ

log µt

c(xi) − 1

Ni + 1

· 1
τ

log

µt

c(cid:48)(xi)

(10)

where Ni = |{c : i ∈ c}|. It is interesting to consider the improvement in F (δ) as a result of the
star update. It can be shown to be exactly:

(cid:33)

(cid:32)

µt

c(cid:48):i∈c(cid:48)

i(xi) · (cid:89)
Ni+1Ni+1
(cid:33) 1

µt

c(xi)

F (δt) − F (δt+1) = − 1
τ

log

(cid:32)

(cid:88)

xi

i(xi) · (cid:89)

µt

c:i∈c

The RHS is known as Matusita’s divergence measure [11]  and is a generalization of the Bhat-
tacharyya divergence to several distributions. Thus the improvement can be easily computed be-
fore actually applying the update and is directly related to how consistent the Ni + 1 distributions
i(xi) are. Recall that at the optimum they all agree as µ ∈ ML  and thus the expected
c(xi)  µt
µt
improvement is zero.

4 Dual Convergence Rate Analysis

We begin with the convergence rates of the dual F using greedy and random schemes described in
Section 3. In Section 5 we subsequently show how to obtain a primal feasible solution and how
the dual rates give rise to primal rates. Our analysis builds on the fact that we can lower bound the
improvement at each step  as a function of some norm of the block gradient.

4.1 Greedy block minimization
Theorem 4.1. Deﬁne B1 to be a constant such that (cid:107)δt − δ∗(cid:107)1 ≤ B1 for all t.
minimization of each block Si satisﬁes:

If coordinate

for all t  then for any  > 0 after T = kB2

1



F (δt) − F (δt+1) ≥ 1
k

(cid:107)∇SiF (δt)(cid:107)2∞

(11)
iterations of the greedy algorithm  F (δT ) − F (δ∗) ≤ .

3Non uniform schedules are also possible. We consider the uniform for simplicity.
4The update is presented here in additive form  there is an equivalent absolute form [21].

4

Proof. Using H¨older’s inequality we obtain the bound:

F (δt) − F (δ∗) ≤ ∇F (δt)(cid:62)(δt − δ∗) ≤ (cid:107)∇F (δt)(cid:107)∞ · (cid:107)δt − δ∗(cid:107)1

(12)
(F (δt) − F (δ∗)). Now  using the condition on the improvement and

Implying: (cid:107)∇F (δt)(cid:107)∞ ≥ 1
the greedy nature of the update  we obtain a bound on the improvement:
F (δt) − F (δt+1) ≥ 1
k

(cid:107)∇F (δt)(cid:107)2∞

B1

(cid:107)∇SiF (δt)(cid:107)2∞ =
1

(cid:0)F (δt) − F (δ∗)(cid:1)2 ≥ 1

1
k

≥

(cid:0)F (δt) − F (δ∗)(cid:1)(cid:0)F (δt+1) − F (δ∗)(cid:1)

kB2
1

≤ F (δt) − F (δ∗) −(cid:0)F (δt+1) − F (δ∗)(cid:1)

(F (δt) − F (δ∗)) (F (δt+1) − F (δ∗))

Hence 

1

kB2
1

kB2
1

=

1

F (δt+1) − F (δ∗)

−

1

F (δt) − F (δ∗)

(13)

Summing over t we obtain:
≤

T
kB2
1

1

F (δT ) − F (δ∗)

−

1

F (δ0) − F (δ∗)

≤

1

F (δT ) − F (δ∗)

(14)

and the desired result follows.

4.2 Stochastic block minimization
Theorem 4.2. Deﬁne B2 to be a constant such that (cid:107)δt − δ∗(cid:107)2 ≤ B2 for all t.
minimization of each block Si satisﬁes:

If coordinate

(15)

F (δt) − F (δt+1) ≥ 1
k

(cid:107)∇SiF (δt)(cid:107)2

2

2

for all t  then for any  > 0 after T = k|S|B2
E[F (δT )] − F (δ∗) ≤ .5
The proof is similar to Nesterov’s analysis (see Theorem 1 in [16]). The proof in [16] relies on the
improvement condition in Eq. (15) and not on the precise nature of the update. Note that since the
cost of the update is roughly linear in the size of the block then this bound does not tell us which
block size is better (the cost of an update times the number of blocks is roughly constant).

iterations of the stochastic algorithm we have that



4.3 Analysis of DM APτ block minimization

We can now obtain rates for our coordinate minimization scheme for optimizing DM APτ by ﬁnding
the k to be used in conditions Eq. (15) and Eq. (11). The result for the star update is given below.
Proposition 4.3. The star update for xi satisﬁes the conditions in Eqs. 15 and 11 with k = 4τ Ni.

This can be shown using Equation 2.4 in [14]  which states that if Fi(δSi; δ) (see Eq.
(9)) has
Lipschitz constant Li then Eq. (15) is satisﬁed with k = 2Li. We can then use the fact that the
Lipschitz constant of a star block is at most 2τ Ni (this can be calculated as in [18]) to obtain the
result.6 To complete the analysis  it turns out that B1 and B2 can be bounded via a function of θ by
bounding (cid:107)δ(cid:107)1 (see supplementary  Lemma 1.2). We proceed to discuss the implications of these
bounds.

4.4 Comparing the different schemes

The results we derived have several implications. First  we see that both stochastic and greedy
schemes achieve a rate of O( τ
 ). This matches the known rates for regular (non-accelerated) gra-
dient descent on functions with Lipschitz continuous gradient (e.g.  see [14])  although in practice
coordinate minimization is often much faster.

5Expectation is taken with respect to the randomization of blocks.
6We also provide a direct proof in the supplementary  Section 2.

5

The main difference between the greedy and stochastic rates is that the factor |S| (the number of
blocks) does not appear in the greedy rate  and does appear in the stochastic one. This can have a
considerable effect since |S| is either the number of variables n (in the star update) or the number
of factors |C| (in MPLP). Both can be signiﬁcant (e.g.  |C| is the number of edges in a pairwise
MRF model). The greedy algorithm does pay a price for this advantage  since it has to ﬁnd the
optimal block to update at each iteration. However  for the problem we study here this can be
done much more efﬁciently using a priority queue. To see this  consider the star update. A change
in the variables δ·i(·) will only affect the blocks that correspond to variables j that are in c such
that i ∈ c. In many cases this is small (e.g.  low degree pairwise MRFs) and thus we will only
have to change the priority queue a small number of times  and this cost would be negligible when
using a Fibonacci heap for example.7 Indeed  our empirical results show that the greedy algorithm
consistently outperforms the stochastic one (see Section 6).

5 Primal convergence

Thus far we have considered only dual variables. However  it is often important to recover the primal
variables. We therefore focus on extracting primal feasible solutions from current δ  and characterize
the degree of primal optimality and associated rates. The primal variables µ(δ) (see Eq. (8)) need
not be feasible in the sense that the consistency constraints in Eq. (3) are not necessarily satisﬁed.
This is true also for other approaches to recovering primal variables from the dual  such as averaging
subgradients when using subgradient descent (see  e.g.  [21]).
We propose a simple two-step algorithm for transforming any dual variables δ into primal feasible
variables ˜µ(δ) ∈ ML. The resulting ˜µ(δ) will also be shown to converge to the optimal primal
solution in Section 5.1. The procedure is described in Algorithm 1 below.

µi(xi) +(cid:80)
1|Xc\i| (µc(xi) − ¯µi(xi))

c:i∈c

1|Xc\i| µc(xi)

(cid:17)

Algorithm 1 Mapping to feasible primal solution
Step 1: Make marginals consistent.
For all i do: ¯µi(xi) =

(cid:16)

1+(cid:80)

1
c:i∈c

1|Xc\i|

i:i∈c
Step 2: Make marginals non-negative.
λ = 0
for c ∈ C  xc do

For all c do: ¯µc(xc) = µc(xc) −(cid:80)
(cid:27)
(cid:27)

else if ¯µc(xc) > 1 then

if ¯µc(xc) < 0 then

−¯µc(xc)+ 1|Xc|

(cid:26)
(cid:26)

λ = max

λ 

−¯µc(xc)

λ = max

λ 

¯µc(xc)−1
¯µc(xc)− 1|Xc|

end if

end for
for (cid:96) = 1  . . .   n; c ∈ C do

˜µ(cid:96)(x(cid:96)) = (1 − λ)¯µ(cid:96)(x(cid:96)) + λ 1|X(cid:96)|

end for
Importantly  all steps consist of cheap elementary local calculations in contrast to other methods pre-
viously proposed for this task (compare to [18  27]). The ﬁrst step performs a Euclidian projection
of µ(δ) to consistent marginals ¯µ. Speciﬁcally  it solves:

min

¯µ

1
2

(cid:107)µ(δ) − ¯µ(cid:107)2

 

s.t. ¯µc(xi) = ¯µi(xi)  for all c  i ∈ c  xi

 

¯µi(xi) = 1  for all i

(cid:88)

i

Note that we did not include non-negativity constraints above  so the projection might result in neg-
ative ¯µ. In the second step we “pull” ¯µ back into the feasible regime by taking a convex combination

7This was also used in the residual belief propagation approach [4]  which however is less theoretically

justiﬁed than what we propose here.

6

with the uniform distribution u (see [3] for a related approach). In particular  this step solves the
simple problem of ﬁnding the smallest λ ∈ [0  1] such that 0 ≤ ˜µ ≤ 1 (where ˜µ = (1 − λ)¯µ + λu).
Since this step interpolates between two distributions that satisfy consistency and normalization
constraints  ˜µ will be in the local polytope ML.

5.1 Primal convergence rate

Now that we have a procedure for obtaining a primal solution we analyze the corresponding conver-
gence rate. First  we show that if we have δ for which (cid:107)∇F (δ)(cid:107)∞ ≤  then ˜µ(δ) (after Algorithm
1) is an O() primal optimal solution.
Theorem 5.1. Denote by P ∗
τ the optimum of the smoothed primal P M APτ . For any set of dual
variables δ  and any  ∈ R(τ ) (see supp. for deﬁnition of R(τ )) it holds that if (cid:107)∇F (δ)(cid:107)∞ ≤  then
τ − Pτ (˜µ(δ)) ≤ C0. The constant C0 depends only on the parameters θ and is independent of τ.
P ∗
The proof is given in the supplementary ﬁle (Section 1). The key idea is to break F (δ) − Pτ (˜µ(δ))
into components  and show that each component is upper bounded by O(). The range R(τ ) consists
of  ≥ O( 1
τ ) and  ≤ O(e−τ ). As we show in the supplementary this range is large enough to
guarantee any desired accuracy in the non-smoothed primal. We can now translate dual rates into
primal rates. This can be done via the following well known lemma:
Lemma 5.2. Any convex function F with Lipschitz continuous gradient and Lipschitz constant L
satisﬁes (cid:107)∇F (δ)(cid:107)2
These results together with the fact that (cid:107)∇F (δ)(cid:107)2
2 ≥ (cid:107)∇F (δ)(cid:107)2∞  and the Lipschitz constant of
F (δ) is O(τ )  lead to the following theorem.
Theorem 5.3. Given any algorithm for optimizing DM APτ and  ∈ R(τ )  if the algorithn is
guaranteed to achieve F (δt) − F (δ∗) ≤  after O(g()) iterations  then it is guaranteed to be 
primal optimal  i.e.  P ∗
The theorem lets us directly translate dual convergence rates into primal ones. Note that it applies
to any algorithm for DM APτ (not only coordinate minimization)  and the only property of the
algorithm used in the proof is F (δt) ≤ F (0) for all t. Put in the context of our previous results  any
algorithm that achieves F (δt)− F (δ∗) ≤  in t = O(τ /) iterations  then it is guaranteed to achieve
τ − Pτ (˜µ(δt(cid:48)
P ∗

τ − Pτ (˜µ(δt)) ≤  after O(g( 2

)) ≤  in t(cid:48) = O(τ 2/2) iterations.

2 ≤ 2L (F (δ) − F (δ∗)).

τ )) iterations.8

6 Experiments





(cid:17)

In this section we evaluate coordinate minimization algorithms on a MAP problem  and compare
them to state-of-the-art baselines. Speciﬁcally  we compare the running time of greedy coordinate
minimization  stochastic coordinate minimization  full gradient descent  and FISTA – an accelerated
gradient method [1] (details on the gradient-based algorithms are provided in the supplementary 

Section 3). Gradient descent is known to converge in O(cid:0) 1
(cid:16) 1√

(cid:1) iterations while FISTA converges

in O
iterations [1]. We compare the performance of the algorithms on protein side-chain
prediction problems from the dataset of Yanover et al. [28]. These problems involve ﬁnding the 3D
conﬁguration of rotamers given the backbone structure of a protein. The problems are modeled by
singleton and pairwise factors and can be posed as ﬁnding a MAP assignment for the given model.
Figure 1(a) shows the objective value for each algorithm over time. We ﬁrst notice that the greedy
algorithm converges faster than the stochastic one. This is in agreement with our theoretical analysis.
Second  we observe that the coordinate minimization algorithms are competitive with the acceler-
ated gradient method FISTA and are much faster than the gradient method. Third  as Theorem 5.3
predicts  primal convergence is slower than dual convergence (notice the logarithmic timescale).
Finally  we can see that better convergence of the dual objective corresponds to better convergence
of the primal objective  in both fractional and integral domains. In our experiments the quality of
the decoded integral solution (dashed lines) signiﬁcantly exceeds that of the fractional solution. Al-
though sometimes a fractional solution can be useful in itself  this suggests that if only an integral
solution is sought then it could be enough to decode directly from the dual variables.

8We omit constants not depending on τ and .

7

(a)

(b) talg/tgreedy

Greedy
Stochastic
FISTA
Gradient

1
8.6 ± 0.6
814.2 ± 38.1
13849.8 ± 6086.5

Figure 1: Comparison of coordinate minimization  gradient descent  and the accelerated gradient
algorithms on protein side-chain prediction task. Figure (a) shows a typical run of the algorithms.
For each algorithm the dual objective of Eq. (6) is plotted as a function of execution time. The value
(Eq. (4)) of the feasible primal solution of Algorithm 1 is also shown (lower solid line)  as well as
the objective (Eq. (1)) of the best decoded integer solution (dashed line; those are decoded directly
from the dual variables δ). Table (b) shows the ratio of runtime of each algorithm w.r.t. the greedy
algorithm. The mean ratio over the proteins in the dataset is shown followed by standard error.

The table in Figure 1(b) shows overall statistics for the proteins in the dataset. Here we run each
algorithm until the duality gap drops bellow a ﬁxed desired precision ( = 0.1) and compare the
total runtime. The table presents the ratio of runtime of each algorithm w.r.t. the greedy algorithm
(talg/tgreedy). These results are consistent with the example in Figure 1(a).

7 Discussion

We presented the ﬁrst convergence rate analysis of dual coordinate minimization algorithms on
MAP-LP relaxations. We also showed how such dual iterates can be turned into primal feasible
iterates and analyzed the rate with which these primal iterates converge to the primal optimum. The
primal mapping is of considerable practical value  as it allows us to monitor the distance between the
upper (dual) and lower (primal) bounds on the optimum and use this as a stopping criterion. Note
that this cannot be done without a primal feasible solution.9
The overall rates we obtain are of the order O( τ
 ) for the DM APτ problem. If one requires an 
accurate solution for P M AP   then τ needs to be set to O( 1
 ) (see Eq. (5)) and the overall rate is
2 ) in the dual. As noted in [8  18]  a faster rate of O( 1
 ) may be obtained using accelerated
O( 1
methods such as Nesterov’s [15] or FISTA [1]. However  these also have an extra factor of N which
does not appear in the greedy rate. This could partially explain the excellent performance of the
greedy scheme when compared to FISTA (see Section 6).
Our analysis also highlights the advantage of using greedy block choice for MAP problems. The
advantage comes from the fact that the choice of block to update is quite efﬁcient since its cost is of
the order of the other computations required by the algorithm. This can be viewed as a theoretical
reinforcement of selective scheduling algorithms such as Residual Belief Propagation [4].
Many interesting questions still remain to be answered. How should one choose between different
block updates (e.g.  MSD vs star)? What are lower bounds on rates? Can we use acceleration as in
[15] to obtain better rates? What is the effect of adaptive smoothing (see [19]) on rates? We plan to
address these in future work.
Acknowledgments: This work was supported by BSF grant 2008303. Ofer Meshi is a recipient of the Google
Europe Fellowship in Machine Learning  and this research is supported in part by this Google Fellowship.

9An alternative commonly used progress criterion is to decode an integral solution from the dual variables 
and see if its value is close to the dual upper bound. However  this will only work if P M AP has an integral
solution and we have managed to decode it.

8

10−2100102104106−50050100150200250Runtime (secs)Objective  GreedyStochasticFISTAGradientReferences
[1] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems.

SIAM J. Img. Sci.  2(1):183–202  Mar. 2009.

[2] Y. Boykov  O. Veksler  and R. Zabih. Fast approximate energy minimization via graph cuts. In Proc.

IEEE Conf. Comput. Vision Pattern Recog.  1999.

[3] D. Burshtein. Iterative approximate linear programming decoding of ldpc codes with linear complexity.

IEEE Transactions on Information Theory  55(11):4835–4859  2009.

[4] G. Elidan  I. Mcgraw  and D. Koller. Residual belief propagation: informed scheduling for asynchronous

message passing. In UAI  2006.

[5] A. Globerson and T. Jaakkola. Fixing max-product: Convergent message passing algorithms for MAP

LP-relaxations. In J. Platt  D. Koller  Y. Singer  and S. Roweis  editors  NIPS 20. MIT Press  2008.

[6] M. Guignard and S. Kim. Lagrangean decomposition: A model yielding stronger Lagrangean bounds.

Mathematical Programming  39(2):215–228  1987.

[7] T. Hazan and A. Shashua. Norm-product belief propagation: Primal-dual message-passing for approxi-

mate inference. IEEE Transactions on Information Theory  56(12):6294–6316  2010.

[8] V. Jojic  S. Gould  and D. Koller. Fast and smooth: Accelerated dual decomposition for MAP inference.

In Proceedings of International Conference on Machine Learning (ICML)  2010.

[9] V. Kolmogorov. Convergent tree-reweighted message passing for energy minimization. IEEE Transac-

tions on Pattern Analysis and Machine Intelligence  28(10):1568–1583  2006.

[10] A. L. Martins  M. A. T. Figueiredo  P. M. Q. Aguiar  N. A. Smith  and E. P. Xing. An augmented

lagrangian approach to constrained map inference. In ICML  pages 169–176  2011.

[11] K. Matusita. On the notion of afﬁnity of several distributions and some of its applications. Annals of the

Institute of Statistical Mathematics  19:181–192  1967. 10.1007/BF02911675.

[12] O. Meshi and A. Globerson. An alternating direction method for dual map lp relaxation. In ECML PKDD 

pages 470–483. Springer-Verlag  2011.

[13] O. Meshi  D. Sontag  T. Jaakkola  and A. Globerson. Learning efﬁciently with approximate inference via

dual losses. In ICML  pages 783–790  New York  NY  USA  2010. ACM.

[14] Y. Nesterov. Introductory Lectures on Convex Optimization: A Basic Course  volume 87. Kluwer Aca-

demic Publishers  2004.

[15] Y. Nesterov. Smooth minimization of non-smooth functions. Math. Prog.  103(1):127–152  May 2005.
[16] Y. Nesterov. Efﬁciency of coordinate descent methods on huge-scale optimization problems. Core dis-

cussion papers  Universit catholique de Louvain  2010.

[17] A. Saha and A. Tewari. On the ﬁnite time convergence of cyclic coordinate descent methods  2010.

preprint arXiv:1005.2146.

[18] B. Savchynskyy  S. Schmidt  J. Kappes  and C. Schnorr. A study of Nesterov’s scheme for lagrangian

decomposition and map labeling. CVPR  2011.

[19] B. Savchynskyy  S. Schmidt  J. H. Kappes  and C. Schn¨orr. Efﬁcient mrf energy minimization via adaptive

diminishing smoothing. In UAI  2012.

[20] S. Shalev-Shwartz and A. Tewari. Stochastic methods for l1-regularized loss minimization. J. Mach.

Learn. Res.  12:1865–1892  July 2011.

[21] D. Sontag  A. Globerson  and T. Jaakkola. Introduction to dual decomposition for inference. In Optimiza-

tion for Machine Learning  pages 219–254. MIT Press  2011.

[22] P. Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization 1. Jour-

nal of Optimization Theory and Applications  109(3):475–494  2001.

[23] M. Wainwright  T. Jaakkola  and A. Willsky. MAP estimation via agreement on trees: message-passing

and linear programming. IEEE Transactions on Information Theory  51(11):3697–3717  2005.

[24] M. Wainwright and M. I. Jordan. Graphical Models  Exponential Families  and Variational Inference.

Now Publishers Inc.  Hanover  MA  USA  2008.

[25] T. Werner. A linear programming approach to max-sum problem: A review. IEEE Transactions on Pattern

Analysis and Machine Intelligence  29(7):1165–1179  2007.

[26] T. Werner. Revisiting the decomposition approach to inference in exponential families and graphical

models. Technical Report CTU-CMP-2009-06  Czech Technical University  2009.

[27] T. Werner. How to compute primal solution from dual one in MAP inference in MRF? In Control Systems

and Computers (special issue on Optimal Labeling Problems in Structual Pattern Recognition)  2011.

[28] C. Yanover  T. Meltzer  and Y. Weiss. Linear programming relaxations and belief propagation – an

empirical study. Journal of Machine Learning Research  7:1887–1907  2006.

9

,Zheng Wen
Benjamin Van Roy
Cynthia Dwork
Vitaly Feldman
Moritz Hardt
Toni Pitassi
Omer Reingold
Aaron Roth
Zelda Mariet
Suvrit Sra