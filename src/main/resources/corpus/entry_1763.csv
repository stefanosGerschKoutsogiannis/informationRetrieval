2017,Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems,We propose a generic algorithmic building block to accelerate training of  machine learning models on heterogeneous compute systems. Our scheme allows to efficiently employ compute accelerators such as GPUs and FPGAs for the training of large-scale machine learning models  when the training data exceeds their memory capacity. Also  it provides adaptivity to any system's memory hierarchy in terms of size and processing speed. Our technique is built upon novel theoretical insights regarding primal-dual coordinate methods  and uses duality gap information to dynamically decide which part of the data should be made available for fast processing. To illustrate the power of our approach we demonstrate its performance for training of generalized linear models on a large-scale dataset exceeding the memory size of a modern GPU  showing an order-of-magnitude speedup over existing approaches.,Efﬁcient Use of Limited-Memory Accelerators
for Linear Learning on Heterogeneous Systems

Celestine D¨unner

IBM Research - Zurich

Switzerland

Thomas Parnell

IBM Research - Zurich

Switzerland

Martin Jaggi

EPFL

Switzerland

cdu@zurich.ibm.com

tpa@zurich.ibm.com

martin.jaggi@epfl.ch

Abstract

We propose a generic algorithmic building block to accelerate training of machine
learning models on heterogeneous compute systems. Our scheme allows to efﬁ-
ciently employ compute accelerators such as GPUs and FPGAs for the training
of large-scale machine learning models  when the training data exceeds their me-
mory capacity. Also  it provides adaptivity to any system’s memory hierarchy in
terms of size and processing speed. Our technique is built upon novel theoretical
insights regarding primal-dual coordinate methods  and uses duality gap informa-
tion to dynamically decide which part of the data should be made available for
fast processing. To illustrate the power of our approach we demonstrate its perfor-
mance for training of generalized linear models on a large-scale dataset exceeding
the memory size of a modern GPU  showing an order-of-magnitude speedup over
existing approaches.

Introduction

1
As modern compute systems rapidly increase in size  complexity and computational power  they
become less homogeneous. Today’s systems exhibit strong heterogeneity at many levels: in terms
of compute parallelism  memory size and access bandwidth  as well as communication bandwidth
between compute nodes (e.g.  computers  mobile phones  server racks  GPUs  FPGAs  storage nodes
etc.). This increasing heterogeneity of compute environments is posing new challenges for the
development of efﬁcient distributed algorithms. That is to optimally exploit individual compute
resources with very diverse characteristics without suffering from the I/O cost of exchanging data
between them.
In this paper  we focus on the task of training large scale
machine learning models in such heterogeneous compute en-
vironments and propose a new generic algorithmic building
block to efﬁciently distribute the workload between heteroge-
neous compute units. Assume two compute units  denoted A
and B  which differ in compute power as well as memory ca-
pacity as illustrated in Figure 1. The computational power of
unit A is smaller and its memory capacity is larger relative to
its peer unit B (i.e.  we assume that the training data ﬁts into
the memory of A  but not into B’s). Hence  on the compu-
tationally more powerful unit B  only part of the data can be
processed at any given time. The two units  A and B  are able
to communicate with each other over some interface  however
there is cost associated with doing so.
This generic setup covers many essential elements of modern machine learning systems. A typical
example is that of accelerator units  such as a GPUs or FPGAs  augmenting traditional computers

Figure 1: Compute units A  B with
different memory size  bandwidth
and compute power.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Unit A⚙Unit B⚙⚙⚙⚙or servers. While such devices can offer a signiﬁcant increase in computational power due to their
massively parallel architectures  their memory capacity is typically very limited. Another example
can be found in hierarchical memory systems where data in the higher level memory can be accessed
and hence processed faster than data in the – typically larger – lower level memory. Such memory
systems are spanning from fast on-chip caches on one extreme to slower hard drives on the other
extreme.
The core question we address in this paper is the following: How can we efﬁciently distribute the
workload between heterogeneous units A and B in order to accelerate large scale learning?
The generic algorithmic building block we propose systematically splits the overall problem into two
workloads  a more data-intensive but less compute-intensive part for unit A and a more compute-
intensive but less data-intensive part for B. These workloads are then executed in parallel  enabling
full utilization of both resources while keeping the amount of necessary communication between
the two units minimal. Such a generic algorithmic building block is useful much more widely than
just for training on two heterogeneous compute units – it can serve as a component of larger training
algorithms or pipelines thereof. In a distributed training setting  our scheme allows each individual
node to locally beneﬁt from its own accelerator  therefore speeding up the overall task on a cluster 
e.g.  as part of [14] or another distributed algorithm. Orthogonal to such a horizontal application  our
scheme can also be used as a building block vertically integrated in a system  serving the efﬁciency
of several levels of the memory hierarchy of a given compute node.

Related Work. The most popular existing approach to deal with memory limitations is to process
data in batches. For example  for the special case of SVMs  [16] splits data samples into blocks
which are then loaded and processed sequentially (on B)  in the setting of limited RAM and the
full data residing on disk. This approach enables contiguous chunks of data to be loaded which is
beneﬁcial in terms of I/O overhead; it however treats samples uniformly. The same holds for [15]
where blocks to be loaded are selected randomly. Later  in [2  7] it is proposed to selectively load
and keep informative samples in memory in order to reduce disk access  but this approach is speciﬁc
to support vectors and is unable to theoretically quantify the possible speedup.
In this work  we propose a novel  theoretically-justiﬁed scheme to efﬁciently deal with memory
limitations in the heterogeneous two-unit setting illustrated in Figure 1. Our scheme can be applied
to a broad class of machine learning problems  including generalized linear models  empirical risk
minimization problems with a strongly convex regularizer  such as SVM  as well as sparse models 
such as Lasso. In contrast to the related line of research [16  2  7]  our scheme is designed to take full
advantage of both compute resources A and B for training  by systematically splitting the workload
among A and B in order to adapt to their speciﬁc properties and to the available bandwidth between
them. At the heart of our approach lies a smart data selection scheme using coordinate-wise duality
gaps as selection criteria. Our theory will show that our selection scheme provably improves the
convergence rate of training overall  by explicitly quantifying the beneﬁt over uniform sampling. In
contrast  existing work [2  7] only showed that the linear convergence rate on SVMs is preserved
asymptotically  but not necessarily improved.
A different line of related research is steepest coordinate selection. It is known that steepest coor-
dinate descent can converge much faster than uniform [8] for single coordinate updates on smooth
objectives  however it typically does not perform well for general convex problems  such as those
with L1 regularization. In our work  we overcome this issue by using the generalized primal-dual
gaps [4] which do extend to L1 problems. Related to this notion  [3  9  11] have explored the use
of similar information as an adaptive measure of importance  in order to adapt the sampling prob-
abilities of coordinate descent. Both this line of research as well as steepest coordinate descent [8]
are still limited to single coordinate updates  and cannot be readily extended to arbitrary accuracy
updates on a larger subset of coordinates (performed per communication round) as required in our
heterogeneous setting.

Contributions. The main contributions of this work are summarized as follows:
• We analyze the per-iteration-improvement of primal-dual block coordinate descent and how it
depends on the selection of the active coordinate block at that iteration. Further  we extend the
convergence theory to arbitrary approximate updates on the coordinate subsets. We propose
a novel dynamic selection scheme for blocks of coordinates  which relies on coordinate-wise
duality gaps  and precisely quantify the speedup of the convergence rate over uniform sampling.

2

• Our theoretical ﬁndings result in a scheme for learning in heterogeneous compute environments
which is easy to use  theoretically justiﬁed and versatile in that it can be adapted to given re-
source constraints  such as memory  computation and communication. Furthermore our scheme
enables parallel execution between  and also within  two heterogeneous compute units.

• For the example of joint training in a CPU plus GPU environment – which is very challenging
for data-intensive work loads – we demonstrate a more than 10× speed-up over existing methods
for limited-memory training.

min
α∈Rn

O(α) := f (Aα) + g(α)

where f is a smooth function and g(α) =(cid:80)

2 Learning Problem
For the scope of this work we focus on the training of convex generalized linear models of the form
(1)
i gi(αi) is separable  α ∈ Rn describes the parameter
vector and A = [a1  a2  . . .   an] ∈ Rd×n the data matrix with column vectors ai ∈ Rd. This setting
covers many prominent machine learning problems  including generalized linear models as used for
regression  classiﬁcation and feature selection. To avoid confusion  it is important to distinguish the
two main application classes: On one hand  we cover empirical risk minimization (ERM) problems
with a strongly convex regularizer such as L2-regularized SVM – where α then is the dual variable
vector and f is the smooth regularizer conjugate  as in SDCA [13]. On the other hand  we also cover
the class of sparse models such as Lasso or ERM with a sparse regularizer – where f is the data-ﬁt
term and g takes the role of the non-smooth regularizer  so α are the original primal parameters.
Duality Gap. Through the perspective of Fenchel-Rockafellar duality  one can  for any primal-
dual solution pair (α  w)  deﬁne the non-negative duality gap for (1) as

(2)
where the functions f∗  g∗ in (2) are deﬁned as the convex conjugate1 of their corresponding coun-
terparts f  g [1]. Let us consider parameters w that are optimal relative to a given α  i.e. 

:= f (Aα) + g(α) + f∗(w) + g∗(−A(cid:62)w)

gap(α; w)

w := w(α) = ∇f (Aα) 

(3)
which implies f (Aα) + f∗(w) = (cid:104)Aα  w(cid:105). In this special case  the duality gap (2) simpliﬁes and
becomes separable over the columns ai of A and the corresponding parameter weights αi given w.
We will later exploit this property to quantify the suboptimality of individual coordinates.
i (−a(cid:62)

gapi(αi)  where gapi(αi) := w(cid:62)aiαi + gi(αi) + g∗

(cid:88)

gap(α) =

i w).

(4)

i∈[n]

Notation. For the remainder of the paper we use v[P] to denote a vector v with non-zero entries
only for the coordinates i ∈ P ⊆ [n] = {1  . . .   n}. Similarly we write A[P] to denote the matrix A
composing only of columns indexed by i ∈ P.

3 Approximate Block Coordinate Descent
The theory we present in this section serves to derive a theoretical framework for our heterogeneous
learning scheme presented in Section 4. Therefore  let us consider the generic block minimization
scheme described in Algorithm 1 to train generalized linear models of the form (1).

3.1 Algorithm Description
In every round t  of Algorithm 1  a block P of m coordinates of α is selected according to an
arbitrary selection rule. Then  an update is computed on this block of coordinates by optimizing

arg min
∆α[P]∈Rn

O(α + ∆α[P])

(5)

where an arbitrary solver can be used to ﬁnd this update. This update is not necessarily perfectly
optimal but of a relative accuracy θ  in the following sense of approximation quality:

1For h : Rd → R the convex conjugate is deﬁned as h∗(v) := supu∈Rd v(cid:62)u − h(u).

3

Algorithm 1 Approximate Block CD
1: Initialize α(0) := 0
2: for t = 0  1  2  ... do
3:
4: ∆α[P] ← θ-approx. solution to (5)
5: α(t+1) := α(t) + ∆α[P]
6: end for

select a subset P with |P| = m

Algorithm 2 DUHL
1: Initialize α(0) := 0  z := 0
2: for t = 0  1  2  ...
3:
4:
5:
6:
7:
8:
9:
10:
11:

determine P according to (13)
refresh memory B to contain A[P].
on B do:
∆α[P] ← θ-approx. solution to (12)
in parallel on A do:
while B not ﬁnished
sample j ∈ [n]
update zj := gapj(α(t)
j )

α(t+1) := α(t) + ∆α[P]

Deﬁnition 1 (θ-Approximate Update). The block update ∆α[P] is θ-approximate iff
[P]) + (1 − θ)O(α)

∃θ ∈ [0  1] : O(α + ∆α[P]) ≤ θO(α + ∆α(cid:63)

where ∆α(cid:63)

[P] ∈ arg min∆α[P]∈Rn O(α + ∆α[P]).

(6)

3.2 Convergence Analysis

In order to derive a precise convergence rate for Algorithm 1 we build on the convergence analysis
of [4  13]. We extend their analysis of stochastic coordinate descent in two ways: 1) to a block
coordinate scheme with approximate coordinate updates  and 2) to explicitly cover the importance
of each selected coordinate  as opposed to uniform sampling.
We deﬁne

(cid:80)
(cid:80)

1
m
1
n

ρt P :=

j∈P gapj(α(t)
j )
j∈[n] gapj(α(t)
j )

(7)

which quantiﬁes how much the coordinates i ∈ P of α(t) contribute to the global duality gap
(2). Thus giving a measure of suboptimality for these coordinates. In Algorithm 1 an arbitrary
selection scheme (deterministic or randomized) can be applied and our theory will explain how
the convergence of Algorithm 1 depends on the selection through the distribution of ρt P. That
is  for strongly convex functions gi  we found that the per-step improvement in suboptimality is
proportional to ρt P of the speciﬁc coordinate block P being selected at that iteration t:

(t+1) ≤ (1 − ρt P θc) (t)

(8)
where (t) := O(α(t)) − O(α(cid:63)) measures the suboptimality of α(t) and c > 0 is a constant which
will be speciﬁed in the following theorem. A similar dependency on ρt P can also be shown for
non-strongly convex functions gi  leading to our two main convergence results for Algorithm 1:
Theorem 1. For Algorithm 1 running on (1) where f is L-smooth and gi is µ-strongly convex with
µ > 0 for all i ∈ [n]  it holds that

(cid:18)

(cid:19)t

EP [(t) | α(0)] ≤

1 − ηP

m
n

µ

σL + µ

(0)

(9)

op and ηP := mint θ EP [ρt P | α(t)]. Expectations are over the choice of P.

where σ := (cid:107)A[P](cid:107)2
That is  for strongly convex gi  Algorithm 1 has a linear convergence rate. This was shown before
in [13  4] for the special case of exact coordinate updates. In strong contrast to earlier coordinate
descent analyses which build on random uniform sampling  our theory explicitly quantiﬁes the im-
pact of the sampling scheme on the convergence through ρt P. This allows one to beneﬁt from smart
selection and provably improve the convergence rate by taking advantage of the inhomogeneity of
the duality gaps. The same holds for non-strongly convex functions gi:

4

Theorem 2. For Algorithm 1 running on (1) where f is L-smooth and gi has B-bounded support
for all i ∈ [n]  it holds that

EP [(t) | α(0)] ≤ 1
ηP m

op and t ≥ t0 = max(cid:8)0  n

2n + t − t0

2γn2

m log(cid:0) 2ηm(0)

nγ

(10)

(cid:1)(cid:9) where ηP :=

with γ := 2LB2σ where σ := (cid:107)A[P](cid:107)2
mint θ EP [ρt P | α(t)]. Expectations are over the choice of P.
Remark 1. Note that for uniform selection  our proven convergence rates for Algorithm 1 recover
classical primal-dual coordinate descent [4  13] as a special case  where in every iteration a single
coordinate is selected and each update is solved exactly  i.e.  θ = 1. In this case ρt P measures the
contribution of a single coordinate to the duality gap. For uniform sampling  EP [ρt P | α(t)] = 1
and hence ηP = 1 which recovers [4  Theorems 8 and 9].

3.3 Gap-Selection Scheme
The convergence results of Theorems 1 and 2 suggest that the optimal rule for selecting the block
of coordinates P in step 3 of Algorithm 1  leading to the largest improvement in that step  is the
following:

P := arg max
P⊂[n]:|P|=m

(cid:0)α(t)

(cid:1).

j

gapj

(cid:88)

j∈P

(11)

This scheme maximizes ρt P at every iterate. Furthermore  the selection scheme (11) guarantees
ρt P ≥ 1 which quantiﬁes the relative gain over random uniform sampling. In contrast to existing
importance sampling schemes [17  12  5] which assign static probabilities to individual coordinates 
our selection scheme (11) is dynamic and adapts to the current state α(t) of the algorithm  similar
to that used in [9  11] in the standard non-heterogeneous setting.

4 Heterogeneous Training
In this section we build on the theoretical insight of the previous section to tackle the main objective
of this work: How can we efﬁciently distribute the workload between two heterogeneous compute
units A and B to train a large-scale machine learning problem where A and B fulﬁll the following
two assumptions:
Assumption 1 (Difference in Memory Capacity). Compute unit A can ﬁt the whole dataset in its
memory and compute unit B can only ﬁt a subset of the data. Hence  B only has access to A[P]  a
subset P of m columns of A  where m is determined by the memory size of B.
Assumption 2 (Difference in Computational Power). Compute unit B can access and process data
faster than compute unit A.
4.1 DUHL: A Duality Gap-Based Heterogeneous Learning Scheme
We propose a duality gap-based heterogeneous learning scheme  henceforth referring to as DUHL 
for short. DUHL is designed for efﬁcient training on heterogeneous compute resources as described
above. The core idea of DUHL is to identify a block P of coordinates which are most relevant to
improving the model at the current stage of the algorithm  and have the corresponding data columns 
A[P]  residing locally in the memory of B. Compute unit B can then exploit its superior compute
power by using an appropriate solver to locally ﬁnd a block coordinate update ∆α[P]. At the same
time  compute unit A  is assigned the task of updating the block P of important coordinates as
the algorithm proceeds and the iterates change. Through this split of workloads DUHL enables full
utilization of both compute units A and B. Our scheme  summarized in Algorithm 2  ﬁts the theoret-
ical framework established in the previous section and can be viewed as an instance of Algorithm 1 
implementing a time-delayed version of the duality gap-based selection scheme (11).
In the heterogeneous setting compute unit B only has access to its local data
Local Subproblem.
A[P] and some current state v := Aα ∈ Rd in order to compute a block update ∆α[P] in Step 4
of Algorithm 1. While for quadratic functions f this information is sufﬁcient to optimize (5)  for
non-quadratic functions f we consider the following modiﬁed local optimization problem instead:

(cid:88)

i∈P

gi((α + ∆α[P])i).

(12)

arg min
∆α[P]∈Rn

f (v) + (cid:104)∇f (v)  A∆α[P](cid:105) +

(cid:107)A∆α[P](cid:107)2

2 +

L
2

5

Figure 2: Illustration of one round of DUHL as described in Algorithm 2.

It can be shown that the convergence guarantees of Theorems 1 and 2 similarly hold if the block
coordinate update in Step 4 of Algorithm 1 is computed on (12) instead of (5) (see Appendix C for
more details).
A Time-Delayed Gap Measure. Motivated by our theoretical ﬁndings  we use the duality gap as a
measure of importance for selecting which coordinates unit B is working on. However  a scheme as
suggested in (11) is not suitable for our purpose since it requires knowledge of the duality gaps (4)
for every coordinate i at a given iterate α(t). For our scheme this would imply a computationally
expensive selection step at the beginning of every round which has to be performed in sequence to
the update step. To overcome this and enable parallel execution of the two workloads on A and B 
we propose to introduce a gap memory. This is an n-dimensional vector z where zi measures the
importance of coordinate αi. We have zi := gap(α(t(cid:48))
) where t(cid:48) ∈ [0  t] and the different elements
of z are allowed to be based on different  possibly stale iterates α(t(cid:48)). Thus  the entries of z can be
continuously updated during the course of the algorithm. Then  at the beginning of every round the
new block P is chosen based on the current state of z as follows:

i

P := arg max
P⊂[n]:|P|=m

zj.

(13)

(cid:88)

j∈P

In DUHL  keeping z up to date is the job of compute unit A. Hence  while B is computing a block
coordinate update ∆α[P]  A updates z by randomly sampling from the entire training data. Then 
as soon as B is done  the current state of z is used to determine P for the next round and data
columns on B are replaced if necessary. The parallel execution of the two workloads during a single
round of DUHL is illustrated in Figure 2. Note  that the freshness of the gap-memory z depends
on the relative compute power of A versus B  as well as θ which controls the amount of time spent
computing on unit B in every round.
In Section 5.2 we will experimentally investigate the effect of staleness of the values zi on the
convergence behavior of our scheme.

5 Experimental Results
For our experiments we have implemented DUHL for the particular use-case where A corresponds
to a CPU with attached RAM and B corresponds to a GPU – A and B communicate over the PCIe
bus. We use an 8-core Intel Xeon E5 x86 CPU with 64GB of RAM which is connected over PCIe
Gen3 to an NVIDIA Quadro M4000 GPU which has 8GB of RAM. GPUs have recently experience
a widespread adoption in machine learning systems and thus this hardware scenario is timely and
highly relevant. In such a setting we wish to apply DUHL to efﬁciently populate the GPU memory
and thereby making this part of the data available for fast processing.
GPU solver.
In order to beneﬁt from the enormous parallelism offered by GPUs and fulﬁll As-
sumption 2  we need a local solver capable of exploiting the power of the GPU. Therefore  we
have chosen to implement the twice parallel  asynchronous version of stochastic coordinate descent

6

(a)

(b)

(a)

(b)

Figure 3: Validation of faster convergence: (a)
theoretical quantity ρt P (orange)  versus the
practically observed speedup (green) – both re-
lative to the random scheme baseline  (b) con-
vergence of gap selection compared to random
selection.

Figure 4: Effect of stale entries in the gap me-
mory of DUHL: (a) number of rounds needed
to reach suboptimality 10−4 for different update
frequencies compared to o-DUHL  (b) the num-
ber of data columns that are replaced per round
for update frequency of 5%.

(TPA-SCD) that has been proposed in [10] for solving ridge regression. In this work we have gene-
ralized the implementation further so that it can be applied in a similar manner to solve the Lasso 
as well as the SVM problem. For more details about the algorithm and how to generalize it we refer
the reader to Appendix D.

5.1 Algorithm Behavior

Firstly  we will use the publicly available epsilon dataset from the LIBSVM website (a fully dense
dataset with 400’000 samples and 2’000 features) to study the convergence behavior of our scheme.
For the experiments in this section we assume that the GPU ﬁts 25% of the training data  i.e.  m = n
4
and show results for training the sparse Lasso as well as the ridge regression model. For the Lasso
case we have chosen the regularizer to obtain a support size of ∼ 12% and we apply the coordinate-
wise Lipschitzing trick [4] to the L1-regularizer in order to allow the computation of the duality
gaps. For computational details we refer the reader to Appendix E.

Validation of Faster Convergence. From our theory in Section 3.2 we expect that during any
given round t of Algorithm 1  the relative gain in convergence rate of one sampling scheme over
the other should be quantiﬁed by the ratio of the corresponding values of ηt P := θρt P (for the
respective block of coordinates processed in this round). To verify this  we trained a ridge regression
model on the epsilon dataset implementing a) the gap-based selection scheme  (11)  and b) random
selection  ﬁxing θ for both schemes. Then  in every round t of our experiment  we record the value
of ρt P as deﬁned in (7) and measure the relative gain in convergence rate of the gap-based scheme
over the random scheme. In Figure 3(a) we plot the effective speedup of our scheme  and observe
that this speedup almost perfectly matches the improvement predicted by our theory as measured
by ρt P - we observe an average deviation of 0.42. Both speedup numbers are calculated relative to
plain random selection. In Figure 3(b) we see that the gap-based selection can achieve a remarkable
10× improvement in convergence over the random reference scheme. When running on sparse
problems instead of ridge regression  we have observed ρt P of the oracle scheme converging to n
m
within only a few iterations if the support of the problem is smaller than m and ﬁts on the GPU.

Effect of Gap-Approximation.
In this section we study the effect of using stale  inconsistent gap-
memory entries for selection on the convergence of DUHL. While the freshness of the memory
entries is  in reality  determined by the relative compute power of unit B over unit A and the relative
accuracy θ  in this experiment we artiﬁcially vary the number of gap updates performed during each
round while keeping θ ﬁxed. We train the Lasso model and show  in Figure 4(a)  the number of
rounds needed to reach a suboptimality of 10−4  as a function of the number of gap entries updated
per round. As a reference we show o-DUHL which has access to an oracle providing the true duality
gaps. We observe that our scheme is quite robust to stale gap values and can achieve performance
within a factor of two over the oracle scheme up to an average delay of 20 iterations. As the update
frequency decreases we observed that the convergence slows down in the initial rounds because the
algorithm needs more rounds until the active set of the sparse problem is correctly detected.

7

(d) Lasso

(e) SVM

(f) ridge regression

Figure 5: Performance results of DUHL on the 30GB ImageNet dataset. I/O cost (top) and conver-
gence behavior (bottom) for Lasso  SVM and ridge regression.

Reduced I/O operations. The efﬁciency of our scheme regarding I/O operations is demonstrated
in Figure 4(b)  where we plot the number of data columns that are replaced on B in every round
of Algorithm 2. Here the Lasso model is trained assuming a gap update frequency of 5%. We
observe that the number of required I/O operations of our scheme is decreasing over the course of
the algorithm. When increasing the freshness of the gap memory entries we could see the number
of swaps go to zero faster.

5.2 Reference Schemes
In the following we compare the performance of our scheme against four reference schemes. We
compare against the most widely-used scheme for using a GPU to accelerate training when the data
does not ﬁt into the memory of the GPU  that is the sequential block selection scheme presented
in [16]. Here the data columns are split into blocks of size m which are sequentially put on the GPU
and operated on (the data is efﬁciently copied to the GPU as a contiguous memory block).
We also compare against importance sampling as presented in [17]  which we refer to as IS. Since
probabilities assigned to individual data columns are static we cannot use them as importance mea-
sures in a deterministic selection scheme. Therefore  in order to apply importance sampling in the
heterogeneous setting  we non-uniformly sample m data-columns to reside inside the GPU memory
in every round of Algorithm 2 and have the CPU determine the new set in parallel. As we will see 
data column norms often come with only small variance  in particular for dense datasets. Therefore 
importance sampling often fails to give a signiﬁcant gain over uniformly random selection.
Additionally  we compare against a single-threaded CPU implementation of a stochastic coordinate
descent solver to demonstrate that with our scheme  the use of a GPU in such a setting indeed yields a
signiﬁcant speedup over a basic CPU implementation despite the high I/O cost of repeatedly copying
data on and off the GPU memory. To the best of our knowledge  we are the ﬁrst to demonstrate this.
For all competing schemes  we use TPA-SCD as the solver to efﬁciently compute the block update
∆α[P] on the GPU. The accuracy θ of the block update computed in every round is controlled by
the number of randomized passes of TPA-SCD through the coordinates of the selected block P. For
a fair comparison we optimize this parameter for the individual schemes.

5.3 Performance Analysis of DUHL
For our large-scale experiments we use an extended version of the Kaggle Dogs vs. Cats ImageNet
dataset as presented in [6]  where we additionally double the number of samples  while using single
precision ﬂoating point numbers. The resulting dataset is fully dense and consists of 40’000 samples
and 200’704 features  resulting in over 8 billion non-zero elements and a data size of 30GB. Since
the memory capacity of our GPU is 8GB  we can put ∼ 25% of the data on the GPU. We will show

8

results for training a sparse Lasso model  ridge regression as well as linear L2-regularized SVM.
For Lasso we choose the regularization to achieve a support size of 12%  whereas for SVM the
regularizer was chosen through cross-validation. For all three tasks  we compare the performance
of DUHL to sequential block selection  random selection  selection through importance sampling
(IS) all on GPU  as well as a single-threaded CPU implementation. In Figure 5(d) and 5(e) we
demonstrate that for Lasso as well as SVM  DUHL converges 10× faster than any reference scheme.
This gain is achieved by improved convergence – quantiﬁed through ρt P – as well as through
reduced I/O cost  as illustrated in the top plots of Figure 5  which show the number of data columns
replaced per round. The results in Figure 5(f) show that the application of DUHL is not limited
to sparse problems and SVMs. Even for ridge regression DUHL signiﬁcantly outperforms all the
reference scheme considered in this study.

6 Conclusion

We have presented a novel theoretical analysis of block coordinate descent  highlighting how the
performance depends on the coordinate selection. These results prove that the contribution of in-
dividual coordinates to the overall duality gap is indicative of their relevance to the overall model
optimization. Using this measure we develop a generic scheme for efﬁcient training in the presence
of high performance resources of limited memory capacity. We propose DUHL  an efﬁcient gap
memory-based strategy to select which part of the data to make available for fast processing. On a
large dataset which exceeds the capacity of a modern GPU  we demonstrate that our scheme out-
performs existing sequential approaches by over 10× for Lasso and SVM models. Our results show
that the practical gain matches the improved convergence predicted by our theory for gap-based
sampling under the given memory and communication constraints  highlighting the versatility of the
approach.

References
[1] Heinz H Bauschke and Patrick L Combettes. Convex Analysis and Monotone Operator Theory in Hilbert

Spaces. CMS Books in Mathematics. Springer New York  New York  NY  2011.

[2] Kai-Wei Chang and Dan Roth. Selective block minimization for faster convergence of limited memory
large-scale linear models. In Proceedings of the 17th ACM SIGKDD international conference on Knowl-
edge Discovery and Data Mining  pages 699–707  New York  USA  August 2011. ACM.

[3] Dominik Csiba  Zheng Qu  and Peter Richt´arik. Stochastic Dual Coordinate Ascent with Adaptive Proba-
bilities. In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning  February
2015.

[4] Celestine D¨unner  Simone Forte  Martin Tak´ac  and Martin Jaggi. Primal-Dual Rates and Certiﬁcates.
In Proceedings of the 33th International Conference on Machine Learning (ICML) - Volume 48  pages
783–792  2016.

[5] Olivier Fercoq and Peter Richt´arik. Optimization in High Dimensions via Accelerated  Parallel  and

Proximal Coordinate Descent. SIAM Review  58(4):739–771  January 2016.

[6] Christina Heinze  Brian McWilliams  and Nicolai Meinshausen. DUAL-LOCO: Distributing Statistical
Estimation Using Random Projections. In AISTATS - Proceedings of the th International Conference on
Artiﬁcial Intelligence and Statistics  pages 875–883  2016.

[7] Shin Matsushima  SVN Vishwanathan  and Alex J Smola. Linear support vector machines via dual cached
loops. In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and
data mining  pages 177–185  New York  USA  2012. ACM Press.

[8] Julie Nutini  Mark Schmidt  Issam Laradji  Michael Friedlander  and Hoyt Koepke. Coordinate Descent
Converges Faster with the Gauss-Southwell Rule Than Random Selection. In ICML 2015 - Proceedings
of the 32th International Conference on Machine Learning  pages 1632–1641  2015.

[9] Anton Osokin  Jean-Baptiste Alayrac  Isabella Lukasewitz  Puneet K. Dokania  and Simon Lacoste-
In Proceedings of
Julien. Minding the gaps for block frank-wolfe optimization of structured svms.
the 33rd International Conference on Machine Learning (ICML) - Volume 48  pages 593–602. JMLR.org 
2016.

[10] Thomas Parnell  Celestine D¨unner  Kubilay Atasu  Manolis Sifalakis  and Haris Pozidis. Large-Scale
In Proceedings of the 6th International Workshop on Parallel and
Stochastic Learning using GPUs.
Distributed Computing for Large Scale Machine Learning and Big Data Analytics (IPDPSW)  IEEE 
2017.

9

[11] Dmytro Perekrestenko  Volkan Cevher  and Martin Jaggi. Faster Coordinate Descent via Adaptive Impor-

tance Sampling. In AISTATS - Artiﬁcial Intelligence and Statistics  pages 869–877. April 2017.

[12] Zheng Qu and Peter Richt´arik. Coordinate descent with arbitrary sampling I: algorithms and complexity.

Optimization Methods and Software  31(5):829–857  April 2016.

[13] Shai Shalev-Shwartz and Tong Zhang. Stochastic dual coordinate ascent methods for regularized loss. J.

Mach. Learn. Res.  14(1):567–599  February 2013.

[14] Virginia Smith  Simone Forte  Chenxin Ma  Martin Tak´aˇc  Michael I Jordan  and Martin Jaggi. CoCoA:

A General Framework for Communication-Efﬁcient Distributed Optimization. arXiv  November 2016.

[15] Ian En-Hsu Yen  Shan-Wei Lin  and Shou-De Lin. A dual augmented block minimization framework for
learning with limited memory. In C. Cortes  N. D. Lawrence  D. D. Lee  M. Sugiyama  and R. Garnett 
editors  Advances in Neural Information Processing Systems 28  pages 3582–3590. Curran Associates 
Inc.  2015.

[16] Hsiang-Fu Yu  Cho-Jui Hsieh  Kai-Wei Chang  and Chih-Jen Lin. Large Linear Classiﬁcation When Data
Cannot Fit in Memory. ACM Transactions on Knowledge Discovery from Data  5(4):1–23  February
2012.

[17] Peilin Zhao and Tong Zhang. Stochastic Optimization with Importance Sampling for Regularized Loss
Minimization. In ICML 2015 - Proceedings of the 32th International Conference on Machine Learning 
pages 1–9  2015.

10

,Celestine Dünner
Thomas Parnell
Martin Jaggi
Tianyu Pang
Chao Du
Yinpeng Dong
Jun Zhu