2010,Random Conic Pursuit for Semidefinite Programming,We present a novel algorithm  Random Conic Pursuit  that solves semidefinite programs (SDPs) via repeated optimization over randomly selected two-dimensional subcones of the PSD cone. This scheme is simple  easily implemented  applicable to very general SDPs  scalable  and theoretically interesting. Its advantages are realized at the expense of an ability to readily compute highly exact solutions  though useful approximate solutions are easily obtained. This property renders Random Conic Pursuit of particular interest for machine learning applications  in which the relevant SDPs are generally based upon random data and so exact minima are often not a priority. Indeed  we present empirical results to this effect for various SDPs encountered in machine learning; these experiments demonstrate the potential practical usefulness of Random Conic Pursuit. We also provide a preliminary analysis that yields insight into the theoretical properties and convergence of the algorithm.,Random Conic Pursuit for Semideﬁnite Programming

Ariel Kleiner

Computer Science Division
Univerisity of California

Berkeley  CA 94720

Ali Rahimi

Intel Research Berkeley

Berkeley  CA 94720

ali.rahimi@intel.com

Michael I. Jordan

Computer Science Division

University of California

Berkeley  CA 94720

akleiner@cs.berkeley.edu

jordan@cs.berkeley.edu

Abstract

We present a novel algorithm  Random Conic Pursuit  that solves semideﬁnite pro-
grams (SDPs) via repeated optimization over randomly selected two-dimensional
subcones of the PSD cone. This scheme is simple  easily implemented  applica-
ble to very general SDPs  scalable  and theoretically interesting. Its advantages
are realized at the expense of an ability to readily compute highly exact solutions 
though useful approximate solutions are easily obtained. This property renders
Random Conic Pursuit of particular interest for machine learning applications  in
which the relevant SDPs are generally based upon random data and so exact min-
ima are often not a priority. Indeed  we present empirical results to this effect for
various SDPs encountered in machine learning; these experiments demonstrate
the potential practical usefulness of Random Conic Pursuit. We also provide a
preliminary analysis that yields insight into the theoretical properties and conver-
gence of the algorithm.

1

Introduction

Many difﬁcult problems have been shown to admit elegant and tractably computable representations
via optimization over the set of positive semideﬁnite (PSD) matrices. As a result  semideﬁnite
programs (SDPs) have appeared as the basis for many procedures in machine learning  such as
sparse PCA [8]  distance metric learning [24]  nonlinear dimensionality reduction [23]  multiple
kernel learning [14]  multitask learning [19]  and matrix completion [2].
While SDPs can be solved in polynomial time  they remain computationally challenging. General-
purpose solvers  often based on interior point methods  do exist and readily provide high-accuracy
solutions. However  their memory requirements do not scale well with problem size  and they typi-
cally do not allow a ﬁne-grained tradeoff between optimization accuracy and speed  which is often a
desirable tradeoff in machine learning problems that are based on random data. Furthermore  SDPs
in machine learning frequently arise as convex relaxations of problems that are originally compu-
tationally intractable  in which case even an exact solution to the SDP yields only an approximate
solution to the original problem  and an approximate SDP solution can once again be quite useful.
Although some SDPs do admit tailored solvers which are fast and scalable (e.g.  [17  3  7])  deriv-
ing and implementing these methods is often challenging  and an easily usable solver that alleviates
these issues has been elusive. This is partly the case because generic ﬁrst-order methods do not
apply readily to general SDPs.
In this work  we present Random Conic Pursuit  a randomized solver for general SDPs that is simple 
easily implemented  scalable  and of inherent interest due to its novel construction. We consider
general SDPs over Rd×d of the form

min
X(cid:23)0

f (X)

s.t.

gj(X) ≤ 0 

j = 1 . . . k 

(1)

1

where f and the gj are convex real-valued functions  and (cid:23) denotes the ordering induced by the
PSD cone. Random Conic Pursuit minimizes the objective function iteratively  repeatedly randomly
sampling a PSD matrix and optimizing over the random two-dimensional subcone given by this
matrix and the current iterate. This construction maintains feasibility while avoiding the compu-
tational expense of deterministically ﬁnding feasible directions or of projecting into the feasible
set. Furthermore  each iteration is computationally inexpensive  though in exchange we generally
require a relatively large number of iterations. In this regard  Random Conic Pursuit is similar in
spirit to algorithms such as online gradient descent and sequential minimal optimization [20] which
have illustrated that in the machine learning setting  algorithms that take a large number of simple 
inexpensive steps can be surprisingly successful.
The resulting algorithm  despite its simplicity and randomized nature  converges fairly quickly to
useful approximate solutions. Unlike interior point methods  Random Conic Pursuit does not excel
in producing highly exact solutions. However  it is more scalable and provides the ability to trade
off computation for more approximate solutions. In what follows  we present our algorithm in full
detail and demonstrate its empirical behavior and efﬁcacy on various SDPs that arise in machine
learning; we also provide early analytical results that yield insight into its behavior and convergence
properties.

2 Random Conic Pursuit

Random Conic Pursuit (Algorithm 1) solves SDPs of the general form (1) via a sequence of sim-
ple two-variable optimizations (2). At each iteration  the algorithm considers the two-dimensional
cone spanned by the current iterate  Xt  and a random rank one PSD matrix  Yt. It selects as its
next iterate  Xt+1  the point in this cone that minimizes the objective f subject to the constraints
gj(Xt+1) ≤ 0 in (1). The distribution of the random matrices is periodically updated based on the
current iterate (e.g.  to match the current iterate in expectation); these updates yield random matrices
that are better matched to the optimum of the SDP at hand.
The two-variable optimization (2) can be solved quickly in general via a two-dimensional bisection
search. As a further speedup  for many of the problems that we considered  the two-variable opti-
mization can be altogether short-circuited with a simple check that determines whether the solution
Xt+1 = Xt  with ˆβ = 1 and ˆα = 0  is optimal. Additionally  SDPs with a trace constraint tr X = 1
force α + β = 1 and therefore require only a one-dimensional optimization.
Two simple guarantees for Random Conic Pursuit are immediate. First  its iterates are feasible for (1)
because each iterate is a positive sum of two PSD matrices  and because the constraints gj of (2)
are also those of (1). Second  the objective values decrease monotonically because β = 1  α = 0
is a feasible solution to (2). We must also note two limitations of Random Conic Pursuit: it does
not admit general equality constraints  and it requires a feasible starting point. Nonetheless  for
many of the SDPs that appear in machine learning  feasible points are easy to identify  and equality
constraints are either absent or fortuitously pose no difﬁculty.
We can gain further intuition by observing that Random Conic Pursuit’s iterates  Xt  are positive
weighted sums of random rank one matrices and so lie in the random polyhedral cones

(cid:40) t(cid:88)

(cid:41)
t : γi ≥ 0

F x
t :=

γixtx(cid:48)

⊂ {X : X (cid:23) 0}.

(3)

i=1

Thus  Random Conic Pursuit optimizes the SDP (1) by greedily optimizing f w.r.t. the gj constraints
within an expanding sequence of random cones {F x
t }. These cones yield successively better inner
approximations of the PSD cone (a basis for which is the set of all rank one matrices) while allowing
us to easily ensure that the iterates remain PSD.
In light of this discussion  one might consider approximating the original SDP by sampling a random
cone F x
n in one shot and replacing the constraint X (cid:23) 0 in (1) with the simpler linear constraints
X ∈ F x
n. For sufﬁciently large n  F x
n would approximate the PSD cone well (see Theorem 2 below) 
yielding an inner approximation that upper bounds the original SDP; the resulting problem would be
easier than the original (e.g.  it would become a linear program if the gj were linear). However  we
have found empirically that a very large n is required to obtain good approximations  thus negating
any potential performance improvements (e.g.  over interior point methods). Random Conic Pursuit

2

[brackets contain a particular  generally effective  sampling scheme]

n ∈ N: number of iterations
[κ ∈ (0  1): numerical stability parameter]

[p ← N (0  Σ) with Σ = (1 − κ)X0 + κId]

Algorithm 1: Random Conic Pursuit
Input: A problem of the form (1)
X0: a feasible initial iterate

Output: An approximate solution Xn to (1)
p ← a distribution over Rd
for t ← 1 to n do

Sample xt from p and set Yt ← xtx(cid:48)
Set ˆα  ˆβ to the optimizer of

t

min
α β∈R f (αYt + βXt−1)
s.t. gj(αYt + βXt−1) ≤ 0 

α  β ≥ 0

j = 1 . . . k

(2)

Set Xt ← ˆαYt + ˆβXt−1
if ˆα > 0 then Update p based on Xt

[p ← N (0  Σ) with Σ = (1 − κ)Xt + κId]

end
return Xn

successfully resolves this issue by iteratively expanding the random cone F x
t . As a result  we are
able to much more efﬁciently access large values of n  though we compute a greedy solution within
F x
n rather than a global optimum over the entire cone. This tradeoff is ultimately quite advantageous.

3 Applications and Experiments

We assess the practical convergence and scaling properties of Random Conic Pursuit by applying it
to three different machine learning tasks that rely on SDPs: distance metric learning  sparse PCA 
and maximum variance unfolding. For each  we compare the performance of Random Conic Pursuit
(implemented in MATLAB) to that of a standard and widely used interior point solver  SeDuMi [21]
(via cvx [9])  and to the best available solver which has been customized for each problem.
To evaluate convergence  we ﬁrst compute a ground-truth solution X∗ for each problem instance
by running the interior point solver with extremely low tolerance. Then  for each algorithm  we
plot the normalized objective value errors [f (Xt) − f (X∗)]/|f (X∗)| of its iterates Xt as a function
of the amount of time required to generate each iterate. Additionally  for each problem  we plot
the value of an application-speciﬁc metric for each iterate. These metrics provide a measure of
the practical implications of obtaining SDP solutions which are suboptimal to varying degrees. We
evaluate scaling with problem dimensionality by running the various solvers on problems of different
dimensionalities and computing various metrics on the solver runs as described below for each
experiment. Unless otherwise noted  we use the bracketed sampling scheme given in Algorithm 1
with κ = 10−4 for all runs of Random Conic Pursuit.

3.1 Metric Learning
Given a set of datapoints in Rd and a pairwise similarity relation over them  metric learning extracts
dissimilar points are far apart [24]. Let S be the set of similar pairs of datapoints  and let ¯S be its

a Mahalanobis distance dA(x  y) =(cid:112)(x − y)(cid:48)A(x − y) under which similar points are nearby and
complement. The metric learning SDP  for A ∈ Rd×d and C =(cid:80)

(i j)∈S (xi − xj)(xi − xj)(cid:48)  is

min
A(cid:23)0

tr(CA)

dA(xi  xj) ≥ 1.

(4)

s.t. (cid:88)

(i j)∈ ¯S

To apply Random Conic Pursuit  X0 is set to a feasible scaled identity matrix. We solve the two-
variable optimization (2) via a double bisection search: at each iteration  α is optimized out with
a one-variable bisection search over α given ﬁxed β  yielding a function of β only. This resulting
function is itself then optimized using a bisection search over β.

3

d
100
100
100
200
200
300
300
400
400

alg
IP
RCP
PG
RCP
PG
RCP
PG
RCP
PG

f after 2 hrs∗

time to Q > 0.99

2.8e-7  3.0e-7

3.7e-9

1.1e-5

636.3

142.7  148.4

42.3

5.1e-8  6.1e-8

1.6e-5

5.4e-8  6.5e-8

2.0e-5

7.2e-8  1.0e-8

2.4e-5

529.1  714.8

207.7

729.1  1774.7

1095.8

2128.4  2227.2

1143.3

Figure 1: Results for metric learning. (plots) Trajectories of objective value error (left) and Q (right)
on UCI ionosphere data. (table) Scaling experiments on synthetic data (IP = interior point  RCP =
Random Conic Pursuit  PG = projected gradient)  with two trials per d for RCP and times in seconds.
∗For d = 100  third column shows f after 20 minutes.

As the application-speciﬁc metric for this problem  we measure the extent to which the metric
learning goal has been achieved: similar datapoints should be near each other  and dissimilar
datapoints should be farther away. We adopt the following metric of quality of a solution ma-
i |{j : (i  j) ∈ S}| · |{l : (i  l) ∈ ¯S}| and 1[·] is the indicator function:

trix X  where ζ = (cid:80)

(cid:80)

i

(cid:80)
j:(i j)∈S(cid:80)

Q(X) = 1
ζ

l:(i l)∈ ¯S 1[dij(X) < dil(X)].

To examine convergence behavior  we ﬁrst apply the metric learning SDP to the UCI ionosphere
dataset  which has d = 34 and 351 datapoints with two distinct labels (S contains pairs with identical
labels). We selected this dataset from among those used in [24] because it is among the datasets
which have the largest dimensionality and experience the greatest impact from metric learning in
that work’s clustering application. Because the interior point solver scales prohibitively badly in the
number of datapoints  we subsampled the dataset to yield 4 × 34 = 136 datapoints.
To evaluate scaling  we use synthetic data in order to allow variation of d. To generate a d-
dimensional data set  we ﬁrst generate mixture centers by applying a random rotation to the elements
of C1 = {(−1  1)  (−1 −1)} and C2 = {(1  1)  (1 −1)}. We then sample each datapoint xi ∈ Rd
from N (0  Id) and assign it uniformly at random to one of two clusters. Finally  we set the ﬁrst two
components of xi to a random element of Ck if xi was assigned to cluster k ∈ {1  2}; these two
components are perturbed by adding a sample from N (0  0.25I2).
The best known customized solver for the metric learning SDP is a projected gradient algorithm [24] 
for which we used code available from the author’s website.
Figure 1 shows the results of our experiments. The two trajectory plots  for an ionosphere data
problem instance  show that Random Conic Pursuit converges to a very high-quality solution (with
high Q and negligible objective value error) signiﬁcantly faster than interior point. Additionally 
our performance is comparable to that of the projected gradient method which has been customized
for this task. The table in Figure 1 illustrates scaling for increasing d. Interior point scales badly
in part because parsing the SDP becomes impracticably slow for d signiﬁcantly larger than 100.
Nonetheless  Random Conic Pursuit scales well beyond that point  continuing to return solutions
with high Q in reasonable time. On this synthetic data  projected gradient appears to reach high
Q somewhat more quickly  though Random Conic Pursuit consistently yields signiﬁcantly better
objective values  indicating better-quality solutions.

3.2 Sparse PCA
Sparse PCA seeks to ﬁnd a sparse unit length vector that maximizes x(cid:48)Ax for a given data covariance
matrix A. This problem can be relaxed to the following SDP [8]  for X  A ∈ Rd×d:

ρ1(cid:48)|X|1 − tr(AX)

min
X(cid:23)0

s.t.

tr(X) = 1 

(5)

where the scalar ρ > 0 controls the solution’s sparsity. A subsequent rounding step returns the
dominant eigenvector of the SDP’s solution  yielding a sparse principal component.
We use the colon cancer dataset [1] that has been used frequently in past studies of sparse PCA
and contains 2 000 microarray readings for 62 subjects. The goal is to identify a small number of

4

073414682202293600.020.040.060.080.1time (sec)normalized objective value error  Interior PointRandom PursuitProjected Gradient07341468220229360.40.60.81time (sec)pairwise distance quality (Q)  Interior PointRandom PursuitProjected Gradientd
120
120
120
200
200
200
300
300
300
500
500
500

alg
IP
RCP
DSPCA

IP
RCP
DSPCA

IP
RCP
DSPCA

IP
RCP
DSPCA

f after 4 hrs

sparsity after 4 hrs

-10.25

-9.98  -10.02

-10.24
failed

0.55

0.47  0.45

0.55
failed

-10.30  -10.27

0.51  0.50

-11.07
failed

-9.39  -9.29

-11.52
failed

-6.95  -6.54

-11.61

0.64
failed

0.51  0.51

0.69
failed

0.53  0.50

0.78

Figure 2: Results for sparse PCA. All solvers quickly yield similar captured variance (not shown
here). (plots) Trajectories of objective value error (left) and sparsity (right)  for a problem with
d = 100. (table) Scaling experiments (IP = interior point  RCP = Random Conic Pursuit)  with two
trials per d for RCP.

microarray cells that capture the greatest variance in the dataset. We vary d by subsampling the
readings and use ρ = 0.2 (large enough to yield sparse solutions) for all experiments.
To apply Random Conic Pursuit  we set X0 = A/ tr(A). The trace constraint (5) implies that
tr(Xt−1) = 1 and so tr(αYt + βXt−1) = α tr(Yt) + β = 1 in (2). Thus  we can simplify the
two-variable optimization (2) to a one-variable optimization  which we solve by bisection search.
The fastest available customized solver for the sparse PCA SDP is an adaptation of Nesterov’s
smooth optimization procedure [8] (denoted by DSPCA)  for which we used a MATLAB imple-
mentation with heavy MEX optimizations that is downloadable from the author’s web site.
(cid:80)
We compute two application-speciﬁc metrics which capture the two goals of sparse PCA: high
captured variance and high sparsity. Given the top eigenvector u of a solution matrix X  its captured
j 1[|uj| < τ ]; we take τ = 10−3 based on
variance is u(cid:48)Au  and its sparsity is given by 1
qualitative inspection of the raw microarray data covariance matrix A.
The results of our experiments are shown in Figure 2. As seen in the two plots  on a problem instance
with d = 100  Random Conic Pursuit quickly achieves an objective value within 4% of optimal and
thereafter continues to converge  albeit more slowly; we also quickly achieve fairly high sparsity
(compared to that of the exact SDP optimum). In contrast  interior point is able to achieve lower
objective value and even higher sparsity within the timeframe shown  but  unlike Random Conic
Pursuit  it does not provide the option of spending less time to achieve a solution which is still
relatively sparse. All of the solvers quickly achieve very similar captured variances  which are not
shown. DSPCA is extremely efﬁcient  requiring much less time than its counterparts to ﬁnd nearly
exact solutions. However  that procedure is highly customized (via several pages of derivation and an
optimized implementation)  whereas Random Conic Pursuit and interior point are general-purpose.
The table in Figure 2 illustrates scaling by reporting achieved objecive values and sparsities after
the solvers have each run for 4 hours. Interior point fails due to memory requirements for d > 130 
whereas Random Conic Pursuit continues to function and provide useful solutions  as seen from the
achieved sparsity values  which are much larger than those of the raw data covariance matrix. Again 
DSPCA continues to be extremely efﬁcient.

d

3.3 Maximum Variance Unfolding (MVU)

MVU searches for a kernel matrix that embeds high-dimensional input data into a lower-dimensional
manifold [23]. Given m data points and a neighborhood relation i ∼ j between them  it forms
their centered and normalized Gram matrix G ∈ Rm×m and the squared Euclidean distances d2
ij =
Gii +Gjj−2Gij. The desired kernel matrix is the solution of the following SDP  where X ∈ Rm×m
and the scalar ν > 0 controls the dimensionality of the resulting embedding:

(cid:88)

i∼j

tr(X) − ν

(Xii + Xjj − 2Xij − d2

ij)2

max
X(cid:23)0

s.t.

1(cid:48)X1 = 0.

(6)

To apply Random Conic Pursuit  we set X0 = G and use the general sampling formulation in Algo-
rithm 1 by setting p = N (0  Π(∇f (Xt))) in the initialization (i.e.  t = 0) and update steps  where

5

0107621523228430400.020.040.060.080.1time (sec)normalized objective value error  Interior PointRandom PursuitDSPCA107621523228430400.130.260.390.52time (sec)top eigenvector sparsity  Interior PointRandom PursuitDSPCAm
40
40
40
200
200
200
400
400
800
800

alg
IP
RCP
GD
IP
RCP
GD
IP
RCP
IP
RCP

f after convergence

seconds to f > 0.99 ˆf

23.4

22.83 (0.03)

23.2
2972.6

2921.3 (1.4)

2943.3
12255.6

12207.96 (36.58)

0.5 (0.03)

0.4

5.4
12.4

6.6 (0.8)
965.4
97.1

26.3 (9.8)

failed

71231.1 (2185.7)

failed

115.4 (29.2)

Figure 3: Results for MVU. (plots) Trajectories of objective value for m = 200 (left) and m = 800
(right). (table) Scaling experiments showing convergence as a function of m (IP = interior point 
RCP = Random Conic Pursuit  GD = gradient descent).

Π truncates negative eigenvalues of its argument to zero. This scheme empirically yields improved
performance for the MVU problem as compared to the bracketed sampling scheme in Algorithm 1.
To handle the equality constraint  each Yt is ﬁrst transformed to ˘Yt = (I − 11(cid:48)/m)Yt(I − 11(cid:48)/m) 
which preserves PSDness and ensures feasibility. The two-variable optimization (2) proceeds as
before on ˘Yt and becomes a two-variable quadratic program  which can be solved analytically.
MVU also admits a gradient descent algorithm  which serves as a straw-man large-scale solver for
the MVU SDP. At each iteration  the step size is picked by a line search  and the spectrum of the
iterate is truncated to maintain PSDness. We use G as the initial iterate.
To generate data  we randomly sample m points from the surface of a synthetic swiss roll [23]; we
set ν = 1. To quantify the amount of time it takes a solver to converge  we run it until its objective
curve appears qualitatively ﬂat and declare the convergence point to be the earliest iterate whose
objective is within 1% of the best objective value seen so far (which we denote by ˆf).
Figure 3 illustrates that Random Conic Pursuit’s objective values converge quickly  and on problems
where the interior point solver achieves the optimum  Random Conic Pursuit nearly achieves that
optimum. The interior point solver runs out of memory when m > 400 and also fails on smaller
problems if its tolerance parameter is not tuned. Random Conic Pursuit easily runs on larger prob-
lems for which interior point fails  and for smaller problems its running time is within a small factor
of that of the interior point solver; Random Conic Pursuit typically converges within 1000 itera-
tions. The gradient descent solver is orders of magnitude slower than the other solvers and failed to
converge to a meaningful solution for m ≥ 400 even after 2000 iterations (which took 8 hours).

4 Analysis

Analysis of Random Conic Pursuit is complicated by the procedure’s use of randomness and its
handling of the constraints gj ≤ 0 explicitly in the sub-problem (2)  rather than via penalty functions
or projections. Nonetheless  we are able to obtain useful insights by ﬁrst analyzing a simpler setting
having only a PSD constraint. We thus obtain a bound on the rate at which the objective values
of Random Conic Pursuit’s iterates converge to the SDP’s optimal value when the problem has no
constraints of the form gj ≤ 0:
Theorem 1 (Convergence rate of Random Conic Pursuit when f is weakly convex and k = 0). Let
f : Rd×d → R be a convex differentiable function with L-Lipschitz gradients such that the minimum
of the following optimization problem is attained at some X∗:

min
X(cid:23)0

f (X).

(7)

Let X1 . . . Xt be the iterates of Algorithm 1 when applied to this problem starting at iterate X0
(using the bracketed sampling scheme given in the algorithm speciﬁcation)  and suppose (cid:107)Xt−X∗(cid:107)
is bounded. Then

Ef (Xt) − f (X∗) ≤ 1
t
for some constant Γ that does not depend on t.

· max(ΓL  f (X0) − f (X∗)) 

(8)

6

01020301800200022002400260028003000Time (sec)Objective value  Interior PointRandom Pursuit010020030040002468x 104Time (sec)Objective value  Random PursuitProof. We prove that equation (8) holds in general for any X∗  and thus for the optimizer of f in
particular. The convexity of f implies the following linear lower bound on f (X) for any X and Y :
(9)
The Lipschitz assumption on the gradient of f implies the following quadratic upper bound on f (X)
for any X and Y [18]:

f (X) ≥ f (Y ) + (cid:104)∂f (Y )  X − Y (cid:105).

f (X) ≤ f (Y ) + (cid:104)∂f (Y )  X − Y (cid:105) + L

(10)
Deﬁne the random variable ˜Yt := γt(Yt)Yt with γt a positive function that ensures E ˜Yt = X∗. It
sufﬁces to set γt = q(Y )/˘p(Y )  where ˘p is the distribution of Yt and q is any distribution with mean
t with γt(x) = N (x|0  X∗)/N (x|0  Σt) satisﬁes this.
X∗. In particular  the choice ˜Yt := γt(xt)xtx(cid:48)
At iteration t  Algorithm 1 produces αt and βt so that Xt+1 := αtYt + βtXt minimizes f (Xt+1).
We will bound the defect f (Xt+1) − f (X∗) at each iteration by sub-optimally picking ˆαt = 1/t 
ˆβt = 1 − 1/t  and ˆXt+1 = ˆβtXt + ˆαtγt(Yt)Yt = ˆβtXt + ˆαt ˜Yt. Conditioned on Xt  we have

2 (cid:107)X − Y (cid:107)2.

Ef (Xt+1) − f (X∗) ≤ Ef ( ˆβtXt + ˆαt ˜Yt) − f (X∗) = Ef

(cid:17) − f (X∗)

(cid:16)
(cid:69)
Xt − 1
t (Xt − ˜Yt)
t ( ˜Yt − Xt)
+ L
2t2 E(cid:107)Xt − ˜Yt(cid:107)2
t (cid:104)∂f (Xt)  X∗ − Xt(cid:105) + L
t (f (X∗) − f (Xt)) + L
2t2 E(cid:107)Xt − ˜Yt(cid:107)2

∂f (Xt)  1

2t2 E(cid:107)Xt − ˜Yt(cid:107)2

(11)

(12)

≤ f (Xt) − f (X∗) + E(cid:68)
=(cid:0)1 − 1

= f (Xt) − f (X∗) + 1
≤ f (Xt) − f (X∗) + 1

(cid:1)(cid:0)f (Xt) − f (X∗)(cid:1) + L

(13)
(14)
(15)
The ﬁrst inequality follows by the suboptimality of ˆαt and ˆβt  the second by Equation (10)  and the
third by (9).
Deﬁne et := Ef (Xt)− f (X∗). The term E(cid:107) ˜Yt− Xt(cid:107)2 is bounded above by some absolute constant
Γ because E(cid:107) ˜Yt − Xt(cid:107)2 = E(cid:107) ˜Yt − X∗(cid:107)2 +(cid:107)Xt − X∗(cid:107)2. The ﬁrst term is bounded because it is the
variance of ˜Yt  and the second term is bounded by assumption. Taking expectation over Xt gives the

2t2 E(cid:107)Xt − ˜Yt(cid:107)2.

t

bound et+1 ≤(cid:0)1 − 1

(cid:1) et + LΓ

t · max(ΓL  f (X0) − f (X∗)) [16].

t

2t2   which is solved by et = 1

Despite the extremely simple and randomized nature of Random Conic Pursuit  the theorem guar-
antees that its objective values converge at the rate O(1/t) on an important subclass of SDPs. We
omit here some readily available extensions: for example  the probability that a trajectory of iterates
violates the above rate can be bounded by noting that the iterates’ objective values behave as a ﬁnite
difference sub-martingale. Additionally  the theorem and proof could be generalized to hold for a
broader class of sampling schemes.
Directly characterizing the convergence of Random Conic Pursuit on problems with constraints ap-
pears to be signiﬁcantly more difﬁcult and seems to require introduction of new quantities depending
on the constraint set (e.g.  condition number of the constraint set and its overlap with the PSD cone)
whose implications for the algorithm are difﬁcult to explicitly characterize with respect to d and
the properties of the gj  X∗  and the Yt sampling distribution. Indeed  it would be useful to better
understand the limitations of Random Conic Pursuit. As noted above  the procedure cannot readily
accommodate general equality constraints; furthermore  for some constraint sets  sampling only a
rank one Yt at each iteration could conceivably cause the iterates to become trapped at a sub-optimal
boundary point (this could be alleviated by sampling higher rank Yt). A more general analysis is
the subject of continuing work  though our experiments conﬁrm empirically that we realize usefully
fast convergence of Random Conic Pursuit even when it is applied to a variety of constrained SDPs.
We obtain a different analytical perspective by recalling that Random Conic Pursuit computes a
solution within the random polyhedral cone F x
n  deﬁned in (3) above. The distance between this
cone and the optimal matrix X∗ is closely related to the quality of solutions produced by Random
Conic Pursuit. The following theorem characterizes the distance between a sampled cone F x
n and
any ﬁxed X∗ in the PSD cone:
Theorem 2. Let X∗ (cid:31) 0 be a ﬁxed positive deﬁnite matrix  and let x1  . . .   xn ∈ Rd be drawn i.i.d.
from N (0  Σ) with Σ (cid:31) X∗. Then  for any δ > 0  with probability at least 1 − δ 

√
2 log 1
√
δ
n

(cid:113)(cid:12)(cid:12)ΣX∗−1(cid:12)(cid:12)(cid:13)(cid:13)(cid:13)(cid:13)(cid:16)

X∗−1 − Σ−1(cid:17)−1(cid:13)(cid:13)(cid:13)(cid:13)2

(cid:107)X − X∗(cid:107) ≤ 1 +

min
X∈F x

n

· 2
e

7

See supplementary materials for proof. As expected  F x
n provides a progressively better approxima-
tion to the PSD cone (with high probability) as n grows. Furthermore  the rate at which this occurs
depends on X∗ and its relationship to Σ; as the latter becomes better matched to the former  smaller
values of n are required to achieve an approximation of given quality.
The constant Γ in Theorem 1 can hide a dependence on the dimensionality of the problem d  though
the proof of Theorem 2 helps to elucidate the dependence of Γ on d and X∗ for the particular case
when Σ does not vary over time (the constants in Theorem 2 arise from bounding (cid:107)γt(xt)xtx(cid:48)
t(cid:107)).
A potential concern regarding both of the above theorems is the possibility of extremely adverse
dependence of their constants on the dimensionality d and the properties (e.g.  condition number)
of X∗. However  our empirical results in Section 3 show that Random Conic Pursuit does indeed
decrease the objective function usefully quickly on real problems with relatively large d and solution
matrices X∗ which are rank one  a case predicted by the analysis to be among the most difﬁcult.

5 Related Work

Random Conic Pursuit and the analyses above are related to a number of existing optimization and
sampling algorithms.
Our procedure is closely related to feasible direction methods [22]  which move along descent direc-
tions in the feasible set deﬁned by the constraints at the current iterate. Cutting plane methods [11] 
when applied to some SDPs  solve a linear program obtained by replacing the PSD constraint with
a polyhedral constraint. Random Conic Pursuit overcomes the difﬁculty of ﬁnding feasible descent
directions or cutting planes  respectively  by sampling directions randomly and also allowing the
current iterate to be rescaled.
Pursuit-based optimization methods [6  13] return a solution within the convex hull of an a priori-
speciﬁed convenient set of points M. At each iteration  they reﬁne their solution to a point between
the current iterate and a point in M. The main burden in these methods is to select a near-optimal
point in M at each iteration. For SDPs having only a trace equality constraint and with M the set
of rank one PSD matrices  Hazan [10] shows that such points in M can be found via an eigenvalue
computation  thereby obtaining a convergence rate of O(1/t). In contrast  our method selects steps
randomly and still obtains a rate of O(1/t) in the unconstrained case.
The Hit-and-Run algorithm for sampling from convex bodies can be combined with simulated an-
nealing to solve SDPs [15]. In this conﬁguration  similarly to Random Conic Pursuit  it conducts a
search along random directions whose distribution is adapted over time.
Finally  whereas Random Conic Pursuit utilizes a randomized polyhedral inner approximation of
the PSD cone  the work of Calaﬁore and Campi [5] yields a randomized outer approximation to the
PSD cone obtained by replacing the PSD constraint X (cid:23) 0 with a set of sampled linear inequality
constraints. It can be shown that for linear SDPs  the dual of the interior LP relaxation is identical
to the exterior LP relaxation of the dual of the SDP. Empirically  however  this outer relaxation
requires impractically many sampled constraints to ensure that the problem remains bounded and
yields a good-quality solution.

6 Conclusion

We have presented Random Conic Pursuit  a simple  easily implemented randomized solver for
general SDPs. Unlike interior point methods  our procedure does not excel at producing highly exact
solutions. However  it is more scalable and provides useful approximate solutions fairly quickly 
characteristics that are often desirable in machine learning applications. This fact is illustrated by
our experiments on three different machine learning tasks based on SDPs; we have also provided a
preliminary analysis yielding further insight into Random Conic Pursuit.

Acknowledgments

We are grateful to Guillaume Obozinski for early discussions that motivated this line of work.

8

References
[1] U. Alon  N. Barkai  D. A. Notterman  K. Gish  S. Ybarra  D. Mack  and A. J. Levine. Broad patterns
of gene expression revealed by clustering analysis of tumor and normal colon tissues probed by oligonu-
cleotide arrays. Proc. Natl. Acad. Sci. USA  96:6745–6750  June 1999.

[2] S. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press  2004.
[3] S. Burer and R.D.C Monteiro. Local minima and convergence in low-rank semideﬁnite programming.

Mathematical Programming  103(3):427–444  2005.

[4] S. Burer  R.D.C. Monteiro  and Y. Zhang. A computational study of a gradient-based log-barrier algorithm

for a class of large-scale sdps. Mathematical Programming  95(2):359–379  2003.

[5] G. Calaﬁore and M.C. Campi. Uncertain convex programs: randomized solutions and conﬁdence levels.

Mathematical Programming  102(1):25–46  2005.

[6] K. Clarkson. Coresets  sparse greedy approximation  and the frank-wolfe algorithm. In Symposium on

Discrete Algorithms (SODA)  2008.

[7] A. d’Aspremont. Subsampling algorithms for semideﬁnite programming. Technical Report 0803.1990 

ArXiv  2009.

[8] A. d’Aspremont  L. El Ghaoui  M. I. Jordan  and G. R. G. Lanckriet. A direct formulation for sparse pca

using semideﬁnite programming. SIAM Review  49(3):434–448  2007.

[9] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming  version 1.21.

http://cvxr.com/cvx  May 2010.

[10] E. Hazan. Sparse approximate solutions to semideﬁnite programs.

Theoretical informatics  pages 306–316  2008.

In Latin American conference on

[11] C. Helmberg. A cutting plane algorithm for large scale semideﬁnite relaxations. In Martin Gr¨otschel 

editor  The sharpest cut  chapter 15. MPS/SIAM series on optimization  2001.

[12] C. Helmberg and F. Rendl. A spectral bundle method for semideﬁnite programming. SIAM Journal on

Optimization archive  10(3):673–696  1999.

[13] L. K. Jones. A simple lemma on greedy approximation in Hilbert space and convergence rates for pro-
jection pursuit regression and neural network training. The Annals of Statistics  20(1):608–613  March
1992.

[14] G. R. G. Lanckriet  N. Cristianini  P. Bartlett  L. El Ghaoui  and M. I. Jordan. Learning the kernel matrix
with semideﬁnite programming. Journal of Machine Learning Research (JMLR)  5:27–72  December
2004.

[15] L. Lov´asz and S. Vempala. Fast algorithms for logconcave functions: Sampling  rounding  integration

and optimization. In Foundations of Computer Science (FOCS)  2006.

[16] A. Nemirovski  A. Juditsky  G. Lan  and A. Shapiro. Robust stochastic approximation approach to

stochastic programming. SIAM Journal on Optimization  19(4):1574–1609  2009.

[17] Y Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming  103(1):127–

152  May 2005.

[18] Y. Nesterov. Smoothing technique and its applications in semideﬁnite optimization. Mathematical Pro-

gramming  110(2):245–259  July 2007.

[19] G. Obozinski  B. Taskar  and M. I. Jordan. Joint covariate selection and joint subspace selection for

multiple classiﬁcation problems. Statistics and Computing  pages 1573–1375  2009.

[20] J. Platt. Using sparseness and analytic QP to speed training of Support Vector Machines. In Advances in

Neural Information Processing Systems (NIPS)  1999.

[21] J.F. Sturm. Using sedumi 1.02  a matlab toolbox for optimization over symmetric cones. Optimization

Methods and Software  Special issue on Interior Point Methods  11-12:625–653  1999.

[22] W. Sun and Y. Yuan. Optimization Theory And Methods: Nonlinear Programming. Springer Optimization

And Its Applications  2006.

[23] K. Q. Weinberger  F. Sha  Q. Zhu  and L. K. Saul. Graph laplacian regularization for large-scale semidef-

inite programming. In Advances in Neural Information Processing Systems (NIPS)  2006.

[24] E. Xing  A. Ng  M. Jordan  and S. Russell. Distance metric learning  with application to clustering with

side-information. In Advances in Neural Information Processing Systems (NIPS)  2003.

9

,Guy Van den Broeck
Adnan Darwiche