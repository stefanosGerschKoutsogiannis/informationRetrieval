2013,Spike train entropy-rate estimation using hierarchical Dirichlet process priors,Entropy rate quantifies the amount of disorder in a stochastic process.  For spiking neurons  the entropy rate places an upper bound on the rate at which the spike train can convey stimulus information  and a large literature has focused on the problem of estimating entropy rate from spike train data.  Here we present Bayes Least Squares and Empirical Bayesian entropy rate estimators for binary spike trains using Hierarchical Dirichlet Process (HDP) priors.  Our estimator leverages the fact that the entropy rate of an ergodic Markov Chain with known transition probabilities can be calculated analytically  and many stochastic processes that are non-Markovian can still be well approximated by Markov processes of sufficient depth.  Choosing an appropriate depth of Markov model presents challenges due to possibly long time dependencies and short data sequences: a deeper model can better account for long time-dependencies  but is more difficult to infer from limited data. Our approach mitigates this difficulty by using a hierarchical prior to share statistical power across Markov chains of different depths.   We present both a fully Bayesian and empirical Bayes entropy rate estimator based on this model  and demonstrate their performance on simulated and real neural spike train data.,Spike train entropy-rate estimation using hierarchical

Dirichlet process priors

Karin Knudson

Department of Mathematics

kknudson@math.utexas.edu

Jonathan W. Pillow

Center for Perceptual Systems

Departments of Psychology & Neuroscience

The University of Texas at Austin
pillow@mail.utexas.edu

Abstract

Entropy rate quantiﬁes the amount of disorder in a stochastic process. For spiking
neurons  the entropy rate places an upper bound on the rate at which the spike train
can convey stimulus information  and a large literature has focused on the prob-
lem of estimating entropy rate from spike train data. Here we present Bayes least
squares and empirical Bayesian entropy rate estimators for binary spike trains us-
ing hierarchical Dirichlet process (HDP) priors. Our estimator leverages the fact
that the entropy rate of an ergodic Markov Chain with known transition prob-
abilities can be calculated analytically  and many stochastic processes that are
non-Markovian can still be well approximated by Markov processes of sufﬁcient
depth. Choosing an appropriate depth of Markov model presents challenges due
to possibly long time dependencies and short data sequences: a deeper model can
better account for long time dependencies  but is more difﬁcult to infer from lim-
ited data. Our approach mitigates this difﬁculty by using a hierarchical prior to
share statistical power across Markov chains of different depths. We present both
a fully Bayesian and empirical Bayes entropy rate estimator based on this model 
and demonstrate their performance on simulated and real neural spike train data.

1

Introduction

The problem of characterizing the statistical properties of a spiking neuron is quite general  but two
interesting questions one might ask are: (1) what kind of time dependencies are present? and (2) how
much information is the neuron transmitting? With regard to the second question  information theory
provides quantiﬁcations of the amount of information transmitted by a signal without reference to
assumptions about how the information is represented or used. The entropy rate is of interest as a
measure of uncertainty per unit time  an upper bound on the rate of information transmission  and
an intermediate step in computing mutual information rate between stimulus and neural response.
Unfortunately  accurate entropy rate estimation is difﬁcult  and estimates from limited data are of-
ten severely biased. We present a Bayesian method for estimating entropy rates from binary data
that uses hierarchical Dirichlet process priors (HDP) to reduce this bias. Our method proceeds by
modeling the source of the data as a Markov chain  and then using the fact that the entropy rate of
a Markov chain is a deterministic function of its transition probabilities. Fitting the model yields
parameters relevant to both questions (1) and (2) above: we obtain both an approximation of the
underlying stochastic process as a Markov chain  and an estimate of the entropy rate of the process.
For binary data  the HDP reduces to a hierarchy of beta priors  where the prior probability over g  the
probability of the next symbol given a long history  is a beta distribution centered on the probability
of that symbol given a truncated  one-symbol-shorter  history. The posterior over symbols given

1

a certain history is thus “smoothed” by the probability over symbols given a shorter history. This
smoothing is a key feature of the model.
The structure of the paper is as follows. In Section 2  we present deﬁnitions and challenges involved
in entropy rate estimation  and discuss existing estimators. In Section 3  we discuss Markov models
and their relationship to entropy rate. In Sections 4 and 5  we present two Bayesian estimates of
entropy rate using the HDP prior  one involving a direct calculation of the posterior mean transition
probabilities of a Markov model  the other using Markov Chain Monte Carlo methods to sample
from the posterior distribution of the entropy rate. In Section 6 we compare the HDP entropy rate
estimators to existing entropy rate estimators including the context tree weighting entropy rate esti-
mator from [1]  the string-parsing method from [2]  and ﬁnite-length block entropy rate estimators
that makes use of the entropy estimator of Nemenman  Bialek and Shafee [3] and Miller and Madow
[4]. We evaluate the results for simulated and real neural data.

2 Entropy Rate Estimation

In information theory  the entropy of a random variable is a measure of the variable’s average un-
predictability. The entropy of a discrete random variable X with possible values {x1  ...  xn} is

H(X) = − n(cid:88)

p(xi) log(xi)

(1)

i=1

Entropy can be measured in either nats or bits  depending on whether we use base 2 or e for the
logarithm. Here  all logarithms discussed will be base 2  and all entropies will be given in bits.
While entropy is a property of a random variable  entropy rate is a property of a stochastic process 
such as a time series  and quantiﬁes the amount of uncertainty per symbol. The neural and simulated
data considered here will be binary sequences representing the spike train of a neuron  where each
symbol represents either the presence of a spike in a bin (1) or the absence of a spike (0). We view
the data as a sample path from an underlying stochastic process. To evaluate the average uncertainty
of each new symbol (0 or 1) given the previous symbols - or the amount of new information per
symbol - we would like to compute the entropy rate of the process.
For a stochastic process {Xi}∞
i=1 the entropy of the random vector (X1  ...  Xk) grows with k; we
are interested in how it grows. If we deﬁne the block entropy Hk to be the entropy of the distribution
of length-k sequences of symbols  Hk = H(Xi+1  ...Xi+k)  then the entropy rate of a stochastic
process {Xi}∞

i=1is deﬁned by

h = lim
k→∞

1
k

Hk

(2)

when the limit exists (which  for stationary stochastic processes  it must). There are two other
deﬁnitions for entropy rate  which are equivalent to the ﬁrst for stationary processes:

h = lim

h = lim

k→∞ Hk+1 − Hk
k→∞ H(Xi+1|Xi  Xi−1  ...Xi−k)

(3)

(4)

We now brieﬂy review existing entropy rate estimators  to which we will compare our results.

2.1 Block Entropy Rate Estimators

Since much work has been done to accurately estimate entropy from data  Equations (2) and (3)
suggest a simple entropy rate estimator  which consists of choosing ﬁrst a block size k and then
a suitable entropy estimator with which to estimate Hk. A simple such estimator is the “plugin”
entropy estimator  which approximates the probability of each length-k block (x1  ...  xk) by the
proportion of total length-k blocks observed that are equal to (x1  ...  xk). For binary data there are

2

2k possible length-k blocks. When N denotes the data length and ci the number of observations of
each block in the data  we have:

2k(cid:88)

i=1

ˆHplugin =

− ci
N

log

ci
N

(5)

from which we can immediately estimate the entropy rate with hplugin k = ˆHplugin/k  for some
appropriately chosen k (the subject of “appropriate choice” will be taken up in more detail later).
We would expect that using better block entropy estimators would yield better entropy rate esti-
mators  and so we also consider two other block based entropy rate estimators. The ﬁrst uses the
Bayesian entropy estimator HN SB from Nemenman  Shafee and Bialek [3]  which gives a Bayesian
least squares estimate for entropy given a mixture-of-Dirichlet prior. The second uses the Miller and
Madow estimator [4]  which gives a ﬁrst-order correction to the (often signiﬁcantly biased) plugin
entropy estimator of Equation 5:

2k(cid:88)

i=1

ˆHMM =

− ci
N

log

ci
N

+

A − 1
2N

log(e)

(6)

where A is the size of the alphabet of symbols (A = 2 for the binary data sequences presently consid-
ered). For a given k  we obtain entropy rate estimators hN SB k = ˆHN SB/k and hMM k = ˆHMM /k
by applying the entropy estimators from [3] and [4] respectively to the empirical distribution of the
length-k blocks.
While we can improve the accuracy of these block entropy rate estimates by choosing a better
entropy estimator  choosing the block size k remains a challenge.
If we choose k to be small 
we miss long time dependencies in the data and tend to overestimate the entropy; intuitively  the
time series will seem more unpredictable than it actually is  because we are ignoring long-time
dependencies. On the other hand  as we consider larger k  limited data leads to underestimates of
the entropy rate. See the plots of hplugin  hN SB  and hMM in Figure 2d for an instance of this effect
of block size on entropy rate estimates. We might hope that in between the overestimates of entropy
rate for short blocks and the the underestimates for longer blocks  there is some “plateau” region
where the entropy rate stays relatively constant with respect to block size  which we could use as a
heuristic to select the proper block length [1]. Unfortunately  the block entropy rate at this plateau
may still be biased  and for data sequences that are short with respect to their time dependencies 
there may be no discernible plateau at all ([1]  Figure 1).

2.2 Other Entropy Rate Estimators

N log N  free from any explicit block length parameters.

Not all existing techniques for entropy rate estimation involve an explicit choice of block length.
The estimator from [2]  for example  parses the full string of symbols in the data by starting from
the ﬁrst symbol  and sequentially removing and counting as a “phrase” the shortest substring that
has not yet appeared. When M is the number of distinct phrases counted in this way  we obtain the
estimator: hLZ = M
A ﬁxed block length model like the ones described in the previous section uses the entropy of the dis-
tribution of all the blocks of a some length - e.g. all the blocks in the terminal nodes of a context tree
like the one in Figure 1a. In the context tree weighting (CTW) framework of [1]  the authors instead
use a minimum descriptive length criterion to weight different tree topologies  which have within
the same tree terminal nodes corresponding to blocks of different lengths. They use this weighting

to generate Monte Carlo samples and approximate the integral(cid:82) h(θ)p(θ|T  data)p(T|data) dθ dT 

in which T represents the tree topology  and θ represents transition probabilities associated with the
terminal nodes of the tree.
In our approach  the HDP prior combined with a Markov model of our data will be a key tool in
overcoming some of the difﬁculties of choosing a block-length appropriately for entropy rate esti-
mation. It will allow us to choose a block length that is large enough to capture possibly important
long time dependencies  while easing the difﬁculty of estimating the properties of these long time
dependencies from short data.

3

Figure 1: A depth-3 hierarchical Dirichlet prior for binary data

3 Markov Models

The usefulness of approximating our data source with a Markov model comes from (1) the ﬂexibility
of Markov models including their ability to well approximate even many processes that are not truly
Markovian  and (2) the fact that for a Markov chain with known transition probabilities the entropy
rate need not be estimated but is in fact a deterministic function of the transition probabilities.
A Markov chain is a sequence of random variables that has the property that the probability
of the next state depends only on the present state  and not on any previous states. That is 
P (Xi+1|Xi  ...  X1) = P (Xi+1|Xi). Note that this property does not mean that for a binary se-
quence the probability of each 0 or 1 depends only on the previous 0 or 1  because we consider the
state variables to be strings of symbols of length k rather than individual 0s and 1s  Thus we will
discuss “depth-k” Markov models  where the probability of the next state depends only previous k
symbols  or what we will call the length-k context of the symbol. With a binary alphabet  there are
2k states the chain can take  and from each state s  transitions are possible only to two other states.
(So that for  example  110 can transition to state 101 or state 100  but not to any other state). Because
only two transitions are possible from each state  the transition probability distribution from each s
is completely speciﬁed by only one parameter  which we denote gs  the probability of observing a 1
given the context s.
The entropy rate of an ergodic Markov chain with ﬁnite state set A is given by:

h =

p(s)H(x|s) 

(7)

(cid:88)

s∈A

(cid:90)

(cid:88)

where p(s) is the stationary probability associated with state s  and H(x|s) is the entropy of the
distribution of possible transitions from state s. The vector of stationary state probabilities p(s) for
all s is computed as a left eigenvector of the transition matrix T:

p(s)T = p(s)  

(8)
Since each row of the transition matrix T contains only two non-zero entries  gs  and 1 − gs  p(s)
can be calculated relatively quickly. With equations 7 and 8  h can be calculated analytically from
the vector of all 2k transition probabilities {gs}. A Bayesian estimator of entropy rate based on a
Markov model of order k is given by

p(s) = 1

s

h(g)p(g|data)dg

ˆhBayes =

(9)
where g = {gs : |s| = k}  h is the deterministic function of g given by Equations 7 and 8  and
p(g|data) ∝ p(data|g)p(g) given some appropriate prior over g.
Modeling a time series as a Markov chain requires a choice of the depth of that chain  so we have
not avoided the depth selection problem yet. What will actually mitigate the difﬁculty here is the
use of hierarchical Dirichlet process priors.

4 Hierarchical Dirichlet Process priors

We describe a hierarchical beta prior  a special case of the hierarchical Dirichlet process (HDP) 
which was presented in [5] and applied to problems of natural language processing in [6] and [7].

4

The true entropy rate h = limk→∞ Hk/k captures time dependencies of inﬁnite depth. Therefore
to calculate the estimate ˆhBayes in Equation 9 we would like to choose some large k. However  it is
difﬁcult to estimate transition probabilities for long blocks with short data sequences  so choosing
large k may lead to inaccurate posterior estimates for the transition probabilities g. In particular 
shorter data sequences may not even have observations of all possible symbol sequences of a given
length.
This motivates our use of hierarchical priors as follows. Suppose we have a data sequence in which
the subsequence 0011 is never observed. Then we would not expect to have a very good estimate
for g0011; however  we could improve this by using the assumption that  a priori  g0011 should be
similar to g011. That is  the probability of observing a 1 after the context sequence 0011 should be
similar to that of seeing a 1 after 011  since it might be reasonable to assume that context symbols
from the more distant past matter less. Thus we choose for our prior:
gs|gs(cid:48) ∼ Beta(α|s|gs(cid:48)  α|s|(1 − gs(cid:48)))

(10)
where s(cid:48) denotes the context s with the earliest symbol removed. This choice gives the prior
distribution of gs mean gs(cid:48)  as desired. We continue constructing the prior with gs(cid:48)(cid:48)|gs(cid:48) ∼
Beta(α|s(cid:48)|gs(cid:48)(cid:48)   α|s(cid:48)|(1 − gs(cid:48)(cid:48) )) and so on until g[] ∼ Beta(α0p∅  α0(1 − p∅)) where g[] is the proba-
bility of a spike given no context information and p∅ is a hyperparameter reﬂecting our prior belief
about the probability of a spike. This hierarchy gives our prior the tree structure as shown in in
Figure 1. A priori  the distribution of each transition probability is centered around the transition
probability from a one-symbol-shorter block of symbols. As long as the assumption that more dis-
tant contextual symbols matter less actually holds (at least to some degree)  this structure allows
the sharing of statistical information across different contextual depths. We can obtain reasonable
estimates for the transition probabilities from long blocks of symbols  even from data that is so short
that we may have few (or no) observations of each of these long blocks of symbols.
We could use any number of distributions with mean gs(cid:48) to center the prior distribution of gs at gs(cid:48);
we use Beta distributions because they are conjugate to the likelihood. The α|s| are concentration
parameters which control how concentrated the distribution is about its mean  and can also be esti-
mated from the data. We assume that there is one value of α for each level in the hierarchy  but one
could also ﬁx alpha to be constant throughout all levels  or let it vary within each level.
This hierarchy of beta distributions is a special case of the hierarchical Dirichlet process . A Dirichlet
process (DP) is a stochastic process whose sample paths are each probability distributions. Formally 
if G is a ﬁnite measure on a set S  then X ∼ DP (α  G) if for any ﬁnite measurable partition of
the sample space (A1  ...An) we have that X(A1)  ...X(An) ∼ Dirichlet(αG(A1)  ...  αG(An)).
Thus for a partition into only two sets  the Dirichlet process reduces to a beta distribution  which
is why when we specialize the HDP to binary data  we obtain a hierarchical beta distribution. In
[5] the authors present a hierarchy of DPs where the base measure for each DP is again a DP. In
our case  for example  we have G011 = {g011  1 − g011} ∼ DP (α3  G11)  or more generally 
Gs ∼ DP (α|s|  Gs(cid:48)).

5 Empirical Bayesian Estimator

One can generate a sequence from an HDP by drawing each subsequent symbol from the transition
probability distribution associated with its context  which is given recursively by [6] :

(cid:40) cs1

p(1|s) =

α|s|+cs
c1
α0+N + α0

+ α|s|
α|s|+cs
α0+N p∅

p(1|s(cid:48))

if s (cid:54)= ∅
if s = ∅

(11)

where N is the length of the data string  p∅ is a hyperparameter representing the a prior probability
of observing a 1 given no contextual information  cs1 is the number of times the symbol sequence s
followed by a 1 was observed  and cs is the number of times the symbol sequence s was observed.
We can calculate the posterior predictive distribution ˆgpr which is speciﬁed by the 2k values {gs =
p(1|s) : |s| = k} by using counts c from the data and performing the above recursive calculation
to estimate gs for each of the 2k states s. Given the estimated Markov transition probabilities ˆgpr
we then have an empirical Bayesian entropy rate estimate via Equations 7 and 8. We denote this
estimator hempHDP . Note that while ˆgpr is the posterior mean of the transition probabilities  the

5

entropy rate estimator hempHDP is no longer a fully Bayesian estimate  and is not equivalent to
the ˆhBayes of equation 9. We thus lose some clarity and the ability to easily compute Bayesian
conﬁdence intervals. However  we gain a good deal of computational efﬁciency because calculating
hempHDP from ˆgpr involves only one eigenvector computation  instead of the many needed for the
MC approximation to the integral in Equation 9. We present a fully Bayesian estimate next.

6 Fully Bayesian Estimator

Here we return to the Bayes least squares estimator ˆhBayes of Equation 9. The integral is not
analytically tractable  but we can approximate it using Markov Chain Monte Carlo techniques. We
use Gibbs sampling to simulate NM C samples g(i) ∼ g|data from the posterior distribution and
then calculate h(i) from each g(i) via Equations 7 and 8 to obtain the Bayesian estimate:

NM C(cid:88)

i=1

hHDP =

1

NM C

h(i)

(12)

To perform the Gibbs sampling  we need the posterior conditional probabilities of each gs. Because
the parameters of the model have the structure of a tree  each gs for |s| < k is conditionally inde-
pendent from all but its immediate ancestor in the tree  gs(cid:48)  and its two descendants  g0s and g1s. We
have:
p(gs|gs(cid:48)  g0s  g1s.α|s|  α|s|=1) ∝ Beta(gs; α|s|gs(cid:48)  α|s|(1 − gs(cid:48)))Beta(g0s; α|s|+1gs  α|s|+1(1 − gs))

Beta(g1s; α|s|+1gs  α|s|+1(1 − gs))

(13)

and we can compute these probabilities on a discrete grid since they are each one dimensional  then
sample the posterior gs via this grid. We used a uniform grid of 100 points on the interval [0 1] for
our computation. For the transition probabilities from the bottom level of the tree {gs : |s| = k}  the
conjugacy of the beta distributions with binomial likelihood function gives the posterior conditional
of gs a recognizable form: p(gs|gs(cid:48)  data) = Beta(αkgs(cid:48) + cs1  αk(1 − gs(cid:48)) + cs0).
In the HDP model we may treat each α as a ﬁxed hyperparameter  but it is also straightforward to set
a prior over each α and then sample α along with the other model parameters with each pass of the
Gibbs sampler. The full posterior conditional for αi with a uniform prior is (from Bayes’ theorem):

p(αi|gs  gs0  gs1 : |s| = i − 1) ∝ (cid:89)

(gs1gs0)αigs−1((1 − gs1)(1 − gs0))αi(1−gs)−1

Beta(αigs  αi(1 − gs))2

(14)

{s:|s|=i−1}

We sampled α by computing the probabilities above on a grid of values spanning the range [1  2000].
This upper bound on α is rather arbitrary  but we veriﬁed that increasing the range for α had little
effect on the entropy rate estimate  at least for the ranges and block sizes considered.
In some applications  the Markov transition probabilities g  and not just the entropy rate  may be
of interest as a description of the time dependencies present in the data. The Gibbs sampler above
yields samples from the distribution g|data  and averaging these NM C samples yields a Bayes least
squares estimator of transition probabilities  ˆggibbsHDP . Note that this estimate is closely related
to the estimate ˆgpr from the previous section; with more MC samples  ˆggibbsHDP converges to the
posterior mean ˆgpr (when the α are ﬁxed rather than sampled  to match the ﬁxed α per level used in
Equation 11).

7 Results

We applied the model to both simulated data with a known entropy rate and to neural data  where
the entropy rate is unknown. We examine the accuracy of the fully Bayesian and empirical Bayesian
entropy rate estimators hHDP and hempHDP   and compare the entropy rate estimators hplugin 
hN SB  hMM   hLZ [2]  and hCT W [1]  which are described in Section 2. We also consider estimates
of the Markov transition probabilities g produced by both inference methods.

6

Figure 2: Comparison of es-
timated (a) transition prob-
ability and (b c d) entropy
rate for data simulated from
a Markov model of depth
5.
In (a) and (d)  data sets
are 500 symbols long. The
block-based and HDP esti-
mators in (b) and (c) use
block size k = 8. In (b c d)
results were averaged over 5
data sequences  and (c) plots
the average absolute value of
the difference between true
and estimated entropy rates.

7.1 Simulation

We considered data simulated from a Markov model with transition probabilities set so that transi-
tion probabilities from states with similar sufﬁxes are similar (i.e. the process actually does have the
property that more distant context symbols matter less than more recent ones in determining transi-
tions). We used a depth-5 Markov model  whose true transition probabilities are shown in black in
Figure 2a   where each of the 32 points on the x axis represents the probability that the next symbol
is a 1 given the speciﬁed 5-symbol context.
In Figure 2a we compare HDP estimates of transition probabilities of this simulated data to the
plugin estimator of transition probabilities ˆgs = cs1
calculated from a 500-symbol sequence. (The
cs
other estimators do not include calculating transition probabilities as an intermediate step  and so
cannot be included here.) With a series of 500 symbols  we do not expect enough observations of
each of possible transitions to adequately estimate the 2k transition probabilities  even for rather
modest depths such as k = 5. And indeed  the “plugin” estimates of transition probabilities do not
match the true transition probabilities well. On the other hand  the transition probabilities estimated
using the HDP prior show the kind of “smoothing” the prior was meant to encourage  where states
corresponding to contexts with same sufﬁxes have similar estimated transition probabilities.
Lastly  we plot the convergence of the entropy rate estimators with increased length of the data
sequence and the associated error in Figures 2b c. If the true depth of the model is no larger than
the depth k considered in the estimators  all the estimators considered should converge. We see in
Figure 2c that the HDP-based entropy rate estimates converge quickly with increasing data  relative
to other models.
The motivation of the hierarchical prior was to allow observations of transitions from shorter con-
texts to inform estimates of transitions from longer contexts. This  it was hoped  would mitigate the
drop-off with larger block-size seen in block-entropy based entropy rate estimators. Figure 2d indi-
cates that for simulated data that is indeed the case  although we do see some bias the fully Bayesian
entropy rate estimator for large block lengths. The empirical Bayes and and fully Bayesian entropy
rate estimators with HDP priors produce estimates that are close to the true entropy rate across a
wider range of block-size.

7.2 Neural Data

We applied the same analysis to neural spike train data collected from primate retinal ganglion cells
stimulated with binary full-ﬁeld movies refreshed at 100 Hz [8]. In this case  the true transition
probabilities are unknown (and indeed the process may not be exactly Markovian). However  we
calculate the plug-in transition probabilities from a longer data sequence (167 000 bins) so that the
estimates are approximately converged (black trace in Figure 3a)  and note that transition probabil-
ities from contexts with the same most-recent context symbols do appear to be similar. Thus the
estimated transition probabilities reﬂect the idea that more distant context cues matter less  and the
smoothing of the HDP prior appears to be appropriate for this neural data.

7

(b)(c)hNSBhMMhpluginhLZhctwhempHDPhHDPhtrue(a)00.20.40.60.81p(1|s)0000010000010001100000100101000110011100000101001001010110100011010110011101111000001100010100111001001011010101101111010001110011010111101100111101110111111111246810120.70.80.91Block LengthEntropy Rate EstimateNSBMMpluginLZctwempHDPHDPtrue(d)246810120.70.80.91Block LengthEntropy Rate Estimate10110210310400.20.40.60.81Data LengthEntropy Rate Estimate10110210310400.20.40.60.81Absolute ErrorData LengthFigure 3: Comparison of es-
timated (a) transition prob-
ability and (b c d) entropy
rate for neural data. The
‘converged’ estimates are
calculated from 700s of
data with 4ms bins (167 000
symbols).
In (a) and (d) 
training data sequences are
500 symbols (2s) long. The
block-based and HDP esti-
mators in (b) and (c) use
block size k = 8. In (b c d) 
results were averaged over 5
data sequences sampled ran-
domly from the full dataset.

The true entropy rate is also unknown  but again we estimate it using the plugin estimator on a large
data set. We again note the relatively fast convergence of hHDP and hempHDP in Figures 3b c  and
the long plateau of the estimators in Figure 3d indicating the relative stability of the HDP entropy
rate estimators with respect to choice of model depth.

8 Discussion

We have presented two estimators of the entropy rate of a spike train or arbitrary binary sequence.
The true entropy rate of a stochastic process involves consideration of inﬁnitely long time depen-
dencies. To make entropy rate estimation tractable  one can try to ﬁx a maximum depth of time
dependencies to be considered  but it is difﬁcult to choose an appropriate depth that is large enough
to take into account long time dependencies and small enough relative to the data at hand to avoid
a severe downward bias of the estimate. We have approached this problem by modeling the data as
a Markov chain and estimating transition probabilities using a hierarchical prior that links transition
probabilities from longer contexts to transition probabilities from shorter contexts. This allowed us
to choose a large depth even in the presence of limited data  since the structure of the prior allowed
observations of transitions from shorter contexts (of which we have many instances in the data) to
inform estimates of transitions from longer contexts (of which we may have only a few instances).
We presented both a fully Bayesian estimator  which allows for Bayesian conﬁdence intervals  and
an empirical Bayesian estimator  which provides computational efﬁciency. Both estimators show
excellent performance on simulated and neural data in terms of their robustness to the choice of
model depth  their accuracy on short data sequences  and their convergence with increased data.
Both methods of entropy rate estimation also yield estimates of the transition probabilities when
the data is modeled as a Markov chain  parameters which may be of interest in the own right as
descriptive of the statistical structure and time dependencies in a spike train. Our results indicate that
tools from modern Bayesian nonparametric statistics hold great promise for revealing the structure
of neural spike trains despite the challenges of limited data.

Acknowledgments

We thank V. J. Uzzell and E. J. Chichilnisky for retinal data. This work was supported by a Sloan
Research Fellowship  McKnight Scholar’s Award  and NSF CAREER Award IIS-1150186.

8

(b)(a)(c)2468100.20.40.60.81Block LengthEntropy Rate EstimateNSBMMpluginLZctwempHDPHDPconverged00.20.40.60.81p(1|s)000001000001000110000010010100011001110000010100100101011010001101011001110111100000110001010011100100101101010110111101000111001101011110110011110111011111111110200.20.40.60.81Data LengthEstimated Entropy Rate 10200.10.20.30.4Data LengthMean Absolute ErrorhNSBhMMhpluginhLZhctwhempHDPhHDPhconverged(d)10210400.10.20.30.4Data LengthAbsolute Error10210400.20.40.60.81Data LengthEntropy Rate Estimate246810120.50.60.70.80.91Block LengthEntropy Rate EstimateReferences
[1] Matthew B Kennel  Jonathon Shlens  Henry DI Abarbanel  and EJ Chichilnisky. Estimating
entropy rates with bayesian conﬁdence intervals. Neural Computation  17(7):1531–1576  2005.
[2] Abraham Lempel and Jacob Ziv. On the complexity of ﬁnite sequences. Information Theory 

IEEE Transactions on  22(1):75–81  1976.

[3] Ilya Nemenman  Fariel Shafee  and William Bialek. Entropy and inference  revisited. arXiv

preprint physics/0108025  2001.

[4] George Armitage Miller and William Gregory Madow. On the Maximum Likelihood Esti-
mate of the Shannon-Weiner Measure of Information. Operational Applications Laboratory 
Air Force Cambridge Research Center  Air Research and Development Command  Bolling Air
Force Base  1954.

[5] Yee Whye Teh  Michael I Jordan  Matthew J Beal  and David M Blei. Hierarchical dirichlet

processes. Journal of the American Statistical Association  101(476)  2006.

[6] Yee Whye Teh. A hierarchical bayesian language model based on pitman-yor processes. In
Proceedings of the 21st International Conference on Computational Linguistics and the 44th
annual meeting of the Association for Computational Linguistics  pages 985–992. Association
for Computational Linguistics  2006.

[7] Frank Wood  C´edric Archambeau  Jan Gasthaus  Lancelot James  and Yee Whye Teh. A stochas-
tic memoizer for sequence data. In Proceedings of the 26th Annual International Conference on
Machine Learning  pages 1129–1136. ACM  2009.

[8] V. J. Uzzell and E. J. Chichilnisky. Precision of spike trains in primate retinal ganglion cells.

Journal of Neurophysiology  92:780–789  2004.

9

,Karin Knudson
Jonathan Pillow
Noga Alon
Moshe Babaioff
Yannai A. Gonczarowski
Yishay Mansour
Shay Moran
Amir Yehudayoff