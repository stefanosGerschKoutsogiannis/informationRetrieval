2017,Learning Linear Dynamical Systems via Spectral Filtering,We present an efficient and practical algorithm for the online prediction of discrete-time linear dynamical systems with a symmetric transition matrix. We circumvent the non-convex optimization problem using improper learning: carefully overparameterize the class of LDSs by a polylogarithmic factor  in exchange for convexity of the loss functions. From this arises a polynomial-time algorithm with a near-optimal regret guarantee  with an analogous sample complexity bound for agnostic learning. Our algorithm is based on a novel filtering technique  which may be of independent interest: we convolve the time series with the eigenvectors of a certain Hankel matrix.,Learning Linear Dynamical Systems

via Spectral Filtering

Elad Hazan  Karan Singh  Cyril Zhang

Department of Computer Science

Princeton University
Princeton  NJ 08544

{ehazan karans cyril.zhang}@cs.princeton.edu

Abstract

We present an efﬁcient and practical algorithm for the online prediction of
discrete-time linear dynamical systems with a symmetric transition matrix. We
circumvent the non-convex optimization problem using improper learning: care-
fully overparameterize the class of LDSs by a polylogarithmic factor  in exchange
for convexity of the loss functions. From this arises a polynomial-time algorithm
with a near-optimal regret guarantee  with an analogous sample complexity bound
for agnostic learning. Our algorithm is based on a novel ﬁltering technique  which
may be of independent interest: we convolve the time series with the eigenvectors
of a certain Hankel matrix.

1

Introduction

Linear dynamical systems (LDSs) are a class of state space models which accurately model many
phenomena in nature and engineering  and are applied ubiquitously in time-series analysis  robotics 
econometrics  medicine  and meteorology. In this model  the time evolution of a system is explained
by a linear map on a ﬁnite-dimensional hidden state  subject to disturbances from input and noise.
Recent interest has focused on the effectiveness of recurrent neural networks (RNNs)  a nonlinear
variant of this idea  for modeling sequences such as audio signals and natural language.
Central to this ﬁeld of study is the problem of system identiﬁcation: given some sample trajectories 
output the parameters for an LDS which generalize to predict unseen future data. Viewed directly 
this is a non-convex optimization problem  for which efﬁcient algorithms with theoretical guarantees
are very difﬁcult to obtain. A standard heuristic for this problem is expectation-maximization (EM) 
which can ﬁnd poor local optima in theory and practice.
We consider a different approach: we formulate system identiﬁcation as an online learning problem 
in which neither the data nor predictions are assumed to arise from an LDS. Furthermore  we slightly
overparameterize the class of predictors  yielding an online convex program amenable to efﬁcient
regret minimization. This carefully chosen relaxation  which is our main theoretical contribution 
expands the dimension of the hypothesis class by only a polylogarithmic factor. This construction
relies upon recent work on the spectral theory of Hankel matrices.
The result is a simple and practical algorithm for time-series prediction  which deviates signiﬁcantly
from existing methods. We coin the term wave-ﬁltering for our method  in reference to our relax-
ation’s use of convolution by wave-shaped eigenvectors. We present experimental evidence on both
toy data and a physical simulation  showing our method to be competitive in terms of predictive
performance  more stable  and signiﬁcantly faster than existing algorithms.

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

1.1 Our contributions
Consider a discrete-time linear dynamical system with inputs {xt}  outputs {yt}  and a latent state
{ht}  which can all be multi-dimensional. With noise vectors {ηt} {ξt}  the system’s time evolution
is governed by the following equations:

ht+1 = Aht + Bxt + ηt
yt = Cht + Dxt + ξt.

If the dynamics A  B  C  D are known  then the Kalman ﬁlter [Kal60] is known to estimate the
hidden state optimally under Gaussian noise  thereby producing optimal predictions of the system’s
response to any given input. However  this is rarely the case – indeed  real-world systems are seldom
purely linear  and rarely are their evolution matrices known.
We henceforth give a provable  efﬁcient algorithm for the prediction of sequences arising from an
unknown dynamical system as above  in which the matrix A is symmetric. Our main theoretical
contribution is a regret bound for this algorithm  giving nearly-optimal convergence to the lowest
mean squared prediction error (MSE) realizable by a symmetric LDS model:
Theorem 1 (Main regret bound; informal). On an arbitrary sequence {(xt  yt)}T
(cid:19)
makes predictions {ˆyt}T

(cid:18) poly(n  m  d  log T )

t=1  Algorithm 1

t=1 which satisfy

∗
∗
T ) ≤ ˜O
MSE(ˆy1  . . .   ˆyT ) − MSE(ˆy
1  . . .   ˆy

√T

 

t=1 by a symmetric LDS  while running in polynomial time.

compared to the best predictions {y∗
t }T
Note that the signal need not be generated by an LDS  and can even be adversarially chosen. In the
less general batch (statistical) setting  we use the same techniques to obtain an analogous sample
complexity bound for agnostic learning:
Theorem 2 (Batch version; informal). For any choice of ε > 0  given access to an arbitrary dis-
tribution D over training sequences {(xt  yt)}T
t=1  Algorithm 2  run on N i.i.d. sample trajectories
(cid:20)
from D  outputs a predictor ˆΘ such that
∗
MSE( ˆΘ) − MSE(Θ
)

 
compared to the best symmetric LDS predictor Θ∗  while running in polynomial time.
Typical regression-based methods require the LDS to be strictly stable  and degrade on ill-
1−(cid:107)A(cid:107). Our proposed method
conditioned systems; they depend on a spectral radius parameter
of wave-ﬁltering provably and empirically works even for the hardest case of (cid:107)A(cid:107) = 1. Our al-
gorithm attains the ﬁrst condition number-independent polynomial guarantees in terms of regret
(equivalently  sample complexity) and running time for the MIMO setting. Interestingly  our algo-
rithms never need to learn the hidden state  and our guarantees can be sharpened to handle the case
when the dimensionality of ht is inﬁnite.

˜O (poly(n  m  d  log T  log 1/ε))

≤ ε +

√N

(cid:21)

E
D

1

1.2 Related work

The modern setting for LDS arose in the seminal work of Kalman [Kal60]  who introduced the
Kalman ﬁlter as a recursive least-squares solution for maximum likelihood estimation (MLE) of
Gaussian perturbations to the system. The framework and ﬁltering algorithm have proven to be a
mainstay in control theory and time-series analysis; indeed  the term Kalman ﬁlter model is often
used interchangeably with LDS. We refer the reader to the classic survey [Lju98]  and the extensive
overview of recent literature in [HMR16].
Ghahramani and Roweis [RG99] suggest using the EM algorithm to learn the parameters of an LDS.
This approach  which directly tackles the non-convex problem  is widely used in practice [Mar10a].
However  it remains a long-standing challenge to characterize the theoretical guarantees afforded by
EM. We ﬁnd that it is easy to produce cases where EM fails to identify the correct system.
In a recent result of [HMR16]  it is shown for the ﬁrst time that for a restricted class of systems  gra-
dient descent (also widely used in practice  perhaps better known in this setting as backpropagation)

2

guarantees polynomial convergence rates and sample complexity in the batch setting. Their result
applies essentially only to the SISO case (vs. multi-dimensional for us)  depends polynomially on
the spectral gap (as opposed to no dependence for us)  and requires the signal to be created by an
LDS (vs. arbitrary for us).

2 Preliminaries

2.1 Linear dynamical systems

Many different settings have been considered  in which the deﬁnition of an LDS takes on many vari-
ants. We are interested in discrete time-invariant MIMO (multiple input  multiple output) systems
with a ﬁnite-dimensional hidden state.1 Formally  our model is given as follows:
Deﬁnition 2.1. A linear dynamical system (LDS) is a map from a sequence of input vectors
x1  . . .   xT ∈ Rn to output (response) vectors y1  . . .   yT ∈ Rm of the form

ht+1 = Aht + Bxt + ηt
yt = Cht + Dxt + ξt 

(1)
(2)
where h0  . . .   hT ∈ Rd is a sequence of hidden states  A  B  C  D are matrices of appropriate
dimension  and ηt ∈ Rd  ξt ∈ Rm are (possibly stochastic) noise vectors.
Unrolling this recursive deﬁnition gives the impulse response function  which uniquely determines
the LDS. For notational convenience  for invalid indices t ≤ 0  we deﬁne xt  ηt  and ξt to be the
zero vector of appropriate dimension. Then  we have:

T−1(cid:88)

yt =

CAi (Bxt−i + ηt−i) + CAth0 + Dxt + ξt.

(3)

i=1

We will consider the (discrete) time derivative of the impulse response function  given by expanding
yt−1 − yt by Equation (3). For the rest of this paper  we focus our attention on systems subject to
the following restrictions:

(i) The LDS is Lyapunov stable: (cid:107)A(cid:107)2 ≤ 1  where (cid:107)·(cid:107)2 denotes the operator (a.k.a. spectral)
(ii) The transition matrix A is symmetric and positive semideﬁnite.2

norm.

The ﬁrst assumption is standard: when the hidden state is allowed to blow up exponentially  ﬁne-
grained prediction is futile. In fact  many algorithms only work when (cid:107)A(cid:107) is bounded away from 1 
so that the effect of any particular xt on the hidden state (and thus the output) dissipates exponen-
tially. We do not require this stronger assumption.
We take a moment to justify assumption (ii)  and why this class of systems is still expressive and
useful. First  symmetric LDSs constitute a natural class of linearly-observable  linearly-controllable
systems with dissipating hidden states (for example  physical systems with friction or heat diffusion).
Second  this constraint has been used successfully for video classiﬁcation and tactile recognition
tasks [HSC+16]. Interestingly  though our theorems require symmetric A  our algorithms appear to
tolerate some non-symmetric (and even nonlinear) transitions in practice.

2.2 Sequence prediction as online regret minimization

A natural formulation of system identiﬁcation is that of online sequence prediction. At each time
step t  an online learner is given an input xt  and must return a predicted output ˆyt. Then  the true
response yt is observed  and the predictor suffers a squared-norm loss of (cid:107)yt − ˆyt(cid:107)2. Over T rounds 
the goal is to predict as accurately as the best LDS in hindsight.

dimension has no role in our algorithm  and shows up as (cid:107)B(cid:107)F and (cid:107)C(cid:107)F in the regret bound.

1We assume ﬁnite dimension for simplicity of presentation. However  it will be evident that hidden-state
2The psd constraint on A can be removed by augmenting the inputs xt with extra coordinates (−1)t(xt).

We omit this for simplicity of presentation.

3

Note that the learner is permitted to access the history of observed responses {y1  . . .   yt−1}. Even in
the presence of statistical (non-adversarial) noise  the ﬁxed maximum-likelihood sequence produced
by Θ = (A  B  C  D  h0) will accumulate error linearly as T . Thus  we measure performance
against a more powerful comparator  which ﬁxes LDS parameters Θ  and predicts yt by the previous
response yt−1 plus the derivative of the impulse response function of Θ at time t.
We will exhibit an online algorithm that can compete against the best Θ in this setting. Let
ˆy1  . . .   ˆyT be the predictions made by an online learner  and let y∗
T be the sequence of
predictions  realized by a chosen setting of LDS parameters Θ  which minimize total squared error.
Then  we deﬁne regret by the difference of total squared-error losses:

1  . . .   y∗

T(cid:88)
t=1(cid:107)yt − ˆyt(cid:107)2 −

T(cid:88)
t=1(cid:107)yt − y

Regret(T )

def
=

∗
t (cid:107)2.

This setup ﬁts into the standard setting of online convex optimization (in which a sublinear regret
bound implies convergence towards optimal predictions)  save for the fact that the loss functions are
non-convex in the system parameters. Also  note that a randomized construction (set all xt = 0 
and let yt be i.i.d. Bernoulli random variables) yields a lower bound3 for any online algorithm:
E [Regret(T )] ≥ Ω(√T ).
To quantify regret bounds  we must state our scaling assumptions on the (otherwise adversarial)
input and output sequences. We assume that the inputs are bounded: (cid:107)xt(cid:107)2 ≤ Rx. Also  we assume
that the output signal is Lipschitz in time: (cid:107)yt − yt−1(cid:107)2 ≤ Ly. The latter assumption exists to
preclude pathological inputs where an online learner is forced to incur arbitrarily large regret. For a
true noiseless LDS  Ly is not too large; see Lemma F.5 in the appendix.
We note that an optimal ˜O(√T ) regret bound can be trivially achieved in this setting by algorithms
such as Hedge [LW94]  using an exponential-sized discretization of all possible LDS parameters;
this is the online equivalent of brute-force grid search. Strikingly  our algorithms achieve essentially
the same regret bound  but run in polynomial time.

2.3 The power of convex relaxations

Much work in system identiﬁcation  including the EM method  is concerned with explicitly ﬁnding
the LDS parameters Θ = (A  B  C  D  h0) which best explain the data. However  it is evident from
Equation 3 that the CAiB terms cause the least-squares (or any other) loss to be non-convex in Θ.
Many methods used in practice  including EM and subspace identiﬁcation  heuristically estimate
each hidden state ht  after which estimating the parameters becomes a convex linear regression
problem. However  this ﬁrst step is far from guaranteed to work in theory or practice.
Instead  we follow the paradigm of improper learning: in order to predict sequences as accurately as
the best possible LDS Θ∗
∈ H  one need not predict strictly from an LDS. The central driver of our
algorithms is the construction of a slightly larger hypothesis class ˆH  for which the best predictor
ˆΘ∗ is nearly as good as Θ∗. Furthermore  we construct ˆH so that the loss functions are convex under
this new parameterization. From this will follow our efﬁcient online algorithm.
As a warmup example  consider the following overparameterization: pick some time window
τ (cid:28) T   and let the predictions ˆyt be linear in the concatenation [xt  . . .   xt−τ ] ∈ Rτ d. When
(cid:107)A(cid:107) is bounded away from 1  this is a sound assumption.4 However  in general  this approximation
is doomed to either truncate longer-term input-output dependences (short τ)  or suffer from over-
ﬁtting (long τ). Our main theorem uses an overparameterization whose approximation factor ε is
independent of (cid:107)A(cid:107)  and whose sample complexity scales only as ˜O(polylog(T  1/ε)).
2.4 Low approximate rank of Hankel matrices

Our analysis relies crucially on the spectrum of a certain Hankel matrix  a square matrix whose
anti-diagonal stripes have equal entries (i.e. Hij is a function of i + j). An important example is the

3This is a standard construction; see  e.g. Theorem 3.2 in [Haz16].
4This assumption is used in autoregressive models; see Section 6 of [HMR16] for a theoretical treatment.

4

Hilbert matrix Hn θ  the n-by-n matrix whose (i  j)-th entry is

1

i+j+θ . For example 

(cid:34) 1

1/2
1/3

H3 −1 =

(cid:35)

.

1/2
1/3
1/4

1/3
1/4
1/5

This and related matrices have been studied under various lenses for more than a century: see  e.g. 
[Hil94  Cho83]. A basic fact is that Hn θ is a positive deﬁnite matrix for every n ≥ 1  θ > −2.
The property we are most interested in is that the spectrum of a positive semideﬁnite Hankel matrix
decays exponentially  a difﬁcult result derived in [BT16] via Zolotarev rational approximations. We
state these technical bounds in Appendix E.

3 The wave-ﬁltering algorithm

def

Our online algorithm (Algorithm 1) runs online projected gradient descent [Zin03] on the squared
loss ft(Mt)
= (cid:107)yt − ˆyt(Mt)(cid:107)2. Here  each Mt is a matrix specifying a linear map from fea-
turized inputs ˜Xt to predictions ˆyt. Speciﬁcally  after choosing a certain bank of k ﬁlters {φj} 
˜Xt ∈ Rnk+2n+m consists of convolutions of the input time series with each φj (scaled by certain
constants)  along with xt−1  xt  and yt−1. The number of ﬁlters k will turn out to be polylogarithmic
in T .
The ﬁlters {φj} and scaling factors {σ1/4
Hankel matrix ZT ∈ RT×T   whose entries are given by

j } are given by the top eigenvectors and eigenvalues of the

2

Zij :=

(i + j)3 − (i + j)

.

j=1  the top k eigenpairs of ZT .
= nk + 2n + m.

In the language of Section 2.3  one should think of each Mt as arising from an
˜O(poly(m  n  d  log T ))-dimensional hypothesis class ˆH  which replaces the original O((m + n +
d)2)-dimensional class H of LDS parameters (A  B  C  D  h0). Theorem 3 gives the key fact that
ˆH approximately contains H.
Algorithm 1 Online wave-ﬁltering algorithm for LDS sequence prediction
1: Input: time horizon T   ﬁlter parameter k  learning rate η  radius parameter RM .
2: Compute {(σj  φj)}k
3: Initialize M1 ∈ Rm×k(cid:48)
4: for t = 1  . . .   T do
Compute ˜X ∈ Rk(cid:48)
5:
the 2n + m entries of xt−1  xt  and yt−1.
Predict ˆyt := Mt ˜X.
6:
Observe yt. Suffer loss (cid:107)yt − ˆyt(cid:107)2.
7:
Gradient update: Mt+1 ← Mt − 2η(yt − ˆyt) ⊗ ˜X.
8:
if (cid:107)Mt+1(cid:107)F ≥ RM then
9:
Perform Frobenius norm projection: Mt+1 ← RM(cid:107)Mt+1(cid:107)F
10:
end if
11:
12: end for

  with ﬁrst nk entries ˜X(i j) := σ1/4

u=1 φj(u)xt−u(i)  followed by

(cid:80)T−1

  where k(cid:48) def

Mt+1.

j

In Section 4  we provide the precise statement and proof of Theorem 1  the main regret bound for
Algorithm 1  with some technical details deferred to the appendix. We also obtain analogous sample
complexity results for batch learning; however  on account of some deﬁnitional subtleties  we defer
all discussion of the ofﬂine case  including the statement and proof of Theorem 2  to Appendix A.
We make one ﬁnal interesting note here  from which the name wave-ﬁltering arises: when plotted
coordinate-wise  our ﬁlters {φj} look like the vibrational modes of an inhomogeneous spring (see
Figure 1). We provide some insight on this phenomenon (along with some other implementation
concerns) in Appendix B. Succinctly:
in the scaling limit  (ZT /(cid:107)ZT(cid:107)2)T→∞ commutes with a
certain second-order Sturm-Liouville differential operator D. This allows us to approximate ﬁlters
with eigenfunctions of D  using efﬁcient numerical ODE solvers.

5

(a)

(b)

(c)

Figure 1: (a) The entries of some typical eigenvectors of Z1000  plotted coordinate-wise. (b) φ27 of
Z1000 (σ27 ≈ 10−16) computed with ﬁnite-precision arithmetic  along with a numerical solution to
the ODE in Appendix B.1 with λ = 97. (c) Some very high-order ﬁlters  computed using the ODE 
would be difﬁcult to obtain by eigenvector computations.

4 Analysis

We ﬁrst state the full form of the regret bound achieved by Algorithm 1:5
Theorem 1
choice
of k
Θ((R2

Θ(cid:0)log2 T log(RΘRxLyn)(cid:1)  RM

xLy log(RΘRxLyn) n√T log4 T )−1)  achieves regret

(Main). On
=

{(xt  yt)}T

sequence

t=1 
=

any

(cid:16)

Algorithm 1 
Θ(R2

and

with
η

a
=

Θ√k) 
(cid:17)

 

Regret(T ) ≤ O

R4

Θ R2

x Ly log2(RΘRxLyn) · n√T log6 T

competing with LDS predictors (A  B  C  D  h0) with 0 (cid:52) A (cid:52) I and (cid:107)B(cid:107)F  (cid:107)C(cid:107)F  (cid:107)D(cid:107)F  (cid:107)h0(cid:107) ≤
RΘ.

Note that the dimensions m  d do not appear explicitly in this bound  though they typically factor
into RΘ. In Section 4.1  we state and prove Theorem 3  the convex relaxation guarantee for the
ﬁlters  which may be of independent interest. This allows us to approximate the optimal LDS in
hindsight (the regret comparator) by the loss-minimizing matrix Mt : ˜X (cid:55)→ ˆyt. In Section 4.2  we
complete the regret analysis using Theorem 3  along with bounds on the diameter and gradient  to
conclude Theorem 1.
Since the batch analogue is less general (and uses the same ideas)  we defer discussion of Algo-
rithm 2 and Theorem 2 to Appendix A.

4.1 Approximate convex relaxation via wave ﬁlters

Assume for now that h0 = 0; we will remove this at the end  and see that the regret bound is
asymptotically the same. Recall (from Section 2.2) that we measure regret compared to predictions
obtained by adding the derivative of the impulse response function of an LDS Θ to yt−1. Our
approximation theorem states that for any Θ  there is some MΘ ∈ ˆH which produces approximately
the same predictions. Formally:
Theorem 3 (Spectral convex relaxation for symmetric LDSs). Let {ˆyt}T
t=1 be the online predictions
made by an LDS Θ = (A  B  C  D  h0 = 0). Let RΘ = max{(cid:107)B(cid:107)F  (cid:107)C(cid:107)F  (cid:107)D(cid:107)F}. Then  for any
ε > 0  with a choice of k = Ω (log T log(RΘRxLynT /ε))  there exists an MΘ ∈ Rm×k(cid:48)
such that

T(cid:88)
t=1(cid:107)MΘ ˜Xt − yt(cid:107)2 ≤

T(cid:88)
t=1(cid:107)ˆyt − yt(cid:107)2 + ε.

Here  k(cid:48) and ˜Xt are deﬁned as in Algorithm 1 (noting that ˜Xt includes the previous ground truth
yt−1).

5Actually  for a slightly tighter proof  we analyze a restriction of the algorithm which does not learn the

portion M (y)  instead always choosing the identity matrix for that block.

6

02004006008001000−0.20−0.100.000.100.20φ1φ3φ5φ10φ15φ2002004006008001000φ27φODE(97)02004006008001000φODE(500)φODE(5000)Proof. We construct this mapping Θ (cid:55)→ MΘ explicitly. Write MΘ as the block matrix

(cid:2)

M (1) M (2)

··· M (k) M (x(cid:48)) M (x) M (y)(cid:3)  

where the blocks’ dimensions are chosen to align with ˜Xt  the concatenated vector

σ1/4
1

(X ∗ φ1)t σ1/4

2

(X ∗ φ2)t

···

σ1/4
k

(X ∗ φk)t

xt−1

xt

yt−1

so that the prediction is the block matrix-vector product

(cid:104)

(cid:105)

 

MΘ ˜Xt =

j M (j)(X ∗ φj)t + M (x(cid:48))xt−1 + M (x)xt + M (y)yt−1.
σ1/4

k(cid:88)

j=1

l=1.6 Let bl be the l-th row
Without loss of generality  assume that A is diagonal  with entries {αl}d
of B  and cl the l-th column of C. Also  we deﬁne a continuous family of vectors µ : [0  1] → RT  
with entries µ(α)(i) = (αl − 1)αi−1
. Then  our construction is as follows:

l

• M (j) =(cid:80)d
• M (x(cid:48)) = −D  M (x) = CB + D  M (y) = Im×m.

(cid:104)φj  µ(αl)(cid:105) (cl ⊗ bl)  for each 1 ≤ j ≤ k.

−1/4
l=1 σ
j

Below  we give the main ideas for why this MΘ works  leaving the full proof to Appendix C.
Since M (y) is the identity  the online learner’s task is to predict the differences yt − yt−1 as well as
the derivative Θ  which we write here:

ˆyt − yt−1 = (CB + D)xt − Dxt−1 +

= (CB + D)xt − Dxt−1 +

= (CB + D)xt − Dxt−1 +

C(Ai − Ai−1)Bxt−i
(cid:32) d(cid:88)
(cid:0)αi
l − αi−1
T−1(cid:88)

l=1

C

l

(cid:1) el ⊗ el

(cl ⊗ bl)

i=1

µ(αl)(i) xt−i.

(cid:33)

Bxt−i

(4)

the inner sum is an inner product between each coordinate of the past

Notice that
inputs
(xt  xt−1  . . .   xt−T ) with µ(αl) (or a convolution  viewed across the entire time horizon). The crux
j=1.
of our proof is that one can approximate µ(α) using a linear combination of the ﬁlters {φj}k
Writing Z := ZT for short  notice that

i=1

T−1(cid:88)
T−1(cid:88)
d(cid:88)

i=1

l=1

(cid:90) 1

Z =

0

µ(α) ⊗ µ(α) dα 

since the (i  j) entry of the RHS is

(cid:90) 1

0

(α − 1)2αi+j−2 dα =

1

i + j − 1 −

2

i + j

+

1

i + j + 1

= Zij.

What follows is a spectral bound for reconstruction error  relying on the low approximate rank of Z:
Lemma 4.1. Choose any α ∈ [0  1]. Let ˜µ(α) be the projection of µ(α) onto the k-dimensional
subspace of RT spanned by {φj}k

j=1. Then 

(cid:118)(cid:117)(cid:117)(cid:116)6

T(cid:88)

σj ≤ O

j=k+1

(cid:16)

(cid:112)

(cid:17)

−k/ log T
c
0

log T

 

(cid:107)µ(α) − ˜µ(α)(cid:107)2 ≤

for an absolute constant c0 > 3.4.

6Write the eigendecomposition A = U ΛU T . Then  the LDS with parameters ( ˆA  ˆB  ˆC  D  h0) :=

(Λ  BU  U T C  D  h0) makes the same predictions as the original  with ˆA diagonal.

7

By construction of M (j)  MΘ ˜Xt replaces each µ(αl) in Equation (4) with its approximation ˜µ(αl).
Hence we conclude that

MΘ ˜Xt = yt−1 + (CB + D)xt − Dxt−1 +

(cl ⊗ bl)

˜µ(αl)(i) xt−i

d(cid:88)

l=1

T−1(cid:88)

i=1

= yt−1 + (ˆyt − yt−1) + ζt = ˆyt + ζt 

letting {ζt} denote some residual vectors arising from discarding the subspace of dimension T − k.
Theorem 3 follows by showing that these residuals are small  using Lemma 4.1: it turns out that
(cid:107)ζt(cid:107) is exponentially small in k/ log T   which implies the theorem.
4.2 From approximate relaxation to low regret
Let Θ∗
∈ H denote the best LDS predictor  and let MΘ∗ ∈ ˆH be its image under the map
from Theorem 3  so that total squared error of predictions MΘ∗ ˜Xt is within ε from that of
Θ∗. Notice that the loss functions ft(M )
= (cid:107)yt − M ˜Xt(cid:107)2 are quadratic in M  and thus con-
vex. Algorithm 1 runs online gradient descent [Zin03] on these loss functions  with decision set
(cid:107)F be the diameter
M
of M  and Gmax := supM∈M  ˜X(cid:107)∇ft(M )(cid:107)F be the largest norm of a gradient. We can invoke the
classic regret bound:
√
Lemma 4.2 (e.g. Thm. 3.1 in [Haz16]). Online gradient descent  using learning rate Dmax
  has
Gmax
regret

= {M ∈ Rm×k(cid:48) (cid:12)(cid:12) (cid:107)M(cid:107)F ≤ RM}. Let Dmax := supM M(cid:48)∈M(cid:107)M − M(cid:48)

def

def

T

RegretOGD(T )

def
=

ft(Mt) − min
M∈M

ft(M ) ≤ 2GmaxDmax√T .

T(cid:88)

t=1

T(cid:88)

t=1

To ﬁnish  it remains to show that Dmax and Gmax are small.
In particular  since the gradients
contain convolutions of the input by (cid:96)2 (not (cid:96)1) unit vectors  special care must be taken to ensure
that these do not grow too quickly. These bounds are shown in Section D.2  giving the correct
regret of Algorithm 1 in comparison with the comparator M∗
∈ ˆH. By Theorem 3  M∗ competes
arbitrarily closely with the best LDS in hindsight  concluding the theorem.
Finally  we discuss why it is possible to relax the earlier assumption h0 = 0 on the initial hidden
state. Intuitively  as more of the ground truth responses {yt} are revealed  the largest possible effect
of the initial state decays. Concretely  in Section D.4  we prove that a comparator who chooses a
nonzero h0 can only increase the regret by an additive ˜O(log2 T ) in the online setting.

5 Experiments

In this section  to highlight the appeal of our provable method  we exhibit two minimalistic cases
where traditional methods for system identiﬁcation fail  while ours successfully learns the system.
Finally  we note empirically that our method seems not to degrade in practice on certain well-
behaved nonlinear systems. In each case  we use k = 25 ﬁlters  and a regularized follow-the-leader
variant of Algorithm 1 (see Appendix B.2).

5.1 Synthetic systems: two hard cases for EM and SSID

We construct two difﬁcult systems  on which we run either EM or subspace identiﬁcation7 (SSID) 
followed by Kalman ﬁltering to obtain predictions. Note that our method runs signiﬁcantly (>1000
times) faster than this traditional pipeline.
In the ﬁrst example (Figure 2(a)  left)  we have a SISO system (n = m = 1) and d = 2; all xt  ξt 
and ηt are i.i.d. Gaussians  and B(cid:62) = C = [1 1]  D = 0. Most importantly  A = diag ([0.999  0.5])
is ill-conditioned  so that there are long-term dependences between input and output. Observe that
although EM and SSID both ﬁnd reasonable guesses for the system’s dynamics  they turns out to be
local optima. Our method learns to predict as well as the best possible LDS.

7Speciﬁcally  we use “Deterministic Algorithm 1” from page 52 of [VODM12].

8

(a) Two synthetic systems. For clarity  error plots are smoothed by a median ﬁlter. Left: Noisy SISO system
with a high condition number; EM and SSID ﬁnds a bad local optimum. Right: High-dimensional MIMO
system; other methods fail to learn any reasonable model of the dynamics.

(b) Forced pendulum  a physical simulation our method learns in practice  despite a lack of theory.

Figure 2: Visualizations of Algorithm 1. All plots: blue = ours  yellow = EM  red = SSID  black = true
responses  green = inputs  dotted lines = “guess the previous output” baseline. Horizontal axis is time.

The second example (Figure 2(a)  right) is a MIMO system (with n = m = d = 10)  also with
Gaussian noise. The transition matrix A = diag ([0  0.1  0.2  . . .   0.9]) has a diverse spectrum  the
observation matrix C has i.i.d. Gaussian entries  and B = In  D = 0. The inputs xt are random
block impulses. This system identiﬁcation problem is high-dimensional and non-convex; it is thus
no surprise that EM and SSID consistently fail to converge.

5.2 The forced pendulum: a nonlinear  non-symmetric system

We remark that although our algorithm has provable regret guarantees only for LDSs with symmetric
transition matrices  it appears in experiments to succeed in learning some non-symmetric (even
nonlinear) systems in practice  much like the unscented Kalman ﬁlter [WVDM00]. In Figure 2(b) 
we provide a typical learning trajectory for a forced pendulum  under Gaussian noise and random
block impulses. Physical systems like this are widely considered in control and robotics  suggesting
possible real-world applicability for our method.

6 Conclusion

We have proposed a novel approach for provably and efﬁciently learning linear dynamical systems.
Our online wave-ﬁltering algorithm attains near-optimal regret in theory; and experimentally out-
performs traditional system identiﬁcation in both prediction quality and running time. Furthermore 
we have introduced a “spectral ﬁltering” technique for convex relaxation  which uses convolutions
by eigenvectors of a Hankel matrix. We hope that this theoretical tool will be useful in tackling more
general cases  as well as other non-convex learning problems.

Acknowledgments

We thank Holden Lee and Yi Zhang for helpful discussions. We especially grateful to Holden for a
thorough reading of our manuscript  and for pointing out a way to tighten the result in Lemma C.1.

9

System1:ill-conditionedSISO−200−1000100Timeseries(xt yt)xtyt010020030040050010−310−1101103Error||ˆyt−yt||2EMSSIDoursˆyt=yt−1System2:10-dimensionalMIMO−2−101xt(1)yt(1)0200400600800100010−410−2100102EMSSIDoursˆyt=yt−102004006008001000−0.50.00.5(xt yt ˆyt)xtytˆytReferences

[Aud14] Koenraad MR Audenaert. A generalisation of mirsky’s singular value inequalities.

arXiv preprint arXiv:1410.4941  2014.

[BM02] Peter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk
bounds and structural results. Journal of Machine Learning Research  3(Nov):463–
482  2002.

[BT16] Bernhard Beckermann and Alex Townsend. On the singular values of matrices with

displacement structure. arXiv preprint arXiv:1609.09494  2016.

[Cho83] Man-Duen Choi. Tricks or treats with the hilbert matrix. The American Mathematical

Monthly  90(5):301–312  1983.

[DHS11] John Duchi  Elad Hazan  and Yoram Singer. Adaptive subgradient methods for online
learning and stochastic optimization. The Journal of Machine Learning Research 
12:2121–2159  2011.

[GH96] Zoubin Ghahramani and Geoffrey E Hinton. Parameter estimation for linear dynamical
systems. Technical report  Technical Report CRG-TR-96-2  University of Toronto 
Deptartment of Computer Science  1996.

[Gr¨u82] F Alberto Gr¨unbaum. A remark on hilbert’s matrix. Linear Algebra and its Applica-

tions  43:119–124  1982.

[Haz16] Elad Hazan. Introduction to online convex optimization. Foundations and Trends in

Optimization  2(3-4):157–325  2016.

[Hil94] David Hilbert. Ein beitrag zur theorie des legendre’schen polynoms. Acta mathemat-

ica  18(1):155–159  1894.

[HMR16] Moritz Hardt  Tengyu Ma  and Benjamin Recht. Gradient descent learns linear dy-

namical systems. arXiv preprint arXiv:1609.05191  2016.

[HSC+16] Wenbing Huang  Fuchun Sun  Lele Cao  Deli Zhao  Huaping Liu  and Mehrtash Ha-
randi. Sparse coding and dictionary learning with linear dynamical systems. In Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern Recognition  pages
3938–3947  2016.

[Kal60] Rudolph Emil Kalman. A new approach to linear ﬁltering and prediction problems.

Journal of Basic Engineering  82.1:35–45  1960.

[KV05] Adam Kalai and Santosh Vempala. Efﬁcient algorithms for online decision problems.

Journal of Computer and System Sciences  71(3):291–307  2005.

[Lju98] Lennart Ljung. System identiﬁcation: Theory for the User. Prentice Hall  Upper

Saddle Riiver  NJ  2 edition  1998.

[Lju02] Lennart Ljung. Prediction error estimation methods. Circuits  Systems and Signal

Processing  21(1):11–21  2002.

[LW94] Nick Littlestone and Manfred K. Warmuth. The weighted majority algorithm. Infor-

mation and Computation  108(2):212–261  1994.

[Mar10a] James Martens. Learning the linear dynamical system with asos. In Johannes Frnkranz
and Thorsten Joachims  editors  Proceedings of the 27th International Conference on
Machine Learning  pages 743–750. Omnipress  2010.

[Mar10b] James Martens. Learning the linear dynamical system with asos. In Proceedings of

the 27th International Conference on Machine Learning  pages 743–750  2010.

[RG99] Sam Roweis and Zoubin Ghahramani. A unifying review of linear gaussian models.

Neural computation  11(2):305–345  1999.

10

[Sch11] J Schur. Bemerkungen zur theorie der beschr¨ankten bilinearformen mit unendlich
vielen ver¨anderlichen. Journal f¨ur die reine und Angewandte Mathematik  140:1–28 
1911.

[Sle78] David Slepian. Prolate spheroidal wave functions  fourier analysis  and uncertainty:

The discrete case. Bell Labs Technical Journal  57(5):1371–1430  1978.

[SS82] Robert H Shumway and David S Stoffer. An approach to time series smoothing and
forecasting using the em algorithm. Journal of Time Series Analysis  3(4):253–264 
1982.

[VODM12] Peter Van Overschee and BL De Moor. Subspace Identiﬁcation for Linear Systems.

Springer Science & Business Media  2012.

[WVDM00] Eric A Wan and Rudolph Van Der Merwe. The unscented kalman ﬁlter for nonlinear
estimation. In Adaptive Systems for Signal Processing  Communications  and Control
Symposium 2000. AS-SPCC. The IEEE 2000  pages 153–158. IEEE  2000.

[Zin03] Martin Zinkevich. Online convex programming and generalized inﬁnitesimal gradient
ascent. In Proceedings of the 20th International Conference on Machine Learning 
pages 928–936  2003.

11

,Elad Hazan
Karan Singh
Cyril Zhang
Pablo Moreno-Muñoz
Antonio Artés
Mauricio Álvarez
Motonobu Kanagawa
Philipp Hennig