2014,Inferring sparse representations of continuous signals with continuous orthogonal matching pursuit,Many signals  such as spike trains recorded in multi-channel electrophysiological recordings  may be represented as the sparse sum of translated and scaled copies of waveforms whose timing and amplitudes are of interest. From the aggregate signal  one may seek to estimate the identities  amplitudes  and translations of the waveforms that compose the signal. Here we present a fast method for recovering these identities  amplitudes  and translations. The method involves greedily selecting component waveforms and then refining estimates of their amplitudes and translations  moving iteratively between these steps in a process analogous to the well-known Orthogonal Matching Pursuit (OMP) algorithm. Our approach for modeling translations borrows from Continuous Basis Pursuit (CBP)  which we extend in several ways: by selecting a subspace that optimally captures translated copies of the waveforms  replacing the convex optimization problem with a greedy approach  and moving to the Fourier domain to more precisely estimate time shifts. We test the resulting method  which we call Continuous Orthogonal Matching Pursuit (COMP)  on simulated and neural data  where it shows gains over CBP in both speed and accuracy.,Inferring sparse representations of continuous signals

with continuous orthogonal matching pursuit

Karin C. Knudson

Department of Mathematics

The University of Texas at Austin
kknudson@math.utexas.edu

Jacob L. Yates

Department of Neuroscience

The University of Texas at Austin

jlyates@utexas.edu

Alexander C. Huk

Center for Perceptual Systems

Departments of Psychology & Neuroscience

The University of Texas at Austin

huk@utexas.edu

Jonathan W. Pillow

Princeton Neuroscience Institute and

Department of Psychology

Princeton University

pillow@princeton.edu

Abstract

Many signals  such as spike trains recorded in multi-channel electrophysiological
recordings  may be represented as the sparse sum of translated and scaled copies
of waveforms whose timing and amplitudes are of interest. From the aggregate
signal  one may seek to estimate the identities  amplitudes  and translations of the
waveforms that compose the signal. Here we present a fast method for recover-
ing these identities  amplitudes  and translations. The method involves greedily
selecting component waveforms and then reﬁning estimates of their amplitudes
and translations  moving iteratively between these steps in a process analogous
to the well-known Orthogonal Matching Pursuit (OMP) algorithm [11]. Our ap-
proach for modeling translations borrows from Continuous Basis Pursuit (CBP)
[4]  which we extend in several ways: by selecting a subspace that optimally cap-
tures translated copies of the waveforms  replacing the convex optimization prob-
lem with a greedy approach  and moving to the Fourier domain to more precisely
estimate time shifts. We test the resulting method  which we call Continuous Or-
thogonal Matching Pursuit (COMP)  on simulated and neural data  where it shows
gains over CBP in both speed and accuracy.

1

Introduction

It is often the case that an observed signal is a linear combination of some other target signals that
one wishes to resolve from each other and from background noise. For example  the voltage trace
from an electrode (or array of electrodes) used to measure neural activity in vivo may be recording
from a population of neurons  each of which produces many instances of its own stereotyped action
potential waveform. One would like to decompose an analog voltage trace into a list of the timings
and amplitudes of action potentials (spikes) for each neuron.
Motivated in part by the spike-sorting problem  we consider the case where we are given a signal
that is the sum of known waveforms whose timing and amplitude we seek to recover. Speciﬁcally 
we suppose our signal can be modeled as:

y(t) =

an jfn(t − τn j) 

(1)

Nf(cid:88)

J(cid:88)

n=1

j=1

1

where the waveforms fn are known  and we seek to estimate positive amplitudes an j and event
times τn j. Signals of this form have been studied extensively [12  9  4  3].
This a difﬁcult problem in part because of the nonlinear dependence of y on τ. Moreover  in most
applications we do not have access to y(t) for arbitrary t  but rather have a vector of sampled (noisy)
measurements on a grid of discrete time points. One way to simplify the problem is to discretize τ 
considering only a ﬁnite set of possible time shift τn j ∈ {∆  2∆...  N∆∆} and approximating the
signal as

Nf(cid:88)

J(cid:88)

y ≈

an jfn(t − in j∆)  in j ∈ 1  ...  N∆

(2)

n=1

j=1

Once discretized in this way  the problem is one of sparse recovery: we seek to represent the
observed signal with a sparse linear combination of elements of a ﬁnite dictionary {fn j(t) :=
fn(t − j∆)  n ∈ 1  ...  Nf   j ∈ 1  ...  N∆}. Framing the problem as sparse recovery  one can
bring tools from compressed sensing to bear. However  the discretization introduces several new
difﬁculties. First  we can only approximate the translation τ by values on a discrete grid. Secondly 
choosing small ∆ allows us to more closely approximate τ  but demands more computation  and
such ﬁnely spaced dictionary elements yield a highly coherent dictionary  while sparse recovery
algorithms generally have guarantees for low-coherence dictionaries.
A previously introduced algorithm that uses techniques of sparse recovery and returns accurate and
continuous valued estimates of a and τ is Continuous Basis Pursuit (CBP) [4]  which we describe
below. CBP proceeds (roughly speaking) by augmenting the discrete dictionary fn j(t) with other
carefully chosen basis elements  and then solving a convex optimization problem inspired by basis
pursuit denoising. We extend ideas introduced in CBP to present a new method for recovering
the desired time shifts τ and amplitudes a that leverage the speed and tractability of solving the
discretized problem while still ultimately producing continuous valued estimates of τ  and partially
circumventing the problem of too much coherence.
Basis pursuit denoising and other convex optimization or (cid:96)1-minimization based methods have been
effective in the realm of sparse recovery and compressed sensing. However  greedy methods have
also been used with great success. Our approach begins with the augmented bases used in CBP 
but adds basis vectors greedily  drawing on the well known Orthogonal Matching Pursuit algorithm
[11]. In the regimes considered  our greedy approach is faster and more accurate than CBP.
Broadly speaking  our approach has three parts. First  we augment the discretized basis in one of
several ways. We draw on [4] for two of these choices  but also present another choice of basis that
is in some sense optimal. Second  we greedily select candidate time bins of size ∆ in which we
suspect an event has occurred. Finally  we move from this rough  discrete-valued estimate of timing
τ to continuous-valued estimates of τ and a. We iterate the second and third steps  greedily adding
candidate time bins and updating our estimates of τ and a until a stopping criterion is reached.
The structure of the paper is as follows. In Section 2 we describe the method of Continuous Basis
Pursuit (CBP)  which our method builds upon. In Section 3 we develop our method  which we call
Continuous Orthogonal Matching Pursuit (COMP). In Section 4 we present the performance of our
method on simulated and neural data.

2 Continuous basis pursuit

Continuous Basis Pursuit (CBP) [4  3  5] is a method for recovering the time shifts and amplitudes
of waveforms present in a signal of the form (1). A key element of CBP is augmenting or replacing
the set {fn j(t)} with certain additional dictionary elements that are chosen to smoothly interpolate
the one dimensional manifold traced out by fn j(t − τ ) as τ varies in (−∆/2  ∆/2).
The beneﬁt of a dictionary that is expanded in this way is twofold. First  it increases the ability
of the dictionary to represent shifted copies of the waveform fn(t − τ ) without introducing as
much correlation as would be introduced by simply using a ﬁner discretization (decreasing ∆) 
which is an advantage because dictionaries with smaller coherence are generally better suited for
sparse recovery techniques. Second  one can move from recovered coefﬁcients in this augmented
dictionary to estimates an j and continuous-valued estimates of τn j.

2

k=1 c(k)

n j  ...  c(K)

n j )  so afn j(t − τ ) ≈(cid:80)K

In general  there are three ingredients for CBP: basis elements  an interpolator with corresponding
mapping function Φ  and a convex constraint set  C. There are K basis elements {gn j k(t) =
gn k(t− j∆)}k=K
k=1   for each waveform and width-∆ time bin  which together can be used to linearly
interpolate fn j(t − τ ) |τ| < ∆/2. The function Φ maps from amplitude a and time shift τ to K-
tuples of coefﬁcients Φ(a  τ ) = (c(1)
n jgn j k(t). The convex
constraint set C is for K-tuples of coefﬁcients of {gn j k}k=K
k=1 and corresponds to the requirement
that a > 0 and |τ| < ∆/2. If the constraint region corresponding to these requirements is not convex
(e.g. in the polar basis discussed below)  its convex relaxation is used.
As a concrete example  let us ﬁrst consider (as discussed in [4]) the dictionary augmented with
shifted copies of each waveform’s derivative : {f(cid:48)
n(t− j∆)}. Assuming fn is sufﬁciently
smooth  we have from the Taylor expansion that for small τ  afn j(t− τ ) ≈ afn j(t)− aτ f(cid:48)
n j(t). If
we recover a representation of y as c1fn j(t)+c2f(cid:48)
n j(t)  then we can estimate the amplitude a of the
waveform present in y as c1  the time shift τ as −c2/c1. Hence  we estimate y ≈ c1fn j(t+c2/c1) =
c1fn(t − j∆ + c2/c1). Note that the estimate of the time shift τ varies continuously with c1  c2.
In contrast  using shifted copies of the waveforms only as a basis would not allow for a time shift
estimate off of the grid {j∆}j=N∆
Once a suitable dictionary is chosen  one must still recover coefﬁcients (i.e. c1  c2 above). Motivated
by the assumed sparsity of the signal (i.e. y is the sum of relatively few shifted copies of waveforms 
so the coefﬁcients of most dictionary elements will be zero)  CBP draws on the basis pursuit denois-
ing  which has been effective in the compressive sensing setting and elsewhere [10] [1]. Speciﬁcally 
CBP (with a Taylor basis) recovers coefﬁcients using:

n j(t) := f(cid:48)

j=1

.

argminc

(Fnc(1)

n + F(cid:48)

n ) − y

nc(2)

+ λ

s.t. c(1)

n i ≥ 0   |c(2)

n i| ≤ ∆
2

i n ∀ n  i (3)
c(1)

n j and time shift j∆ − ˆτ = j∆ − c(2)

Here we denote by F the matrix with columns {fn j(t)} and F(cid:48) the matrix with columns {f(cid:48)
n j(t)}.
The (cid:96)1 penalty encourages sparsity  pushing most of the estimated amplitudes to zero  with higher
n j (cid:54)= 0  one estimates that there is
λ encouraging greater sparsity. Then  for each (n  j) such that c(1)
a waveform in the shape of fn with amplitude ˆa = c(1)
n j/c(1)
n j
present in the signal. The inequality constraints in the optimization problem ensure ﬁrst that we only
recover positive amplitudes ˆa  and second that estimates ˆτ satisfy |ˆτ| < ∆/2. Requiring ˆτ to fall
in this range keeps the estimated τ in the time bin represented by fn j and also in the regime where
they Taylor approximation to fn j(t−τ ) is accurate. Note that (3) is a convex optimization problem.
Better results in [4] are obtained for a second order Taylor interpolation and the best results come
from a polar interpolator  which represents each manifold of time-shifted waveforms fn j(t −
τ ) |τ| ≤ ∆/2 as an arc of the circle that is uniquely deﬁned to pass through fn j(t)  fn j(t − ∆/2) 
and fn j(t+∆/2). Letting the radius of the arc be r  and its angle be 2θ one represents points on this
arc by linear combinations of functions w  u  v: f (t− τ ) ≈ w(t) + r cos( 2τ
∆ θ)v(t).
The Taylor and polar bases consist of shifted copies of elements chosen in order to linearly interpo-
late the curve in function space deﬁned by fn(t − τ ) as τ varies from −∆/2 to ∆/2. Let Gn k be
the matrix whose columns are gn j k(t) for j ∈ 1  ...  N∆. With choices of basis elements  interpo-
lator  and corresponding convex constraint set C in place  one proceeds to estimate coefﬁcients in
the chosen basis by solving:

∆ θ)u(t) + r sin( 2τ

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) Nf(cid:88)

n=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

2

(cid:13)(cid:13)(cid:13)c(1)

n

(cid:13)(cid:13)(cid:13)1

Nf(cid:88)

n=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)y −

Nf(cid:88)

K(cid:88)

n=1

k=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

2

Nf(cid:88)

n=1

argminc

Gn kc(k)
n

+ λ(cid:107)

n (cid:107)1 subject to (c(1)
c(1)

n j  ...  c(K)

n j ) ∈ C ∀(n  j)

(4)

One then maps back from each nonzero K-tuple of recovered coefﬁcients c(1)
to cor-
responding ˆan j  ˆτn j that represent the amplitude and timing of the nth waveform present in
the jth time bin. This can be done by inverting Φ  if possible  or estimating (ˆan j  ˆτn j) =
argmina τ(cid:107)Φ(a  τ ) − (c(1)

n j  ...  c(K)

n j  ...  c(K)

n j )(cid:107)2
2.

n j

3

Table 1: Basis choices (see also [4]  Table 1.)

Interpolator

Basis Vectors

Taylor
(K=3)

Polar

SVD

n j(t)}

{fn j(t)} {f(cid:48)
{f(cid:48)(cid:48)
{wn j} {un j} 
{vn j}
{u1

n j}...{uK

n j(t)} 

n j}.

Φ(a  τ )
(a −aτ  a τ 2
2 )

(a  ar cos( 2τ
ar sin( 2τ
∆ θ))

∆ θ) 

C

c(1)  c(3) > 0 |c(2)| < c(1) ∆
2  
|c(3)| < c(1) ∆2

c(1) ≥ 0 (cid:112)(c(2))2 + (c(3))2 ≤ rc(1)

rc(1) cos(θ) ≤ c(2) ≤ rc(1)

8

(See Section 3.1)

(See Section 3.1)

3 Continuous Orthogonal Matching Pursuit

We now present our method for recovery  which makes use of the idea of augmented bases presented
above  but differs from CBP in several important ways. First  we introduce a different choice of basis
that we ﬁnd enables more accurate estimates. Second  we make use of a greedy method that iterates
between choosing basis vectors and estimating time shifts and amplitudes  rather than proceeding
via a single convex optimization problem as CBP does. Lastly  we introduce an alternative to the
step of mapping back from recovered coefﬁcients via Φ that notably improves the accuracy of the
recovered time estimates.
Greedy methods such as Orthogonal Matching Pursuit (OMP) [11]  Subspace Pursuit [2]  and Com-
pressive Sampling Matching Pursuit (CoSaMP) [8] have proven to be fast and effective in the realm
of compressed sensing. Since the number of iterations of these greedy methods tend to go as the
sparsity (when the algorithms succeed)  they tend to be extremely fast when for very sparse sig-
nals. Moreover  our the greedy method eliminates the need to choose a regularization constant λ 
a choice that can vastly alter the effectiveness of CBP. (We still need to choose K and ∆.) Our
method is most closely analogous to OMP  but recovers continuous time estimates  so we call it
Continuous Orthogonal Matching Pursuit (COMP). However  the steps below could be adapted in a
straightforward way to create analogs of other greedy methods.

3.1 Choice of ﬁnite basis

We build upon [4]  choosing as our basis N∆ shifted copies of a set of K basis vectors for each
waveform in such away that these K basis vectors can effectively linearly interpolate fn(t − τ )
for |τ| < ∆/2.
In our method  as in Continuous Basis Pursuit  these basis vectors allow us to
represent continuous time shifts instead of discrete time shifts  and expand the descriptive power of
our dictionary without introducing undue amounts of coherence. While previous work introduced
Taylor and polar bases  we obtain the best recovery from a different basis  which we describe now.
The basis comes from a singular value decomposition of a matrix whose columns correspond to
discrete points on the curve in function space traced out by fn j(t − τ ) as we vary τ for |τ| < ∆/2.
Within one time bin of size ∆  consider discretizing further into Nδ = ∆/δ time bins of size δ (cid:28) ∆.
Let Fδ be the matrix with columns that are these (slightly) shifted copies of the waveform  so that
the ith column of Fδ is fn j(t − iδ + ∆/2) for a discrete vector of time points t. Each column of
this matrix is a discrete point on the curve traced out by fn j(t − τ ) as τ varies.
In choosing a basis  we seek the best choice of K vectors to use to linearly interpolate this curve. We
might instead seek to solve the related problem of ﬁnding the best K vectors to represent these ﬁnely
spaced points on the curve  in which case a clear choice for these K vectors is the ﬁrst K left singular
vectors of Fδ. This choice is optimal in the sense that the singular value decomposition yields the
best rank-K approximation to a matrix. If Fδ = UΣVT is the singular value decomposition  and
k=1 ukΣk k(vk)T(cid:107) ≤ (cid:107)F − A(cid:107) for
any rank-K matrix A and any unitarily invariant norm (cid:107) · (cid:107).

uk  vk are the columns of U and V respectively  then (cid:107)Fδ −(cid:80)K

4

k=1 aukΣk kvk

coefﬁcients of this basis. Since afn j(t− iδ) =(cid:80)K
simple way to recover a and τ would to choose τ = iδ and a  i to minimize(cid:80)K

In order to use this SVD basis with CBP or COMP  one must specify a convex constraint set for the
i a reasonable and simply enforced
constraint set would be to assume that the recovered coefﬁcients c(k) corresponding to each basis
vector uk  when divided by c(1) to account for scaling  be between mini Σk kvk
i . A
i )2.
In ﬁgure 3.1  we compare the error between shifted copies of a sample waveform f (t − τ ) for
|τ| < 0.5 and the best (least-squares) approximation of that waveform as a linear combination of
K = 3 vectors from the Taylor  polar  and SVD bases. The structure of the error as a function of the
time shift τ reﬂects the structure of these bases. The Taylor approximation is chosen to be exactly
accurate at τ = 0 while the polar basis is chosen to be precisely accurate at τ = 0  ∆/2 −∆/2. The
SVD basis gives the lowest mean error across time shifts.

i and maxi Σk kvk
k=1(c(k)−aΣk kvk

Figure 1: Using sample waveform f (t) ∝ t exp(−t2) (left panel)  we compare the error introduced
by approximating f (t− τ ) for varying τ with a linear combination of K = 3 basis vectors  from the
Taylor  polar or SVD bases. Basis vectors are shown in the middle three panels  and error in the far
right panel. The SVD basis introduces the least error on average over the shift τ. The average errors
for the Taylor  polar  and SVD bases are 0.026  0.027  and 0.014 respectively.

3.2 Greedy recovery

Having chosen our basis  we then greedily recover the time bins in which an occurrence of each
waveform appears to be present. We would like to build up a set of pairs (n  j) corresponding to
an instance of the nth waveform in the jth time bin. (In our third step  we will reﬁne the estimate
within the chosen bins.)
Our greedy method is motivated by Orthogonal Matching Pursuit (OMP)  which is used to recover a
sparse solution x from measurements y = Ax. In OMP [11]  one greedily adds a single dictionary
element to an estimated support set S at each iteration  and then projects orthogonally to adjust the
coefﬁcients of all chosen dictionary elements. After initializing with S = ∅  x = 0  one iterates the
following until a stopping criterion is met:

r = y − Ax
j = argmaxj{|(cid:104)aj  r(cid:105)| s.t. j ∈ {1  ...J}\S}
S = S ∪ {j}
x = argminz{||y − Az||2 s.t. zi = 0 ∀ i /∈ S}

If we knew the sparsity of the signal  we could use that as our stopping condition. Normally we do
not know the sparsity a priori; we stop when changes in the residual become sufﬁciently small.
We adjust this method to choose at each step not a single additional element but rather a set of
K associated basis vectors. S is again initialized to be empty  but at each step we add a time-
bin/waveform pair (n  j)  which is associated with K basis vectors. In this way  we are adding K
vectors at each step  instead of one as in OMP. We greedily add the next index (n  j) according to:

(n  j) = argminm i

min
cm i

c(k)
m ig(k)

m i − r(cid:107)2

2 s.t. cm i ∈ C}   (m  i) ∈ Sc

(5)

(cid:40)

{(cid:107) k(cid:88)

i=1

5

(cid:41)

5050.500.5Original WaveformApproximation ErrorTaylor: Polar:SVD: 0.0270.027 0.014Basis VectorsTaylorPolarSVD5050.200.25051015052020.500.50.020.040.060.08time shiftl2 error TaylorPolarSVDf(t)ttttm i} are the chosen basis vectors (Taylor  polar  or SVD)  and C is the corresponding con-

Here {g(k)
straint set  as in Section 2.
In comparison with the greedy step in OMP  choosing j as in (5) is more costly  because we need
to perform a constrained optimization over a K dimensional space for each n  j. Fortunately  it is
not necessary to repeat the optimization for each of the Nf · N∆ possible indices each time we add
an index. Assuming waves are localized in time  we need only update the results of the constrained
optimization locally. When we update the residual r by subtracting the newly identiﬁed waveform
n in the jth bin  the residual only changes in the bins at or near the jth bin  so we need only update

the quantity mincn j(cid:48){(cid:107)(cid:80)k

i=1 c(k)

n j(cid:48)g(k)

n j(cid:48) − r(cid:107)2

2 s.t. cn j(cid:48) ∈ C } for j(cid:48) neighboring j.

3.3 Estimating time shifts

Having greedily added a new waveform/timebin index pair (n  j)  we next deﬁne our update step 
which will correspond to the orthogonal projection in OMP. We present two alternatives  one of
which most closely mirrors the corresponding step in OMP  the other of which works within the
Fourier domain to obtain more accurate recovery.
To most closely follow the steps of OMP  at each iteration after updating S we update coefﬁcients c
according to:

subject to cn j ∈ C ∀ (n  j) ∈ S

(6)

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)
(cid:88)
ﬁnding the new residual r =(cid:80)

argminc

(n j)∈S

K(cid:88)

k=1

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2

2

c(k)
n jg(k)

n j − y
(cid:80)K

We alternate between the greedily updating S via (5)  and updating c as in (6)  at each iteration
n j−y ) until the (cid:96)2 stopping criterion is reached.

Then  one maps back from {cn j}(n j)∈S to {a(n j)  τ(n j)}(n j)∈S as described in Section 2.
Alternatively we may replace the orthogonal projection step with a more accurate recovery of spike
timings that involves working in the Fourier domain. We use the property of the Fourier transform
with respect to translation that: (f (t − τ ))∧ = e2πiτ ˆf. This allows us to estimate a  τ directly via:

k=1 c(k)

n jg(k)

(n j)∈S

argmina τ(cid:107)(

an je2πiωτn j ˆfn j(ω)) − ˆy(ω)(cid:107)2 subject to |τn j| < ∆/2 ∀ (n  j) ∈ S

(7)

(cid:88)

n j∈S

This is a nonlinear and non-convex constrained optimization problem. However  it can be solved rea-
sonably quickly using  for example  trust region methods. The search space is dramatically reduced
because τ has only |S| entries  each constrained to be small in absolute value. By searching directly
for a  τ as in (7) we sacriﬁce convexity  but with the beneﬁt of eliminating from this step error of
interpolation introduced as we map back from c to a  τ using Φ−1 or a least squares estimation.
It is easy and often helpful to add inequality constraints to a as well  for example requiring a to be
in some interval around 1  and we do impose this in our spike-sorting simulations and analysis in
Section 4. Such a requirement effectively imposes a uniform prior on a over the chosen interval. It
would be an interesting future project to explore imposing other priors on a.

4 Results

We test COMP and CBP for each choice of basis on simulated and neural data. Here  COMP denotes
the greedy method that includes direct estimation of a and τ during the update set as in (7). The
convex optimization for CBP is implemented using the cvx package for MATLAB [7]  [6].

4.1 Simulated data
We simulate a signal y as the sum of time-shifted copies of two sample waveforms f1(t) ∝
t exp(−t2) and f2(t) ∝ e−t4/16 − e−t2 (Figure 2a). There are s1 = s2 = 5 shifted copies of
f1 and f2  respectively. The time shifts are independently generated for each of the two waveforms
using a Poisson process (truncated after 5 spikes)  and independent Gaussian noise of variance σ2 is

6

Figure 2: (a) Waveforms present in the signal. (b) A noiseless (top) and noisy (bottom) signal with
σ = .2. (c) Recovery using CBP. (d) Recovery using COMP (with a  τ updated as in (7)). (e) For
each recovery method over different values of the standard deviation of the noise σ  misses plus false
positives  divided by the total number of events present  s = s1 + s2. (f) Average distance between
the true and estimated spike for each hit.

added at each time point. Figures 2b c show an example noise-free signal (σ = 0)  and noisy signal
(σ = .2) on which each recovery method will be run.
We run CBP with the Taylor and polar bases  but also with our SVD basis  and COMP with all three
bases. Since COMP here imposes a lower bound on a  we also impose a thresholding step after
recovery with CBP  discarding any recovered waveforms with amplitude less than .3. We ﬁnd the
thresholding generally improved the performance of the CBP algorithm by pruning false positives.
Throughout  we use K = 3  since the polar basis requires 3 basis vectors per bin.
We categorize hits  false positive and misses based on whether a time shift estimate is within a
threshold of  = 1 of the true value. The “average hit error” of Figure 2h  3b is the average distance
between the true and estimated event time for each estimate that is categorized as a hit. Results are
averaged over 20 trials.
We compare CBP and COMP over different parameter regimes  varying the noise (σ) and the bin
size (∆). Figures 2g and 3a show misses plus false positives for each method  normalized by the total
number of events present. Figures 2f and 3b show average distance between the true and estimated
spike for each estimate categorized as a hit. The best performance by both measures across nearly
all parameter regimes considered is achieved by COMP using the SVD basis. COMP is more robust
to noise (Figure 2g)  and also to increases in bin width ∆. Since both algorithms are faster for
higher ∆  robustness with respect to ∆ is an advantage. We also note a signiﬁcant increase in CBP’s
robustness to noise when we implement it with our SVD basis rather than with the Taylor or polar
basis (Figure 2e).
A signiﬁcant advantage of COMP over CBP is its speed. In Figure 3c we compare the speed of
COMP (solid) and CBP (dashed) algorithms for each basis. COMP yields vast gains in speed. The
comparison is especially dramatic for small ∆  where results are most accurate across methods.

4.2 Neural data

We now present recovery of spike times and identities from neural data. Recordings were made
using glass-coated tungsten electrodes in the lateral intraparietal sulcus (LIP) of a macaque monkey
performing a motion discrimination task. In addition to demonstrating the applicability of COMP
to sorting spikes in neural data  this section also shows the resistance of COMP to a certain kind of
error that recovery via CBP can systematically commit  and which is relevant to neural data.

7

5050.500.5t5050.500.5tCBP-SVDCOMP-SVD0.05.1.2.400.511.522.5Noise ()(Misses + False Positives)/s CBPTaylorCBPPolarCBPSVDCOMPTaylorCOMPPolarCOMPSVD0.05.1.2.400.10.20.30.40.5Average Hit ErrorNoise ()02040608010010.500.5102040608010010.500.5102040608010000.511.502040608010000.511.5 TrueCOMPSVD02040608010000.511.502040608010000.511.5 TrueCBPSVDwaveform 1tttwaveform 2waveform 1waveform 1waveform 2waveform 2(a)(b)(c)(d)(e)(f)Figure 3: (a) Misses plus false positives  divided by the total number of events present  s = s1 + s2
over different values of bin width ∆. (b) Average distance between the true and estimated spike for
each hit for each recovery method. (c) Run time for COMP (solid) and CBP (dashed) for each basis.

Figure 4: (a) Two neural waveforms; each is close to as scaled copy of the other (b) Recovery of
spikes via COMP (magenta) and CBP (cyan) using the SVD basis. CBP tends to recover small-
amplitude instances of waveform one where COMP recovers large amplitude instances of waveform
two (c) Top: recovered traces. Lower panel: zooming in on an area of disagreement between COMP
and CBP. The large-ampltude copy of waveform two more closely matches the trace

In the data  the waveform of one neuron resembles a scaled copy of another (Figure 4a).The sim-
ilarity causes problems for CBP or any other (cid:96)1 minimization based method that penalizes large
amplitudes. When the second waveform is present with an amplitude of one  CBP is likely to incor-
rectly add a low-amplitude copy of the ﬁrst waveform (to reduce the amplitude penalty)  instead of
correctly choosing the larger copy of the second waveform; the amplitude penalty for choosing the
correct waveform can outweigh the higher (cid:96)2 error caused by including the incorrect waveform.
This misassignment is exactly what we observe (Figure 4b). We see that CBP tends to report small-
amplitude copies of waveform one where COMP reports large-amplitude copies of waveform two.
Although we lack ground truth  the closer match of the recovered signal to data (Figure 4c) indicates
that the waveform identities and amplitudes identiﬁed via COMP better explain the observed signal.

5 Discussion

We have presented a new greedy method called Continuous Orthogonal Matching Pursuit (COMP)
for identifying the timings and amplitudes for waveforms from a signal that has the form of a (noisy)
sum of shifted and scaled copies of several known waveforms. We draw upon the method of Contin-
uous Basis Pursuit  and extend it in several ways. We leverage the success of Orthogonal Matching
Pursuit in the realm of sparse recovery  use a different basis derived from a singular value decom-
position  and also introduce a move to the Fourier domain to ﬁne-tune the recovered time shifts.
Our SVD basis can also be used with CBP and in our simulations it increased performance of CBP
as compared to previously used bases.
In our simulations COMP obtains increased accuracy as
well as greatly increased speed over CBP across nearly all regimes tested. Our results suggest that
greedy methods of the type introduced here may be quite promising for  among other applications 
spike-sorting during the processing of neural data.

Acknowledgments

This work was supported by the McKnight Foundation (JP)  NSF CAREER Award IIS-1150186
(JP)  and grants from the NIH (NEI grant EY017366 and NIMH grant MH099611 to AH & JP).

8

0.511.522.500.511.52Bin Width ()(Misses + False Positives)/s0.511.522.500.511.52Bin Width ()(Misses + False Positives)/s0.511.522.500.10.20.30.40.50.60.70.8Average Hit ErrorBin Width ()(a)(b)0.511.522.50100200300400500Bin Width ()Computing Time CBPTaylorCBPPolarCBPSVDCOMPTaylorCOMPPolarCOMPSVD(c)00.511.520.50.40.30.20.100.1time (ms) Neuron 1Neuron 2(a)(b)(c)010203040506070809010000.511.5Neuron 1010203040506070809010000.511.5time (ms)Neuron 20204060801000.500.5time (ms)7070.57171.57272.5730.20.100.1time (ms)WaveformsRecovered SpikesVoltage TraceCOMP-SVDCBP-SVDReferences
[1] Scott Shaobing Chen  David L Donoho  and Michael A Saunders. Atomic decomposition by

basis pursuit. SIAM journal on scientiﬁc computing  20(1):33–61  1998.

[2] Wei Dai and Olgica Milenkovic. Subspace pursuit for compressive sensing signal reconstruc-

tion. Information Theory  IEEE Transactions on  55(5):2230–2249  2009.

[3] Chaitanya Ekanadham  Daniel Tranchina  and Eero P Simoncelli. A blind deconvolution
method for neural spike identiﬁcation. In Proceedings of the 25th Annual Conference on Neu-
ral Information Processing Systems (NIPS11)  volume 23  2011.

[4] Chaitanya Ekanadham  Daniel Tranchina  and Eero P Simoncelli. Recovery of sparse
translation-invariant signals with continuous basis pursuit. Signal Processing  IEEE Trans-
actions on  59(10):4735–4744  2011.

[5] D. Ekanadham  C.vand Tranchina and E. P. Simoncelli. A uniﬁed framework and method for

automatic neural spike identiﬁcation. Journal of Neuroscience Methods  222:47–55  2014.

[6] M. Grant and S. Boyd. Graph implementations for nonsmooth convex programs. In V. Blondel 
S. Boyd  and H. Kimura  editors  Recent Advances in Learning and Control  Lecture Notes in
Control and Information Sciences  pages 95–110. Springer-Verlag Limited  2008. http:
//stanford.edu/˜boyd/graph_dcp.html.

[7] CVX Research Inc. CVX: Matlab software for disciplined convex programming  version 2.0.

http://cvxr.com/cvx  August 2012.

[8] Deanna Needell and Joel A Tropp. Cosamp: Iterative signal recovery from incomplete and

inaccurate samples. Applied and Computational Harmonic Analysis  26(3):301–321  2009.

[9] Jonathan W Pillow  Jonathon Shlens  EJ Chichilnisky  and Eero P Simoncelli. A model-based
spike sorting algorithm for removing correlation artifacts in multi-neuron recordings. PloS
one  8(5):e62123  2013.

[10] Robert Tibshirani. Regression shrinkage and selection via the lasso. Journal of the Royal

Statistical Society. Series B (Methodological)  pages 267–288  1996.

[11] Joel A Tropp and Anna C Gilbert. Signal recovery from random measurements via orthogonal

matching pursuit. Information Theory  IEEE Transactions on  53(12):4655–4666  2007.

[12] Martin Vetterli  Pina Marziliano  and Thierry Blu. Sampling signals with ﬁnite rate of innova-

tion. Signal Processing  IEEE Transactions on  50(6):1417–1428  2002.

9

,Jukka Corander
Tomi Janhunen
Jussi Rintanen
Henrik Nyman
Johan Pensar
Karin Knudson
Jacob Yates
Alexander Huk
Jonathan Pillow