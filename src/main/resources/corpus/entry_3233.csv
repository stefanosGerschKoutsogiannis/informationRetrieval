2016,Linear-Memory and Decomposition-Invariant Linearly Convergent Conditional Gradient Algorithm for Structured Polytopes,Recently  several works have shown that natural modifications of the classical conditional gradient method (aka Frank-Wolfe algorithm) for constrained convex optimization  provably converge with a linear rate when the feasible set is a polytope  and the objective is smooth and strongly-convex. However  all of these results suffer from two significant shortcomings: i) large memory requirement due to the need to store an explicit convex decomposition of the current iterate  and as a consequence  large running-time overhead per iteration ii) the worst case convergence rate depends unfavorably on the dimension In this work we present a new conditional gradient variant and a corresponding analysis that improves on both of the above shortcomings. In particular  both memory and computation overheads are only linear in the dimension  and in addition  in case the optimal solution is sparse  the new convergence rate replaces a factor which is at least linear in the dimension in previous works  with a linear dependence on the number of non-zeros in the optimal solution At the heart of our method  and corresponding analysis  is a novel way to compute decomposition-invariant away-steps. While our theoretical guarantees do not apply to any polytope  they apply to several important structured polytopes that capture central concepts such as paths in graphs  perfect matchings in bipartite graphs  marginal distributions that arise in structured prediction tasks  and more. Our theoretical findings are complemented by empirical evidence that shows that our method delivers state-of-the-art performance.,Linear-Memory and Decomposition-Invariant

Linearly Convergent Conditional Gradient Algorithm

for Structured Polytopes

Dan Garber

Toyota Technological Institute at Chicago

dgarber@ttic.edu

Ofer Meshi

Google

meshi@google.com

Abstract

Recently  several works have shown that natural modiﬁcations of the classical
conditional gradient method (aka Frank-Wolfe algorithm) for constrained convex
optimization  provably converge with a linear rate when: i) the feasible set is a
polytope  and ii) the objective is smooth and strongly-convex. However  all of these
results suffer from two signiﬁcant shortcomings:

1. large memory requirement due to the need to store an explicit convex de-
composition of the current iterate  and as a consequence  large running-time
overhead per iteration

2. the worst case convergence rate depends unfavorably on the dimension

In this work we present a new conditional gradient variant and a corresponding
analysis that improves on both of the above shortcomings. In particular:

1. both memory and computation overheads are only linear in the dimension
2. in case the optimal solution is sparse  the new convergence rate replaces a
factor which is at least linear in the dimension in previous work  with a linear
dependence on the number of non-zeros in the optimal solution

At the heart of our method and corresponding analysis  is a novel way to compute
decomposition-invariant away-steps. While our theoretical guarantees do not apply
to any polytope  they apply to several important structured polytopes that capture
central concepts such as paths in graphs  perfect matchings in bipartite graphs 
marginal distributions that arise in structured prediction tasks  and more. Our
theoretical ﬁndings are complemented by empirical evidence which shows that our
method delivers state-of-the-art performance.

1

Introduction

The efﬁcient reduction of a constrained convex optimization problem to a constrained linear optimiza-
tion problem is an appealing algorithmic concept  in particular for large-scale problems. The reason
is that for many feasible sets of interest  the problem of minimizing a linear function over the set
admits much more efﬁcient methods than its non-linear convex counterpart. Prime examples for this
phenomenon include various structured polytopes that arise in combinatorial optimization  such as
the path polytope of a graph (aka the unit ﬂow polytope)  the perfect matching polytope of a bipartite
graph  and the base polyhedron of a matroid  for which we have highly efﬁcient combinatorial
algorithms for linear minimization that rely heavily on the speciﬁc rich structure of the polytope
[21]. At the same time  minimizing a non-linear convex function over these sets usually requires the
use of generic interior point solvers that are oblivious to the speciﬁc combinatorial structure of the
underlying set  and as a result  are often much less efﬁcient. Indeed  it is for this reason  that the

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

conditional gradient (CG) method (aka Frank-Wolfe algorithm)  a method for constrained convex
optimization that is based on solving linear subproblems over the feasible domain  has regained much
interest in recent years in the machine learning  signal processing and optimization communities. It
has been recently shown that the method delivers state-of-the-art performance on many problems of
interest  see for instance [14  17  4  10  11  22  19  25  12  15].
As part of the regained interest in the conditional gradient method  there is also a recent effort to
understand the convergence rates and associated complexities of conditional gradient-based methods 
which are in general far less understood than other ﬁrst-order methods  e.g.  the projected gradient
method. It is known  already from the ﬁrst introduction of the method by Frank and Wolfe in the
1950’s [5] that the method converges with a rate of roughly O(1/t) for minimizing a smooth convex
function over a convex and compact set. However  it is not clear if this convergence rate improves
under an additional standard strong-convexity assumption. In fact  certain lower bounds  such as in
[18  8]  suggest that such improvement  even if possible  should come with a worse dependence on
the problem’s parameters (e.g.  the dimension). Nevertheless  over the past years  various works tried
to design natural variants of the CG method that converge provably faster under the strong convexity
assumption  without dramatically increasing the per-iteration complexity of the method. For instance 
GuéLat and Marcotte [9] showed that a CG variant which uses the concept of away-steps converges
exponentially fast in case the objective function is strongly convex  the feasible set is a polytope 
and the optimal solution is located in the interior of the set. A similar result was presented by Beck
and Teboulle [3] who considered a speciﬁc problem they refer to as the convex feasibility problem
over an arbitrary convex set. They also obtained a linear convergence rate under the assumption that
an optimal solution that is far enough from the boundary of the set exists. In both of these works 
the exponent depends on the distance of the optimal solution from the boundary of the set  which
in general can be arbitrarily small. Later  Ahipasaoglu et al. [1] showed that in the speciﬁc case of
minimizing a smooth and strongly convex function over the unit simplex  a variant of the CG method
which also uses away-steps  converges with a linear rate. Unfortunately  it is not clear from their
analysis how this rate depends on natural parameters of the problem such as the dimension and the
condition number of the objective function.
Recently  Garber and Hazan presented a linearly-converging CG variant for polytopes without any
restrictions on the location of the optimum [8]. In a later work  Lacoste-Julien and Jaggi [16] gave
a reﬁned afﬁne-invariant analysis of an algorithm presented in [9] which also uses away steps  and
showed that it also converges exponentially fast in the same setting as the Garber-Hazan result. More
recently  Beck and Shtern [2] gave a different  duality-based  analysis for the algorithm of [9]  and
showed that it can be applied to a wider class of functions than purely strongly convex functions.
However  the explicit dependency of their convergence rate on the dimension is suboptimal  compared
to [8  16]. Aside from the polytope case  Garber and Hazan [7] have shown that in case the feasible
set is strongly-convex and the objective function satisﬁes certain strong convexity-like proprieties 
then the standard CG method converges with an accelerated rate of O(1/t2). Finally  in [6] Garber
showed a similar improvement (roughly quadratic) for the spectrahedron – the set of unit trace
positive semideﬁnite matrices.
Despite the exponential improvement in convergence rate for polytopes obtained in recent results 
they all suffer from two major drawbacks. First  while in terms of the number of calls per-iteration to
the linear optimization oracle  these methods match the standard CG method  i.e.  a single call per
iteration  the overhead of other operations both in terms of running time and memory requirements is
signiﬁcantly worse. The reason is that in order to apply the so-called away-steps  which all methods
use  they require to maintain at all times an explicit decomposition of the current iterate into vertices
of the polytope. In the worst case  maintaining such a decomposition and computing the away-steps
require both memory and per-iteration runtime overheads that are at least quadratic in the dimension.
This is much worse than the standard CG method  whose memory and runtime overheads are only
linear in the dimension. Second  the convergence rate of all previous linearly convergent CG methods
depends explicitly on the dimension. While it is known that this dependency is unavoidable in certain
cases  e.g.  when the optimal solution is  informally speaking  dense (see for instance the lower bound
in [8])  it is not clear that such an unfavorable dependence is mandatory when the optimum is sparse.
In this paper  we revisit the application of CG variants to smooth and strongly-convex optimization
over polytopes. We introduce a new variant which overcomes both of the above shortcomings from
which all previous linearly-converging variants suffer. The main novelty of our method  which is the
key to its improved performance  is that unlike previous variants  it is decomposition-invariant  i.e.  it

2

Paper
Frank & Wolfe [5]
Garber & Hazan [8]
Lacoste-Julien & Jaggi [16]
Beck & Shtern [2]
This paper

#iterations to ✏ err.

#LOO calls

runtime

memory

D 2/✏

nD2 log(1/✏)
nD2 log(1/✏)
n2D2 log(1/✏)

card(x⇤)D2 log(1/✏)

1
1
1
1
2

n

n

n min(n  t)
n min(n  t)
n min(n  t)

n min(n  t)
n min(n  t)
n min(n  t)

n

n

Table 1: Comparison with previous work. We deﬁne  := /↵  we let n denote the dimension and D
denote the Euclidean diameter of the polytope. The third column gives the number of calls to the
linear optimization oracle per iteration  the fourth column gives the additional arithmetic complexity
at iteration t  and the ﬁfth column gives the worst case memory requirement at iteration t. The
bounds for the algorithms of [8  16  2]  which are independent of t  assume an algorithmic version of
Carathéodory’s theorem  as fully detailed in [2]. The bound on number of iterations of [16] depends
on the squared inverse pyramidal width of P  which is difﬁcult to evaluate  however  this quantity is
at least proportional to n.

does not require to maintain an explicit convex decomposition of the current iterate. This principle
proves to be crucial both for eliminating the memory and runtime overheads  as well as to obtaining
shaper convergence rates for instances that admit a sparse optimal solution.
A detailed comparison of our method to previous art is shown in Table 1. We also provide in Section
5 empirical evidence that the proposed method delivers state-of-the-art performance on several tasks
of interest. While our method is less general than previous ones  i.e.  our theoretical guarantees do not
hold for arbitrary polytopes  they readily apply to many structured polytopes that capture important
concepts such as paths in graphs  perfect matchings in bipartite graphs  Markov random ﬁelds  and
more.

2 Preliminaries
Throughout this work we let k·k denote the standard Euclidean norm. Given a point x 2 Rn  we let
card(x) denote the number of non-zero entries in x.
Deﬁnition 1. We say that a function f (x) : Rn ! R is ↵-strongly convex w.r.t. a norm k·k   if for
all x  y 2 Rn it holds that f (y)  f (x) + rf (x) · (y  x) + ↵
Deﬁnition 2. We say that a function f (x) : Rn ! R is -smooth w.r.t. a norm k·k   if for all
x  y 2 Rn it holds that f (y)  f (x) + rf (x) · (y  x) + 
The ﬁrst-order optimality condition implies that for a ↵-strongly convex f  if x⇤ is the unique
minimizer of f over a convex and compact set K⇢ Rn  then for all x 2K it holds that

2 kx  yk2.

2kx  yk2.

f (x)  f (x⇤) 

↵
2 kx  x⇤k2.

(1)

2.1 Setting
In this work we consider the optimization problem minx2P f (x)  where we assume that:

• f (x) is ↵-strongly convex and -smooth with respect to the Euclidean norm.
• P is a polytope which satisﬁes the following two properties:

1. P can be described algebraically as P = {x 2 Rn | x  0  Ax = b} .
2. All vertices of P lie on the hypercube {0  1}n.

We let x⇤ denote the (unique) minimizer of f over P  and we let D denote the Euclidean diameter of
P  namely  D = maxx y2P kx  yk. We let V denote the set of vertices of P  where according to
our assumptions  it holds that V✓{ 0  1}n.
While the polytopes that satisfy the above assumptions are not completely general  these assumptions
already capture several important concepts such as paths in graphs  perfect-matchings  Markov

3

random ﬁelds  and more. Indeed  a surprisingly large number of applications from machine learning 
signal processing and other domains are formulated as optimization problems in this category (e.g. 
[13  15  16]). We give detailed examples of such polytopes in Section A in the appendix. Importantly 
the above assumptions allow us to get rid of the dependency of the convergence rate on certain
geometric parameters (such as   ⇠ in [8] or the pyramidal width in [16])  which can be polynomial
in the dimension  and hence result in an impractical convergence rate. Finally  for many of these
polytopes  the vertices are sparse  i.e.  for any vertex v 2V   card(v) << n. In this case  when the
optimum x⇤ can be decomposed as a convex combination of only a few vertices (and thus  sparse by
itself)  we get a sharper convergence rate that depends on the sparsity of x⇤ and not explicitly on the
dimension  as in previous work. We believe that our theoretical guarantees could be well extended to
more general polytopes  as suggested in Section C in the appendix; we leave this extension for future
work.

3 Our Approach

In order to better communicate our ideas  we begin by ﬁrst brieﬂy introducing the standard conditional
gradient method and its accelerated away-steps-based variants. We discuss both the blessings and
shortcomings of these away-steps-based variants in Subsection 3.1. Then  in Subsection 3.2  we
present our new method  a decomposition-invariant away-steps-based conditional gradient algorithm 
and discuss how it addresses the shortcomings of previous variants.

3.1 The conditional gradient method and acceleration via away-steps

The standard conditional gradient algorithm is given below (Algorithm 1). It is well known that
when setting the step-size ⌘t in an appropriate way  the worst case convergence rate of the method is
O(D 2/t) [13]. This convergence rate is tight for the method in general  see for instance [18].

Algorithm 1 Conditional Gradient
1: let x1 be some vertex in V
2: for t = 1... do
3:
4:
5:
6: end for

vt arg minv2V v ·r f (xt)
choose a step-size ⌘t 2 (0  1]
xt+1 xt + ⌘t(vt  xt)

Algorithm 2 Pairwise Conditional Gradient
1: let x1 be some vertex in V
2: for t = 1... do
3:

be an explicitly main-

t v(i)

t

i=1 (i)

let Pkt
tained convex decomposition of xt
v+
t arg minv2V v ·r f (xt)
jt arg minj2[kt] v(j)
choose a step-size ⌘t 2 (0  (jt)
xt+1 xt + ⌘t(v+
update the convex decomposition of xt+1

· (rf (xt))

t  v(jt)

t
)

]

4:
5:
6:
7:
8:
9: end for

t

t

Consider the iterate of Algorithm 1 on iteration t  and let xt =Pk
i=1 ivi be its convex decomposition
into vertices of the polytope P. Note that Algorithm 1 implicitly discounts each coefﬁcient i by
a factor (1  ⌘t)  in favor of the new added vertex vt. A different approach is not to decrease all
vertices in the decomposition of xt uniformly  but to more-aggressively decrease vertices that are
worse than others with respect to some measure  such as their product with the gradient direction.
This key principle proves to be crucial to breaking the 1/t rate of the standard method  and to achieve
a linear convergence rate under certain strong-convexity assumptions  as described in the recent
works [8  16  2]. For instance  in [8] it has been shown  via the introduction of the concept of a Local
Linear Optimization Oracle  that using such a non-uniform reweighing rule  in fact approximates a
certain proximal problem  that together with the shrinking effect of strong convexity  as captured by
Eq. (1)  yields a linear convergence rate. We refer to these methods as away-step-based CG methods.
As a concrete example  which will also serve as a basis for our new method  we describe the pairwise
variant recently studied in [16]  which applies this principle in Algorithm 2.1 Note that Algorithm 2
decreases the weight of exactly one vertex in the decomposition: that with the largest product with
the gradient.

1While the convergence rate of this pairwise variant  established in [16]  is signiﬁcantly worse than other
away-step-based variants  here we show that a proper analysis yields state-of-the-art performance guarantees.

4

It is important to note that since previous away-step-based CG variants do not decrease the coefﬁcients
in the convex decomposition of the current iterate uniformly  they all require to explicitly store and
maintain a convex decomposition of the current iterate. This issue raises two main disadvantages:
Superlinear memory and running-time overheads Storing a decomposition of the current iterate
as a convex combination of vertices generally requires O(n2) memory in the worst case. While
the away-step-based variants increase the size of the decomposition by at most a single vertex per
iteration  they also typically exhibit linear convergence after performing at least ⌦(n) steps [8  16  2] 
and thus  this O(n2) estimate still holds. Moreover  since these methods require i) to ﬁnd the worst
vertex in the decomposition  in terms of dot-product with current gradient direction  and ii) to update
this decomposition at each iteration (even when using sophisticated update techniques such as in [2]) 
then the worst case per-iteration overhead in terms of computation is also ⌦(n2).
Decomposition-speciﬁc performance The choice of away-step depends on the speciﬁc decomposi-
tion that is maintained by the algorithm. Since the feasible point xt may admit several different convex
decompositions  committing to one such decomposition  might result in sub-optimal away-steps. As
observable in Table 1  for certain problems in which the optimal solution is sparse  all analyses of
previous away-steps-based variants are signiﬁcantly suboptimal  since they all depend explicitly on
the dimension. This seems to be an unavoidable side-effect of being decomposition-dependent. On
the other hand  the fact that our new approach is decomposition-invariant allows us to obtain sharper
convergence rates for such instances.

3.2 A new decomposition-invariant pairwise conditional gradient method
Our main observation is that in many cases of interest  given a feasible iterate xt  one can in fact
compute an optimal away-step from xt without relying on any single speciﬁc decomposition. This
observation allows us to overcome both of the main disadvantages of previous away-step-based CG
variants. Our algorithm  which we refer to as a decomposition-invariant pairwise conditional gradient
(DICG)  is given below in Algorithm 3.

Algorithm 3 Decomposition-invariant Pairwise Conditional Gradient
1: input: sequence of step-sizes {⌘t}t1
2: let x0 be an arbitrary point in P
3: x1 arg minv2V v ·r f (x0)
4: for t = 1... do
5:
6:

deﬁne the vector ˜rf (xt) 2 Rn as follows: [ ˜rf (xt)]i :=⇢ [rf (xt)]i
1
vt arg minv2V v · ( ˜rf (xt))
choose a new step-size ˜⌘t using one of the following two options:

v+
t arg minv2V v ·r f (xt)

7:
8:

Option 1: predeﬁned step-size

if xt(i) > 0
if xt(i) = 0

Option 2: line-search

let t be the smallest natural number such that 2t  ⌘t  and set a new step-size ˜⌘t 2t
t max2[0 1]{xt + (v+

˜⌘t min⌘2(0 t] f (xt + ⌘(v+

t  vt )  0} 

t  vt ))

9:
10: end for

xt+1 xt + ˜⌘t(v+

t  vt )

The following observation shows the optimality of away-steps taken by Algorithm 3.
Observation 1 (optimal away-steps in Algorithm 3). Consider an iteration t of Algorithm 3 and
suppose that the iterate xt is feasible. Let xt =Pk
i=1 ivi for some integer k  be an irreducible
way of writing xt as a convex sum of vertices of P  i.e.  i > 0 for all i 2 [k]. Then it holds that
8i 2 [k] : vi ·r f (xt)  vt
Proof. Let xt =Pk
i=1 ivi be a convex decomposition of xt into vertices of P  for some integer
k  where each i is positive. Note that it must hold that for any j 2 [n] and any i 2 [k]  xt(j) =
0 ) vi(j) = 0  since by our assumption V⇢ Rn
+. The observation then follows directly from the
deﬁnition of vt .

·r f (xt)  and t  min{xt(i)| i 2 [n]  xt(i) > 0}.

We next state the main theorem of this paper  which bounds the convergence rate of Algorithm 3. The
proof is provided in Section B.3 in the appendix.

5

2 .

D 2

2

t◆ .

8D 2card(x⇤)

f (xt)  f (x⇤) 

Theorem 1. Let M1 =p↵/(8card(x⇤)) and M2 = D 2/2. Consider running Algorithm 3 with
Option 1 as the step-size  and suppose that 8t  1 : ⌘t =M1/(2pM2)1  M 2
1 /(4M2) t1
Then  the iterates of Algorithm 3 are always feasible  and 8t  1:
↵

exp✓
We now turn to make several remarks regarding Algorithm 3 and Theorem 1:
The so-called dual gap  deﬁned as gt := (xt  v+
t ) ·r f (xt)  which serves as a certiﬁcate for the
sub-optimality of the iterates of Algorithm 3  also converges with a linear rate  as we prove in Section
B.4 in the appendix.
Note that despite the different parameters of the problem at hand (e.g.  ↵    D  card(x⇤))  running
the algorithm with Option 1 for choosing the step-size  for which the guarantee of Theorem 1
holds  requires knowing a single parameter  i.e.  M1/pM2. In particular  it is an easy consequence
that running the algorithm with an estimate M 2 [0.5M1/pM2  M1/pM2]  will only affect the
leading constant in the convergence rate listed in the theorem. Hence  M1/pM2 could be efﬁciently
estimated via a logarithmic-scale search.
Theorem 1 improves signiﬁcantly over the convergence rate established for the pairwise conditional
gradient variant in [16]. In particular  the number of iterations to reach an ✏ error in the analysis of
[16] depends linearly on |V|!  where |V| is the number of vertices of P.
4 Analysis

Throughout this section we let ht denote the approximation error of Algorithm 3 on iteration t  for
any t  1  i.e.  ht = f (xt)  f (x⇤).
4.1 Feasibility of the iterates generated by Algorithm 3
We start by proving that the iterates of Algorithm 3 are always feasible. While feasibility is straight-
forward when using the the line-search option to set the step-size (Option 2)  it is less obvious when
using Option 1. We will make use of the following observation  which is a simple consequence of the
optimal choice of vt and our assumptions on P. A proof is given in Section B.1 in the appendix.
Observation 2. Suppose that on some iteration t of Algorithm 3  the iterate xt is feasible  and that
the step-size is chosen using Option 1. Then  if for all i 2 [n] for which xt(i) 6= 0 it holds that
xt(i)  ˜⌘t  the following iterate xt+1 is also feasible.
Lemma 1 (feasibility of iterates under Option 1). Suppose that the sequence of step-sizes {⌘t}t1 is
monotonically non-increasing  and contained in the interval [0  1]. Then  the iterates generated by
Algorithm 3 using Option 1 for setting the step-size  are always feasible.

Proof. We are going to prove by induction that on each iteration t there exists a non-negative integer-
valued vector st 2 Nn  such that for any i 2 [n]  it holds that xt(i) = 2tst(i). The lemma
then follows since  by deﬁnition  ˜⌘t = 2t  and by applying Observation 2. The base case t = 1
holds since x1 is a vertex of P and thus for any i 2 [n] we have that x1(i) 2{ 0  1} (recall that
V⇢{ 0  1}n). On the other hand  since ⌘1  1  it follows that 1  0. Thus  there indeed exists a
non-negative integer-valued vector s1  such that x1 = 21s1.
Suppose now that the induction holds for some t  1. Since by deﬁnition of vt   subtracting ˜⌘tvt
from xt can only decrease positive entries in xt (see proof of Observation 2)  and both vt   v+
t are
vertices of P (and thus in {0  1}n)  and ˜⌘t = 2t  it follows that each entry i in xt+1 is given by:

t (i) = 1 or vt (i) = v+

t (i) = 0

xt+1(i) = 2t8<:

st(i)
st(i)  1
st(i) + 1

if st(i)  1 & vt (i) = v+
if st(i)  1 & vt (i) = 1 & v+
if vt (i) = 0 & v+
t (i) = 1

t (i) = 0

Thus  xt+1 can also be written in the form 2t ˜st+1 for some ˜st+1 2 Nn. By deﬁnition of t and the
monotonicity of {⌘t}t1  we have that
2t+1 ˜st+1 
the induction holds also for t + 1.

2t
2t+1 is a positive integer. Thus  setting st+1 = 2t

6

t M2.
⌘2

i=1(ii)vi+(Pk

4.2 Bounding the per-iteration error-reduction of Algorithm 3
The following technical lemma is the key to deriving the linear convergence rate of our method  and
in particular  to deriving the improved dependence on the sparsity of x⇤  instead of the dimension. At
a high-level  the lemma translates the `2 distance between two feasible points into a `1 distance in a
simplex deﬁned over the set of vertices of the polytope.
Lemma 2. Let x  y 2P . There exists a way to write x as a convex combination of vertices of P 
x =Pk
i=1 i)z
with i 2 [0  i]8i 2 [k] z 2P   andPk

i=1 ivi for some integer k  such that y can be written as y =Pk
i=1 i pcard(y)kx  yk.

The proof is given in Section B.2 in the appendix. The next lemma bounds the per-iteration improve-
ment of Algorithm 3 and is the key step to proving Theorem 1. We defer the rest of the proof of
Theorem 1 to Section B.3 in the appendix.
Lemma 3. Consider the iterates of Algorithm 3  when the step-sizes are chosen using Option 1. Let
t +

M1 =p↵/(8card(x⇤)) and M2 = D 2/2. For any t  1 it holds that ht+1  ht  ⌘tM1h1/2
Proof. Deﬁne t = p2card(x⇤)ht/↵  and note that from Eq. (1) we have that t 
pcard(x⇤)kxt  x⇤k. As a ﬁrst step  we are going to show that the point yt := xt + t(v+
t  vt )
satisﬁes: yt ·r f (xt)  x⇤ ·r f (xt). From Lemma 2 it follows that we can write x as a convex com-
bination xt =Pk
i=1 iz  where i 2 [0  i] 
z 2P   andPk

i=1(i  i)vi +Pk

i=1 ivi and write x⇤ as x⇤ =Pk
i=1 i  t. It holds that
(yt  xt) ·r f (xt) = t(v+
 Xk
xt + t(v+

t  vt ) ·r f (xt)

t  vt ) ·r f (xt) Xk
i(z  vi) ·r f (xt) = (x⇤  xt) ·r f (xt) 
t  vt ) ·r f (xt)  0  and the second inequality follows
(2)
2  ˜⌘t  ⌘t. Using the

t  vt ) ·r f (xt)  x⇤ ·r f (xt).

Observe now that from the deﬁnition of ˜⌘t it follows for any t  1 that ⌘t
smoothness of f (x) we have that

where the ﬁrst inequality follows since (v+
from the optimality of v+

t and vt (Observation 1). Rearranging  we have that indeed

i(v+

i=1

i=1

ht+1 = f (xt + ˜⌘t(v+

 ht + ˜⌘t(v+
= ht +

⌘t

t  vt ))  f (x⇤)  ht + ˜⌘t(v+
t  vt ) ·r f (xt) +
 ht +
2t(xt + t(v+

˜⌘2
t D 2

2

t  vt ) ·r f (xt) +

˜⌘2
t 
2 kv+
t  vt ) ·r f (xt) +
(v+
⌘2
t D 2

⌘t
2

t  vt k2
⌘2
t D 2

2

t  vt )  xt ·r f (xt) +
t  vt ) ·r f (xt)  0  the forth inequality follows from
where the third inequality follows since (v+
Eq. (2)  and the last inequality follows from convexity of f (x). Finally  plugging the value of t
completes the proof.

(x⇤  xt) ·r f (xt) +

 ht +

 ht 

⌘t
2t

⌘t
2t

⌘2
t D 2

⌘2
t D 2

ht +

2

2

2

 

5 Experiments
In this section we illustrate the performance of our algorithm in numerical experiments. We use
the two experimental settings from [16]  which include a constrained Lasso problem and a video
co-localization problem. In addition  we test our algorithm on a learning problem related to an
optical character recognition (OCR) task from [23]. In each setting we compare the performance
of our algorithm (DICG) to standard conditional gradient (CG)  as well as to the fast away (ACG)
and pairwise (PCG) variants [16]. For the baselines in the ﬁrst two settings we use the publicly
available code from [16]  to which we add our own implementation of Algorithm 3. Similarly  for the
OCR problem we extend code from [20]  kindly provided by the authors. For all algorithms we use
line-search to set the step size.

7

Lasso

Video co-localization

OCR

 

p
a
G

10−2

10−4

10−6

10−8
 
0

10−2

10−4

10−6

p
a
G

400

Iteration

600

800

1000

 

CG
ACG
PCG
DICG

 

CG
ACG
PCG
DICG

500

1000

Iteration

1500

2000

 

CG
ACG
PCG
DICG

10−1

p
a
G

10−2

10−3

 
0

10-2

p
a
G

10-3

 

CG
ACG
PCG
DICG

500

1000

Effective passes

1500

2000

CG
ACG
PCG
DICG

105

100

p
a
G

CG
ACG
PCG
DICG

200

10−5

 
0

105

100

p
a
G

10−5

 
0

2

4
6
Time (sec)

8

10

10−8
 
0

5

10

15

Time (sec)

20

25

30

0

1

2

3

Time (hr)

4

5

6

Figure 1: Duality gap gt vs. iterations (top) and time (bottom) in various settings.

Lasso In the ﬁrst example the goal is to solve the problem: minx2M k ¯Ax  ¯bk2  where M is a
scaled `1 ball. Notice that the constraints M do not match the required structure of P  however  with
a simple change of variables we can obtain an equivalent optimization problem over the simplex.
We generate the random matrix ¯A and vector ¯b as in [16]. In Figure 1 (left  top) we observe that
our algorithm (DICG) converges similarly to the pairwise variant PCG and faster than the other
baselines. This is expected since the away direction v in DICG (Algorithm 3) is equivalent to the
away direction in PCG (Algorithm 2) in the case of simplex constraints.

Video co-localization The second example is a quadratic program over the ﬂow polytope  originally
proposed in [15]. This is an instance of P that is mentioned in Section A in the appendix. As can
be seen in Figure 1 (middle  top)  in this setting our proposed algorithm signiﬁcantly outperforms
the baselines  as a result of ﬁnding a better away direction v. Figure 1 (middle  bottom) shows
convergence on a time scale  where the difference between the algorithms is even larger. One
reason for this difference is the costly search over the history of vertices maintained by the baseline
algorithms. Speciﬁcally  the number of stored vertices grows fast with the number of iterations and
reaches 1222 for away steps and 1438 for pairwise steps (out of 2000 iterations).

OCR We next conduct experiments on a structured SVM learning problem resulting from an OCR
task. The constraints in this setting are the marginal polytope corresponding to a chain graph over
the letters of a word (see [23])  and the objective function is quadratic. Notice that the marginal
polytope has a concise characterization in this case and also satisﬁes our assumptions (see Section A
in the appendix for more details). For this problem we actually run Algorithm 3 in a block-coordinate
fashion  where blocks correspond to training examples in the dual SVM formulation [17  20]. In
Figure 1 (right  top) we see that our DICG algorithm is comparable to the PCG algorithm and faster
than the other baselines on the iteration scale. Figure 1 (right  bottom) demonstrates that in terms
of actual running time we get a noticeable speedup compared to all baselines. We point out that
for this OCR problem  both ACG and PCG each require about 5GB of memory to store the explicit
decomposition in the implementation of [20]. In comparison  our algorithm requires 220MB of
memory to store the current iterate  and the other variables in the code require 430MB (common to
all algorithms)  so using DICG results in signiﬁcant memory savings.

6 Extensions

Our results are readily extendable in two important directions. First  we can relax the strong convexity
requirement of f (x) and handle a broader class of functions  namely the class considered in [2].
Second  we extend the line-search variant of Algorithm 3 to handle arbitrary polytopes  but without
convergence guarantees  which is left as future work. Both extensions are brought in full detail in
Section C in the appendix.

8

References
[1] S. Damla Ahipasaoglu  Peng Sun  and Michael J. Todd. Linear convergence of a modiﬁed frank-wolfe
algorithm for computing minimum-volume enclosing ellipsoids. Optimization Methods and Software 
23(1):5–19  2008.

[2] Amir Beck and Shimrit Shtern. Linearly convergent away-step conditional gradient for non-strongly

convex functions. arXiv preprint arXiv:1504.05002  2015.

[3] Amir Beck and Marc Teboulle. A conditional gradient method with linear rate of convergence for solving

convex linear systems. Math. Meth. of OR  59(2):235–247  2004.

[4] Miroslav Dudík  Zaïd Harchaoui  and Jérôme Malick. Lifted coordinate descent for learning with trace-

norm regularization. Journal of Machine Learning Research - Proceedings Track  22:327–336  2012.

[5] M. Frank and P. Wolfe. An algorithm for quadratic programming. Naval Research Logistics Quarterly 

3:149–154  1956.

[6] Dan Garber. Faster projection-free convex optimization over the spectrahedron.

arXiv:1605.06203  2016.

arXiv preprint

[7] Dan Garber and Elad Hazan. Faster rates for the frank-wolfe method over strongly-convex sets. In
Proceedings of the 32nd International Conference on Machine Learning  ICML 2015  Lille  France  6-11
July 2015  pages 541–549  2015.

[8] Dan Garber and Elad Hazan. A linearly convergent variant of the conditional gradient algorithm under
strong convexity  with applications to online and stochastic optimization. SIAM Journal on Optimization 
26(3):1493–1528  2016.

[9] Jacques GuéLat and Patrice Marcotte. Some comments on Wolfe’s ‘away step’. Mathematical Program-

ming  35(1)  1986.

[10] Zaïd Harchaoui  Matthijs Douze  Mattis Paulin  Miroslav Dudík  and Jérôme Malick. Large-scale image
In IEEE Conference on Computer Vision and Pattern

classiﬁcation with trace-norm regularization.
Recognition  CVPR  2012.

[11] Elad Hazan and Satyen Kale. Projection-free online learning. In Proceedings of the 29th International

Conference on Machine Learning  ICML  2012.

[12] Elad Hazan and Haipeng Luo. Variance-reduced and projection-free stochastic optimization. CoRR 

abs/1602.02101  2016.

[13] Martin Jaggi. Revisiting frank-wolfe: Projection-free sparse convex optimization. In Proceedings of the

30th International Conference on Machine Learning  ICML  2013.

[14] Martin Jaggi and Marek Sulovský. A simple algorithm for nuclear norm regularized problems.

Proceedings of the 27th International Conference on Machine Learning  ICML  2010.

In

[15] Armand Joulin  Kevin Tang  and Li Fei-Fei. Efﬁcient image and video co-localization with Frank-Wolfe

algorithm. In Computer Vision–ECCV 2014  pages 253–268. Springer  2014.

[16] Simon Lacoste-Julien and Martin Jaggi. On the global linear convergence of Frank-Wolfe optimization

variants. In Advances in Neural Information Processing Systems  pages 496–504  2015.

[17] Simon Lacoste-Julien  Martin Jaggi  Mark W. Schmidt  and Patrick Pletscher. Block-coordinate frank-
wolfe optimization for structural svms. In Proceedings of the 30th International Conference on Machine
Learning  ICML  2013.

[18] Guanghui Lan. The complexity of large-scale convex programming under a linear optimization oracle.

CoRR  abs/1309.5550  2013.

[19] Sören Laue. A hybrid algorithm for convex semideﬁnite optimization.

International Conference on Machine Learning  ICML  2012.

In Proceedings of the 29th

[20] Anton Osokin  Jean-Baptiste Alayrac  Puneet K. Dokania  and Simon Lacoste-Julien. Minding the gaps
for block frank-wolfe optimization of structured svm. In International Conference on Machine Learning
(ICML)  2016.

[21] A. Schrijver. Combinatorial Optimization - Polyhedra and Efﬁciency. Springer  2003.
[22] Shai Shalev-Shwartz  Alon Gonen  and Ohad Shamir. Large-scale convex minimization with a low-rank

constraint. In Proceedings of the 28th International Conference on Machine Learning  ICML  2011.

[23] B. Taskar  C. Guestrin  and D. Koller. Max-margin Markov networks. In Advances in Neural Information

Processing Systems. MIT Press  2003.

[24] M. Wainwright and M. I. Jordan. Graphical Models  Exponential Families  and Variational Inference.

Now Publishers Inc.  Hanover  MA  USA  2008.

[25] Yiming Ying and Peng Li. Distance metric learning with eigenvalue optimization. J. Mach. Learn. Res. 

13(1):1–26  January 2012.

9

,Austin Benson
Jason Lee
Bartek Rajwa
David Gleich
Jimmy Ren
Li Xu
Qiong Yan
Wenxiu Sun
Dan Garber
Dan Garber
Ofer Meshi