2018,A Bandit Approach to Sequential Experimental Design with False Discovery Control,We propose a new adaptive sampling approach to multiple testing which aims to maximize statistical power while ensuring anytime false discovery control. We consider $n$ distributions whose means are partitioned by whether they are below or equal to a baseline (nulls)  versus above the baseline (true positives). In addition  each distribution can be sequentially and repeatedly sampled. Using techniques from multi-armed bandits  we provide an algorithm that takes as few samples as possible to exceed a target true positive proportion (i.e. proportion of true positives discovered) while giving anytime control of the false discovery proportion (nulls predicted as true positives). Our sample complexity results match known information theoretic lower bounds and through simulations we show a substantial performance improvement over uniform sampling and an adaptive elimination style algorithm. Given the simplicity of the approach  and its sample efficiency  the method has promise for wide adoption in the biological sciences  clinical testing for drug discovery  and maximization of click through in A/B/n testing problems.,A Bandit Approach to Multiple Testing with False

Discovery Control

Kevin Jamieson⇤ †  Lalit Jain⇤

{jamieson lalitj}@cs.washington.edu

⇤Paul G. Allen School of Computer Science & Engineering 

University of Washington  Seattle  WA  and

†Optimizely  San Francisco  CA

Abstract

We propose an adaptive sampling approach for multiple testing which aims to
maximize statistical power while ensuring anytime false discovery control. We
consider n distributions whose means are partitioned by whether they are below or
equal to a baseline (nulls)  versus above the baseline (actual positives). In addition 
each distribution can be sequentially and repeatedly sampled. Inspired by the
multi-armed bandit literature  we provide an algorithm that takes as few samples
as possible to exceed a target true positive proportion (i.e. proportion of actual
positives discovered) while giving anytime control of the false discovery proportion
(nulls predicted as actual positives). Our sample complexity results match known
information theoretic lower bounds and through simulations we show a substantial
performance improvement over uniform sampling and an adaptive elimination style
algorithm. Given the simplicity of the approach  and its sample efﬁciency  the
method has promise for wide adoption in the biological sciences  clinical testing
for drug discovery  and online A/B/n testing problems.

1

Introduction

Consider n possible treatments  say  drugs in a clinical trial  where each treatment either has a
positive expected effect relative to a baseline (actual positive)  or no difference (null)  with a goal
of identifying as many actual positive treatments as possible. If evaluating the ith trial results in a
noisy outcome (e.g. due to variance in the actual measurement or just diversity in the population)
then given a total measurement budget of B  it is standard practice to execute and average B/n
measurements of each treatment  and then output a set of predicted actual positives based on the
measured effect sizes. False alarms (i.e. nulls predicted as actual positives) are controlled by either
controlling family-wise error rate (FWER)  where one bounds the probability that at least one of the
predictions is null  or false discovery rate (FDR)  where one bounds the expected proportion of the
number of predicted nulls to the number of predictions. FDR is a weaker condition than FWER but is
often used in favor of FWER because of its higher statistical power: more actual positives are output
as predictions using the same measurements.
In the pursuit of even greater statistical power  there has recently been increased interest in the
biological sciences to reject the uniform allocation strategy of B/n trials to the n treatments in
favor of an adaptive allocation. Adaptive allocations partition the budget B into sequential rounds
of measurements in which the measurements taken at one round inform which measurements are
taken in the next [1  2]. Intuitively  if the effect size is relatively large for some treatment  fewer
trials will be necessary to identify that treatment as an actual positive relative to the others  and
that savings of measurements can be allocated towards treatments with smaller effect sizes to boost
the signal. However  both [1  2] employed ad-hoc heuristics which may not only have sub-optimal

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

statistical power  but also may even result in more false alarms than expected. As another example 
in the domain of A/B/n testing in online environments  the desire to understand and maximize
click-through-rate across treatments (e.g.  web-layouts  campaigns  etc.) has become ubiquitous
across retail  social media  and headline optimization for the news. And in this domain  the desire for
statistically rigorous adaptive sampling methods with high statistical power are explicit [3].
In this paper we propose an adaptive measurement allocation scheme that achieves near-optimal
statistical power subject to FWER or FDR false alarm control. Perhaps surprisingly  we show that
even if the treatment effect sizes of the actual positives are identical  adaptive measurement allocation
can still substantially improve statistical power. That is  more actual positives can be predicted using
an adaptive allocation relative to the uniform allocation under the same false alarm control.

1.1 Problem Statement
Consider n distributions (or arms) and a game where at each time t  the player chooses an arm
iid⇠ ⌫i where Xi t 2 [0  1]1 and
i 2 [n] := {1  . . .   n} and immediately observes a reward Xi t
E⌫i[Xi t] = µi. For a known threshold µ0  deﬁne the sets2

H1 = {i 2 [n] : µi > µ0}

and H0 = {i 2 [n] : µi = µ0} = [n] \ H1.

i=1  µ0) it satisﬁes E[|St\H0|

The value of the means µi for i 2 [n] and the cardinality of H1 are unknown. The arms (treatments)
in H1 have means greater than µ0 (positive effect) while those in H0 have means equal to µ0 (no
effect over baseline). At each time t  after the player plays an arm  she also outputs a set of indices
St ✓ [n] that are interpreted as discoveries or rejections of the null-hypothesis (that is  if i 2S t then
the player believes i 2H 1). For as small a ⌧ 2 N as possible  the goal is to have the number of
true detections |St \H 1| be approximately |H1| for all t  ⌧  subject to the number of false alarms
|St \H 0| being small uniformly over all times t 2 N. We now formally deﬁne our notions of false
alarm control and true discoveries.
Deﬁnition 1 (False Discovery Rate  FDR-). Fix some  2 (0  1). We say an algorithm is FDR- if for
|St|_1 ]   for all t 2 N simultaneously.
all possible problem instances ({⌫i}n
Deﬁnition 2 (Family-wise Error Rate  FWER-). Fix some  2 (0  1). We say an algorithm is
i=1  µ0) it satisﬁes P(S1t=1{St \H 0 6= ;})  .
FWER- if for all possible problem instances ({⌫i}n
Note FWER- implies FDR-  the former being a stronger condition than the latter. Allowing a
relatively small number of false discoveries is natural  especially if |H1| is relatively large. Because
µ0 is known  there exist schemes that guarantee FDR- or FWER- even if the arm means µi and the
cardinality of H1 are unknown (see Section 2.1). It is also natural to relax the goal of identifying all
arms in H1 to simply identifying a large proportion of them.
Deﬁnition 3 (True Positive Rate  TPR-  ⌧). Fix some  2 (0  1). We say an algorithm is TPR-  ⌧
on an instance ({⌫i}n
Deﬁnition 4 (Family-wise Probability of Detection  FWPD-  ⌧). Fix some  2 (0  1). We say an
algorithm is FWPD-  ⌧ on an instance ({⌫i}n
Note that FWPD-  ⌧ implies TPR-  ⌧  the former being a stronger condition than the latter. Also
note P(S1t=1{St \H 0 6= ;})   and P(H1 ✓S ⌧ )  1   together imply P(H1 = S⌧ )  1  2.
We will see that it is possible to control the number of false discoveries |St \H 0| regardless of how
the player selects arms to play. It is the rate at which St includes H1 that can be thought of as the
statistical power of the algorithm  which we formalize as its sample complexity:
Deﬁnition 5 (Sample Complexity). Fix some  2 (0  1) and an algorithm A that is FDR- (or
FWER-) over all possible problem instances. Fix a particular problem instance ({⌫i}n
i=1  µ0). At
each time t 2 N  A chooses an arm i 2 [n] to obtain an observation from  and before proceeding to
the next round outputs a set St ✓ [n]. The sample complexity of A on this instance is the smallest
time ⌧ 2 N such that A is TPR-  ⌧ (or FWPD-  ⌧).
The sample complexity and value of ⌧ of an algorithm will depend on the particular instance
i=1  µ0). For example  if H1 = {i 2 [n] : µi = µ0 +} and H0 = [n]\H1  then we expect the
({⌫i}n
1All results without modiﬁcation apply to unbounded  sub-Gaussian random variables.
2All results generalize to the case when H0 = {i : µi  µ0}.

i=1  µ0) if P(H1 ✓S t)  1   for all t  ⌧.

i=1  µ0) if E[|St\H1|
|H1|

]  1   for all t  ⌧.

2

False alarm control

FDR-
maxt E[|St\H0|
|St|_1 ]  

Theorem 2

n2

Theorem 3

FWER-

P(S1t=1{St \H 0 6= ;})  
(n  k)2 + k2 log(n  k)

Theorem 5

Theorem 4

Detection Probability

TPR-  ⌧

E[|S⌧\H1|
|H1|
FWPD-  ⌧

]  1  

P(H1 ✓S ⌧ )  1  
(n  k)2 log(k) + k2 log(n  k)
Table 1: Informal summary of sample complexity results proved in this paper for |H1| = k  constant  (e.g. 
 = .05) and = min i2H1 µi  µ0. Uniform sampling across all settings requires at least n2 log(n/k)
samples  and in the FWER+FWPD setting requires n2 log(n). Constants and log log factors are ignored.

(n  k)2 log(k) + k2

sample complexity to increase as  decreases since at least 2 samples are necessary to determine
whether an arm has mean µ0 versus µ0 + . The next section will give explicit cases.
Remark 1 (Impossibility of stopping time). We emphasize that just as in the non-adaptive setting 
at no time can an algorithm stop and declare that it is TPR-  ⌧ or FWPD-  ⌧ for any ﬁnite ⌧ 2 N.
This is because there may be an arm in H1 with a mean inﬁnitesimally close to µ0 but distinct such
that no algorithm can determine whether it is in H0 or H1. Thus  the algorithm must run indeﬁnitely
or until it is stopped externally. However  using an anytime conﬁdence bound (see Section 2) one can
always make statements like “either H1 ✓S t  or maxi2H1\St µi  µ0  ✏” where the ✏ will depend
on the width of the conﬁdence interval.

1.2 Contributions and Informal Summary of Main Results
In Section 2 we propose an algorithm that handles all four combinations of {FDR-  FWER-} and
{TPR-  ⌧  FWPD-  ⌧}. A reader familiar with the multi-armed bandit literature would expect an
adaptive sampling algorithm to have a large advantage over uniform sampling when there is a large
diversity in the means of H1 since larger means can be distinguished from µ0 with fewer samples.
However  one should note that to declare all of H1 as discoveries  one must sample every arm in H0 at
least as many times as the most sampled arm in H1  otherwise they are statistically indistinguishable.
As discoveries are typically uncovering rare phenomenon  it is common to assume |H1| = n for
 2 (0  1) [4  5]  or |H1| = o(n)  but this implies that the number of samples taken from the arms
in H1  regardless of how samples are allocated to those arms  will almost always be dwarfed by the
number of samples allocated to those arms in H0 since there are ⌦(n) of them. This line of reasoning 
in part  is what motivates us to give our sample complexity results in terms of the quantities that
best describe the contributions from those arms in H0  namely  the cardinality |H1| = n |H 0|  the
conﬁdence parameter  (e.g.   = .05)  and the gap := min i2H1 µi  µ0 between the means of
the arms in H0 and the smallest mean in H1. Reporting sample complexity results in terms of 
also allows us to compare to known lower bounds in the literature [6  4  7  8]. Nevertheless  we do
address the case where the means of H1 are varied in Theorem 2.
An informal summary of the sample complexity results proven in this work are found in Table 1 for
|H1| = k. For the least strict setting of FDR+TPR  the upper-left quadrant of Table 1 matches the
lower bound of [4]  a sample complexity of just 2n. In this FDR+TPR setting (which requires
the fewest samples of the four settings)  uniform sampling which pulls each arm an equal number of
times has a sample complexity of at least n2 log(n/|H1|) (see Theorem 7 in Appendix G)  which
exceeds all results in Table 1 demonstrating the statistical power gained by adaptive sampling. For the
most strict setting of FWER+FWPD  the lower-right quadrant of Table 1 matches the lower bounds
of [7  9  8]  a sample complexity of (n  k)2 log(k) + k2 log(n  k). Uniform sampling in
the FWER+FWPD setting has a sample complexity lower bounded by n2 log(n) (see Theorem 8
in Appendix G). The settings of FDR+FWPD and FWER+TPR are sandwiched between these results 
and we are unaware of existing lower bounds for these settings.
All the results in Table 1 are novel  and to the best of our knowledge are the ﬁrst non-trivial sample
complexity results for an adaptive algorithm in the ﬁxed conﬁdence setting where a desired conﬁdence
 is set  and the algorithm attempts to minimize the number of samples taken to meet the desired
conditions. We also derive tools that we believe may be useful outside this work: for always valid
p-values (c.f. [3  10]) we show that FDR is controlled for all times using the Benjamini-Hochberg

3

procedure [11] (see Lemma 1)  and also provide an anytime high probability bound on the false
discovery proportion (see Lemma 2).
Finally  as a direct consequence of the theoretical guarantees proven in this work and the empirical
performance of the FDR+TPR variant of the algorithm on real data  an algorithm faithful to the theory
was implemented and is in use in production at a leading A/B testing platform [12].

1.3 Related work

Identifying arms with means above a threshold  or equivalently  multiple testing via rejecting null-
hypotheses with small p-values  is an ubiquitous problem in the biological sciences. In the standard
setup  each arm is given an equal number of measurements (i.e.  a uniform sampling strategy) 
a p-value Pi is produced for each arm where P(Pi  x)  x for all x 2 (0  1] and i 2H 0 
and a procedure is then run on these p-values to declare small p-values as rejections of the null-
hypothesis  or discoveries. For a set of p-values P1  P2 ··· Pn  the so-called Bonferroni
selection rule selects SBF = {i : Pi  /n}. The fact that FWER control implies FDR control 
E[|SBF \H 0|]  P(Si2H0{Pi  /n})   |H0|n    suggests that greater statistical power
(i.e. more discoveries) could be achieved with procedures designed speciﬁcally for FDR. The BH
procedure [11] is one such procedure to control FDR and is widely used in practice (with its many
extensions [6] and performance investigations [5]). Recall that a uniform measurement strategy where
every arm is sampled the same number of times requires n2 log(n/k) samples in the FDR+TPR
setting  and n2 log(n) samples in the FWER+FWPD setting (Theorems 7 and 8 in Appendix G) 
which can be substantially worse than our adaptive procedure (see Table 1).
Adaptive sequential testing has been previously addressed in the ﬁxed budget setting: the procedure
takes a sampling budget as input  and the guarantee states that if the given budget is larger than a
problem dependent constant  the procedure drives the error probability to zero and the detection
probability to one. One of the ﬁrst methods called distilled sensing [13] assumed that arms from
H0 were Gaussian with mean at most µ0  and successively discarded arms after repeated sampling
by thresholding at µ0–at most the median of the null distribution–thereby discarding about half
the nulls at each round. The procedure made guarantees about FDR and TPR  which were later
shown to be nearly optimal [4]. Speciﬁcally  [4  Corollary 4.2] implies that any procedure with
max{F DR + (1  T P R)}  requires a budget of at least 2n log(1/)  which is consistent
with our work. Later  another thresholding algorithm for the ﬁxed budget setting addressed the
FWER and FWPD metrics [7]. In particular  if their procedure is given a budget exceeding (n 
|H1|)2 log(|H1|) + |H1|2 log(n |H 1|) then the FWER is driven to zero  and the FWPD is
driven to one. By appealing to the optimality properties of the SPRT (which knows the distributions
precisely) it was argued that this is optimal. These previous works mostly focused on the asymptotic
regime as n ! 1 and |H1| = o(n).
Our paper  in contrast to these previous works considers the ﬁxed conﬁdence setting: the procedure
takes a desired FDR (or FWER) and TPR (or FWPD) and aims to minimize the number of samples
taken before these constraints are met. To the best of our knowledge  our paper is the ﬁrst to propose
a scheme for this problem in the ﬁxed conﬁdence regime with near-optimal sample complexity
guarantees.
A related line of work is the threshold bandit problem  where all the means of H1 are assumed to be
strictly above a given threshold  and the means of H0 are assumed to be strictly below the threshold
[14  15]. To identify this partition  each arm must be pulled a number of times inversely proportional
to the square of its deviation from the threshold. This contrasts with our work  where the majority of
arms may have means equal to the threshold and the goal is to identify arms with means greater than
the threshold subject to discovery constraints. If the arms in H0 are assumed to be strictly below the
threshold it is possible to declare arms as in H0. In our setting we can only ever determine that an
arm is in H1 and not H0  but it is impossible to detect that an arm is in H0 and not in H1.
Note that the problem considered in this paper is very related to the top-k identiﬁcation problem
where the objective is to identify the unique k arms with the highest means with high probability
[16  9  8]. Indeed  if we knew |H1|  then our FWER+FWPD setting is equivalent to the top-k problem
with k = |H1|. Lower bounds derived for the top-k problem assume the algorithm has knowledge of
the values of the means  just not their indices [16  8]. Thus  these lower bounds also apply to our
setting and are what are referenced in Section 1.2.

4

Algorithm 1 An algorithm for identifying arms with means above a threshold µ0 using as few samples as
possible subject to false alarm and true discovery conditions. The set St is designed to control FDR at level .
The set Rt is designed to control FWER at level .
Input: Threshold µ0  conﬁdence  2 (0  e1]  conﬁdence interval (· ·)
Initialize: Pull each arm i 2 [n] once and let Ti(t) denote the number of times arm i has been pulled
up to time t. Set Sn+1 = ;  Rn+1 = ;  and
If TPR

⇠t = 1 

Else if FWPD

and

⌫t = 1 8t

5



6.4 log(36/) to obtain  FDR-controlled

set St:

For t = n + 1  n + 2  . . .

⇠t

and

⌫t = max{|St|  1}8 t
) 

⇠t = max{2|St| 
Pull arm It = arg max
Apply Benjamini-Hochberg [11] selection at level 0 =

3(14) log(1/)} 
i2[n]\Stbµi Ti(t) + (Ti(t)  
s(k) = {i 2 [n] :bµi Ti(t)  (Ti(t)  0 k
St+1 = s(bk) wherebk = max{k 2 [n] : |s(k)| k} (if 6 9bk set St+1 = St)
If FWER and St 6= ;:
Pull arm Jt = arg max
i2St\Rtbµi Ti(t) + (Ti(t)  
Apply Bonferroni-like selection to obtain FWER-controlled set Rt:
t = n  (1  20(1 + 40))|St| + 4(1+40)
log(5 log2(n/0)/0)
Rt+1 = Rt [{ i 2S t :bµi Ti(t)  (Ti(t)  
)  µ0}
t

n )  µ0}  8k 2 [n]

)

⌫t

3

As pointed out by [14]  both our setting and the threshold bandit problem can be posed as a combi-
natorial bandits problem as studied in [17  18]  but such generality leads to unnecessary log factors.
The techniques used in this work aim to reduce extraneous log factors  a topic of recent interest in
the top-1 and top-k arm identiﬁcation problem [19  20  21  22  16  8]. While these works are most
similar to exact identiﬁcation (FWER+FWPD)  there also exist examples of approximate top-k where
the objective is to ﬁnd any k means that are each within ✏ of the best k means [9]. Approximate
recovery is also studied in a ranking context with a symmetric difference metric [23] which is more
similar to the FDR and TPR setting  but neither this nor that work subsumes one another.
Finally  maximizing the number of discoveries subject to a FDR constraint has been studied in a
sequential setting in the context of A/B testing with uniform sampling [3]. This work popularized the
concept of an always valid p-value that we employ here (see Section 2). The work of [10] controls
FDR over a sequence of independent bandit problems that each outputs at most one discovery. While
[10] shares much of the same vocabulary as this paper  the problem settings are very different.

2 Algorithm and Discussion

Throughout  we will assume the existence of an anytime conﬁdence interval. Namely  ifbµi t denotes
the empirical mean of the ﬁrst t bounded i.i.d. rewards in [0  1] from arm i  then for any  2 (0  1) we
assume the existence of a function  such that for any  we have P (T1t=1{|bµi t  µi| (t  )}) 
1. We assume that (t  ) is non-increasing in its second argument and that there exists an absolute
constant c such that (t  ) q c log(log2(2t)/)
. It sufﬁces to deﬁne  with this upper bound with
c = 4 but there are much sharper known bounds that should be used in practice (e.g.  they may take
empirical variance into account)  see [21  24  25  26]. Anytime bounds constructed with such a (t  )
are known to be tight in the sense that P(S1t=1{|bµi t  µi| (t  )})   and that there exists an
absolute constant h 2 (0  1) such that P({|bµi t  µi| h (t  ) for inﬁnitely many t 2 N}) = 1 by

the Law of the Iterated Logarithm [27].
Consider Algorithm 1. Before entering the for loop  time-dependent variables ⇠t and ⌫t are deﬁned
that should be updated at each time t for different settings. If just FDR control is desired  the
algorithm merely loops over the three lines following the for loop  pulling the arm It not in St that

t

5

has the highest upper conﬁdence bound; such strategies are common for pure-exploration problems
[21  10]. But if FWER control is desired then at most one additional arm Jt is pulled per round to
provide an extra layer of ﬁltering and evidence before an arm is added to Rt. Below we describe
the main elements of the algorithm and along the way sketch out the main arguments of the analysis 
shedding light on the constants ⇠t and ⌫t.

Pi t := sup{↵ 2 (0  1] :bµi t  µ0  (t  ↵)} log2(2t) exp(t(bµi t  µ0)2/c).

2.1 False alarm control
St is FDR-controlled. In addition to its use as a conﬁdent bound  we can also use (t  ) to construct:
(1)
Proposition 1 of [10] (and the proof of our Lemma 1) shows that if i 2H 0 so that µi = µ0 then
Pi t is an anytime  sub-uniformly distributed p-value in the sense that P(S1t=1{Pi t  x})  x.
Sequences that have this property are sometimes referred to as always-valid p-values [3]. Note that
if i 2H 1 so that µi > µ0  we would intuitively expect the sequence {Pi t}1t=1 to be point-wise
smaller than if µi = µ0 by the property that (· ·) is non-increasing in its second argument. This
leads to the intuitive rule to reject the null-hypothesis (i.e.  declare i /2H 0) for those arms i 2 [n]
where Pi t is very small. The Benjamini-Hochberg (BH) procedure introduced in [11] proceeds
by ﬁrst sorting the p-values so that P(1) T(1)(t)  P(2) T(2)(t) ··· P(n) T(n)(t)  then deﬁnes
bk = max{k : P(k) T(k)(t)   k
n}. Note that this procedure is
identical to deﬁning sets
settingbk = max{k : |s(k)| k}  and SBH = s(bk)  which is exactly the set St = SBH in Algo-
rithm 1. Thus  St in Algorithm 1 is equivalent to applying the BH procedure at a level O(/ log(1/))
to the anytime p-values of (1). We now discuss the extra logarithmic factor.
Because the algorithm is pulling arms sequentially  some dependence between the p-values may be
introduced. Because the anytime p-values are not independent  the BH procedure at level  does not
directly guarantee FDR-control at level . However  it has been shown [28] that for even arbitrarily
dependent p-values the BH procedure at level  controls FDR at level  log(n) (and that it is nearly
tight). Similarly  the following theorem  which may be of independent interest  is a signiﬁcant
improvement when applied to our setting.
Theorem 1. Fix  2 (0  e1). Let p1  . . .   pn be random variables such that {pi}i2H0 are indepen-
dent and sub-uniformly distributed so that maxi2H0 P(pi  x)  x. For any k 2{ 0  1  . . .   n}  let
Rk := {i : pi   k

n}  and sets SBH = {i : Pi Ti(t)  bk
n} = {i :bµi Ti(t)  (Ti(t)  k

s(k) = {i : Pi Ti(t)   k

n )  µ0} 

.

E"

n} and \F DP (Rk) := maxpi2Rk pi
|Rk|_1
F DP (Rk)#  |H0|

n ⇣2 log( 2n
In other words  any procedure that chooses a set {i : pi  k
controlled at level O( log(1/)).

 4 log(9/)

k:\F DP (Rk)

max

|H0| ) + log(8e5 log( 8n

|H0| ))⌘
n }|  k is FDR
n } satisfying |{i : pi  k

Recall  ifbk = max{k : \F DP (Rk)  } then E[F DP (Rbk)]   by the standard BH result. When
running the algorithm we recommend using BH at level   not level O(/ log(1/)). As Ti gets very
large  Pi Ti(t) ! Pi ⇤ and we know that if BH is run on Pi ⇤ at level  then FDR would be controlled
at level . We believe this inﬂation to be somewhat of an artifact of our proofs.
Rt is FWER-controlled. A core obstacle in our analysis is the fact that we don’t know the cardinality
of H1. If we did know |H1| (and equivalently know |H0| = n|H1|) then a FWER+FWPD algorithm
is equivalent to the so-called top-k multi-armed bandit problem [9  8] and controlling FWER would
be relatively simple using a Bonferroni correction:
)  µ0}⌘ |H 0| 
|H0|
which implies FWER-. Comparing the ﬁrst expression immediately above to the deﬁnition of Rt
in the algorithm  it is clear our strategy is to use |St| as a surrogate for |H1|. Note that we could

P⇣[1t=1{bµi t  (t 

)  µ0}⌘  Xi2H0

[1t=1{bµi t  (t 

P⇣ [i2H0

n|H1|


|H0|



6

use the bound |H0| = n |H 1| n to guarantee FWER-  but this could be very loose and induce
an n log(n) sample complexity. Using |St| as a surrogate for |H1| in Rt is intuitive because by the
FDR guarantee  we know |H1| E[|St \H 1|] = E[|St|]  E[|St \H 0|]  (1  )E[|St|]  implying
that |H0| = n |H 1| n  (1  )E[|St|] which may be much tighter than n if E[|St|] !|H 1|.
Because we only know |St| and not its expectation  the extra factors in the surrogate expression used
in Rt are used to ensure correctness with high-probability (see Lemma 7).
2.2 Sampling strategies to boost statistical power
The above discussion about controlling false alarms for St and Rt holds for any choice of arms It
and Jt that may be pulled at time t. Thus  It and Jt are chosen in order to minimize the amount of
time necessary to add arms into St and Rt  respectively  and optimize the sample complexity.
µi 8t 2 N}. Because  is an anytime conﬁdence bound  E [|I|]  (1)|H1|. If = min i2H1 µi
µ0  then mini2I µi  µ0 + and we claim that with probability at least 1  O() (Section C)

TPR-  ⌧ setting implies ⇠t = ⌫t = 1. Deﬁne the random set I = {i 2H 1 :bµi Ti(t) + (Ti(t)  ) 

P1t=1 1{It 2H 0 I 6✓ St} P1t=1 1{It 2H 0 bµIt TIt (t) + (TIt(t)  )  µ0 + }

 c|H0|2 log(log(2/).

Thus once this number of samples has been taken  either I✓S t  or arms in I will be repeatedly
sampled until they are added to St since each arm i 2I has its upper conﬁdence bound larger than
those arms in H0 by deﬁnition. It is clear that an arm in H1 that is repeatedly sampled will eventually
be added to St since its anytime p-value of (1) approaches 0 at an exponential rate as it is pulled  and
BH selects for low p-values. A similar argument holds for Jt and adding arms to Rt.
Remark 2. While the main objective of Algorithm 1 is to identify all arms with means above a
given threshold  we note that prior to adding an arm to St in the TPR setting (i.e.  when ⇠t = 1)
Algorithm 1 behaves identically to the nearly optimal best-arm identiﬁcation algorithm lil’UCB of
[21]. Thus  whether the goal is best-arm identiﬁcation or to identify all arms with means above a
certain threshold  Algorithm 1 is applicable.

P(Si2H1 [1t=1{bµi t + (t  

FWPD-  ⌧ setting is more delicate and uses inﬂated values of ⇠t and ⌫t. This time  we must ensure
that {H1 6✓ St} =) maxi2H1\Sc
t µi  µ0 + . Because
then we could argue that either H1 ⇢S t  or only arms in H1 are sampled until they are added to St
(mirroring the TPR argument). As in the FWER setting above  if we knew the value of |H1| the we
could set ⇠t |H 1| to observe that
) < µi}⌘ |H 1| 
which is less than   to guarantee such a condition. But we don’t know |H1| so we use |St|
as a surrogate  resulting in the inﬂated deﬁnitions of ⇠t and ⌫t relative to the TPR setting. The
)  µ0 + by the
key argument is that either I 6✓ St so that maxi2I\Sc
deﬁnition of I (since ⇠t  1)  or I⇢S t and |St| 1
2|H1| with high probability which implies
⇠t = max{2|St| 
3 Main Results

t bµi Ti(t) + (Ti(t)  )  mini2H1\Sc
) < µi}) Pi2H1 P⇣[1t=1{bµi t + (t  
t bµi Ti(t) + (Ti(t)  

3(14) log(1/)}|H 1| and the union bound of the display above holds.

⇠t

⇠t

⇠t

⇠t

5

In what follows  we say f . g if there exists a c > 0 that is independent of all problem parameters
and f  cg. The theorems provide an upper bound on the sample complexity ⌧ 2 N as deﬁned in
Section 1.1 for TPR-  ⌧ or FWER-  ⌧ that holds with probability at least 1  c for different values
of c3. We begin with the least restrictive setting  resulting in the smallest sample complexity of all the
results presented in this work. Note the slight generalization in the below theorem where the means
of H0 are assumed to be no greater than µ0.
Theorem 2 (FDR  TPR). Let H1 = {i 2 [n] : µi > µ0}  H0 = {i 2 [n] : µi  µ0}. Deﬁne
i = µi  µ0 for i 2H 1  = min i2H1 i  and i = minj2H1 µj  µi =+ ( µ0  µi) for
3 Each theorem relies on different events holding with high probability  and consequently a different c for
each. To have c = 1 for each of the four settings  we would have had to deﬁne different constants in the
algorithm for each setting. We hope the reader forgives us for this attempt at minimizing clutter.

7

2

i

i

log(log(2

i

2

i

log(n log(2

)/) 

Pi2H0

)/) +Pi2H1

|St|_1 ]  . Moreover  with probability at least 1  2 there

i 2H 0. For all t 2 N we have E[|St\H0|
exists a T such that
T . minn2 log(log(2)/) 
]  1   for all t  T . Neither argument of the minimum follows from the other.

and E[|St\H1|
|H1|
If the means of H1 are very diverse so that maxi2H1 µi  µ0  mini2H1 µi  µ0 then the second
argument of the min in Theorem 2 can be tighter than the ﬁrst. But as discussed above  this advantage
is inconsequential if |H1| = o(n). The remaining theorems are given in terms of just . The
log log(2) dependence is due to inverting the  conﬁdence interval and is unavoidable on at least
one arm when  is unknown a priori due to the law of the iterated logarithm [27  21  22].
Informally  Theorem 2 states that if just most true detections sufﬁce while not making too many
mistakes  then O(n) samples sufﬁce. The ﬁrst argument of the min is known to be tight in a minimax
sense up to doubly logarithmic factors due to the lower bound of [4]. As a consequence of this work 
an algorithm inspired by Algorithm 1 in this setting is now in production at one of the largest A/B
testing platforms on the web. The full proof of Theorem 2 (and all others) is given in the Appendix
due to space.
Theorem 3 (FDR  FWPD). For all t 2 N we have E[|St\H0|
|St|_1 ]  . Moreover  with probability at
least 1  5  there exists a T such that
T . (n |H 1|)2 log(max{|H1|  log log(n/)} log(2)/) + |H1|2 log(log(2)/)
and H1 ✓S t for all t  T .
Here T roughly scales like (n |H 1|) max{log(|H1|)  log log log(n/)} + |H1| where the
log log log(n/) term comes from a high probability bound on the false discovery proportion for
anytime p-values (in contrast to just expectation) in Lemma 2 that may be of independent interest.
While negligible for all practical purposes  it appears unnatural and we suspect that this is an artifact of
our analysis. We note that if |H1| = ⌦(log(n)) then the sample complexity sheds this awkwardness4.
The next two theorems are concerned with controlling FWER on the set Rt and determining how
long it takes before the claimed detection conditions are satisﬁed on the set Rt. Note we still have
that FDR is controlled on the set St but now this set feeds into Rt.
Theorem 4 (FWER  FWPD). For all t we have E[|St\H0|
|St|_1 ]  . Moreover  with probability at least
1  6  we have H0 \R t = ; for all t 2 N and there exists a T such that
T .(n |H 1|)2 log(max{|H1|  log log(n/)} log(2)/)

+ |H1|2 log(max{n  (1  2(1 + 4))|H1|  log log(n/)} log(2)/)

and H1 ✓R t for all t  T . Note  together this implies H1 = Rt for all t  T .
Theorem 4 has the strongest conditions  and therefore the largest sample complexity. Ignoring
log log log(n) factors  T roughly scales as (n|H 1|) log(|H1|)+|H1| log(n(12(1+4))|H1|).
Inspecting the top-k lower bound of [8] where the arms’ means in H1 are equal to µ0 +   the arms’
means in H0 are equal to µ0  and the algorithm has knowledge of the cardinality of H1  a necessary
sample complexity of (n|H 1|) log(|H1|) +|H1| log(n|H 1|) is given. It is not clear whether this
small difference of log(n (1 2(1 + 4))|H1|) versus log(n|H 1|) is an artifact of our analysis 
or a fundamental limitation when the cardinality |H1| is unknown. We now state our ﬁnal theorem.
Theorem 5 (FWER  TPR). For all t we have E[|St\H0|
|St|_1 ]  . Moreover  with probability at least
1  7 we have H0 \R t = ; for all t 2 N and there exists a T such that

T .(n |H 1|)2 log(log(2)/)

and E[|Rt\H1|

+ |H1|2 log(max{n  (1  ⌘)|H1|  log log(n log(1/)/)} log(2)/)
]  1   for all t  T   where ⌘ = (1  3 p2 log(1/)/|H1|).

4In the asymptotic n regime  it is common to study the case when |H1| = n for  2 (0  1) [4  13].

|H1|

8

4 Experiments
The distribution of each arm equals ⌫i = N (µi  1) where µi = µ0 = 0 if i 2H 0  and µi > 0 if
i 2H 1. We consider three algorithms: i) uniform allocation with anytime BH selection as done in
Algorithm 1  ii) successive elimination (SE) (see Appendix G)5 that performs uniform allocation
on only those arms that have not yet been selected by BH  and iii) Algorithm 1 (UCB). Algorithm
1 and the BH selection rule for all algorithms use (t  ) =q 2 log(1/)+6 log log(1/)+3 log(log(et/2))
from [25  Theorem 8]. In addition  we ran BH at level  instead of /(6.4 log(36/)) as discussed
in section 3. Here we present the sample complexity for TPR+FDR with  = 0.05 and different
parameterizations of µ  n  |H1|.

t

The ﬁrst panel shows an empirical estimate of E[|St\H1|
] at each time t for each algorithm  averaged
|H1|
over 1000 trials. The black dashed line on the ﬁrst panel denotes the level E[|St\H1|
] = 1   = .95 
|H1|
and corresponds to the dashed black line on the second panel. The right four panels show the number
of samples each algorithm takes before the true positive rate exceeds 1   = .95  relative to the
number of samples taken by UCB  for various parameterizations. Panels two  three  and four have
i = for i 2H 1 while panel ﬁve is a case where the i’s are linear for i 2H 1. While the
differences are most clear on the second panel when |H1| = 2 = o(n)  over all cases UCB uses at
least ⇡ 3 times fewer samples than uniform and SE. For FDR+TPR  Appendix G shows uniform
sampling roughly has a sample complexity that scales like n2 log( n
) while SE’s is upper
|H1|
2
bounded by min{n2 log( n
log(n)}. Comparing
i
|H1|
with Theorem 2 for the difference cases (i.e.  |H1| = 2 pn  n/5) provides insight into the relative
difference between UCB  uniform  and SE on the different panels.

)  (n |H 1|)2 log( n
|H1|

) +Pi2H1

Acknowledgments
This work was informed and inspired by early discussions with Aaditya Ramdas on methods for
controlling the false discovery rate (FDR) in multiple testing; we are grateful to have learned from
a leader in the ﬁeld. We also thank him for his careful reading and feedback. We’d also like to
thank Martin J. Zhang for his input. We also thank the leading experimentation and A/B testing
platform on the web  Optimizely  for its support  insight into its customers’ needs  and for committing
engineering time to implementing this research into their platform [12]. In particular  we thank
Whelan Boyd  Jimmy Jin  Pete Koomen  Sammy Lee  Ajith Mascarenhas  Sonesh Surana  and Hao
Xia at Optimizely for their efforts.

5Inspired by the best-arm identiﬁcation literature [19].

9

References
[1] Linhui Hao  Akira Sakurai  Tokiko Watanabe  Ericka Sorensen  Chairul A Nidom  Michael A
Newton  Paul Ahlquist  and Yoshihiro Kawaoka. Drosophila rnai screen identiﬁes host genes
important for inﬂuenza virus replication. Nature  454(7206):890  2008.

[2] GJ Rocklin  TM Chidyausiku  I Goreshnik  A Ford  S Houliston  A Lemak  L Carter  R Ravichan-
dran  VK Mulligan  A Chevalier  CH Arrowsmith  and D Baker. Global analysis of protein
folding using massively parallel design  synthesis  and testing. Science  357:168–175  2017.

[3] Ramesh Johari  Leo Pekelis  and David J Walsh. Always valid inference: Bringing sequential

analysis to a/b testing. arXiv preprint arXiv:1512.04922  2015.

[4] Rui M Castro. Adaptive sensing performance lower bounds for sparse signal detection and

support estimation. Bernoulli  20(4):2217–2246  2014.

[5] Maxim Rabinovich  Aaditya Ramdas  Michael I Jordan  and Martin J Wainwright. Optimal

rates and tradeoffs in multiple testing. arXiv preprint arXiv:1705.05391  2017.

[6] A. Ramdas  R. Foygel Barber  M. J. Wainwright  and M. I. Jordan. A Uniﬁed Treatment of

Multiple Testing with Prior Knowledge. ArXiv e-prints  March 2017.

[7] Matthew L Malloy and Robert D Nowak. Sequential testing for sparse recovery.

Transactions on Information Theory  60(12):7862–7873  2014.

IEEE

[8] Max Simchowitz  Kevin Jamieson  and Benjamin Recht. The simulator: Understanding adaptive
sampling in the moderate-conﬁdence regime. In Conference on Learning Theory  pages 1794–
1834  2017.

[9] Shivaram Kalyanakrishnan  Ambuj Tewari  Peter Auer  and Peter Stone. Pac subset selection in

stochastic multi-armed bandits. In ICML  volume 12  pages 655–662  2012.

[10] Fanny Yang  Aaditya Ramdas  Kevin G Jamieson  and Martin J Wainwright. A framework
for multi-a(rmed)/b(andit) testing with online fdr control. In Advances in Neural Information
Processing Systems  pages 5959–5968  2017.

[11] Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and
powerful approach to multiple testing. Journal of the royal statistical society. Series B (Method-
ological)  pages 289–300  1995.

[12] Optimizely. Accelerating experimentation through machine learning  https://help.

optimizely.com/Build_Campaigns_and_Experiments/Stats_Accelerator  2018.

[13] Jarvis Haupt  Rui M Castro  and Robert Nowak. Distilled sensing: Adaptive sampling for sparse
detection and estimation. IEEE Transactions on Information Theory  57(9):6222–6235  2011.

[14] Andrea Locatelli  Maurilio Gutzeit  and Alexandra Carpentier. An optimal algorithm for
the thresholding bandit problem. In International Conference on Machine Learning  pages
1690–1698  2016.

[15] Hideaki Kano  Junya Honda  Kentaro Sakamaki  Kentaro Matsuura  Atsuyoshi Nakamura 
arXiv preprint

and Masashi Sugiyama. Good arm identiﬁcation via bandit feedback.
arXiv:1710.06360  2017.

[16] Lijie Chen  Jian Li  and Mingda Qiao. Nearly instance optimal sample complexity bounds for

top-k arm selection. In Artiﬁcial Intelligence and Statistics  pages 101–110  2017.

[17] Shouyuan Chen  Tian Lin  Irwin King  Michael R Lyu  and Wei Chen. Combinatorial pure
exploration of multi-armed bandits. In Advances in Neural Information Processing Systems 
pages 379–387  2014.

[18] Tongyi Cao and Akshay Krishnamurthy. Disagreement-based combinatorial pure exploration:
Efﬁcient algorithms and an analysis with localization. arXiv preprint arXiv:1711.08018  2017.

10

[19] Eyal Even-Dar  Shie Mannor  and Yishay Mansour. Action elimination and stopping conditions
for the multi-armed bandit and reinforcement learning problems. Journal of machine learning
research  7(Jun):1079–1105  2006.

[20] Zohar Karnin  Tomer Koren  and Oren Somekh. Almost optimal exploration in multi-armed
bandits. In Proceedings of the 30th International Conference on Machine Learning (ICML-13) 
pages 1238–1246  2013.

[21] Kevin Jamieson  Matthew Malloy  Robert Nowak  and Sébastien Bubeck. lil’ucb: An optimal
exploration algorithm for multi-armed bandits. In Conference on Learning Theory  pages
423–439  2014.

[22] Lijie Chen  Jian Li  and Mingda Qiao. Towards instance optimal bounds for best arm identiﬁca-

tion. In Conference on Learning Theory  pages 535–592  2017.

[23] Reinhard Heckel  Max Simchowitz  Kannan Ramchandran  and Martin Wainwright. Approxi-
mate ranking from pairwise comparisons. In International Conference on Artiﬁcial Intelligence
and Statistics  pages 1057–1066  2018.

[24] A. Balsubramani. Sharp Finite-Time Iterated-Logarithm Martingale Concentration. ArXiv

e-prints  May 2014.

[25] Emilie Kaufmann  Olivier Cappé  and Aurélien Garivier. On the complexity of best arm
identiﬁcation in multi-armed bandit models. Journal of Machine Learning Research  17(1):1–
42  2016.

[26] Ervin Tanczos  Robert Nowak  and Bob Mankoff. A kl-lucb algorithm for large-scale crowd-
sourcing. In I. Guyon  U. V. Luxburg  S. Bengio  H. Wallach  R. Fergus  S. Vishwanathan  and
R. Garnett  editors  Advances in Neural Information Processing Systems 30  pages 5896–5905.
2017.

[27] Philip Hartman and Aurel Wintner. On the law of the iterated logarithm. American Journal of

Mathematics  63(1):169–176  1941.

[28] Yoav Benjamini and Daniel Yekutieli. The control of the false discovery rate in multiple testing

under dependency. Annals of statistics  pages 1165–1188  2001.

[29] Maxim Raginsky and Alexander Rakhlin. Lower bounds for passive and active learning. In

Advances in Neural Information Processing Systems  pages 1026–1034  2011.

[30] Alexandre B Tsybakov. Introduction to nonparametric estimation  2009.
[31] Pascal Massart et al. The tight constant in the dvoretzky-kiefer-wolfowitz inequality. The annals

of Probability  18(3):1269–1283  1990.

11

,Yinlam Chow
Mohammad Ghavamzadeh
Kevin Jamieson
Lalit Jain