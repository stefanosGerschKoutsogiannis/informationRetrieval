2017,AIDE: An algorithm for measuring the accuracy of probabilistic inference algorithms,Approximate probabilistic inference algorithms are central to many fields. Examples include sequential Monte Carlo inference in robotics  variational inference in machine learning  and Markov chain Monte Carlo inference in statistics. A key problem faced by practitioners is measuring the accuracy of an approximate inference algorithm on a specific data set. This paper introduces the auxiliary inference divergence estimator (AIDE)  an algorithm for measuring the accuracy of approximate inference algorithms. AIDE is based on the observation that inference algorithms can be treated as probabilistic models and the random variables used within the inference algorithm can be viewed as auxiliary variables. This view leads to a new estimator for the symmetric KL divergence between the approximating distributions of two inference algorithms. The paper illustrates application of AIDE to algorithms for inference in regression  hidden Markov  and Dirichlet process mixture models. The experiments show that AIDE captures the qualitative behavior of a broad class of inference algorithms and can detect failure modes of inference algorithms that are missed by standard heuristics.,AIDE: An algorithm for measuring the accuracy of

probabilistic inference algorithms

Marco F. Cusumano-Towner
Probabilistic Computing Project

Massachusetts Institute of Technology

marcoct@mit.edu

Vikash K. Mansinghka

Probabilistic Computing Project

Massachusetts Institute of Technology

vkm@mit.edu

Abstract

Approximate probabilistic inference algorithms are central to many ﬁelds. Exam-
ples include sequential Monte Carlo inference in robotics  variational inference
in machine learning  and Markov chain Monte Carlo inference in statistics. A
key problem faced by practitioners is measuring the accuracy of an approximate
inference algorithm on a speciﬁc data set. This paper introduces the auxiliary
inference divergence estimator (AIDE)  an algorithm for measuring the accuracy of
approximate inference algorithms. AIDE is based on the observation that inference
algorithms can be treated as probabilistic models and the random variables used
within the inference algorithm can be viewed as auxiliary variables. This view leads
to a new estimator for the symmetric KL divergence between the approximating
distributions of two inference algorithms. The paper illustrates application of AIDE
to algorithms for inference in regression  hidden Markov  and Dirichlet process
mixture models. The experiments show that AIDE captures the qualitative behavior
of a broad class of inference algorithms and can detect failure modes of inference
algorithms that are missed by standard heuristics.

1

Introduction

Approximate probabilistic inference algorithms are central to diverse disciplines  including statistics 
robotics  machine learning  and artiﬁcial intelligence. Popular approaches to approximate inference
include sequential Monte Carlo  variational inference  and Markov chain Monte Carlo. A key problem
faced by practitioners is measuring the accuracy of an approximate inference algorithm on a speciﬁc
data set. The accuracy is inﬂuenced by complex interactions between the speciﬁc data set in question 
the model family  the algorithm tuning parameters such as the number of iterations  and any associated
proposal distributions and/or approximating variational family. Unfortunately  practitioners assessing
the accuracy of inference have to rely on heuristics that are either brittle or specialized for one type
of algorithm [1]  or both. For example  log marginal likelihood estimates can be used to assess
the accuracy of sequential Monte Carlo and variational inference  but these estimates can fail to
signiﬁcantly penalize an algorithm for missing a posterior mode. Expectations of probe functions do
not assess the full approximating distribution  and they require design speciﬁc to each model.
This paper introduces an algorithm for estimating the symmetrized KL divergence between the output
distributions of a broad class of exact and approximate inference algorithms. The key idea is that
inference algorithms can be treated as probabilistic models and the random variables used within
the inference algorithm can be viewed as latent variables. We show how sequential Monte Carlo 
Markov chain Monte Carlo  rejection sampling  and variational inference can be represented in a
common mathematical formalism based on two new concepts: generative inference models and
meta-inference algorithms. Using this framework  we introduce the Auxiliary Inference Divergence
Estimator (AIDE)  which estimates the symmetrized KL divergence between the output distributions

31st Conference on Neural Information Processing Systems (NIPS 2017)  Long Beach  CA  USA.

Gold standard

inference algorithm

Target inference algorithm

(the algorithm being measured)

Number of gold-standard
inference runs

Ng

Number of meta-inference
runs for gold-standard

Mg

AIDE

Auxiliary Inference
Divergence Estimator

Nt

Number of target
inference runs

Mt

Number of meta-inference
runs for target

Symmetrized KL divergence estimate ˆD

ˆD ≈ DKL(gold-standard||target) + DKL(target||gold-standard)

Figure 1: Using AIDE to estimate the accuracy of a target inference algorithm relative to a gold-
standard inference algorithm. AIDE is a Monte Carlo estimator of the symmetrized Kullback-Leibler
(KL) divergence between the output distributions of two inference algorithms. AIDE uses meta-
inference: inference over the internal random choices made by an inference algorithm.

Figure 2: AIDE applies to SMC  variational  and MCMC algorithms. Left: AIDE estimates for
SMC converge to zero  as expected. Right: AIDE estimates for variational inference converge to
a nonzero asymptote that depends on the variational family. Middle: The symmetrized divergence
between MH and the posterior converges to zero  but AIDE over-estimates the divergence in expecta-
tion. Although increasing the number of meta-inference runs Mt reduces the bias of AIDE  AIDE is
not yet practical for measuring MH accuracy due to inaccurate meta-inference for MH.

of two inference algorithms that have both been endowed with a meta-inference algorithm. We also
show that the conditional SMC update of Andrieu et al. [2] and the reverse AIS Markov chain of
Grosse et al. [3] are both special cases of a ‘generalized conditional SMC update’  which we use as a
canonical meta-inference algorithm for SMC. AIDE is a practical tool for measuring the accuracy
of SMC and variational inference algorithms relative to gold-standard inference algorithms. Note
that this paper does not provide a practical solution to the MCMC convergence diagnosis problem.
Although in principle AIDE can be applied to MCMC  to do so in practice will require more accurate
meta-inference algorithms for MCMC to be developed.

2 Background
Consider a generative probabilistic model with latent variables X and observed variables Y . We
denote assignments to these variables by x ∈ X and y ∈ Y. Let p(x  y) denote the joint distribution of
x p(x  y)

the generative model. The posterior distribution is p(x|y) := p(x  y)/p(y) where p(y) =(cid:80)

is the marginal likelihood  or ‘evidence’.
Sampling-based approximate inference strategies including Markov chain Monte Carlo (MCMC 
[4  5])  sequential Monte Carlo (SMC  [6])  annealed importance sampling (AIS  [7]) and importance
sampling with resampling (SIR  [8  9])  generate samples of the latent variables that are approximately
distributed according to p(x|y). Use of a sampling-based inference algorithm is often motivated by

2

100101102Number of particles02468AIDE estimate (nats)Sequential Monte CarloMt=100Mt=101Mt=1031001011021 + Number of transitions02468AIDE estimate (nats)Metropolis-Hastings100101102103104Number of gradient steps02468AIDE estimate (nats)Variational Inferencetheoretical guarantees of exact convergence to the posterior in the limit of inﬁnite computation (e.g.
number of transitions in a Markov chain  number of importance samples in SIR). However  how well
the sampling distribution approximates the posterior distribution for ﬁnite computation is typically
difﬁcult to analyze theoretically or estimate empirically with conﬁdence.
Variational inference [10] explicitly minimizes the approximation error of the approximating dis-
tribution qθ(x) over parameters θ of a variational family. The error is usually quantiﬁed using the
Kullback-Leibler (KL) divergence from the approximation qθ(x) to the posterior p(x|y)  denoted
DKL(qθ(x) (cid:107) p(x|y)). Unlike sampling-based approaches  variational inference does not generally
give exact results for inﬁnite computation because the variational family does not include the posterior.
Minimizing the KL divergence is performed by maximizing the ‘evidence lower bound’ (ELBO)
L = log p(y) − DKL(qθ(x) (cid:107) p(x|y)) over θ. Since log p(y) is usually unknown  the actual error
(the KL divergence) of a variational approximation is also unknown.

3 Estimating the symmetrized KL divergence between inference algorithms

This section deﬁnes our mathematical formalism for analyzing inference algorithms; shows how
to represent SMC  MCMC  rejection sampling  and variational inference in this formalism; and
introduces the Auxiliary Inference Divergence Estimator (AIDE)  an algorithm for estimating the
symmetrized KL divergence between two inference algorithms.

3.1 Generative inference models and meta-inference algorithms

We deﬁne an inference algorithm as a procedure that returns a single approximate posterior sample.
Repeated runs of the algorithm give independent samples. The algorithm has an ‘output distribution’
q(x) that gives the probability of returning x. Note that the dependence of q(x) on the observations
y that deﬁne the inference problem is suppressed in the notation. The algorithm is accurate when
q(x) ≈ p(x|y) for all x. We denote a sample returned from the algorithm by x ∼ q(x).
A naive simple Monte Carlo estimator of the KL divergence between the output distributions of two
inference algorithms requires evaluating output probabilities for both algorithms. However  it is
typically intractable to compute output probabilities for sampling-based inference algorithms like
MCMC and SMC  because that would require marginalizing over all possible values that the random
variables drawn during the algorithm could possibly take. A similar difﬁculty arises when computing
the marginal likelihood p(y) of a generative probabilistic model p(x  y). This suggests that we treat
the inference algorithm as a generative model  estimate its output probabilities using ideas from
marginal likelihood estimation  and use these estimates in a Monte Carlo estimator of the divergence.
We begin by making the analogy between an inference algorithm and a generative model explicit:
Deﬁnition 3.1 (Generative inference model). A generative inference model is a tuple (U X   q)
where q(u  x) is a joint distribution deﬁned on U × X . A generative inference model models an
inference algorithm if the output probability of the inference algorithm is the marginal likelihood
u q(u  x) of the model for all x. An element u ∈ U represents a complete assignment
to the internal random variables within the inference algorithm  and is called a ‘trace’. The ability
to simulate from q(u  x) is required  but the ability to compute the probability q(u  x) is not. A
simulation  denoted u  x ∼ q(u  x)  may be obtained by running the inference algorithm and recording
the resulting trace u and output x.1

q(x) =(cid:80)

A generative inference model can be understood as a generative probabilistic model where the u are
the latent variables and the x are the observations. Note that two different generative inference models
may use different representations for the internal random variables of the same inference algorithm. In
practice  constructing a generative inference model from an inference algorithm amounts to deﬁning
the set of internal random variables. For marginal likelihood estimation in a generative inference
model  we use a ‘meta-inference’ algorithm:
Deﬁnition 3.2 (Meta-inference algorithm). For a given generative inference model (U X   q)  a
meta-inference algorithm is a tuple (r  ξ) where r(u; x) is a distribution on traces u ∈ U of the
inference algorithm  indexed by outputs x ∈ X of the inference algorithm  and where ξ(u  x) is the
1The trace data structure could in principle be obtained by writing the inference algorithm in a probabilistic

programming language like Church [11]  but the computational overhead would be high.

3

following function of u and x for some Z > 0:

q(u  x)
r(u; x)

ξ(u  x) := Z

(1)
We require the ability to sample u ∼ r(u; x) given a value for x  and the ability to evaluate ξ(u  x)
given u and x. We call a procedure for sampling from r(u; x) a ‘meta-inference sampler’. We do not
require the ability to evaluate the probability r(u; x).
A meta-inference algorithm is considered accurate for a given x if r(u; x) ≈ q(u|x) for all u.
Conceptually  a meta-inference sampler tries to answer the question ‘how could my inference
algorithm have produced this output x?’ Note that if it is tractable to evaluate the marginal likelihood
q(x) of the generative inference model up to a normalizing constant  then it is not necessary to
represent internal random variables for the inference algorithm  and a generative inference model can
deﬁne the trace as an empty token u = () with U = {()}. In this case  the meta-inference algorithm
has r(u; x) = 1 for all x and ξ(u  x) = Zq(x).

3.2 Examples

We now show how to construct generative inference models and corresponding meta-inference
algorithms for SMC  AIS  MCMC  SIR  rejection sampling  and variational inference. The meta-
inference algorithms for AIS  MCMC  and SIR are derived as special cases of a generic SMC
meta-inference algorithm.

t  wi

t and W i

Sequential Monte Carlo. We consider a general class of SMC samplers introduced by Del Moral
et al. [6]  which can be used for approximate inference in both sequential state space and non-
sequential models. We brieﬂy summarize a slightly restricted variant of the algorithm here  and refer
the reader to the supplement and Del Moral et al. [6] for full details. The SMC algorithm propagates
P weighted particles through T steps  using proposal kernels kt and multinomial resampling based
on weight functions w1(x1) and wt(xt−1  xt) for t > 1 that are deﬁned in terms of ‘backwards
kernels’ (cid:96)t for t = 2 . . . T . Let xi
t denote the value  unnormalized weight  and normalized
weight of particle i at time t  respectively. We deﬁne the output sample x of SMC as a single draw
from the particle approximation at the ﬁnal time step  which is obtained by sampling a particle
index IT ∼ Categorical(W 1:P
T )  and then
setting x ← xIT
T . The generative inference model uses traces of the form u = (x  a  IT )  where x
contains the values of all particles at all time steps and where a (for ‘ancestor’) contains the index
t ∈ {1 . . . P} of the parent of particle xi
t+1 for each particle i and each time step t = 1 . . . T − 1.
ai
Algorithm 1 deﬁnes a canonical meta-inference sampler for this generative inference model that takes
as input a latent sample x and generates an SMC trace u ∼ r(u; x) as output. The meta-inference
sampler ﬁrst generates an ancestral trajectory of particles (xI1
T ) that terminates in the
output sample x  by sampling sequentially from the backward kernels (cid:96)t  starting from xIT
T = x.
Next  it runs a conditional SMC update [2] conditioned on the ancestral trajectory. For this choice of

r(u; x) and for Z = 1  the function ξ(u  x) is closely related to the marginal likelihood estimate (cid:100)p(y)
produced by the SMC scheme:2 ξ(u  x) = p(x  y)/(cid:100)p(y). See supplement for derivation.

denotes the vector of weights (W 1

) where W 1:P

1   xI2

2   . . .   xIT

T

T

T   . . .   W P

Annealed importance sampling. When a single particle is used (P = 1)  and when each forward
kernel kt satisﬁes detailed balance for some intermediate distribution  the SMC algorithm simpliﬁes
to annealed importance sampling (AIS  [7])  and the canonical SMC meta-inference inference
(Algorithm 1) consists of running the forward kernels in reverse order  as in the reverse annealing
algorithm of Grosse et al. [3  12]. The canonical meta-inference algorithm is accurate (r(u; x) ≈
q(u; x)) if the AIS Markov chain is kept close to equilibrium at all times. This is achieved if the
intermediate distributions form a sufﬁciently ﬁne-grained sequence. See supplement for analysis.

Markov chain Monte Carlo. We deﬁne each run of an MCMC algorithm as producing a single
output sample x that is the iterate of the Markov chain produced after a predetermined number of burn-
in steps has passed. We also assume that each MCMC transition operator satisﬁes detailed balance

2AIDE also applies to approximate inference algorithms for undirected probabilistic models; the marginal

likelihood estimate is replaced with the estimate of the partition function.

4

Algorithm 1 Generalized conditional SMC (a canonical meta-inference sampler for SMC)
Require: Latent sample x  SMC parameters

IT ∼ Uniform(1 . . . P )
T ← x
xIT
for t ← T − 1 . . . 1 do
It ∼ Uniform(1 . . . P )
(cid:46) Sample from backward kernel
t ∼ (cid:96)t+1(·; xIt+1
xIt
t+1 )
for i ← 1 . . . P do
if i (cid:54)= I1 then xi
1 ∼ k1(·)
1 ← w1(xi
wi
1)
for t ← 2 . . . T do
t−1 ← w1:P
W 1:P
for i ← 1 . . . P do
if i = It then ai
else

i=1 wi
t−1)
t−1 ← It−1

t−1/((cid:80)P

t−1 ∼ Categorical(W 1:P
ai
t−1 )
t ∼ kt(·; x
ai
t−1
xi
t−1 )
t ← wt(x
ai
t−1
t−1   xi
wi
t)
(cid:46) Return an SMC trace

u ← (x  a  IT )
return u

Latent sample
(input to meta-inference sampler)

x

δ

x1
3

x2
3

x3
3

x4
3

I3 = 2

(cid:96)3

x1
2

x2
2

x3
2

x4
2

I2 = 3

(cid:96)2

x1
1

x2
1

x3
1

x4
1

I1 = 1

T = 3

xi
t

Member of ancestral
trajectory

with respect to the posterior p(x|y). Then  this is formally a special case of AIS. However  unless the
Markov chain was initialized near the posterior p(x|y)  the chain will be far from equilibrium during
the burn-in period  and the AIS meta-inference algorithm will be inaccurate.

1 ← x  and samples the other P − 1 particles from the importance distribution k1(x).

Importance sampling with resampling.
Importance sampling with resampling  or SIR [8] can be
seen as a special case of SMC if we set the number of steps to one (T = 1). The trace of the SIR
1 for i ∈ {1  . . .   P} and output particle index I1. Given output
algorithm is then the set of particles xi
sample x  the canonical SMC meta-inference sampler then simply samples I1 ∼ Uniform(1 . . . P ) 
sets xI1
Rejection sampling. To model a rejection sampler for a posterior distribution p(x|y)  we assume
it is tractable to evaluate the unnormalized posterior probability p(x  y). We deﬁne U = {()} as
described in Section 3.1. For meta-inference  we deﬁne Z = p(y) so that ξ(u  x) = p(y)p(x|y) =
p(x  y). It is not necessary to represent the internal random variables of the rejection sampler.

Variational inference. We suppose a variational approximation qθ(x) has been computed through
optimization over the variational parameters θ. We assume that it is possible to sample from
the variational approximation  and evaluate its normalized probability distribution. Then  we use
U = {()} and Z = 1 and ξ(u  x) = qθ(x). This formulation also applies to amortized variational
inference algorithms  which reuse the parameters θ for inference across observation contexts y.

3.3 The auxiliary inference divergence estimator

Consider a probabilistic model p(x  y)  a set of observations y  and two inference algorithms that
approximate p(x|y). One of the two inference algorithms is considered the ‘gold-standard’  and has a
generative inference model (U X   qg) and a meta-inference algorithm (rg  ξg). The second algorithm
is considered the ‘target’ algorithm  with a generative inference model (V X   qt) (we denote a trace
of the target algorithm by v ∈ V)  and a meta-inference algorithm (rt  ξt). This section shows how to
estimate an upper bound on the symmetrized KL divergence between qg(x) and qt(x)  which is:

(cid:20)

(cid:21)

DKL(qg(x) (cid:107) qt(x)) + DKL(qt(x) (cid:107) qg(x)) = Ex∼qg(x)

log

qg(x)
qt(x)

+Ex∼qt(x)

log

(cid:20)

(cid:21)

qt(x)
qg(x)

(2)

We take a Monte Carlo approach. Simple Monte Carlo applied to the Equation (2) requires that qg(x)
and qt(x) can be evaluated  which would prevent the estimator from being used when either inference
algorithm is sampling-based. Algorithm 2 gives the Auxiliary Inference Divergence Estimator

5

(AIDE)  an estimator of the symmetrized KL divergence that only requires evaluation of ξg(u  x) and
ξt(v  x) and not qg(x) or qt(x)  permitting its use with sampling-based inference algorithms.

Algorithm 2 Auxiliary Inference Divergence Estimator (AIDE)
Require: Gold-standard inference model and meta-inference algorithm (U X   qg) and (rg  ξg)
(V X   qt) and (rt  ξt)
Target inference model and meta-inference algorithm
Number of runs of gold-standard algorithm
Ng
Number of runs of meta-inference sampler for gold-standard Mg
Number of runs of target algorithm
Nt
Number of runs of meta-inference sampler for target
Mt

(cid:46) Run gold-standard algorithm  record trace un 1 and output xn

un m ∼ rg(u; xn) (cid:46) Run meta-inference sampler for gold-standard algorithm  on input xn
vn m ∼ rt(v; xn) (cid:46) Run meta-inference sampler for target algorithm  on input xn

for n ← 1 . . . Ng do

un 1  xn ∼ qg(u  x)
for m ← 2 . . . Mg do
for m ← 1 . . . Mt do

for n ← 1 . . . Nt do

n ∼ qt(v  x)
n 1  x(cid:48)
v(cid:48)
for m ← 2 . . . Mt do
n m ∼ rt(v; x(cid:48)
v(cid:48)
for m ← 1 . . . Mg do
n m ∼ rg(u; x(cid:48)
u(cid:48)
ˆD ← 1
Mg
Ng
1
Mt
return ˆD

 1

Ng(cid:88)

log

n=1

(cid:46) Run target algorithm  record trace v(cid:48)

n 1 and output x(cid:48)

n

n) (cid:46) Run meta-inference sampler for target algorithm  on input x(cid:48)
n) (cid:46) Run meta-inference sampler for gold-standard algorithm  on input x(cid:48)

n

n

 +

Nt(cid:88)

n=1

1
Nt

log

 1

Mt
1
Mg

(cid:80)Mt
(cid:80)Mg

m=1 ξt(v(cid:48)
m=1 ξg(u(cid:48)

n m  x(cid:48)
n)
n m  x(cid:48)
n)

(cid:80)Mg
(cid:80)Mt

m=1 ξg(un m  xn)

m=1 ξt(vn m  xn)



(cid:46) ˆD is an estimate of DKL(qg(x)||qt(x)) + DKL(qt(x)||qg(x))

The generic AIDE algorithm above is deﬁned in terms of abstract generative inference models and
meta-inference algorithms. For concreteness  the supplement contains the AIDE algorithm specialized
to the case when the gold-standard is AIS and the target is a variational approximation.
Theorem 1. The estimate ˆD produced by AIDE is an upper bound on the symmetrized KL divergence
in expectation  and the expectation is nonincreasing in AIDE parameters Mg and Mt.

See supplement for proof. Brieﬂy  AIDE estimates an upper bound on the symmetrized divergence in
expectation because it uses unbiased estimates of qt(xn) and qg(xn)−1 for xn ∼ qg(x)  and unbiased
n ∼ qt(x). For Mg = 1 and Mt = 1  AIDE over-estimates
estimates of qg(x(cid:48)
the true symmetrized divergence by:

n) and qt(x(cid:48)

n)−1 for x(cid:48)

(cid:18)

E[ ˆD] − (DKL(qg(x) (cid:107) qt(x)) + DKL(qt(x) (cid:107) qg(x))) =

Ex∼qg(x) [DKL(qg(u|x) (cid:107) rg(u; x)) + DKL(rt(v; x) (cid:107) qt(v|x))]
+ Ex∼qt(x) [DKL(qt(v|x) (cid:107) rt(v; x)) + DKL(rg(u; x) (cid:107) qg(u|x))]

(cid:19) Bias of AIDE

for Mg=Mt=1

(3)

Note that this expression involves KL divergences between the meta-inference sampling distributions
(rg(u; x) and rt(v; x)) and the posteriors in their respective generative inference models (qg(u|x) and
qt(v|x)). Therefore  the approximation error of meta-inference determines the bias of AIDE. When
both meta-inference algorithms are exact (rg(u; x) = qg(u|x) for all u and x and rt(v; x) = qt(v|x)
for all v and x)  AIDE is unbiased. As Mg or Mt are increased  the bias decreases (see Figure 2 and
Figure 4 for examples). If the generative inference model for one of the algorithms does not use a
trace (i.e. U = {()} or V = {()})  then that algorithm does not contribute a KL divergence term to
the bias of Equation (3). The analysis of AIDE is equivalent to that of Grosse et al. [12] when the
target algorithm is AIS and Mt = Mg = 1 and the gold-standard inference algorithm is a rejection
sampler.

4 Related Work

Diagnosing the convergence of approximate inference is a long-standing problem. Most existing work
is either tailored to speciﬁc inference algorithms [13]  designed to detect lack of exact convergence
[1]  or both. Estimators of the non-asymptotic approximation error of general approximate inference

6

Figure 3: AIDE detects when an inference algorithm misses a posterior mode. Left: A bimodal
posterior density  with kernel estimates of the output densities of importance sampling with resampling
(SIR) using two proposals. The ‘broad’ proposal (blue) covers both modes  and the ‘offset’ proposal
(pink) misses the ‘L’ mode. Middle: AIDE detects the missing mode in offset-proposal SIR. Right:
Log marginal likelihood estimates suggest that the offset-proposal SIR is nearly converged.

algorithms have received less attention. Gorham and Mackey [14] propose an approach that applies
to arbitrary sampling algorithms but relies on special properties of the posterior distribution such as
log-concavity. Our approach does not rely on special properties of the posterior distribution.
Our work is most closely related to Bounding Divergences with REverse Annealing (BREAD  [12])
which also estimates upper bounds on the symmetric KL divergence between the output distribution
of a sampling algorithm and the posterior distribution. AIDE differs from BREAD in two ways: First 
whereas BREAD handles single-particle SMC samplers and annealed importance sampling (AIS) 
AIDE handles a substantially broader family of inference algorithms including SMC samplers with
both resampling and rejuvenation steps  AIS  variational inference  and rejection samplers. Second 
BREAD estimates divergences between the target algorithm’s sampling distribution and the posterior
distribution  but the exact posterior samples necessary for BREAD’s theoretical properties are only
readily available when the observations y that deﬁne the inference problem are simulated from the
generative model. Instead  AIDE estimates divergences against an exact or approximate gold-standard
sampler on real (non-simulated) inference problems. Unlike BREAD  AIDE can be used to evaluate
inference in both generative and undirected models.
AIDE estimates the error of sampling-based inference using a mathematical framework with roots
in variational inference. Several recent works have treated sampling-based inference algorithms as
variational approximations. The Monte Carlo Objective (MCO) formalism of Maddison et al. [15]
is closely related to our formalism of generative inference models and meta-inference algorithms—
indeed a generative inference model and a meta-inference algorithm with Z = 1 give an MCO deﬁned
by: L(y  p) = Eu x∼q(u x)[log(p(x  y)/ξ(u  x))]  where y denotes observed data. In independent
and concurrent work to our own  Naesseth et al. [16]  Maddison et al. [15] and Le et al. [17] treat
SMC as a variational approximation using constructions similar to ours. In earlier work  Salimans
et al. [18] recognized that MCMC samplers can be treated as variational approximations. However 
these works are concerned with optimization of variational objective functions instead of estimation
of KL divergences  and do not involve generating a trace of a sampler from its output.

5 Experiments

5.1 Comparing the bias of AIDE for different types of inference algorithms
We used a Bayesian linear regression inference problem where exact posterior sampling is tractable
to characterize the bias of AIDE when applied to three different types of target inference algorithms:
sequential Monte Carlo (SMC)  Metropolis-Hastings (MH)  and variational inference. For the gold-
standard algorithm we used a posterior sampler with a tractable output distribution qg(x)  which does
not introduce bias into AIDE  so that AIDE’s bias could be completely attributed to the approximation
error of meta-inference for each target algorithm. Figure 2 shows the results. The bias of AIDE
is acceptable for SMC  and AIDE is unbiased for variational inference  but better meta-inference
algorithms for MCMC are needed to make AIDE practical for estimating the accuracy of MH.

7

2024100101102103Number of particlesposteriordensityLR100101102103Number of particles0204060Large penalty formissing modeAIDE estimate(nats)Offset proposalBroad proposal100101102103Number of particles6040200Small penaltyLog marginallikelihood (nats)Offset proposalBroad proposalGold-standard5.2 Evaluating approximate inference in a Hidden Markov model
We applied AIDE to measure the approximation error of SMC algorithms for posterior inference in
a Hidden Markov model (HMM). Because exact posterior inference in this HMM is tractable via
dynamic programming  we used this opportunity to compare AIDE estimates obtained using the exact
posterior as the gold-standard with AIDE estimates obtained using a ‘best-in-class’ SMC algorithm as
the gold-standard. Figure 4 shows the results  which indicate AIDE estimates using an approximate
gold-standard algorithm can be nearly identical to AIDE estimates obtained with an exact posterior
gold-standard.

Target algorithms

Measuring accuracy

of target algorithms using
posterior as gold-standard

Ground truth states

SMC prior proposal

1 particle

Posterior marginals

SMC prior proposal

10 particles

Measuring accuracy

of target algorithms using

SMC gold-standard

SMC optimal proposal

1000 particles

(SMC gold standard)

SMC optimal proposal

100 particles

Figure 4: Comparing use of an exact posterior as the gold-standard and a ‘best-in-class’ approximate
algorithm as the gold-standard  when measuring accuracy of target inference algorithms with AIDE.
We consider inference in an HMM  so that exact posterior sampling is tractable using dynamic
programming. Left: Ground truth latent states  posterior marginals  and marginals of the the output
of a gold-standard and three target SMC algorithms (A B C) for a particular observation sequence.
Right: AIDE estimates using the exact gold-standard and using the SMC gold-standard are nearly
identical. The estimated divergence bounds decrease as the number of particles in the target sampler
increases. The optimal proposal outperforms the prior proposal. Increasing Mt tightens the estimated
divergence bounds. We used Mg = 1.

Figure 5: Contrasting AIDE against a heuristic convergence diagnostic for evaluating the accuracy of
approximate inference in a Dirichlet process mixture model (DPMM). The heuristic compares the
expected number of clusters under the target algorithm to the expectation under the gold-standard
algorithm [19]. White circles identify single-particle likelihood-weighting  which samples from the
prior. AIDE clearly indicates that single-particle likelihood-weighting is inaccurate  but the heuristic
suggests it is accurate. Probe functions like the expected number of clusters can be error prone
measures of convergence because they only track convergence along a speciﬁc projection of the
distribution. In contrast  AIDE estimates a joint KL divergence. Shaded areas in both plots show the
standard error. The amount of target inference computation used is the same for the two techniques 
although AIDE performs a gold-standard meta-inference run for each target inference run.

8

150time120state150time120state150time120state150time120stateA150time120stateB150time120stateC100101102Number of particles020406080AIDE estimate (nats)ABC100101102Number of particles020406080AIDE estimate (nats)ABCSMC  prior proposal  1 meta-inference run (Mt=1)SMC  prior proposal  100 meta-inference runs (Mt=100)SMC  optimal proposal  1 meta-inference run (Mt=1)SMC  optimal proposal  100 meta-inference runs (Mt=100)100101102Number of particles0510152025natsLikelihood weightingwith 1 particle appearsleast accurateAIDE estimates100101102Number of particles2.53.03.54.0Average numberof clustersAppears accurateHeuristic diagnosticSMC  prior proposal0 rejuvenation sweepsSMC  optimal proposal0 rejuvenation sweepsSMC  optimal proposal4 rejuvenation sweepsGold-standardLikelihood-weighting(1 particle)5.3 Comparing AIDE to alternative inference evaluation techniques
A key feature of AIDE is that it applies to different types of inference algorithms. We compared AIDE
to two existing techniques for evaluating the accuracy of inference algorithms that share this feature:
(1) comparing log marginal likelihood (LML) estimates made by a target algorithm against LML
estimates made by a gold-standard algorithm  and (2) comparing the expectation of a probe function
under the approximating distribution to the same expectation under the gold-standard distribution
[19]. Figure 3 shows a comparison of AIDE to LML  on a inference problem where the posterior
is bimodal. Figure 5 shows a comparison of AIDE to a ‘number of clusters’ probe function in a
Dirichlet process mixture model inference problem for a synthetic data set. We also used AIDE to
evaluate the accuracy of several SMC algorithms for DPMM inference on a real data set of galaxy
velocities [20] relative to an SMC gold-standard. This experiment is described in the supplement due
to space constraints.

6 Discussion

AIDE makes it practical to estimate bounds on the error of a broad class of approximate inference
algorithms including sequential Monte Carlo (SMC)  annealed importance sampling (AIS)  sampling
importance resampling (SIR)  and variational inference. AIDE’s reliance on a gold-standard inference
algorithm raises two questions that merit discussion:
If we already had an acceptable gold-standard  why would we want to evaluate other inference
algorithms? Gold-standard algorithms such as very long MCMC runs  SMC runs with hundreds of
thousands of particles  or AIS runs with a very ﬁne annealing schedule  are often too slow to use
in production. AIDE make it possible to use gold-standard algorithms during an ofﬂine design and
evaluation phase to quantitatively answer questions like “how few particles or rejuvenation steps
or samples can I get away with?” or “is my fast variational approximation good enough?”. AIDE
can thus help practitioners conﬁdently apply Monte Carlo techniques in challenging  performance
constrained applications  such as probabilistic robotics or web-scale machine learning. In future
work we think it will be valuable to build probabilistic models of AIDE estimates  conditioned on
features of the data set  to learn ofﬂine what problem instances are easy or hard for different inference
algorithms. This may help practitioners bridge the gap between ofﬂine evaluation and production
more rigorously.
How do we ensure that the gold-standard is accurate enough for the comparison with it to be
meaningful? This is an intrinsically hard problem—we are not sure that near-exact posterior inference
is really feasible  for most interesting classes of models. In practice  we think that gold-standard
inference algorithms will be calibrated based on a mix of subjective assumptions and heuristic
testing—much like models themselves are tested. For example  users could initially build conﬁdence
in a gold-standard algorithm by estimating the symmetric KL divergence from the posterior on
simulated data sets (following the approach of Grosse et al. [12])  and then use AIDE with the trusted
gold-standard for a focused evaluation of target algorithms on real data sets of interest. We do not
think the subjectivity of the gold-standard assumption is a unique limitation of AIDE.
A limitation of AIDE is that its bias depends on the accuracy of meta-inference  i.e.
inference
over the auxiliary random variables used by an inference algorithm. We currently lack an accurate
meta-inference algorithm for MCMC samplers that do not employ annealing  and therefore AIDE is
not yet suitable for use as a general MCMC convergence diagnostic. Research on new meta-inference
algorithms for MCMC and comparisons to standard convergence diagnostics [21  22] are needed.
Other areas for future work include understanding how the accuracy of meta-inference depends
on parameters of an inference algorithm  and more generally what makes an inference algorithm
amenable to efﬁcient meta-inference.
Note that AIDE does not rely on asymptotic exactness of the inference algorithm being evaluated.
An interesting area of future work is in using AIDE to study the non-asymptotic error of scalable but
asymptotically biased sampling algorithms [23]. It also seems fruitful to connect AIDE to results
from theoretical computer science  including the computability [24] and complexity [25–28] of
probabilistic inference. It should be possible to study the computational tractability of approximate
inference empirically using AIDE estimates  as well as theoretically using a careful treatment of the
variance of these estimates. It also seems promising to use ideas from AIDE to develop Monte Carlo
program analyses for samplers written in probabilistic programming languages.

9

Acknowledgments

This research was supported by DARPA (PPAML program  contract number FA8750-14-2-0004) 
IARPA (under research contract 2015-15061000003)  the Ofﬁce of Naval Research (under research
contract N000141310333)  the Army Research Ofﬁce (under agreement number W911NF-13-1-
0212)  and gifts from Analog Devices and Google. This research was conducted with Government
support under and awarded by DoD  Air Force Ofﬁce of Scientiﬁc Research  National Defense
Science and Engineering Graduate (NDSEG) Fellowship  32 CFR 168a.

References
[1] Mary Kathryn Cowles and Bradley P Carlin. Markov chain Monte Carlo convergence diagnos-
tics: a comparative review. Journal of the American Statistical Association  91(434):883–904 
1996.

[2] Christophe Andrieu  Arnaud Doucet  and Roman Holenstein. Particle Markov chain Monte
Carlo methods. Journal of the Royal Statistical Society: Series B (Statistical Methodology)  72
(3):269–342  2010.

[3] Roger B Grosse  Zoubin Ghahramani  and Ryan P Adams. Sandwiching the marginal likelihood

using bidirectional Monte Carlo. arXiv preprint  arXiv:1511.02543  2015.

[4] Nicholas Metropolis  Arianna W Rosenbluth  Marshall N Rosenbluth  Augusta H Teller  and
Edward Teller. Equation of state calculations by fast computing machines. The Journal of
Chemical Physics  21(6):1087–1092  1953.

[5] W Keith Hastings. Monte Carlo sampling methods using Markov chains and their applications.

Biometrika  57(1):97–109  1970.

[6] Pierre Del Moral  Arnaud Doucet  and Ajay Jasra. Sequential Monte Carlo samplers. Journal

of the Royal Statistical Society: Series B (Statistical Methodology)  68(3):411–436  2006.

[7] Radford M Neal. Annealed importance sampling. Statistics and Computing  11(2):125–139 

2001.

[8] Donald B Rubin. Using the SIR algorithm to simulate posterior distributions. Bayesian statistics 

3(1):395–402  1988.

[9] Adrian FM Smith and Alan E Gelfand. Bayesian statistics without tears: a sampling-resampling

perspective. The American Statistician  46(2):84–88  1992.

[10] Michael I Jordan  Zoubin Ghahramani  Tommi S Jaakkola  and Lawrence K Saul. An in-
troduction to variational methods for graphical models. Machine Learning  37(2):183–233 
1999.

[11] Noah Goodman  Vikash K Mansinghka  Daniel M Roy  Keith Bonawitz  and Joshua B Tenen-
baum. Church: a language for generative models with non-parametric memoization and
approximate inference. In Uncertainty in Artiﬁcial Intelligence  2008.

[12] Roger B Grosse  Siddharth Ancha  and Daniel M Roy. Measuring the reliability of MCMC
In Advances in Neural Information Processing

inference with bidirectional Monte Carlo.
Systems (NIPS)  pages 2451–2459  2016.

[13] Augustine Kong. A note on importance sampling using standardized weights. Technical Report

348  University of Chicago  Department of Statistics  1992.

[14] Jackson Gorham and Lester Mackey. Measuring sample quality with Stein’s method.

Advances in Neural Information Processing Systems (NIPS)  pages 226–234  2015.

In

[15] Chris J Maddison  Dieterich Lawson  George Tucker  Nicolas Heess  Mohammad Norouzi 
Andriy Mnih  Arnaud Doucet  and Yee Whye Teh. Filtering variational objectives. arXiv
preprint  arXiv:1705.09279  2017.

10

[16] Christian A Naesseth  Scott W Linderman  Rajesh Ranganath  and David M Blei. Variational

sequential Monte Carlo. arXiv preprint  arXiv:1705.11140  2017.

[17] Tuan Anh Le  Maximilian Igl  Tom Jin  Tom Rainforth  and Frank Wood. Auto-encoding

sequential Monte Carlo. arXiv preprint  arXiv:1705.10306  2017.

[18] Tim Salimans  Diederik Kingma  and Max Welling. Markov chain Monte Carlo and variational
inference: Bridging the gap. In International Conference on Machine Learning (ICML)  pages
1218–1226  2015.

[19] Yener Ulker  Bilge Günsel  and Taylan Cemgil. Sequential Monte Carlo samplers for Dirichlet

process mixtures. In Artiﬁcial Intelligence and Statistics (AISTATS)  pages 876–883  2010.

[20] Michael J Drinkwater  Quentin A Parker  Dominique Proust  Eric Slezak  and Hernán Quin-
tana. The large scale distribution of galaxies in the Shapley supercluster. Publications of the
Astronomical Society of Australia  21(1):89–96  2004.

[21] Andrew Gelman and Donald B Rubin. Inference from iterative simulation using multiple

sequences. Statistical Science  7(4):457–472  1992.

[22] John Geweke. Getting it right: Joint distribution tests of posterior simulators. Journal of the

American Statistical Association  99(467):799–804  2004.

[23] Elaine Angelino  Matthew James Johnson  and Ryan P Adams. Patterns of scalable Bayesian

inference. Foundations and Trends in Machine Learning  9(2-3):119–247  2016.

[24] Nathanael L Ackerman  Cameron E Freer  and Daniel M Roy. On the computability of

conditional probability. arXiv preprint  arXiv:1005.3014  2010.

[25] Cameron E Freer  Vikash K Mansinghka  and Daniel M Roy. When are probabilistic programs
probably computationally tractable? In NIPS Workshop on Advanced Monte Carlo Methods
with Applications  2010.

[26] Jonathan H Huggins and Daniel M Roy. Convergence of sequential Monte Carlo-based sampling

methods. arXiv preprint  arXiv:1503.00966  2015.

[27] Sourav Chatterjee and Persi Diaconis. The sample size required in importance sampling. arXiv

preprint  arXiv:1511.01437  2015.

[28] S Agapiou  Omiros Papaspiliopoulos  D Sanz-Alonso  and AM Stuart. Importance sampling:

Intrinsic dimension and computational cost. Statistical Science  32(3):405–431  2017.

11

,Marco Cusumano-Towner
Vikash Mansinghka