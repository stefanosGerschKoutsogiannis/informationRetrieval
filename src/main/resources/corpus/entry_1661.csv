2012,Dynamic Pruning of Factor Graphs for Maximum Marginal Prediction,We study the problem of maximum marginal prediction (MMP) in probabilistic graphical models  a task that occurs  for example  as the Bayes optimal decision rule under a Hamming loss. MMP is typically performed as a two-stage procedure: one estimates each variable's marginal probability and then forms a prediction from the states of maximal probability. In this work we propose a simple yet effective technique for accelerating MMP when inference is sampling-based: instead of the above two-stage procedure we directly estimate the posterior probability of each decision variable. This allows us to identify the point of time when we are sufficiently certain about any individual decision. Whenever this is the case  we dynamically prune the variable we are confident about from the underlying factor graph. Consequently  at any time only samples of variable whose decision is still uncertain need to be created. Experiments in two prototypical scenarios  multi-label classification and image inpainting  shows that adaptive sampling can drastically accelerate MMP without sacrificing prediction accuracy.,Dynamic Pruning of Factor Graphs
for Maximum Marginal Prediction

Christoph H. Lampert

IST Austria (Institute of Science and Technology Austria)

Am Campus 1  3400 Klosterneuburg  Austria

http://www.ist.ac.at/∼chl

chl@ist.ac.at

Abstract

We study the problem of maximum marginal prediction (MMP) in probabilistic
graphical models  a task that occurs  for example  as the Bayes optimal decision
rule under a Hamming loss. MMP is typically performed as a two-stage proce-
dure: one estimates each variable’s marginal probability and then forms a predic-
tion from the states of maximal probability.
In this work we propose a simple yet effective technique for accelerating MMP
when inference is sampling-based: instead of the above two-stage procedure we
directly estimate the posterior probability of each decision variable. This allows us
to identify the point of time when we are sufﬁciently certain about any individual
decision. Whenever this is the case  we dynamically prune the variables we are
conﬁdent about from the underlying factor graph. Consequently  at any time only
samples of variables whose decision is still uncertain need to be created.
Experiments in two prototypical scenarios  multi-label classiﬁcation and image
inpainting  show that adaptive sampling can drastically accelerate MMP without
sacriﬁcing prediction accuracy.

Introduction

1
Probabilistic graphical models (PGMs) have become useful tools for classical machine learning
tasks  such as multi-label classiﬁcation [1] or semi-supervised learning [2]  as well for many real-
world applications  for example image processing [3]  natural language processing [4]  bioinfor-
matics [5]  and computational neuroscience [6]. Despite their popularity  the question of how to
best perform (approximate) inference in any given graphical models is still far from solved. While
variational approximations and related message passing algorithms have been proven useful for cer-
tain classes of models (see [7] for an overview)  there is still a large number of cases for which
sampling-based approaches are the safest choice. Unfortunately  inference by sampling is often
computationally costly: many samples are required to reach a conﬁdent result  and generating the
individual samples can be a complex task in itself  in particular if the underlying graphical model is
large and highly connected.
In this work we study a particular inference problem: maximum marginal prediction (MMP) in
binary-valued PGMs  i.e. the task of determining for each variable in the graphical model which of
its states has highest marginal probability. MMP occurs naturally as the Bayes optimal decision rule
under Hamming loss [8]  and it has also found use as a building block for more complex prediction
tasks  such as M-best MAP prediction [9]. The standard approach to sampling-based MMP is
to estimate each variable’s marginal probability distribution from a set of samples from the joint
probability  and for each variable pick the state of highest estimated marginal probability. In this
work  we propose an almost as simple  but more efﬁcient way. We introduce one binary indicator
variable for each decision we need to make  and keep estimates of the posterior probabilities of
each of these during the process of sampling. As soon as we are conﬁdent enough about any of

1

the decisions  we remove it from the factor graph that underlies the sampling process  so no more
samples are generated for it. Consequently  the factor graph shrinks over time  and later steps in the
sampling procedure are accelerated  often drastically so.
Our main contribution lies in the combination of two relatively elementary components that we
will introduce in the following section: an estimate for the posterior distributions of the decision
variables  and a mean ﬁeld-like construction for removing individual variables from a factor graph.

p(x) ∝ exp(cid:0) − E(x)(cid:1)

(cid:88)

2 Adaptive Sampling for Maximum Marginal Prediction
Let p(x) be a ﬁxed probability distribution over the set X = {0  1}V of binary labelings of a vertex
set V = {1  . . .   n}. We assume that p is given to us by means of a factor graph  G = (V F)  with
factor set F = {F1 . . .   Fk}. Each factor  Fj ⊂ V   has an associated log-potential  ψj  which is a
real-valued function of only the variables occurring in Fj. Writing xFj = (xi)i∈Fj we have

with E(x) =

(cid:80)m

F∈F ψF (xF ).

(1)
for any x ∈ {0  1}V . Our goal is maximum marginal prediction  i.e. to infer the values of decision
variables (zi)i∈V that are deﬁned by zi := 0 if µi ≤ 0.5  and zi := 1 otherwise  where µi := p(xi =
1) is the marginal probability of the ith variable taking the value 1. Computing the marginals µi in a
loopy graphical model is in general #P-complete [10]  so one has to settle for approximate marginals
and approximate predictions.
In this work  we assume access to a suitable constructed sampler
based on the Markov chain Monte Carlo (MCMC) principle [11  12]  e.g. a Gibbs sampler [3] It
produces a chain of states Sm = {x(1)  . . .   x(N )}  where each x(i) is a random sample from the
joint distribution p(x). From the set of sample we can compute an estimate  ˆµi = 1
of
the true marginal  µi  and make approximate decisions: ˆzi := 1 if and only if ˆµi ≥ 0.5. Under mild
m
conditions on the sampling procedure the law of large number guarantees that limN→∞ ˆµi = µi 
and the decisions will become correct almost surely.
The main problem with sampling-based inference is when to stop sampling [13]. The more samples
we have  the lower the variance on the estimates  so the more conﬁdent we can be about our deci-
sions. However  each sample we generate increases the computational cost at least proportionally to
the numbers of factors and variables involved. At the same time  the variance of the estimators ˆµi
is reduced only proportionally to the square root of the sample size. In combination  this means that
often  one spends a large amount of computational resources on a small win in predictive accuracy.
In the rest of this section  we explain our proposed idea of adaptive sampling in graphical models 
which reduces the number of variables and factors during the course of the sampling procedure.
As an illustrative example we start by the classical situation of adaptive sampling in the case of a
single binary variable. This is a special case of Bayesian hypothesis selection  and –for the case of
i.i.d. data– has recently also been rediscovered in the pattern recognition literature  for example for
evaluating decision trees [14]. We then introduce our proposed extensions to correlated samples  and
show how the per-variable decisions can be applied in the graphical model situation with potentially
many variables and dependencies between them.

j=1 x(j)

i

2.1 Adaptive Sampling of Binary Variables
Let x be a single binary variable  for which we have a set of samples  S = {x(1)  . . .   x(N )} 
available. The main insight lies in the fact that even though samples are used to empirically estimate
the (marginal) probability µ  the latter is not the actual quantity of interest to us. Ultimately  we are
only interested in the value of the associated decision variable z.

Independent samples. Assuming for the moment that the samples are independent (i.i.d.)  we can
derive an analytic expression for the posterior probability of z given the observed samples 

p(z = 0|S) =

p(q|S)dq

(2)

(cid:90) 1

2

0

2

where p(q|S) is the conditional probability density for µ having the value q. Applying Bayes’ rule
with likelihood p(x|q) = qx(1 − q)1−x and uniform prior  p(q) = 1  results in

(cid:90) 1

2

0

=

where m = (cid:80)N

1

B(m+ 1  N−m+1)

qm(1−q)N−m dq = I 1

2

(m+1  N−m+1) 

(3)

j=1 x(j). The normalization factor B(α  β) = Γ(α)Γ(β)

Γ(α+β)

is the beta function; the
2). In combination  they form the

integral is called the incomplete beta function (here evaluated at 1
regularized incomplete beta function Ix(α  β) [15].
From the above derivation we obtain a stopping criterion of -conﬁdence: given any number of
samples we compute p(z = 0|S) using Equation (3). If its value is above 1 −   we are -conﬁdent
that the correct decision is z = 0. If it is below   we are equally conﬁdent that the correct decision
is z = 1. Only if it lies inbetween we need to continue sampling. An analogue derivation to the
above leads to a conﬁdence bound for estimates of the marginal probability  ˆµ = m/N  itself:

p(|ˆµ − µ| ≤ δ|S) = Iˆµ+δ(m+1  N−m+1) − Iˆµ−δ(m+1  N−m+1).

(4)
Note that both tests are computable fast enough to be done after each sample  or small batches of
samples. Evaluating the regularized incomplete beta function does not require numeric integration 
and for ﬁxed parameter  the values N and m that bound the regions of conﬁdence can also be
tabulated [16]. A ﬁgure illustrating the difference between conﬁdence in the MMP  and conﬁdence
in the estimated marginals can be found in the supplemental material. It shows that only relatively
few independent samples (tens to hundreds) are sufﬁcient to get a very conﬁdent MMP decision 
if the actual marginals are close to 0 or 1. Intuitively  this makes sense  since in this situation a
even coarse estimate of the marginal is sufﬁcient to make of a decision with low error probability.
Only if the true marginal lies inside of a relatively narrow interval around 0.5  the MMP decision
becomes hard  and a large number of samples will be necessary to make a conﬁdent decision. Our
experiments in Section 4 will show that in practical problem where the probability distribution is
learned from data  the regions close to 0 and 1 are in fact the most relevant ones.

Dependent samples. Practical sampling procedures  such as MCMC  do not create i.i.d. samples 
but dependent ones. Using the above bounds directly with these would make the tests overconﬁdent.
We overcome this problem  approximately  by borrowing the concept of effective sample size (ESS)
from the statistics literature. Intuitively  the ESS reﬂects how many independent samples  N(cid:48)  a set of
N correlated sample is equivalent to. In ﬁrst order 1  one estimates the effective sample size as N(cid:48) =
1−r
1+r N  where r is the ﬁrst order autocorrelation coefﬁcient  r = 1
  and
N−1
σ2 is the estimated variance of the sample sequence. Consequently  we can adjust the conﬁdence
tests deﬁned above to correlated data: we ﬁrst collecting a small number of samples  N0  which we
use to estimate initial values of σ2 and r. Subsequently  we estimate the conﬁdence of a decision by
(5)
i.e. we replace the sample size N by the effective sample size N(cid:48) and the raw count m by its adjusted
value ˆµN(cid:48).

(ˆµN(cid:48) + 1  (1 − ˆµ)N(cid:48) + 1) 

p(z = 0|S) = I 1

(cid:80)N−1

(x(j)−ˆµ)(x(j+1)−ˆµ)

j=1

σ2

2

2.2 Adaptive Sampling in Graphical Models

In this section we extend the above conﬁdence criterion from single binary decisions to the situation
of joint sampling from the joint probability of multiple binary variables. Note that we are only inter-
ested in per-variable decisions  so we can treat the value of each variable x(j)
in a joint sample x(j) as
a separate sample from the marginal probability p(xi). We will have to take the dependence between
different samples x(j)
into account  but between variable dependencies within a sample do
not pose problems. Consequently  estimate the conﬁdence of any decision variable zi is straight
forward from Equation (5)  applied separately to the binary sample set Si = {x(1)
}. Note
that all quantities deﬁned above for the single variable case need to be computed separately for each
decision. For example  each variable has its own autocorrelation estimate and effective sample size.

  . . .   x(N )

and x(k)

i

i

i

i

i

1Many more involved methods for estimating the effective sample size exist  see  for example  [17]  but in

our experiments the ﬁrst-order method proved sufﬁcient for our purposes.

3

Computing p(xu) = (cid:80)

The difference to the binary situation lies in what we do when we are conﬁdent enough about the
decision of some subset of variables  V c ⊂ V . Simply stopping all sampling would be too risky 
since we are still uncertain about the decisions of V u := V \ V c. Continuing to sample until we are
certain about all decision will be wasteful  since we know that variables with marginal close to 0.5
require many more samples than others for a conﬁdent decision. We therefore propose to continue
sampling  but only for the variables about which we are still uncertain. This requires us to derive an
expression for p(xu)  the marginal probability of all variables that we are still uncertain about.

¯xc∈{0 1}V c p(¯xc  xu) exactly is almost always infeasible  otherwise  we
would not have needed to resort to sampling based inference in the ﬁrst place. An alternative idea
would be to continue using the original factor graph  but to clamp all variables we are certain about
to their MMP values. This is computationally feasible  but it results in samples from a conditional
distribution  p(xu|xc = zc)  not from the desired marginal one. The new construction that we in-
troduce combines advantages of both previous ideas: it is computationally as efﬁcient as the value
clamping  but it uses a distribution that approximates the marginal distribution as closely as possible.
Similar as in mean-ﬁeld methods [7]  the main step consists of ﬁnding distributions q and q(cid:48) such
that p(x) ≈ q(xu)q(cid:48)(xc). Subsequently  q(xu) can be used as approximate replacement to p(xu) 
¯xc∈{0 1}V c q(cid:48)(¯xc)q(xu) = q(xu). The main difference to
mean-ﬁeld inference lies in the fact that q and q(cid:48) have different role in our construction. For q(cid:48) we
prefer a distribution that factorizes over the variables that we are conﬁdent about. Because we want
q also to respect the marginal probabilities  ˆµi for i ∈ V c  as estimated them from the sampling
i (1 − ˆµi)xi. The distribution q contain all variables
that we are not yet conﬁdent about  so we want to avoid making any limiting assumptions about its
potential values or structure. Instead  we deﬁne it as the solution of minimizing KL(p|qq(cid:48)) over all
distributions q  which yields the solution

because p(xu) =(cid:80)
¯xc∈{0 1}V c p(x) ≈(cid:80)
process so far  we obtain q(cid:48)(xc) = (cid:81)

What remains is to deﬁne factors F(cid:48) and log-potentials ψ(cid:48)  such that q(xu) ∝ exp(cid:0) −
F (xF )(cid:1) while also allowing for efﬁcient sampling from q. For this we partition the orig-
(cid:80)
F∈F(cid:48) ψ(cid:48)

q(xu) ∝ exp( −E¯xc∼q(cid:48)(xc){E(¯xc  xu)} ).

inal factor set into three disjoint sets  F = F c ∪ F u ∪ F0  with F c := {F ⊂ F : F ⊂ V c} 
F u := {F ⊂ F : F ⊂ V u}  and F0 := F \ (F c ∪ F u). Each factor F0 ∈ F0 we split further into
its certain and uncertain components  F c
(cid:88)
With this we obtain a decomposition of the exponent in Equation (6):
E¯xc∼q(cid:48){E(¯xc  xu)} =

0 ⊂ V u  respectively.
0 ⊂ V c and F u
(cid:88)
(cid:88)

q(cid:48)(¯xc)ψF c (xF c) +

ψFu (xFu)+

(cid:88)

(cid:88)

i∈V c ˆµxi

q(cid:48)(¯xF c

)ψF (¯xF c

  xF u

)

(6)

0

0

0

F c∈F c

¯xF c

Fu∈F u

F0∈F0

¯xF c
0

(cid:80){F u=F∩V u:F∈F0} ψ(cid:48)

The ﬁrst sum is a constant with respect to xu  so we can disregard it in the construction of F(cid:48). The
factors and log-potentials in the second sum already depend only on V u  so we can re-use them
F = ψF for every F ∈ F u. The third sum we rewrite as
in unmodiﬁed form for F(cid:48)  we set ψ(cid:48)
(cid:88)
F u (xF u )  with

i (1 − ˆµi)1−¯xi(cid:3)ψF (¯xc  xu).

ψ(cid:48)
F u (xu) :=

(cid:2) (cid:89)

ˆµ¯xi

(7)

¯xc∈{0 1}Fc

i∈Fc

q(xu) ∝ exp(cid:0) (cid:88)

F (xF )(cid:1)

ψ(cid:48)

F∈F(cid:48)

for any F ∈ F0  where we have made use of the explicit form of ¯q. If factors with identical variable
set occur during this construction  we merge them by summing their log-potentials. Ultimately  we
obtain a new factor set F(cid:48) := F u ∪ {F ∩ V u : F ∈ F0}  and probability distribution

for xu ∈ {0  1}V u

.

(8)

Note that during the process  not only the number of variables is reduced  but also the number of
factors and the size of each factor can never grow. Consequently  if sampling was feasible for the
original distribution p  it will also be feasible for q  and potentially more efﬁcient.

3 Related Work
Sequential sampling with the option of early stopping has a long tradition in Bayesian statistics. First
introduced by Wald in 1945 [18]  the ability to continuously accumulate information until a decision
can be made with sufﬁcient conﬁdence was one of the key factors that contributed to the success of

4

Bayesian reasoning for decision making. Today  it has been a standard technique in areas as diverse
as clinical medicine (e.g. for early stop of drug trials [19])  social sciences (e.g. for designing and
evaluating experiments [20])  and economics (e.g. in modelling stock market behavior [21]).
In current machine learning research  sequential sampling is used less frequently for making indi-
vidual decisions  but in the form of MCMC it has become one of the most successful techniques for
statistical inference of probability distributions with many dependent variables [12  22]. Neverthe-
less  to the best of our knowledge  the method we propose is the ﬁrst one that performs early stopping
of subsets of variables in this context. Many other approaches to reduce the complexity of sampling
iterations exist  however  for example to approximate complex graphical models by simpler ones 
such as trees [23]  or loopy models of low treewidth [24]. These fall into a different category than the
proposed method  though  as they are usually performed statically and prior to the actual inference
step  so they cannot dynamically assign computational resources where they are needed most. Beam
search [25] and related techniques take an orthogonal approach to ours. They dynamically exclude
low-likelihood label combinations from the inference process  but they keep the size and topology of
the factor graph ﬁxed. Select and sample [26] disregards a data-dependent subset of variables dur-
ing each sampling iterations. It is not directly applicable in our situation  though  since it requires
that the underlying graphical model is bipartite  such that the individual variables are conditionally
independent of each other. Given their complementary nature  we believe that the idea of combining
adaptive MMP with beam search and/or select and sample could be a promising direction for future
work.

4 Experimental Evaluation
To demonstrate the effect of adaptive MMP compared to naive MMP  we performed experiments in
two prototypical applications: multi-label classiﬁcation and binary image inpainting. In both tasks 
performance is typically measured by the Hamming loss  so MMP is the preferred method of test
time prediction.

4.1 Multi-Label Classiﬁcation
In multi-label classiﬁcation  the task is to predict for each input y ∈ Y  which labels out of a label
set L = {1  . . .   K} are correct. The difference to multi-class classiﬁcation is that several labels can
be correct simultaneously  or potentially none at all. Multi-label classiﬁcation can be formulated
as simultaneous prediction of K binary labels (xi)i=1 ...K  where xi = 1 indicates that the label i
is part of the prediction  and xi = 0 indicates that it is not. Even though multi-label classiﬁcation
can in principle be solved by training K independent predictors  several studies have shown that
by making use of dependencies between label  the accuracy of the individual predictions can be
improved [1  27  28].
For our experiments we follow [1] in using a fully-connected conditional random ﬁeld model.
Given an input y  each label variable i has a unary factor Fi = {i} with log-linear potential
ψi(xi) = (cid:104)wi  y(cid:105)xi  where wi is a label-speciﬁc weight vector that was learned from training
data. Additionally there are K(K − 1)/2 pairwise factors  Fij = {i  j}  with log-potentials
ψij(xi  xj) = ηijxixj. Its free parameter ηij is learned as well. The resulting conditional joint
distribution has the form of a Boltzmann machine  p(x|y) ∝ exp(−Ey(x))  with energy function
j=i+1 ηijxixj in minimal representation  where ηi and ηij depend
on y. We downloaded several standard datasets and trained the CRF on each of them using a stochas-
tic gradient descent procedure based on the sgd2 package. The necessary gradients are computing
using a junction tree algorithms for problems with 20 variables or less  and by Gibbs sampling
otherwise. For model selection  when required  we used 10-fold cross-validation on the training set.
Note that our goal in this experiment is not to advocate a new model multi-label classiﬁcation  but to
create probability distributions as they would appear in real problems. Nevertheless  we also report
classiﬁcation accuracy in Table 1 to show that a) the learned models have similar characteristics as
earlier work  in particular to [29]  where the an identical model was trained using structured SVM
learning  and b) adaptive MMP can achieve as high prediction accuracy as ordinary Gibbs sampling 
as long as the conﬁdence parameter  is not chosen overly optimistically. In fact  in many cases even

i=1 ηixi +(cid:80)L

Ey(x) =(cid:80)K

(cid:80)L

i=1

2http://leon.bottou.org/projects/sgd

5

SCENE

RCV1-10 [29]

MEDIAMILL-10 [29]

Dataset

SYNTH1 [29]
SYNTH2 [29]

YEAST

TMC2007
AWA [30]
MEDIAMILL

RCV1

[28]
—
—

[29]
#Labels #Train #Test
6.9
5045
471
7.0
10000
1000
10.1 9.5 ± 2.1
1196
1211
5.6
2916
2914
18.8
29415 12168
20.2 20.2 ± 1.3
917
1500
7077 — 3.3 ± 2.7
21519
24295
6180 —
29415 12168 — 3.6 ± 0.5
3000

6
10
6
10
10
14
22
85
101
103

3000 —

—
—

—

—

Exact Gibbs
5.3
5.2
10.0
10.0
10.3
10.4
4.2
4.2
18.6
18.4
20.2
20.0
5.3
5.3
— 32.2
3.7
—
—
1.5

Proposed

5.2 / 5.2 / 5.2
10.0/10.0/10.0
10.2/10.2/10.2
4.6 / 4.4 / 4.2
19.0/18.6/18.4
23.4/21.4/20.5
5.3 / 5.3 / 5.3
32.7/32.7/32.7
3.6 / 3.5 / 3.6
1.7 / 1.6 / 1.5

Table 1: Multi-label classiﬁcation. Dataset characteristics (number of labels  number of training
examples  number of test examples) and classiﬁcation error rate in percent. [29] used the same model
as we do  but trained it using a structured SVM framework and predicted using MAP. [28] compared
12 different multi-label classiﬁcation techniques  we report their mean and standard deviation. The
remaining columns give MMP prediction accuracy of the trained CRF models: Exact computes the
exact marginal values by a junction tree  Gibbs and Proposed performs ordinary Gibbs sampling  or
the proposed adaptive version with  = 10−2/10−5/10−8  both run for up to 500 iterations.

Figure 1: Results of adaptive pruning on RCV1 dataset for  = 10−2  10−5  10−8 (left to right).
x-axis: regularization parameter C used for training  y-axis: ratio of iterations/variables/factors/
runtime used by adaptive sampling relative to Gibbs sampling.

a relative large value  such as  = 0.01 results in a smaller loss of accuracy than the potential 1% 
but overall  a value of 10−5 or less seems advisable.
Figures 1 and 2 show in more detail how the adaptive sampling behaves on two exemplary datasets
with respect to four aspects: the number of iterations  the number of variables  the number of fac-
tors  and the overall runtime. For each aspect we show a box plot of the corresponding relative
quantity compared to the Gibbs sampler. For example  a value of 0.5 in iterations means that the
adaptive sample terminated after 250 iterations instead of the maximum of 500  because it was con-
ﬁdent about all decisions. Values of 0.2 in variables and factors means that the number of variable
states samples by the adaptive sampler was 20%  and the number of factors in the corresponding
factor graphs was 10% of the corresponding quantities for the Gibbs sampler. Within each plot  we
reported results for the complete range of regularization parameters in order to illustrate the effect
that regularization has on the distribution of marginals.

6

IterationsVariablesRuntimeFactors0.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.000.050.100.150.200.250.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.0Figure 2: Results of adaptive pruning on YEAST dataset for  = 10−2  10−5  10−8 (left to right).
x-axis: regularization parameter C used for training  y-axis: ratio of iterations/variables/factors/
runtime used by adaptive sampling relative to Gibbs sampling. Note that the scaling of the y-axis
differs between columns.

Figure 1 shows results for the relatively simple RCV1 dataset. As one can see  a large number of
variables and factors are removed quickly from the factor graph  leading to a large speedup compared
to the ordinary Gibbs sampler. In fact  as the ﬁrst row shows  it was possible to make a conﬁdent
decision for all variables far before the 500th iteration  such that the adaptive method terminated
early. As a general trend  the weaker the regularization (larger C value in the plot)  the earlier the
adaptive sampler is able to remove variables and factors  presumably because more extreme values
of the energy function result in more marginal probabilities close to 0 or 1. A second insight is that
despite the exponential scaling of the conﬁdence parameter between the columns  the runtime grows
only roughly linearly. This indicates that we can choose  conservatively without taking a large
performance hit. On the hard YEAST dataset (Figure 2) in the majority of cases the adaptive sampling
does not terminate early  indicating that some of the variables have marginal probabilities close to
0.5. Nevertheless  a clear gain in speed can be observed  in particular in the weakly regularized case 
indicating that nevertheless  many tests for conﬁdence are successful early during the sampling.

4.2 Binary Image Inpainting

Inpainting is a classical image processing task: given an image (in our case black-and-white) in
which some of the pixels are occluded or have missing values  the goal is to predict a completed
image in which the missing pixels are set to their correct value  or at least in a visually pleasing
way. Image inpainting has been tackled successfully by grid-shaped Markov random ﬁeld models 
where each pixel is represented by a random variable  unary factors encode local evidence extracted
from the image  and pairwise terms encode the cooccurrence of pixel value. For our experiment  we
use the Hard Energies from Chinese Characters (HECC) dataset [31]  for which the authors provide
pre-computed energy functions. The dataset has 100 images  each with between 4992 and 17856
pixels  i.e. binary variables. Each variable has one unary and up to 64 pairwise factors  leading to an
overall factor count of 146224 to 553726. Because many of the pairwise factors act repulsively  the
underlying energy function is highly non-submodular  and sampling has proven a more successful
mean of inference than  for example  message passing [31].
Figure 3 shows exemplary results of the task. The complete set can be found in the supplemental
material. In each case  we ran an ordinary Gibbs sampler and the adaptive sampler for 30 seconds 

7

IterationsVariablesRuntimeFactors0.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.000.050.100.150.200.250.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.10.20.30.40.50.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.00.010.11101001000100000.00.20.40.60.81.0input

Gibbs

 = 10−2

 = 10−5

 = 10−8

Figure 3: Example results of binary image inpainting on HECC dataset. From left to right: image to
be inpainted  result of Gibbs sampling  result of adaptive sampling  where each method was run for
up to 30 seconds per image. The left plot of each result shows the marginal probabilities  the right
plot shows how often each pixel was sampled on a log scale from 10 (dark blue) to 100000 (bright
red). Gibbs sampling treats all pixels uniformly  reaching around 100 sampling sweeps within the
given time budget. Adaptive sampling stops early for parts of the image that it is certain about  and
concentrates its samples in the uncertain regions  i.e. pixels with marginal probability close to 0.5.
The larger   the more pronounced this effect it.

and we visualize the resulting marginal probabilities as well as the number of samples created for
each of the pixels. One can see that adaptive sampling comes to a more conﬁdent prediction within
the given time budget. The larger the  parameter  the earlier to stops sampling the ’easy’ pixels 
spending more time on the difﬁcult cases  i.e. pixel with marginal probability close to 0.5.

5 Summary and Outlook

In this paper we derived an analytic expression for how conﬁdent one can be about the maximum
marginal predictions (MMPs) of a binary graphical model after a certain number of samples  and
we presented a method for pruning factor graphs when we want to stop sampling for a subset of
the variables. In combination  this allowed us to more efﬁciently infer the MMPs: starting from
the whole factor graph  we sample sequentially  and whenever we are sufﬁciently certain about a
prediction  we prune it from the factor graph before continuing to sample. Experiments on multi-
label classiﬁcation and image inpainting show a clear increase in performance at virtually no loss in
accuracy  unless the conﬁdence is chosen too optimistically.
Despite the promising results there are two main limitations that we plan to address. On the one
hand  the multi-label experiments showed that sometimes  a conservative estimate of the conﬁdence
is required to achieve highest accuracy. This is likely a consequence of the fact that our pruning
uses the estimated marginal to build a new factor graph  and even if the decision conﬁdence is high 
the marginals can still vary considerately. We plan to tackle this problem by also integrating bounds
on the marginals with data-dependent conﬁdence into our framework. A second limitation is that
we can currently only handle binary-valued labelings. This is sufﬁcient for multi-label classiﬁcation
and many problems in image processing  but ultimately  one would hope to derive similar early
stopping criteria also for graphical models with larger label set. Our pruning method would be
readily applicable to this situation  but an open challenge lies in ﬁnding a suitable criterion when
to prune variables. This will require a deeper understanding of tail probabilities of multinomial
decision variables  but we are conﬁdent it will be achievable  for example based on existing prior
works from the case of i.i.d. samples [14  32].

8

References
[1] N. Ghamrawi and A. McCallum. Collective multi-label classiﬁcation. In CIKM  2005.
[2] X. Zhu  Z. Ghahramani  and J. Lafferty. Semi-supervised learning using Gaussian ﬁelds and harmonic

functions. In ICML  2003.

[3] S. Geman and D. Geman. Stochastic relaxation  Gibbs distributions  and the Bayesian restoration of

images. PAMI  6(6)  1984.

[4] S. Della Pietra  V. Della Pietra  and J. Lafferty. Inducing features of random ﬁelds. PAMI  19(4)  1997.
[5] C. Yanover and Y. Weiss. Approximate inference and protein folding. In NIPS  volume 15  2002.
[6] E. Schneidman  M. J. Berry  R. Segev  and W. Bialek. Weak pairwise correlations imply strongly corre-

lated network states in a neural population. Nature  440(7087)  2006.

[7] M. J. Wainwright and M. I. Jordan. Graphical models  exponential families  and variational inference.

Foundations and Trends in Machine Learning  1(1-2)  2008.

[8] J. Marroquin  S. Mitter  and T. Poggio. Probabilistic solution of ill-posed problems in computational

vision. Journal of the American Statistical Association  82(397)  1987.

[9] C. Yanover and Y. Weiss. Finding the m most probable conﬁgurations using loopy belief propagation. In

NIPS  volume 16  2004.

[10] M. Jerrum and A. Sinclair. Polynomial-time approximation algorithms for the Ising model. SIAM Journal

on Computing  22  1993.

[11] R. M. Neal. Probabilistic inference using Markov chain Monte Carlo methods. Technical Report CRG-

TR-93-1  Department of Computer Science  University of Toronto  1993.

[12] D. J. C. MacKay. Introduction to Monte Carlo methods. In Proceedings of the NATO Advanced Study

Institute on Learning in graphical models  1998.

[13] A. E. Raftery and S. Lewis. How many iterations in the Gibbs sampler. Bayesian Statistics  4(2)  1992.
[14] A. G. Schwing  C. Zach  Y. Zheng  and M. Pollefeys. Adaptive random forest – how many ”experts” to

ask before making a decision? In CVPR  2011.

[15] H. Weiler. The use of incomplete beta functions for prior distributions in binomial sampling. Technomet-

rics  1965.

[16] C. M. Thompson  E. S. Pearson  L. J. Comrie  and H. O. Hartley. Tables of percentage points of the

incomplete beta-function. Biometrika  1941.

[17] R. V. Lenth. Some practical guidelines for effective sample size determination. The American Statistician 

55(3)  2001.

[18] A. Wald. Sequential tests of hypotheses. Annals of Mathematical Statistics  16  1945.
[19] D. A. Berry. Bayesian clinical trials. Nature Reviews Drug Discovery  5(1)  2006.
[20] A. E. Raftery. Bayesian model selection in social research. Sociological Methodology  25  1995.
[21] D. Easley  N. M. Kiefer  M. O’hara  and J. B. Paperman. Liquidity  information  and infrequently traded

stocks. Journal of Finance  1996.

[22] C. J. Geyer. Practical Markov chain Monte Carlo. Statistical Science  7(4)  1992.
[23] C. Chow and C. Liu. Approximating discrete probability distributions with dependence trees.

Transactions on Information Theory  14(3)  1968.

IEEE

[24] F. Bach and M. I. Jordan. Thin junction trees. In NIPS  volume 14  2002.
[25] M. J. Collins. A new statistical parser based on bigram lexical dependencies. In ACL  1996.
[26] J. A. Shelton  J. Bornschein  A. S. Sheikh  P. Berkes  and J. L¨ucke. Select and sample – a model of

efﬁcient neural inference and learning. In NIPS  volume 24  2011.

[27] Y. Guo and S. Gu. Multi-label classiﬁcation using conditional dependency networks. In IJCAI  2011.
[28] G. Madjarov  D. Kocev  D. Gjorgjevikj  and S. Dzeroski. An extensive experimental comparison of

methods for multi-label learning. Pattern Recognition  2012.

[29] T. Finley and T. Joachims. Training structural SVMs when exact inference is intractable. In ICML  2008.
[30] C. H. Lampert  H. Nickisch  and S. Harmeling. Learning to detect unseen object classes by between-class

attribute transfer. In CVPR  2009.

[31] S. Nowozin  C. Rother  S. Bagon  T. Sharp  B. Yao  and P. Kohli. Decision tree ﬁelds. In ICCV  2011.
[32] D. Chafai and D. Concordet. Conﬁdence regions for the multinomial parameter with small sample size.

Journal of the American Statistical Association  104(487)  2009.

9

,Yuanjun Xiong
Wei Liu
Deli Zhao
Xiaoou Tang