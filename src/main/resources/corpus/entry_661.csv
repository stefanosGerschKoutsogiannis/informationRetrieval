2013,Auxiliary-variable Exact Hamiltonian Monte Carlo Samplers for Binary Distributions,We present a new approach to sample from generic binary distributions  based on an exact  Hamiltonian Monte Carlo algorithm applied to a piecewise continuous augmentation  of the binary distribution of interest. An extension of this idea to distributions over mixtures of binary and continuous variables allows us to sample from posteriors of   linear and probit regression models with spike-and-slab priors and truncated parameters. We illustrate the advantages of these algorithms in several examples in which they outperform the Metropolis or Gibbs samplers.,Auxiliary-variable Exact Hamiltonian Monte

Carlo Samplers for Binary Distributions

Ari Pakman and Liam Paninski

Department of Statistics

Center for Theoretical Neuroscience

Grossman Center for the Statistics of Mind

Columbia University
New York  NY  10027

Abstract

We present a new approach to sample from generic binary distributions  based
on an exact Hamiltonian Monte Carlo algorithm applied to a piecewise continu-
ous augmentation of the binary distribution of interest. An extension of this idea to
distributions over mixtures of binary and possibly-truncated Gaussian or exponen-
tial variables allows us to sample from posteriors of linear and probit regression
models with spike-and-slab priors and truncated parameters. We illustrate the ad-
vantages of these algorithms in several examples in which they outperform the
Metropolis or Gibbs samplers.

1

Introduction

Mapping a problem involving discrete variables into continuous variables often results in a more
tractable formulation. For the case of probabilistic inference  in this paper we present a new ap-
proach to sample from distributions over binary variables  based on mapping the original discrete
distribution into a continuous one with a piecewise quadratic log-likelihood  from which we can
sample efﬁciently using exact Hamiltonian Monte Carlo (HMC).
The HMC method is a Markov Chain Monte Carlo algorithm that usually has better performance
over Metropolis or Gibbs samplers  because it manages to propose transitions in the Markov chain
which lie far apart in the sampling space  while maintaining a reasonable acceptance rate for these
proposals. But the implementations of HMC algorithms generally involve the non-trivial tuning of
numerical integration parameters to obtain such a reasonable acceptance rate (see [1] for a review).
The algorithms we present in this work are special because the Hamiltonian equations of motion
can be integrated exactly  so there is no need for tuning a step-size parameter and the Markov chain
always accepts the proposed moves. Similar ideas have been used recently to sample from trun-
cated Gaussian multivariate distributions [2]  allowing much faster sampling than other methods.
It should be emphasized that despite the apparent complexity of deriving the new algorithms  their
implementation is very simple.
Since the method we present transforms a binary sampling problem into a continuous one  it is natu-
ral to extend it to distributions deﬁned over mixtures of binary and Gaussian or exponential variables 
transforming them into purely continuous distributions. Such a mixed binary-continuous problem
arises in Bayesian model selection with a spike-and-slab prior and we illustrate our technique by
focusing on this case. In particular  we show how to sample from the posterior of linear and pro-
bit regression models with spike-and-slab priors  while also imposing truncations in the parameter
space (e.g.  positivity).
The method we use to map binary to continuous variables consists in simply identifying a binary
variable with the sign of a continuous one. An alternative relaxation of binary to continuous vari-

1

ables  known in statistical physics as the “Gaussian integral trick” [3]  has been used recently to
apply HMC methods to binary distributions [4]  but the details of that method are different than
ours. In particular  the HMC in that work is not ‘exact’ in the sense used above and the algorithm
only works for Markov random ﬁelds with Gaussian potentials.

2 Binary distributions

We are interested in sampling from a probability distribution p(s) deﬁned over d-dimensional binary
vectors s ∈ {−1  +1}d  and given in terms of a function f (s) as

p(s) =

1
Z

f (s) .

(1)

Here Z is a normalization factor  whose value will not be needed. Let us augment the distribu-
tion p(s) with continuous variables y ∈ Rd as

where p(y|s) is non-zero only in the orthant deﬁned by

p(s  y) = p(s)p(y|s)

(2)

(3)

(4)

The essence of the proposed method is that we can sample from p(s) by sampling y from

si = sign(yi)

i = 1  . . .   d.

p(y) =

p(s(cid:48))p(y|s(cid:48))  

(cid:88)

s(cid:48)

= p(s)p(y|s)  

(5)
and reading out the values of s from (3). In the second line we have made explicit that for each y 
only one term in the sum in (4) is non-zero  so that p(y) is piecewise deﬁned in each orthant.
In order to sample from p(y) using the exact HMC method of [2]  we require log p(y|s) to be a
quadratic function of y on its support. The idea is to deﬁne a potential energy function

U (y) = − log p(y|s) − log f (s)  

(6)

introduce momentum variables qi  and consider the piecewise continuous Hamiltonian

H(y  q) = U (y) + q·q
2  

(7)
whose value is identiﬁed with the energy of a particle moving in a d-dimensional space. Suppose the
particle has initial coordinates y(0). In each iteration of the sampling algorithm  we sample initial
values q(0) for the momenta from a standard Gaussian distribution and let the particle move during
a time T according to the equations of motion

˙y(t) =

∂H
∂q(t)

 

˙q(t) = − ∂H
∂y(t)

.

(8)

The ﬁnal coordinates  y(T )  belong to a Markov chain with invariant distribution p(y)  and are used
as the initial coordinates of the next iteration. The detailed balance condition follows directly from
the conservation of energy and (y  q)-volume along the trajectory dictated by (8)  see [1  2] for
details.
The restriction to quadratic functions of y in log p(y|s) allows us to solve the differential equa-
tions (8) exactly in each orthant. As the particle moves  the potential energy U (y) and the kinetic
energy q·q
2 change in tandem  keeping the value of the Hamiltonian (7) constant. But this smooth
interchange gets interrupted when any coordinate reaches zero. Suppose this ﬁrst happens at time tj
for coordinate yj  and assume that yj < 0 for t < tj. Conservation of energy imposes now a jump
on the momentum qj as a result of the discontinuity in U (y). Let us call qj(t−
j ) the
value of the momentum qj just before and after the coordinate hits yj = 0. In order to enforce
conservation of energy  we equate the Hamiltonian at both sides of the yj = 0 wall  giving

j ) and qj(t+

j (t+
q2
j )
2

= ∆j +

j (t−
q2
j )
2

2

(9)

with

∆j = U (yj = 0  sj = −1) − U (yj = 0  sj = +1)

(10)

j (t+

j )  the coordinate yj crosses the boundary and continues
If eq. (9) gives a positive value for q2
j (t+
j )  the
its trajectory in the new orthant. On the other hand  if eq.(9) gives a negative value for q2
j ) = −qj(t−
particle is reﬂected from the yj = 0 wall and continues its trajectory with qj(t+
j ). When
∆j < 0  the situation can be understood as the limit of a scenario in which the particle faces an
upward hill in the potential energy  causing it to diminish its velocity until it either reaches the top
of the hill with a lower velocity or stops and then reverses. In the limit in which the hill has ﬁnite
height but inﬁnite slope  the velocity change occurs discontinuously at one instant. Note that we
used in (9) that the momenta qi(cid:54)=j are continuous  since this sudden inﬁnite slope hill is only seen
by the yj coordinate.
Regardless of whether the particle bounces or crosses the yj = 0 wall  the other coordinates move
unperturbed until the next boundary hit  where a similar crossing or reﬂection occurs  and so on 
until the ﬁnal position y(T ).
The framework we presented above is very general and in order to implement a particular sampler
we need to select the distributions p(y|s). Below we consider in some detail two particularly simple
choices that illustrate the diversity of options here.

2.1 Gaussian augmentation
Let us consider ﬁrst for p(y|s) the truncated Gaussians

(cid:26)

p(y|s) =

(2/π)d/2 e− y·y
0

2

for sign(yi) = si 
otherwise  

i = 1  . . .   d

(11)

The equations of motion (8) lead to ¨y(t) = −y(t)  ¨q(t) = −q(t)  and have a solution

yi(t) = yi(0) cos(t) + qi(0) sin(t)  

(12)
(13)
(14)
(15)
This setting is similar to the case studied in [2] and from φi = tan−1(yi(0)/qi(0)) the boundary hit
times ti are easily obtained. When a boundary is reached  say yj = 0  the coordinate yj changes its
trajectory for t > tj as

qi(t) = −yi(0) sin(t) + qi(0) cos(t)  

= ui sin(φi + t)  

= ui cos(φi + t) .

yj(t) = qj(t+

j ) sin(t − tj)  

(16)

j ) obtained as described above.

with the value of qj(t+
Choosing an appropriate value for the travel time T is crucial when using HMC algorithms [5]. As
is clear from (13)  if we let the particle travel during a time T > π  each coordinate reaches zero at
least once  and the hitting times can be ordered as

(17)
Moreover  regardless of whether a coordinate crosses zero or gets reﬂected  it follows from (16) that
the successive hits occur at

0 < tj1 ≤ tj2 ≤ ··· ≤ tjd < π .

ti + nπ  n = 1  2  . . .

(18)
and therefore the hitting times only need to be computed once for each coordinate in every iteration.
If we let the particle move during a time T = nπ  each coordinate reaches zero n times  in the
cyclical order (17)  with a computational cost of O(nd) from wall hits. But choosing precisely
T = nπ is not recommended for the following reason. As we just showed  between yj(0) and yj(π)
the coordinate touches the boundary yj = 0 once  and if yj gets reﬂected off the boundary  it is easy
to check that we have yj(π) = yj(0). If we take T = nπ and the particle gets reﬂected all the n
times it hits the boundary  we get yj(T ) = yj(0) and the coordinate yj does not move at all. To
2 )π  which generalizes the recommended
avoid these singular situations  a good choice is T = (n + 1

3

travel time T = π/2 for truncated Gaussians in [2]. The value of n should be chosen for each
distribution  but we expect optimal values for n to grow with d.
With T = (n + 1
2 )π  the total cost of each sample is O((n + 1/2)d) on average from wall hits 
plus O(d) from the sampling of q(0) and from the d inverse trigonometric functions to obtain the
hit times ti. But in complex distributions  the computational cost is dominated by the the evaluation
of ∆i in (10) at each wall hit.
Interestingly  the rate at which wall yi = 0 is crossed coincides with the acceptance rate in a
Metropolis algorithm that samples uniformly a value for i and makes a proposal of ﬂipping the
binary variable si. See the Appendix for details. Of course  this does not mean that the HMC algo-
rithm is the same as Metropolis  because in HMC the order in which the walls are hit is ﬁxed given
the initial velocity  and the values of q2
i at successive hits of yi = 0 within the same iteration are not
independent.

2.2 Exponential and other augmentations

Another distribution that allows one an exact solution of the equations of motion (8) is

p(y|s) =

i=1 |yi|

for sign(yi) = si 
otherwise  

i = 1  . . .   d

which leads to the equations of motion ¨yi(t) = −si  with solutions of the form

(cid:26)

e−(cid:80)d

0

(19)

(20)

yi(t) = yi(0) + qi(0)t − sit2
2

.

In this case  the initial hit time for every coordinate is the solution of the quadratic equation yi(t) =
0. But  unlike the case of the Gaussian augmentation  the order of successive hits is not ﬁxed.
Indeed  if coordinate yj hits zero at time tj  it continues its trajectory as

(t − tj)2  

(21)

so the next wall hit yj = 0 will occur at a time t(cid:48)

yj(t > tj) = q(t+

j )(t − tj) − sj
2
j given by
j )|  

j − tj) = 2|qj(t+
(t(cid:48)

(22)
where we used sj = sign(qj(t+
j )). So we see that the time between successive hits of the same
coordinate depends only on its momentum after the last hit. Moreover  since the value of |qj(t+)|
is smaller than |qj(t−)| if the coordinate crosses to an orthant of lower probability  equation (22)
implies that the particle moves away faster from areas of lower probability. This is unlike the Gaus-
sian augmentation  where a coordinate ‘waits in line’ until all the other coordinates touch their wall
before hitting its wall again.
The two augmentations we considered above have only scratched the surface of interesting possibili-
ties. One could also deﬁne f (y|s) as a uniform distribution in a box such that the computation of the
times for wall hits would becomes purely linear and we get a classical ‘billiards’ dynamics. More
generally  one could consider different augmentations in different orthants and potentially tailor the
algorithm to mix faster in complex and multimodal distributions.

3 Spike-and-slab regression with truncated parameters

The subject of Bayesian sparse regression has seen a lot of work during the last decade. Along with
priors such as the Bayesian Lasso [6] and the Horsehoe [7]  the classic spike-and-slab prior [8  9]
still remains very competitive  as shown by its superior performance in the recent works [10  11  12].
But despite its successes  posterior inference remains a computational challenge for the spike-and-
slab prior. In this section we will show how the HMC binary sampler can be extended to sample
from the posterior of these models. The latter is a distribution over a set of binary and continuous
variables  with the binary variables determining whether each coefﬁcient should be included in the
model or not. The idea is to map these indicator binary variables into continuous variables as we did
above  obtaining a distribution from which we can sample again using exact HMC methods. Below
we consider a regression model with Gaussian noise but the extension to exponential noise (or other
scale-mixtures of Gaussians) is immediate.

4

3.1 Linear regression

Consider a regression problem with a log-likelihood that depends quadratically on its coefﬁcients 
such as

log p(D|w) = − 1
2

(23)
where D represents the observed data. In a linear regression model z = Xw+ε  with ε ∼ N (0  σ2) 
we have M = X(cid:48)X/σ2 and r = z(cid:48)X/σ2. We are interested in a spike-and-slab prior for the
coefﬁcients w of the form

w(cid:48)Mw + r · w + const.

p(w  s|a  τ 2) =

p(wi|si  τ 2)p(si|a) .

(24)

Each binary variable si = ±1 has a Bernoulli prior p(si|a) = a
whether the coefﬁcient wi is included in the model. The prior for wi  conditioned on si  is

(1 − a)

(1−si)

(1+si)

2

2

and determines

p(wi|si  τ 2) =

2πτ 2 e

− w2
i
2τ 2

for si = +1 
for si = −1

i=1

d(cid:89)
 1√

δ(wi)

(25)

(26)

(27)

+w+τ−2

δ(w−)a|s+|(1 − a)|s−|

We are interested in sampling from the posterior  given by
p(w  s|D  a  τ 2) ∝ p(D|w)p(w  s|a  τ 2)
2 w(cid:48)Mw+r·we− 1
2 w(cid:48)
(2πτ 2)|s+|/2

∝ e− 1
∝ e− 1
2 w(cid:48)

+(M++τ−2)w++r+·w+
(2πτ 2)|s+|/2

δ(w−)a|s+|(1 − a)|s−|

(28)
where s+ are the variables with si = +1 and s− those with si = −1. The notation r+  M+ and
w+ indicates a restriction to the s+ subspace and w− indicates a restriction to the s− space. In the
passage from (27) to (28) we see that the spike-and-slab prior shrinks the dimension of the Gaussian
likelihood from d to |s+|. In principle we could integrate out the weights w and obtain a collapsed
distribution for s  but we are interested in cases in which the space of w is truncated and therefore
the integration is not feasible. An example would be when a non-negativity constraint wi ≥ 0 is
imposed.
In these cases  one possible approach is to sample from (28) with a block Gibbs sampler over the
pairs {wi  si}  as proposed in [10]. Here we will present an alternative method  extending the ideas
of the previous section. For this  we consider a new distribution  obtained in two steps. Firstly  we
replace the delta functions in (28) by a factor similar to the slab (25)
si = −1

δ(wi) → 1√

− w2
i
2τ 2

(29)

e

2πτ 2

The introduction of a non-singular distribution for those wi’s that are excluded from the model
in (28) creates a Reversible Jump sampler [13]: the Markov chain can now keep track of all the
coefﬁcients  whether they belong or not to the model in a given state of the chain  thus allowing
them to join or leave the model along the chain in a reversible way.
Secondly  we augment the distribution with y variables as in (2)-(5) and sum over s. Using the
Gaussian augmentation (11)  this gives a distribution

p(w  y|D  a  τ 2) ∝ e− 1

2 w(cid:48)

+(M++τ−2)w++r+·w+e

(30)
where the values of s in the rhs are obtained from the signs of y. This is a piecewise Gaussian 
different in each orthant of y  and possibly truncated in the w space. Note that the changes in
p(w  y|D  a  τ 2) across orthants of y come both from the factors a|s+|(1 − a)|s−| and from the
functional dependence on the w variables. Sampling from (30) gives us samples from the original
distribution (28) using a simple rule: each pair (wi  yi) becomes (wi  si = +1) if yi ≥ 0 and

− w−·w−

2τ 2 e− y·y

2 a|s+|(1 − a)|s−|

5

(wi = 0  si = −1) if yi < 0. This undoes the steps we took to transform (28) into (30): the
identiﬁcation si = sign(yi) takes us from p(w  y|D  a  τ 2) to p(w  s|D  a  τ 2)  and setting wi = 0
when si = −1 undoes the replacement in (29).
Since (30) is a piecewise Gaussian distribution  we can sample from it again using the methods
of [2]. As in that work  the possible truncations for w are given as gn(w) ≥ 0 for n = 1  . . .   N 
with gn(w) any product of linear and quadratic functions of w. The details are a simple extension
of the purely binary case and are not very illuminating  so we leave them for the Appendix.

3.2 Probit regression
Consider a probit regression model in which binary variables bi = ±1 are observed with probability

p(bi|w  xi) =

1√
2π

zibi≥0

dzie− 1

2 (zi+xiw)2

(31)

(cid:90)

p(z  w  s|x  a  τ 2) ∝ N(cid:89)

Given a set of N pairs (bi  xi)  we are interested in the posterior distribution of the weights w using
the spike-and-slab prior (24). This posterior is the marginal over the zi’s of the distribution

e− 1

2 (zi+xiw)2

p(w  s|a  τ 2)

zibi ≥ 0  

(32)

i=1

and we can use the same approach as above to transform this distribution into a truncated piecewise
Gaussian  deﬁned over the (N + 2d)-dimensional space of the vector (z  w  y). Each zi is truncated
according to the sign of bi and we can also truncate the w space if we so desire. We omit the details
of the HMC algorithm  since it is very similar to the linear regression case.

4 Examples

We present here three examples that illustrate the advantages of the proposed HMC algorithms over
Metropolis or Gibbs samplers.

1D Ising model

−(cid:80)d

4.1
We consider a 1D periodic Ising model  with p(s) ∝ e−βE[s]  where the energy is E[s] =
i=1 sisi+1  with sd+1 = s1 and β is the inverse temperature. Figure 1 shows the ﬁrst 1000
iterations of both the Gaussian HMC and the Metropolis1 sampler on a model with d = 400 and
β = 0.42  initialized with all spins si = 1. In HMC we took a travel time T = 12.5π and  for
the sake of comparable computational costs  for the Metropolis sampler we recorded the value of
s every d × 12.5 ﬂip proposals. The plot shows clearly that the Markov chain mixes much faster
(cid:80)d
with HMC than with Metropolis. A useful variable that summarizes the behavior of the Markov
i=1 si   whose expected value is (cid:104)m(cid:105) = 0. The oscillations
chain is the magnetization m = 1
d
of both samplers around this value illustrate the superiority of the HMC sampler. In the Appendix
we present a more detailed comparison of the HMC Gaussian and exponential and the Metropolis
samplers  showing that the Gaussian HMC sampler is the most efﬁcient among the three.

2D Ising model

4.2
We consider now a 2D Ising model on a square lattice of size L × L with periodic boundary con-
ditions below the critical temperature. Starting from a completely disordered state  we compare the
time it takes for the sampler to reach one of the two low energy states with magnetization m (cid:39) ±1.
Figure 2 show the results of 20 simulations of such a model with L = 100 and inverse tempera-
ture β = 0.5. We used a Gaussian HMC with T = 2.5π and a Metropolis sampler recording values
of s every 2.5L2 ﬂip proposals. In general we see that the HMC sampler reaches higher likelihood
regions faster.

1As is well known (see e.g.[14])  for binary distributions  the Metropolis sampler that chooses a random

spin and makes a proposal of ﬂipping its value  is more efﬁcient than the Gibbs sampler.

6

Figure 1: 1D Ising model. First 1000 iterations of Gaussian HMC and Metropolis samplers on a
model with d = 400 and β = 0.42  initialized with all spins si = 1 (black dots). For HMC the travel
time was T = 12.5π and in the Metropolis sampler we recorded the state of the Markov chain once
every d × 12.5 ﬂip proposals. The lower two panels show the state of s at every iteration for each
sampler. The plots show clearly that the HMC model mixes faster than Metropolis in this model.

Figure 2: 2D Ising model. First samples from 20 simulations in a 2D Ising model in a square lattice
of side length L = 100 with periodic boundary conditions and inverse temperature β = 0.5. The
initial state is totally disordered. We do not show the ﬁrst 4 samples in order to ease the visualization.
For the Gaussian HMC we used T = 2.5π and for Metropolis we recorded the state of the chain
every 2.5L2 ﬂip proposals. The plots illustrate that in general HMC reaches equilibrium faster than
Metropolis in this model.

Note that these results of the 1D and 2D Ising models illustrate the advantage of the HMC method
in relation to two different time constants relevant for Markov chains [15]. Figure 1 shows that the
HMC sampler explores faster the sampled space once the chain has reached its equilibrium distribu-
tion  while Figure 2 shows that the HMC sampler is faster in reaching the equilibrium distribution.

7

01002003004005006007008009001000−101Magnetization01002003004005006007008009001000−1000−950−900Energy  MetropolisHMCMetropolis1002003004005006007008009001000200400HMCIteration1002003004005006007008009001000200400545851251652052452851.71.751.81.851.91.952x 104Log likelihoodIteration  5458512516520524528500.20.40.60.81Absolute MagnetizationIterationHMCMetropolisFigure 3: Spike-and-slab linear regression with constraints. Comparison of the proposed HMC
method with the Gibbs sampler of [10] for the posterior of a linear regression model with spike-and-
slab prior  with a positivity constraint on the coefﬁcients. See the text for details of the synthetic data
used. Above: log-likelihood as a function of the iteration. Middle: samples of the ﬁrst coefﬁcient.
Below: ACF of the ﬁrst coefﬁcient. The plots shows clearly that HMC mixes much faster than Gibbs
and is more consistent in exploring areas of high probability.

4.3 Spike-and-slab linear regression with positive coefﬁcients

We consider a linear regression model z = Xw + ε with the following synthetic data. X has
N = 700 rows  each sampled from a d = 150-dimensional Gaussian whose covariance matrix has 3
in the diagonal and 0.3 in the nondiagonal entries. The noise is ε ∼ N (0  σ2 = 100). The data z is
generated with a coefﬁcients vector w  with 10 non-zero entries with values between 1 and 10. The
spike-and-slab hyperparameters are set to a = 0.1 and τ = 10. Figure 3 compares the results of the
proposed HMC method versus the Gibbs sampler used in [10]. In both cases we impose a positivity
constraint on the coefﬁcients. For the HMC sampler we use a travel time T = π/2. This results in a
number of wall hits (both for w and y variables) of (cid:39) 150  which makes the computational cost of
every HMC and Gibbs sample similar. The advantage of the HMC method is clear  both in exploring
regions of higher probability and in the mixing speed of the sampled coefﬁcients. This impressive
difference in the efﬁciency of HMC versus Gibbs is similar to the case of truncated multivariate
Gaussians studied in [2].

5 Conclusions and outlook

We have presented a novel approach to use exact HMC methods to sample from generic binary
distributions and certain distributions over mixed binary and continuous variables 
Even though with the HMC algorithm is better than Metropolis or Gibbs in the examples we pre-
sented  this will clearly not be the case in many complex binary distributions for which specialized
sampling algorithms have been developed  such as the Wolff or Swendsen-Wang algorithms for 2D
Ising models near the critical temperature [14]. But in particularly difﬁcult distributions  these HMC
algorithms could be embedded as inner loops inside more powerful algorithms of Wang-Landau
type [16]. We leave the exploration of these newly-opened realms for future projects.

Acknowledgments

This work was supported by an NSF CAREER award and by the US Army Research Laboratory
and the US Army Research Ofﬁce under contract number W911NF-12-1-0594.

8

100300500700900110013001500170019002520254025602580IterationLog likelihood  HMCGibbs100300500700900110013001500170019007.47.67.888.2Samples of first coefficientIteration  HMCGibbs0100200300400500600700800900100000.51LagACF of first coefficient  HMCGibbsReferences
[1] R Neal. MCMC Using Hamiltonian Dynamics. Handbook of Markov Chain Monte Carlo 

pages 113–162  2011.

[2] Ari Pakman and Liam Paninski. Exact Hamiltonian Monte Carlo for Truncated Multivariate

Gaussians. Journal of Computational and Graphical Statistics  2013  arXiv:1208.4118.

[3] John A Hertz  Anders S Krogh  and Richard G Palmer. Introduction to the theory of neural

computation  volume 1. Westview press  1991.

[4] Yichuan Zhang  Charles Sutton  Amos Storkey  and Zoubin Ghahramani. Continuous Relax-
ations for Discrete Hamiltonian Monte Carlo. In Advances in Neural Information Processing
Systems 25  pages 3203–3211  2012.

[5] M.D. Hoffman and A. Gelman. The No-U-Turn sampler: adaptively setting path lengths in

Hamiltonian Monte Carlo. Arxiv preprint arXiv:1111.4246  2011.

[6] T. Park and G. Casella. The Bayesian lasso. Journal of the American Statistical Association 

103(482):681–686  2008.

[7] C.M. Carvalho  N.G. Polson  and J.G. Scott. The horseshoe estimator for sparse signals.

Biometrika  97(2):465–480  2010.

[8] T.J. Mitchell and J.J. Beauchamp. Bayesian variable selection in linear regression. Journal of

the American Statistical Association  83(404):1023–1032  1988.

[9] E.I. George and R.E. McCulloch. Variable selection via Gibbs sampling. Journal of the Amer-

ican Statistical Association  88(423):881–889  1993.

[10] S. Mohamed  K. Heller  and Z. Ghahramani. Bayesian and L1 approaches to sparse unsuper-

vised learning. arXiv preprint arXiv:1106.1157  2011.

[11] I.J. Goodfellow  A. Courville  and Y. Bengio. Spike-and-slab sparse coding for unsupervised

feature discovery. arXiv preprint arXiv:1201.3382  2012.

[12] Yutian Chen and Max Welling. Bayesian structure learning for Markov random ﬁelds with a

spike and slab prior. arXiv preprint arXiv:1206.1088  2012.

[13] Peter J Green. Reversible jump Markov chain Monte Carlo computation and Bayesian model

determination. Biometrika  82(4):711–732  1995.

[14] Mark E.J. Newman and Gerard T. Barkema. Monte Carlo methods in statistical physics. Ox-

ford: Clarendon Press  1999.  1  1999.

[15] Alan D Sokal. Monte Carlo methods in statistical mechanics: foundations and new algorithms 

1989.

[16] Fugao Wang and David P Landau. Efﬁcient  multiple-range random walk algorithm to calculate

the density of states. Physical Review Letters  86(10):2050–2053  2001.

9

,Ari Pakman
Liam Paninski
Guillaume Hennequin
Laurence Aitchison
Mate Lengyel