2018,Learning to Teach with Dynamic Loss Functions,Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g.  textbooks)  but also sets up appropriate learning objectives (e.g.  course projects and exams) considering different situations of a student. When it comes to artificial intelligence  treating machine learning models as students  the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work  we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed  in our framework  the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end  similar to human teaching  the teacher  a parametric model  dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible  exempt of the ineffective solutions such as policy optimization. We name our method as ``learning to teach with dynamic loss functions'' (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models.,Learning to Teach with Dynamic Loss Functions

1Lijun Wu†∗  2Fei Tian†  2Yingce Xia  3Yang Fan(cid:63) 

2Tao Qin  1Jianhuang Lai  2Tie-Yan Liu

1Sun Yat-sen University  Guangzhou  China

2Microsoft Research  Beijing  China

3University of Science and Technology of China  Hefei  China

1wulijun3@mail2.sysu.edu.cn  stsljh@mail.sysu.edu.cn

2{fetia  yingce.xia  taoqin  tie-yan.liu}@microsoft.com  3fyabc@mail.ustc.edu.cn

Abstract

Teaching is critical to human society: it is with teaching that prospective students
are educated and human civilization can be inherited and advanced. A good
teacher not only provides his/her students with qualiﬁed teaching materials (e.g. 
textbooks)  but also sets up appropriate learning objectives (e.g.  course projects
and exams) considering different situations of a student. When it comes to artiﬁcial
intelligence  treating machine learning models as students  the loss functions that
are optimized act as perfect counterparts of the learning objective set by the teacher.
In this work  we explore the possibility of imitating human teaching behaviors
by dynamically and automatically outputting appropriate loss functions to train
machine learning models. Different from typical learning settings in which the loss
function of a machine learning model is predeﬁned and ﬁxed  in our framework  the
loss function of a machine learning model (we call it student) is deﬁned by another
machine learning model (we call it teacher). The ultimate goal of teacher model
is cultivating the student to have better performance measured on development
dataset. Towards that end  similar to human teaching  the teacher  a parametric
model  dynamically outputs different loss functions that will be used and optimized
by its student model at different training stages. We develop an efﬁcient learning
method for the teacher model that makes gradient based optimization possible 
exempt of the ineffective solutions such as policy optimization. We name our
method as “learning to teach with dynamic loss functions” (L2T-DLF for short).
Extensive experiments on real world tasks including image classiﬁcation and neural
machine translation demonstrate that our method signiﬁcantly improves the quality
of various student models.

1

Introduction

Teaching  which aims to help students learn new knowledge or skills effectively and efﬁciently  is
important to advance modern human civilization. In human society  the rapid growth of qualiﬁed
students not only relies on their intrinsic learning capability  but also  even more importantly  relies on
the substantial guidance from their teachers. The duties of teachers cover a wide spectrum: deﬁning
the scope of learning (e.g.  the knowledge and skills that we expect students to demonstrate by the end
of a course)  choosing appropriate instructional materials (e.g.  textbooks)  and assessing the progress
of students (e.g.  through course projects or exams). Effective teaching involves progressively and
dynamically reﬁning the teaching strategy based on reﬂection and feedback from students.
Recently  the concept of teaching has been introduced into artiﬁcial intelligence (AI)  so as to improve
the learning process of a machine learning model. Currently  teaching in AI mainly focuses on

∗The work was done when the ﬁrst and fourth authors were interns at Microsoft Research Asia.
†The ﬁrst two authors contribute equally to this work.

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

training data selection. For example  machine teaching [56  34  35] aims at identifying the smallest
training data that is capable of producing the optimal learner models. The very recent work  learning
to teach (L2T for short) [13]  demonstrates how to automatically design teacher models for better
machine learning process. While conceptually L2T can cover different aspects of teaching in AI  [13]
only studies the problem of training data teaching.
In this work  inspired from learning to teach  we study loss function teaching in a formal and concrete
manner for the ﬁrst time. The main motivation of our work is a natural observation on the analogy
between loss functions in machine learning and exams in educating human students: appropriate
exams reﬂect the progress of students and urge them to make improvements accordingly  while loss
values outputted by the loss function evaluate the performance of current machine learning model
and set the optimization direction for the model parameters.
In our loss function teaching framework  a teacher model plays the role of outputting loss functions
for the student model (i.e.  the daily machine learning model to solve a task) to minimize. Inspired
from human teaching  we design the teacher model according to the following principles. First 
similar to the different difﬁculty levels of exams with respect to the progress of student in human
education  the loss function set by the teacher model should be dynamic  i.e.  the loss functions
should be adaptive to different phases of the training process of the student model. To achieve
this  we require our teacher model to take the status of student model into consideration in setting
the loss functions  and to dynamically change the loss functions with respect to the growth of the
student model. Such process is shown in Fig. 1. Second  the teacher model should be able to make
self-improvement  just as a human teacher can accumulate more knowledge and improve his/her
teaching skills through more teaching practices. To achieve that  we assume the loss function takes
the form of neural network whose coefﬁcients are determined via a parametric teacher model  which
is also a neural network. The parameters of the teacher model can be automatically optimized in
the teaching process. Through optimization  the teacher keeps improving its teaching model and
consequently the quality of loss functions it outputs. We name our method as learning to teach with
dynamic loss functions (L2T-DLF).
The eventual goal of the teacher model is that its output can
serve as the loss function of the student model to maximize
the long-term performance of the student  measured via a task-
speciﬁc objective such as 0-1 accuracy in classiﬁcation and
BLEU score in sequence prediction [41]  on a stand-alone de-
velopment dataset. Learning a good teaching model is not triv-
ial  since on the one hand the task-speciﬁc objective is usually
non-smooth w.r.t. student model outputs  and on the other hand
the ﬁnal evaluation of the student model is incurred on the dev
set  disjoint with the training dataset where the teaching process
actually happens. We design an efﬁcient gradient based opti-
mization algorithm to optimize teacher models. Speciﬁcally  to
tackle the ﬁrst challenge  we smooth the task-speciﬁc measure
to its expected version where the expectation is taken on the
direct output of student model. To address the second challenge 
inspired by Reverse-Mode Differentiation (RMD) [6  7  38] 
through reversing the stochastic gradient descent training pro-
cess of the student model  we obtain derivatives of the param-
eters of the teacher model via chaining backwards the error
signals incurred on the development dataset .
We demonstrate the effectiveness of L2T-DLF on various real-
world tasks including image classiﬁcation and neural machine
translation with different student models such as multi-layer
perception networks  convolutional neural networks and sequence-to-sequence models with attention.
The improvements clearly demonstrate the effectiveness of the new loss function learnt by L2T-DLF.

Figure 1: The student model is
trained via minimizing the dynamic
loss functions taught by the teacher
model (yellow curve). The bottom
black plane represents the parame-
ter space of student model and the
four colored mesh surfaces denote
different loss functions outputted vi-
a teacher model at different phases
of student model training.

2

2 Related Work

The study of teaching for AI  inspired by human teaching process  has a long history [1  17]. The
most recent efforts of teaching mainly focus on the level of training data selection. For example 
the machine teaching [56  34  35] literature targets at building the smallest training set to obtain a
pre-given optimal student model. A teaching strategy is designed in [18  19] to iteratively select
unlabeled data to label within the context of multi label propagation  in a similar manner with
curriculum learning [8  27]. Furthermore there are research on pedagogical teaching inspired from
cognitive science [44  23  39] in which a teacher module is responsible for providing informative
examples to the learner for the sake of understanding a concept rapidly.
The recent work learning to teach (L2T) [13] offers a more comprehensive view of teaching for AI 
including training data teaching  loss function teaching and hypothesis space teaching. Furthermore 
L2T breaks the strong assumption towards the existence of an optimal off-the-shelf student model
adopted by previous machine teaching literature [56  35]. Our work belongs to the general framework
of L2T  with a particular focus on a thorough landscape of loss function teaching  including the
detailed problem setup and efﬁcient solution for dynamically setting loss functions for training
machine learning models.
Our work  and the more general L2T  leverages automatic techniques to bypass human prior knowl-
edge as much as possible  which is in line with the principles of learning to learn and meta learn-
ing [43  50  2  57  37  29  10  14]. What makes our work different with others  from the technical
point of view  is that: 1) we leverage gradient based optimization method rather than reinforce-
ment learning [57  13]; 2) we need to handle the difﬁculty when the error information cannot be
directly back propagated from the loss function  since we aim at discovering the best loss function
for the machine learning models. We design an algorithm based on Reverse-Mode Differentiation
(RMD) [7  38  15] to tackle such a difﬁculty.
Specially designed loss functions play important roles in boosting the performances of real-world
tasks  either by approximating the non-smooth task-speciﬁc objective such as 0-1 accuracy in
classiﬁcation [40]  NDCG in ranking [49]  BLEU in machine translation [45  3] and MAP in object
detection [22  46]  or easing the optimization process of the student model such as overcoming the
difﬁculty brought by data imbalance [30  32] and numerous local optima [20]. L2T-DLF differs from
prior works in that: 1) the loss functions are automatically learned  covering a large space and without
the demand of heuristic understanding for task speciﬁc objective and optimization process; 2) the
loss function dynamically evolves during the training process  leading to a more coherent interaction
between loss and student model.

3 Model

In this section  we introduce the details of L2T-DLF  including the student model and the teacher
model  as well as the training strategy for optimizing the teacher model.

3.1 Student Model
For a task of interest  we denote its input space and output space respectively as X and Y. The student
model for this task is then denoted as fω : X → Y  with ω as its weight parameters. The training of
student model fω is an optimization process that discovers a good weight parameter ω∗ within a hy-
pothesis space Ω  by minimizing a loss function l on the training data Dtrain containing M data points
Dtrain = {(xi  yi)}M
l(fω(x)  y).
(x y)∈D l(fω(x)  y)
where D is a dataset and will simultaneously name L as loss function when the context is clear. The
learnt student model fω∗ is then evaluated on a test data set Dtest = {(xi  yi)}N
i=1 to obtain a score
m(fω∗ (x)  y)  as its performance. Here the task speciﬁc objective

(cid:80)
For the convenience of description  we deﬁne a new notation L(fω  D) = (cid:80)
M(fω∗   Dtest) =(cid:80)

(x y)∈Dtest

i=1. Speciﬁcally ω∗ is obtained via solving minω∈Ω

(x y)∈Dtrain

m(y1  y2) measures the similarity between two output candidates y1 and y2.
The loss function l(ˆy  y)  taking the model prediction ˆy = fω(x) and ground-truth y as inputs  acts as
the surrogate of m to evaluate the student model fω during its training process  just as the exams in
real-world human teaching. We assume l(ˆy  y) is a neural network with some coefﬁcients Φ  denoted
as lΦ(ˆy  y). It can be a simple linear model  or a deep neural network (some concrete examples

3

are provided in section 4.1 and section 4.2). With such a loss function lΦ(ˆy  y) (and the induced
notation LΦ)  the student model gets sequentially updated via minimizing the output value of lΦ by 
for example  stochastic gradient descent (SGD): ωt+1 = ωt − ηt
  t = {1  2 ···   T} 
train ⊆ Dtrain  ωt and ηt is respectively the mini-batch training data  student model weight
where Dt
parameter and learning rate at t-th timestep. For ease of statement we simply set ω∗ = ωT .

∂LΦ(fωt  Dt

train)

∂ωt

3.2 Teacher Model

A teacher model is responsible for setting the proper loss function l to the student model by outputting
appropriate loss function coefﬁcients Φ. To cater for different status of student model training  we
ask the teacher model to output different loss functions lt at each training step t. To achieve that  the
status of a student model is represented by a state vector st at timestep t  which contains for example
the current training/dev accuracy and iteration number. The teacher model  denoted as µ  then takes
st as inputs to compute the coefﬁcients of loss function Φt at t-th timestep as Φt = µθ(st)  where
θ is the parameters of the teacher model. We further provide some examples of µθ in section 4.1
and section 4.2. The actual loss function for student model is then lt = lΦt. The learning process of
student model then switches to:
ωt+1 = ωt − ηt

∂Lµθ(st)(fωt  Dt

= ωt − ηt

∂LΦt(fωt  Dt

train)

train)

(1)

∂ωt

∂ωt

.

Such a sequential procedure of obtaining fω∗ (i.e.  fωT ) is the learning process of the student model
with training data Dtrain and loss function provided via the teacher model µθ  and we use an abstract
operator F to denote it: fω∗ = F(Dtrain  µθ).
Just as the training and testing setup in typical machine learning scenarios  the teacher model here
similarly follows the two phases setup. Speciﬁcally  in the training process of teacher model  similar
to qualiﬁed human teachers are good at improving the quality of exams  the teacher model in L2T-DLF
reﬁnes the loss function it sets up via optimizing its own θ. The ultimate goal of teacher model is to
maximize the performance of induced student model on a stand-alone development dataset Ddev:

M(fω∗   Ddev) = max

θ

max

θ

M(F(Dtrain  µθ)  Ddev).

(2)

We introduce the detailed training process (i.e.  how to efﬁciently optimize Eqn. (2)) in section 3.3.
In the testing process of the teacher model  θ is ﬁxed and the student model fω gets updated with the
guidance of teacher model µθ  as speciﬁed in Eqn. (1).

3.3 Training Process of Teacher Model

There are two challenges to optimize teacher model: 1) the evaluation measure m is typically non-
smooth and non-differentiable w.r.t. the parameters of student model; 2) the error is incurred on dev
set while the teacher model plays effect in training phase.
We use continuous relaxation of m to tackle the ﬁrst challenge. The main idea is to inject random-
ness into m to form an approximated version ˜m  where the randomness comes from the student
model [49]. Thanks to the fact that quite a few student models output probabilistic distributions on
Y  the randomness naturally comes from the direct outputs of fω. Speciﬁcally  to approximate the
y∗∈Y m(y∗  y)pω(y∗|x) 
where pω(y∗|x) is the probability of predicting y∗ given x using fω. The gradient of ω is then
easy to obtain via ∂ ˜m(fω(x) y)
. We further introduce a new notation
˜m(fω(x)  y) which approximates the objective of the teacher model
(x y)∈Ddev

performance of fω on a test data sample (x  y)  we have ˜m(fω(x)  y) =(cid:80)
˜M(fω  Ddev) =(cid:80)

M(fωT   Ddev).
We use Reverse-Mode Differentiation (RMD) [6  7  38] to ﬁll in the gap between training data and
development data. To better show the RMD process  we can view the sequential process in Eqn. (1)
as a special feed-forward process of a deep neural network where each t corresponds to one layer 
and RMD corresponds to the backpropagation process looping the SGD process backwards from T
to 1. Speciﬁcally denote dθ as the gradient of ˜M (fωT   Ddev) w.r.t. the teacher model parameters
θ  which has initial value dθ = 0. On the dev dataset Ddev  the gradient of ˜M(fω  Ddev) w.r.t. the

y∗∈Y m(y∗  y) ∂pω(y∗|x)

=(cid:80)

∂ω

∂ω

4

parameter of student model ωT is calculated as
∂ ˜M(fωT   Ddev)

dωT =

∂ωT

(cid:88)

∂ ˜m(fωT (x)  y)

(x y)∈Ddev

∂ωT

=

.

(3)

Then looping backwards from T and corresponding to Eqn. (1)  at each step t = {T − 1 ···   1} we
have

dωt =

∂ ˜M(fωt  Ddev)

∂ωt

= dωt+1 − ηt

∂2Lµθ(st)(fωt  Dt

train)

dωt+1.

∂ω2
t

At the same time  the gradient of ˜M w.r.t. θ is accumulated at this time step as:

dθ = dθ − ηt

∂2Lµθ(st)(fωt  Dt

train)

∂θ∂ωt

dωt+1.

(4)

(5)

We leave the detailed derivations for Eqn. (4) and (5) to Appendix. Furthermore it is worth-noting that
the computing of dωt and dθ involves hessian vector product  which can be effectively computed via
∂2g
∂x∂y v = ∂( ∂g
∂y v)/∂x  without explicitly calculating the Hessian matrix. Reverting backwards from
t = T to t = 1  we obtain dθ and then θ is updated using any gradient based optimization algorithm
such as momentum SGD  forming one step optimization for θ which we call teacher optimization
step. By iterating teacher optimization steps we obtain the ﬁnal teacher model. The details are listed
in Algorithm 1.

Algorithm 1 Training Teacher Model µθ

Input: Continuous relaxation ˜m. Initial value of θ.
while Teacher model parameter θ not converged do
Randomly initialize student model parameter ω0.
for each time step t = 0 ···   T − 1 do

Conduct student model training step via Eqn. (1).

end for
dθ = 0. Compute dωT via Eqn. (3).
for each time step t = T − 1 ···   0 do

Update dθ as Eqn. (5).
Compute dωt as Eqn. (4).

end for
Update θ using dθ via gradient based optimization algorithm.

end while
Output: the ﬁnal teacher model µθ.

(cid:46) One teacher optimization step

(cid:46) Teach student model

(cid:46) Reversely calculating the gradient dθ

3.4 Discussion

Another possible way to conduct teacher model optimization is through deep reinforcement learning.
By treating the teacher model as a policy outputting continuous action (i.e.  the loss function)  one
can leverage continuous control algorithm such as DDPG [31] to optimize teacher model. However 
reinforcement learning algorithms  including Q-learning based ones such as DDPG are sample
inefﬁcient  probably requiring huge amount of sampled trajectories to approximate the reward using
a critic network. Considering the training of student model is typically costly  we resort to gradient
based optimization algorithms instead.
Furthermore  there are similarity between L2T-DLF and actor-critic (AC) method [5  48] in rein-
forcement learning (RL)  in which a critic (corresponding to the parametric loss function) guides the
optimization of an actor (corresponding to the student model). Apart from the difference within appli-
cation domain (supervised learning versus RL)  there are differences between the design principle of
L2T-DLF and AC. For AC  by treating student model as actor  the student model output (e.g.  fωt(xt))
is essentially the action at timestep t  fed into the critic to output an approximation to the future
reward (e.g.  dev set accuracy). This is typically difﬁcult since: 1) the student model output (i.e.  the
action) at a particular step t is weakly related with the ﬁnal dev performance. Therefore optimizing its
action with the guidance from critic network is largely meaningless; 2) the approximation to the future

5

(a) loss function

(b) teacher model

Figure 2: Left: the bilinear neural network specifying the loss function lΦt(pω  y) = −σ((cid:126)y(cid:48)Φt log pw).
Right: the teacher model outputting Φt via attention mechanism:Φt = µθ(st) = W sof tmax(V st).

reward is hard given the performance measure is highly non-smooth. As a comparison  L2T-DLF is
more general in that at each timestep: 1) the teacher model considers the overall status of the student
model for the sake of optimizing its parameters  rather than the instant action (i.e.  the direct output);
2) the teacher model outputs a loss function with the goal of maximizing  but not approximating the
future reward. In that sense  L2T-DLF is more appropriate to real world applications.

4 Experiments

We conduct comprehensive empirical veriﬁcations of the proposed L2T-DLF  in automatically dis-
covering the most appropriate loss functions for student model training. The tasks in our experiments
come from two domains: image classiﬁcation  and neural machine translation.

4.1

Image Classiﬁcation

yx + by)/(cid:80)

y∗∈Y exp (w(cid:48)

The evaluation measure m here is the 0-1 accuracy: m(y1  y2) = 1y1=y2 where 1 is the 0-1
indicator function. The student model fω can be a logistic classiﬁer specifying a softmax distribution
pω(y|x) = exp (w(cid:48)
y∗ x + by∗ ) with ω = {wy∗   by∗}y∗∈Y. The class label
is predicted as ˆy = arg maxy∗∈Y pω(y∗|x) given input data x.
Instead of imposing loss on ˆy
and ground-truth y  for the sake of efﬁcient optimization l typically takes the direct model output
pω and y as inputs. For example  the most widely adopted loss function l is cross-entropy loss
l(pω  y) = − log pω(y|x)  which could be re-written in vector form l(pω  y) = −(cid:126)y(cid:48) log pω  where
(cid:126)y ∈ {0  1}|Y| is a one-hot representation of the true label y  i.e.  (cid:126)yj = 1j=y ∀j ∈ Y  (cid:126)y(cid:48) is the
transpose of (cid:126)y and pw ∈ R|Y| is the probabilities for each class outputted via fω.
Generalizing the cross entropy loss  we set the loss function coefﬁcients Φ as a matrix inter-
acting between log pw and (cid:126)y  which switches loss function at t-th timestep into lΦt(pω  y) =
−σ((cid:126)y(cid:48)Φt log pw)  Φt ∈ R|Y|×|Y|  as is shown in Fig. 2(a). σ is the sigmoid function. The teacher
model µθ here is then responsible for setting Φt according to the state feature vector of student model
st: Φt = µθ(st). One possible form of the teacher model is a neural network with attention mechanis-
m (shown in Fig. 2(b)): Φt = µθ(st) = W sof tmax(V st)  where W ∈ R|Y|×|Y|×N   V ∈ RN×|st|
constitute the teacher model parameter set θ  N = 10 is the number of keys in attention mechanism.
The state vector st is a 13 dimensional vector composing of 1) the current iteration number t; 2)
current training accuracy of fω; 3) current dev accuracy of fω; 4) current precision of fω for the 10
classes on the dev set  all normalized into [0  1].
We choose three widely adopted datasets: the MNIST  CIFAR-10 and CIFAR-100 datasets. For
the sake of showing the robustness of L2T-DLF  the student models we choose cover a wide range 
including multi-layer perceptron (MLP)  plain convolutional neural network (CNN) following LeNet
architecture [28]  and advanced CNN architecture including ResNet [21]  Wide-ResNet [55] and
DenseNet [24]. For all the student models  we use momentum stochastic gradient descent to perform
training. In Appendix we describe the network structures of student models.
The different loss functions we compare include: 1) Cross entropy loss Lce(pω(x)  y) =
− log pω(y|x)  which is the most widely adopted loss function to train neural network model;

6

Table 1: The recognition results (error rate %) on MNIST dataset.

Student Model/

Loss
MLP
LeNet

Cross

Entropy [11]

Smooth [40] Large-Margin
Softmax [36]

L2T-DLF

1.94
0.98

1.89
0.94

1.83
0.88

1.69
0.77

Table 2: The recognition results (error rate %) on CIFAR-10 (C10) and CIFAR-100 (C100) dataset

Student Model/

Loss

ResNet-8
ResNet-20
ResNet-32
WRN
DenseNet-BC

Cross

Entropy [11]
C10/C100
12.45/39.79
8.75/32.33
7.51/30.38

3.80/-
3.54/-

Smooth [40] Large-Margin
Softmax [36]
C10/C100
11.34/38.93
8.02/31.65
7.01/29.56

C10/C100
12.08/39.52
8.53/32.01
7.42/30.12

3.81/-
3.48/-

3.69/-
3.37/-

L2T-DLF

C10/C100
10.82/38.27
7.63/30.97
6.95/29.25

3.42/-
3.08/-

2) The smooth 0-1 loss proposed in [40]. It optimizes a smooth version of 0-1 accuracy in bi-
nary classiﬁcation. We extend it to handle multi-class case by modifying the loss function as
Lsmooth(pω(x)  y) = − log σ(K(log pω(y|x) − maxy∗(cid:54)=y log pω(y∗|x))). It is not difﬁcult to ob-
serve when K → +∞  −Lsmooth exactly matches the 0-1 accuracy. We choose the value of K to be
50 according to the performance on dev set; 3) The large-margin softmax loss in [36] denoted as Llm 
which aims to enhance discrimination between different classes via maximizing the margin induced
by the angle between x and a target class representation wy. We use the open-sourced code released
by the authors in our experiment; 4) The loss function discovered via the teacher in L2T-DLF. The
teacher models are optimized with Adam [26] and the detailed setting is in Appendix.
The classiﬁcation results on MNIST  CIFAR-10 and CIFAR-100 are respectively shown in Table 1
and 2. As can be observed  on all the three tasks  the dynamic loss functions outputted via teacher
model help to cultivate better student model. For example  the teacher model helps WRN to achieve
3.42% classiﬁcation error rate on CIFAR-10  which is on par with the result discovered via automatic
architecture search (e.g.  3.41% of NASNet [57]). Furthermore  our dynamic loss functions for
DenseNet on CIFAR-10 reduces the error rate of DenseNet-BC (k=40) from 3.54% to 3.08%  where
the gain is a non-trival margin.

4.1.1 Teacher Optimization

In Fig. 3  we provide the dev measure performance along with the teacher model optimization in
MNIST experiment  the student model is LeNet. It can be observed that the dev measure is increasing
along with the teacher model optimizing  and ﬁnally converges to a high score.

4.1.2 Analysis Towards the Loss Functions

To better understand the loss functions outputted via teacher model  we visualize the coefﬁcients of
some loss functions outputted by teacher model for training ResNet-8 in CIFAR-100 classiﬁcation
task. Speciﬁcally  note that the loss function lΦt(pω  y) = −σ((cid:126)y(cid:48)Φt log pw) essentially characterizes
the correlations among different classes via the coefﬁcients Φt. Positive Φt(i  j) value means positive
correlation between class i and j that their probabilities should be jointly maximized whereas negative
value imposes negative correlation and higher discrimination between the two classes i and j. We
choose two classes in CIFAR-100: the Otter and Baby as class i and for each of them pick several
representative classes as class j. The corresponding Φt(i  j) values are visualized in Fig. 4  with
t = 20  40  60 denoting the coefﬁcients outputted via teacher model at t-th epoch of student model
training. As can be observed  at the initial phase of training student model (t = 20)  the teacher
model chooses to enhance the correlation between two similar classes  e.g  Otter and Dolphin  Baby
and Boy  for the sake of speeding up training. Comparatively  when the student model is powerful
enough (t = 60)  the teacher model will force it to perform better in discriminating two similar
classes  as indicated via the more negative coefﬁcient values Φt(i  j). The variation of Φt(i  j)

7

Figure 3: Measure score on the MNIST dev set along the teacher model optimization. The student
model is LeNet.

(a) Class Otter

(b) Class Baby

Figure 4: Coefﬁcient matrix Φt outputted via teacher model. The y-axis (20  40  60) corresponds to
the different epochs of the student model training. Darker color means the coefﬁcients value are more
negative while shallower color means more positive. In each ﬁgure  the leftmost two columns denote
similar classes and the rightmost three columns represent dissimilar classes.

values w.r.t. t well demonstrates the teacher model captures the status of student model in outputting
correspondingly appropriate loss functions.

4.2 Neural Machine Translation

autoregressive  in that fω factorizes the translation probability as pω(y|x) =(cid:81)|y|
generalizing cross entropy loss is lΦ = −(cid:80)|y|

In the task of neural machine translation (NMT)  the evaluation measure m(ˆy  y) is typically the
BLEU score [41] between the translated sentence ˆy and ground-truth reference y. The student model
fω is a neural network performing sequence-to-sequence generation based on models including
RNN [47]  CNN [16] and self-attention network [51]. The decoding process of fω is typically
r=1 pω(yr|x  y<r).
Here pω(·|x  y<r) is the distribution on target vocabulary V at the r-th position  taking the source side
sentence x and the previous words y<r as inputs. Similar to the classiﬁcation task  the loss function
rdiag(Φ) log pω(·|x  y<r))  where Φ ∈ R|V| is
the coefﬁcients of the loss function and diag(Φ) denotes the diagnoal matrix with Φ as its diagonal
elements. Here we set the interaction matrix as diagonal mainly for the sake of computational
efﬁciency  since the target vocabulary size |V| is usally very large (e.g.  30k). The teacher model then
outputs Φt at timestep t taking st as input: Φt = µθ(st) = W sof tmax(V st)  where teacher model
parameter θ = {W ∈ R|V|×N   V ∈ RN×|st|}. We set N = 5 and for the state vector st  it is the

r=1 σ((cid:126)y(cid:48)

8

0510152025303540Teacher optimization step0.98860.98880.98900.98920.98940.98960.9898Dev measureLeNet on MNISTTable 3: The translation results (BLEU score) on IWSLT-14 German-English task.

Cross

Student Model/

Loss

LSTM-1
LSTM-2

Transformer

Entropy [52] RL [42] AC [3]
27.75
31.21
34.34

27.28
30.86
34.01

27.53
31.03
34.32

Softmax-Margin [12] L2T-DLF

28.12
31.22
34.46

29.52
31.75
34.80

same with that in classiﬁcation except: 1) the training/dev set accuracy is now replaced with BLEU
scores; 2) the last ten features in st for classiﬁcation are ignored  leading to |st| = 3.
We choose a widely used benchmark dataset in NMT literature [42  54  53]  released in IWSLT-14
German-English evaluation campaign [9]  as the test-bed for different loss functions. The student
model fω for this task is based on LSTM with attention [4]. For the sake of fair comparison
with previous works [3  42]  we use single layer LSTM model as fω and name it as LSTM-1. To
further verify the effectiveness of L2T-DLF  we use a deeper translation model stacking two LSTM
layers as fω. We denote such stronger student model as LSTM-2. Furthermore  we also evaluate
our L2T-DLF on the Transformer [51] network. The Transformer architecture is based on the
self-attention mechanism [33]  and it achieves superior performance on several NMT tasks. Both
LSTM/Transformer student models are trained with simple SGD. In Appendix we provide the details
of the LSTM/Transformer student models and the training settings of student/teacher models.
The loss functions we leverage to train student models include: 1) Cross entropy loss Lce to perform
maximum likelihood estimation (MLE) for training LSTM/Transformer model with teacher forc-
ing [52]; 2) The reinforcement learning (RL) loss Lrl  a.k.a  sequence level training [42] or minimum
risk training [45]  targets at directly optimizing the BLEU scores for NMT models. A typical RL loss
y∗∈Y log pω(y∗|x)(BLEU (y∗  y) − b)  where b is the reward baseline and
Y is the candidate subset; 3) The loss speciﬁed via actor-critic (AC) algorithm Lac [3]  which approx-
imates the BLEU score via a critic network; 4) The softmax-margin loss  which is empirically shown
to be the most effective structural prediction loss for NMT [12]; 5) The loss function discovered via
our L2T-DLF.
We report the experimental results in Table 3. From the table  we can clearly observe the dynamic loss
functions outputted via our teacher model can guide the student model to have superior performance
compared with other specially designed loss functions. Speciﬁcally  with a shallow student model
LSTM-1  we improve the BLEU score by more than 2.0 points compared with predeﬁned cross-
entropy loss. In addition  our LSTM-2 student model achieves 31.75 BLEU score and it surpasses
previously reported best result 30.08 by [25] on IWSLT-14 German-English achieved via RNN/LSTM
models. With a much stronger Transformer student model  we also improve the model performance
from BLEU score 34.01 to 34.80. The above results clearly demonstrate the effectiveness of our
L2T-DLF approach.

is Lrl(pω(x)  y) = −(cid:80)

5 Conclusion

In contrast to expert designed and ﬁxed loss functions in conventional machine learning systems 
we in this paper study how to learn dynamic loss functions so as to better teach a student machine
learning model. Since loss functions provided by the teacher model dynamically change with respect
to the growth of the student model and the teacher model is trained through end-to-end optimization 
the quality of the student model gets improved signiﬁcantly  as shown in our experiments. We hope
our work will stimulate and inspire the research community to automatically discover loss functions
better than expert designed ones. As to future work  we would like to conduct empirical veriﬁcation
on tasks with more powerful student models and larger datasets. We are also interested in trying more
complicated teacher models such as deeper neural networks.

Acknowledgments

This work was partially supported by the NSFC 61573387. We thank all the anonymous reviewers
for their constructive feedbacks.

9

References
[1] John R Anderson  C Franklin Boyle  and Brian J Reiser. Intelligent tutoring systems. Science 

228(4698):456–462  1985.

[2] Marcin Andrychowicz  Misha Denil  Sergio Gomez  Matthew W Hoffman  David Pfau  Tom
Schaul  and Nando de Freitas. Learning to learn by gradient descent by gradient descent. In
Advances in Neural Information Processing Systems  pages 3981–3989  2016.

[3] Dzmitry Bahdanau  Philemon Brakel  Kelvin Xu  Anirudh Goyal  Ryan Lowe  Joelle Pineau 
Aaron Courville  and Yoshua Bengio. An actor-critic algorithm for sequence prediction. arXiv
preprint arXiv:1607.07086  2016.

[4] Dzmitry Bahdanau  Kyunghyun Cho  and Yoshua Bengio. Neural machine translation by jointly

learning to align and translate. arXiv preprint arXiv:1409.0473  2014.

[5] Andrew G Barto  Richard S Sutton  and Charles W Anderson. Neuronlike adaptive elements
that can solve difﬁcult learning control problems. IEEE transactions on systems  man  and
cybernetics  (5):834–846  1983.

[6] Atilim Gunes Baydin and Barak A Pearlmutter. Automatic differentiation of algorithms for

machine learning. arXiv preprint arXiv:1404.7456  2014.

[7] Yoshua Bengio. Gradient-based optimization of hyperparameters. Neural computation 

12(8):1889–1900  2000.

[8] Yoshua Bengio  Jérôme Louradour  Ronan Collobert  and Jason Weston. Curriculum learning.

In Proceedings of the 26th ICML  pages 41–48. ACM  2009.

[9] M Cettolo  J Niehues  S Stüker  L Bentivogli  and M Federico. Report on the 11th iwslt
In IWSLT-International Workshop on Spoken Language

evaluation campaign  iwslt 2014.
Processing  pages 2–17. Marcello Federico  Sebastian Stüker  François Yvon  2014.

[10] Yutian Chen  Matthew W Hoffman  Sergio Gómez Colmenarejo  Misha Denil  Timothy P
Lillicrap  Matt Botvinick  and Nando de Freitas. Learning to learn without gradient descent by
gradient descent. arXiv preprint arXiv:1611.03824  2016.

[11] Pieter-Tjerk De Boer  Dirk P Kroese  Shie Mannor  and Reuven Y Rubinstein. A tutorial on the

cross-entropy method. Annals of operations research  134(1):19–67  2005.

[12] Sergey Edunov  Myle Ott  Michael Auli  David Grangier  and Marc’Aurelio Ranzato. Classical
structured prediction losses for sequence to sequence learning. arXiv preprint arXiv:1711.04956 
2017.

[13] Yang Fan  Fei Tian  Tao Qin  Xiang-Yang Li  and Tie-Yan Liu. Learning to teach. In Interna-

tional Conference on Learning Representations  2018.

[14] Chelsea Finn  Pieter Abbeel  and Sergey Levine. Model-agnostic meta-learning for fast adapta-
tion of deep networks. In Doina Precup and Yee Whye Teh  editors  Proceedings of the 34th
International Conference on Machine Learning  volume 70 of Proceedings of Machine Learning
Research  pages 1126–1135  International Convention Centre  Sydney  Australia  06–11 Aug
2017. PMLR.

[15] Luca Franceschi  Michele Donini  Paolo Frasconi  and Massimiliano Pontil. Forward and
reverse gradient-based hyperparameter optimization. In Doina Precup and Yee Whye Teh 
editors  Proceedings of the 34th International Conference on Machine Learning  volume 70
of Proceedings of Machine Learning Research  pages 1165–1173  International Convention
Centre  Sydney  Australia  06–11 Aug 2017. PMLR.

[16] Jonas Gehring  Michael Auli  David Grangier  Denis Yarats  and Yann N Dauphin. Convolutional
sequence to sequence learning. In International Conference on Machine Learning  pages 1243–
1252  2017.

[17] S.A. Goldman and M.J. Kearns. On the complexity of teaching. J. Comput. Syst. Sci.  50(1):20–

31  February 1995.

10

[18] Chen Gong  Dacheng Tao  Wei Liu  Liu Liu  and Jie Yang. Label propagation via teaching-
to-learn and learning-to-teach. IEEE transactions on neural networks and learning systems 
28(6):1452–1465  2017.

[19] Chen Gong  Dacheng Tao  Jie Yang  and Wei Liu. Teaching-to-learn and learning-to-teach for

multi-label propagation. In AAAI 2016  pages 1610–1616  2016.

[20] Elad Hazan  Kﬁr Yehuda Levy  and Shai Shalev-Shwartz. On graduated optimization for
stochastic non-convex problems. In International Conference on Machine Learning  pages
1833–1841  2016.

[21] Kaiming He  Xiangyu Zhang  Shaoqing Ren  and Jian Sun. Deep residual learning for image
recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition 
pages 770–778  2016.

[22] Paul Henderson and Vittorio Ferrari. End-to-end training of object class detectors for mean
average precision. In Asian Conference on Computer Vision  pages 198–213. Springer  2016.

[23] Mark K Ho  Michael Littman  James MacGlashan  Fiery Cushman  and Joseph L Auster-
weil. Showing versus doing: Teaching by demonstration. In Advances in Neural Information
Processing Systems 29  pages 3027–3035. 2016.

[24] Gao Huang  Zhuang Liu  Laurens Van Der Maaten  and Kilian Q Weinberger. Densely connected

convolutional networks. In CVPR  2017.

[25] Po-Sen Huang  Chong Wang  Sitao Huang  Dengyong Zhou  and Li Deng. Towards neural
phrase-based machine translation. In International Conference on Learning Representations 
2018.

[26] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint

arXiv:1412.6980  2014.

[27] M Pawan Kumar  Benjamin Packer  and Daphne Koller. Self-paced learning for latent variable

models. In Advances in Neural Information Processing Systems  pages 1189–1197  2010.

[28] Yann LeCun  Léon Bottou  Yoshua Bengio  and Patrick Haffner. Gradient-based learning

applied to document recognition. Proceedings of the IEEE  86(11):2278–2324  1998.

[29] Ke Li and Jitendra Malik. Learning to optimize. arXiv preprint arXiv:1606.01885  2016.

[30] Yaoyong Li  Hugo Zaragoza  Ralf Herbrich  John Shawe-Taylor  and Jaz S. Kandola. The
perceptron algorithm with uneven margins. In Proceedings of the Nineteenth International
Conference on Machine Learning  ICML ’02  pages 379–386  San Francisco  CA  USA  2002.
Morgan Kaufmann Publishers Inc.

[31] Timothy P Lillicrap  Jonathan J Hunt  Alexander Pritzel  Nicolas Heess  Tom Erez  Yuval Tassa 
David Silver  and Daan Wierstra. Continuous control with deep reinforcement learning. arXiv
preprint arXiv:1509.02971  2015.

[32] Tsung-Yi Lin  Priya Goyal  Ross Girshick  Kaiming He  and Piotr Dollár. Focal loss for dense

object detection. arXiv preprint arXiv:1708.02002  2017.

[33] Zhouhan Lin  Minwei Feng  Cicero Nogueira dos Santos  Mo Yu  Bing Xiang  Bowen Zhou 

and Yoshua Bengio. A structured self-attentive sentence embedding. In ICLR  2017.

[34] Ji Liu and Xiaojin Zhu. The teaching dimension of linear learners. Journal of Machine Learning

Research  17(162):1–25  2016.

[35] Weiyang Liu  Bo Dai  James Rehg  and Le Song. Iterative machine teaching. In Proceedings of
the 34st International Conference on Machine Learning (ICML-17)  pages 1188–1196  2017.

[36] Weiyang Liu  Yandong Wen  Zhiding Yu  and Meng Yang. Large-margin softmax loss for
In International Conference on Machine Learning  pages

convolutional neural networks.
507–516  2016.

11

[37] Renqian Luo  Fei Tian  Tao Qin  and Tie-Yan Liu. Neural architecture optimization. arXiv

preprint arXiv:1808.07233  2018.

[38] Dougal Maclaurin  David Duvenaud  and Ryan Adams. Gradient-based hyperparameter opti-
mization through reversible learning. In International Conference on Machine Learning  pages
2113–2122  2015.

[39] Smitha Milli  Pieter Abbeel  and Igor Mordatch. Interpretable and pedagogical examples. arXiv

preprint arXiv:1711.00694  2017.

[40] Tan Nguyen and Scott Sanner. Algorithms for direct 0–1 loss optimization in binary classiﬁca-

tion. In International Conference on Machine Learning  pages 1085–1093  2013.

[41] Kishore Papineni  Salim Roukos  Todd Ward  and Wei-Jing Zhu. Bleu: a method for automatic
evaluation of machine translation. In Proceedings of the 40th annual meeting on association for
computational linguistics  pages 311–318. Association for Computational Linguistics  2002.

[42] Marc’Aurelio Ranzato  Sumit Chopra  Michael Auli  and Wojciech Zaremba. Sequence level

training with recurrent neural networks. arXiv preprint arXiv:1511.06732  2015.

[43] Jurgen Schmidhuber. Evolutionary principles in self-referential learning. Diploma thesis 

Institut f. Informatik  Tech. Univ. Munich  1987.

[44] Patrick Shafto  Noah D Goodman  and Thomas L Grifﬁths. A rational account of pedagogical
reasoning: Teaching by  and learning from  examples. Cognitive psychology  71:55–89  2014.
[45] Shiqi Shen  Yong Cheng  Zhongjun He  Wei He  Hua Wu  Maosong Sun  and Yang Liu.
Minimum risk training for neural machine translation. In Proceedings of the 54th Annual
Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)  pages
1683–1692. Association for Computational Linguistics  2016.

[46] Yang Song  Alexander Schwing  Raquel Urtasun  et al. Training deep neural networks via direct
loss minimization. In International Conference on Machine Learning  pages 2169–2177  2016.
[47] Ilya Sutskever  Oriol Vinyals  and Quoc V Le. Sequence to sequence learning with neural

networks. In Advances in neural information processing systems  pages 3104–3112  2014.

[48] Richard Stuart Sutton. Temporal credit assignment in reinforcement learning. 1984.
[49] Michael Taylor  John Guiver  Stephen Robertson  and Tom Minka. Softrank: optimizing non-
smooth rank metrics. In Proceedings of the 2008 International Conference on Web Search and
Data Mining  pages 77–86. ACM  2008.

[50] Sebastian Thrun and Lorien Pratt. Learning to learn. Springer Science & Business Media 

2012.

[51] Ashish Vaswani  Noam Shazeer  Niki Parmar  Jakob Uszkoreit  Llion Jones  Aidan N Gomez 
Łukasz Kaiser  and Illia Polosukhin. Attention is all you need. In Advances in Neural Informa-
tion Processing Systems  pages 6000–6010  2017.

[52] Ronald J Williams and David Zipser. A learning algorithm for continually running fully

recurrent neural networks. Neural computation  1(2):270–280  1989.

[53] Lijun Wu  Fei Tian  Tao Qin  Jianhuang Lai  and Tie-Yan Liu. A study of reinforcement learning

for neural machine translation. In EMNLP  2018.

[54] Lijun Wu  Yingce Xia  Li Zhao  Fei Tian  Tao Qin  Jianhuang Lai  and Tie-Yan Liu. Adversarial

neural machine translation. In ACML  2018.

[55] Sergey Zagoruyko and Nikos Komodakis. Wide residual networks. arXiv preprint arX-

iv:1605.07146  2016.

[56] Xiaojin Zhu. Machine teaching: An inverse problem to machine learning and an approach
toward optimal education. In Proceedings of the Twenty-Ninth AAAI Conference on Artiﬁcial
Intelligence  AAAI’15  pages 4083–4087. AAAI Press  2015.

[57] Barret Zoph and Quoc Le. Neural architecture search with reinforcement learning. In Interna-

tional Conference on Learning Representations  2017.

12

,Lijun Wu
Fei Tian
Yingce Xia
Yang Fan
Tao Qin
Lai Jian-Huang
Tie-Yan Liu