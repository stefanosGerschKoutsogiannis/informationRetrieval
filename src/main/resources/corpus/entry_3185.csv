2012,Learning with Target Prior,In the conventional approaches for supervised parametric learning  relations between data and target variables are provided through training sets consisting of pairs of corresponded data and target variables. In this work  we describe a new learning scheme for parametric learning  in which the target variables $\y$ can be modeled with a prior model $p(\y)$ and the relations between data and target variables are estimated through $p(\y)$ and a set of uncorresponded data $\x$ in training. We term this method as learning with target priors (LTP). Specifically  LTP learning seeks parameter $\t$ that maximizes the log likelihood of $f_\t(\x)$ on a uncorresponded training set with regards to $p(\y)$. Compared to the conventional (semi)supervised learning approach  LTP can make efficient use of prior knowledge of the target variables in the form of probabilistic distributions  and thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach  the learned parametric regressor in LTP can be more efficiently implemented and deployed in tasks where running efficiency is critical  such as on-line BCI signal decoding. We demonstrate the effectiveness of the proposed approach on parametric regression tasks for BCI signal decoding and pose estimation from video.,Learning with Target Prior

Zuoguan Wang

Troy  NY 12180

wangz6@rpi.edu

Gerwin Schalk

Albany  NY  12201

schalk@wadsworth.org

Siwei Lyu

Albany  NY 12222

lsw@cs.albany.edu

Qiang Ji

Troy  NY 12180
jiq@rpi.edu

Dept. of ECSE  Rensselaer Polytechnic Inst.

Computer Science  Univ. at Albany  SUNY

Wadsworth Center  NYS Dept. of Health

Dept. of ECSE  Rensselaer Polytechnic Inst.

Abstract

In the conventional approaches for supervised parametric learning  relations be-
tween data and target variables are provided through training sets consisting of
pairs of corresponded data and target variables.
In this work  we describe a
new learning scheme for parametric learning  in which the target variables y can
be modeled with a prior model p(y) and the relations between data and target
variables are estimated with p(y) and a set of uncorresponded data X in train-
ing. We term this method as learning with target priors (LTP). Speciﬁcally 
LTP learning seeks parameter θ that maximizes the log likelihood of fθ(X) on
a uncorresponded training set with regards to p(y). Compared to the conventional
(semi)supervised learning approach  LTP can make efﬁcient use of prior knowl-
edge of the target variables in the form of probabilistic distributions  and thus re-
moves/reduces the reliance on training data in learning. Compared to the Bayesian
approach  the learned parametric regressor in LTP can be more efﬁciently imple-
mented and deployed in tasks where running efﬁciency is critical. We demonstrate
the effectiveness of the proposed approach on parametric regression tasks for BCI
signal decoding and pose estimation from video.

Introduction

1
One of the central problems in machine learning is prediction/inference  where given an input da-
tum X  we would like to predict or infer the value of a target variable of interest  y  assuming X
and y have some intrinsic relationship. The prediction/inference task in many practical applications
involves high dimensional and structured data and target variables. Depending on the form of knowl-
edge about X and y and their relationship available to us  there are several different methodologies
to solve the prediction inference problem.
In the Bayesian approach  our knowledge about input and target variables  as well as their relation-
ships  are all represented as probability distributions. Correspondingly  the prediction/inference task
is solved with optimizations based on the posterior distribution p(y|X)  a common choice of which
is the maximum a posteriori objective: maxy p(y|X). The posterior distribution can be explicitly
constructed from the target prior  p(y)  which encodes our knowledge on the internal structure of
the target y  and the likelihood  p(X|y)  which summarizes the process of generating X from y  as
p(y|X) ∝ p(X|y)p(y). Or it can be directly handled as in the conditional random ﬁelds [9] without
referring to the target prior or the likelihood. The advantage of the Bayesian approach is that it
incorporates prior knowledge about data and target variables into the prediction/inference task in a
principled manner. The main downside is that  in many practical problems  the relationship between
X and y could be complicated and defy straightforward modeling. Furthermore  except for a few
special cases (e.g.  Gaussian models)  the Bayesian prediction/inference of y from data X usually
requires expensive numerical optimization or Monte-Carlo sampling.

1

1
m

An alternative approach to prediction/inference is supervised parametric learning  where the in-
formation about X and y and their relationship is described in the form of a set of corre-
(cid:80)m
sponding examples  {Xi  yi}m
i=1  and the goal of learning is to choose an optimal member from
a parametric family fθ(X) that minimizes the average prediction error using a loss function
i=1 L(yi − fθ(Xi)). Usually  the optimization may also include a regularization penalty
minθ
on θ to reduce over-ﬁtting. The most signiﬁcant drawback of the supervised parametric learning
approach is that the learning performance relies heavily on the quality and quantity of the train-
ing data. This problem is somewhat alleviated in semi-supervised learning [28]  where the training
data include unlabeled examples of X. However  unlike the Bayesian approach  it is usually difﬁ-
cult to incorporate prior knowledge in the form of probabilistic distributions into (semi)supervised
parametric learning.
In this work  we describe a new approach to learning a parametric regressor fθ(X)  which we term
as learning with target prior (LTP). In many practical applications  the target variables y follow the
some regular spatial and temporal patterns that can be described probabilistically  and the observed
target variables are samples of such distributions. For instance  to perform an activity like grasping
a cup  the traces of ﬁnger movements tend to have similar patterns that are caused by many factors 
such as the underlying physiological  anatomical and dynamic constraints. Such regular patterns
can beneﬁt the task of decoding the ﬁnger movements from ECoG signals in a brain computer
interface (BCI) system  Fig.1  as it regularizes the decoder to produce similar patterns. Similarly 
the skeleton structures and the dynamic dependencies constraint the body pose to have similar spatial
and temporal patterns for the same activity (e.g. walking  running and jumping)  which can be used
for body pose estimation in computer vision.
In LTP learning  we incorporate such spatial and temporal regular patterns of the target variables
into the learning framework. Speciﬁcally  we learn a probability distribution p(y) that captures the
spatial and temporal regularities of the target variable y  then we estimate the function parameters
θ  by maximizing the log-likelihood of the output y = fθ(X) with respect to the the prior distribu-
tion. LTP learning can be applied to both unsupervised learning  in which no corresponded input
and output are available  and semi-supervised learning in which part of corresponding outputs are
available. We demonstrate the effectiveness of LTP learning in two problems: BCI decoding and
pose estimation.
The rest of the paper is organized as the following: Section 2 discusses the related work. Section
3 describes the general framework for our method and compare with other existing methodologies.
In Sections 4 and 5  details on deployment and experimental evaluation of this general framework
in two applications  namely BCI decoding and pose estimation from video  are described. Section 6
concludes the paper with discussion and future works.
2 Related Work
LTP learning is related to several existing learning schemes. The prior knowledge about the target
variables in classiﬁcation problems is exploited in recent works as learning with uncertain labels 
in which the distribution over the target class labels for each data example is used in place of cor-
responding pairs of data/target variables [10]. A similar idea in semi-supervised learning uses the
proportion of different classes [16  28] to predict the class labels on the uncorresponded training
data examples. The knowledge about class proportion conditioned on certain input feature is cap-
tured by generalized expectation (GE)[12  13]. There are several works directly embed domain
constraints about the target variables in learning. For instance  constraint driven learning (CODL)
[3] enforces task speciﬁc constraints on the target labels by appending a penalty term in the ob-
jective function. Posterior regularization [5] directly imposes regularization on the posterior of the
latent target variables  of which CODL can be seen as a special case with MAP approximation. A
general framework  which incorporates prior information as measurements in the Bayesian frame-
work  is proposed in [11]. However  all these approaches have only been applied to problems with
discrete outputs (classiﬁcation or labeling) and may be difﬁcult to extend to incorporate complex
dependencies in high-dimensional continuous target variables.
LTP learning is also related to learning with structured outputs. Dependencies in the target variables
can be directly modeled in conditional random ﬁelds (CRF) [9]  as a probabilistic graphical model
between the output components. However  the learned regressor is usually not in closed form and
predictions has to be obtained by numerical optimization or Monte-Carlo sampling. Some of the
recent supervised parametric learning methods can take advantage of some structure constraints over
the target variables. The max margin Markov network [21] trains an SVM classiﬁer with outputs

2

Figure 1: Experiment setup for this study.

whose structures are described by graphs. The structured SVM was further extended with high order
loss function [20] or models with latent variables [27]. These methods can be viewed as special cases
of LTP learning  where general probabilistic models for target variables can be incorporated.
3 General Framework
In this section  we describe the general framework of learning with target priors. Speciﬁcally  our
task is to learn the parameter θ in a parametric family of functions of X  fθ(x)  to best predict
the corresponding target variable y. Both the data and target variable can be of high dimensions.
Knowledge about target variable is provided through a target prior model in the form of a parametric
probability distribution  pη(y)  with model parameter η. The speciﬁc form of pη(y) is determined
based on different applications  ranging from simple distributions to more complex models such
as Markov random ﬁelds. The model parameter θ is estimated by maximizing the log-likelihood
log pη(fθ(X)). In the following  we apply the LTP learning to unsupervised learning in which no
corresponded input and output are available  as well as semi-supervised learning in which part of
corresponding outputs are available.
For the unsupervised learning  assume we are given a set of outputs y ∈ RY×m  as well as a set of
uncorresponded inputs X ∈ RX×n  where Y and X are the dimensionality  and m and n are the
temporal length for y and X respectively. This is applicable to the case of BCI where it is easier to
gather inputs X or structured targets y than it is to gather corresponded inputs and targets (X  y).
In many real BCI applications the input brain signals X are collected only under thoughts without
actual body movement y. The body movements could be easily collected when the brain signals
are not being recorded. In the problem of pose estimation  it is a tedious work to label poses y on
the input images X. In both the ﬁnger movement decoding and pose estimation  y and X could be
extracted from different subjects. A prior model pη(y) is learned from {yi}m
i=1  where yi ∈ RY×1
and η is parameter of the prior model. Then the function parameter θ is estimated by maximizing

log pη(fθ(Xi)) 

(1)

where Xi ∈ RX×1. The parameter θ is chosen in the way that the output on the {Xi}n
i=1 maximally
consistent of the prior distribution pη(y). The setting of semi-supervised learning is slightly different
from unsupervised learning  in which the corresponding input {Xi}m
i=1 are
also given. Then the learning becomes the combination of supervised and unsupervised learning:

i=1 of the output {yi}m

n(cid:88)

i=1

max

θ

1
n

m(cid:88)

i=1

n(cid:88)

i=1

min

θ

1
m

L(yi − fθ(Xi)) − λ
n

log pη(fθ(Xi)) 

(2)

where L is the loss function and λ is a constant representing the tradeoff between the two terms. In
eq. 2  the parameter θ is chosen in the way that the outputs not only minimize the loss function on
training data  but also make the predicted targets on the unlabeled data comply with the target prior.
Next  we adapt unsupervised/semi-supervised learning with LTP to the prediction/inference in two
applications  namely  decoding ECoG signal to predict ﬁnger movement in BCI and estimation of
body poses from videos  where the-state-of-the-art performances are achieved.
4 Finger Movement Decoding in ECoG based BCI
The main task in brain-computer interface (BCI) systems is to convert electronic signals recorded
from human brain into controlling commands for patients with motor disabilities (e.g.  paraly-
sis). Many recent studies in neurobiology have suggested that electrocorticographic (ECoG) signals

3

recorded near the brain surface show strong correlations with limb motions [2  8]. ECoG signal
decoding is the critical step in ECoG based BCI systems  the goal of which is to obtain a functional
mapping between the ECoG signals and the kinematic variables (e.g.  spatial locations and move-
ment velocities of ﬁngers recorded by a digital glove) [8]. The ECoG decoding problem has been
widely solved with supervised parametric learning [26  8  25]  where corresponded ECoG signals
and target kinematic variables are collected from one subject and used to train a parametric regres-
sor. However  the decoder learned from data collected from one subject in a controlled experiment
usually has trouble to generalize for the same subject over time and in an open environment (tem-
poral generalization) [18]  or to decode signals from other subjects (cross-subject generalization)
[24]. The former is due to the strong variances in ECoG signals that are caused by other concurrent
brain activities  and the latter is due to the difference in shape and volume of the brains for different
subjects. These limitations are regarded as the most challenging issues in current BCI systems [7].
There have been several works addressing these issues. For instance  to improve the generalization
performance across trials  several adaptive classiﬁcation methods are proposed [18]  i.e.  updating
the LDA with labeled feed back data. To generalize better across subjects  a collaborative paradigm
was proposed to integrating information from multiple subjects [24]. In [17] it is investigated that
certain spectral features of ECoG signals can be used across subjects to classify movements. How-
ever  these methods do not provide satisfactory solutions since the central challenge in extending the
parametric decoder across time and subject is that the conventional parametric learning approach 
on which all these methods are based  relies on training data to obtain information for learning the
regressor  which in these cases are difﬁcult to collect. At the same time  in BCI it is typically much
easier to gather samples of uncorresponded target variables  i.e  traces of ﬁnger movements recorded
by digital gloves  than it is to gather corresponding pairs of training samples.
Thus in this work  we propose to improve the temporal and cross-subject generalization of BCI
decoders with the learning with target priors framework. In the ﬁrst step  we obtain a parametric
target prior model using uncorresponded samples of the target data  in this case  the traces of ﬁnger
positions.
In the second step  we estimate a linear decoding function using the general method
described in Section 3. Let us ﬁrst deﬁne notations that are to be used subsequently: we use a linear
decoding function  as: fθ(x) = XT θ  to predict the traces of ﬁnger movements y as target variable.
Speciﬁcally  we deﬁne y ∈ RY where Y corresponds to the number of samples in the ﬁnger traces.
X ∈ RL×Y is a matrix whose columns are a subset of ECoG signal features of length L. The model
parameter θ ∈ RL is a vector. Linear decoding function are widely used in BCI decoding [1] for its
simplicity and run-time efﬁciency in constructing hardware based BCI system.

4.1 Target Prior Model

(cid:80)
We use the Gaussian-Bernoulli restricted Boltzmann machine (GB-RBM) [14]:
pη(y) =
h e−Eη(y h)  where Z is the normalizing constant  and h ∈ {0  1}H are binary hidden vari-
1
Z
ables  as the parametric target prior model. The pdf is deﬁned in terms of the joint energy function
over y and h  as:

Y(cid:88)

(yi − ci)2

−

i=1

2

Y H(cid:88)

Wijyihj −

bjhj.

i=1 j=1

j=1

H(cid:88)

Eη(y  h) =

where Wij is the interaction strength between the hidden node hi and visible node yj. c and b are
the bias for the visible layer and hidden layer  respectively. The target variable y is normalized to
have zero mean and unit standard variance. The parameters in this model  (W  c  b)  are collec-
tively represented with η. Direct maximum likelihood training of GB-RBM is intractable due to the
normalizing factor Z  so we use contrastive divergence [6] to estimate η from data.

4.2 Learning Regressor Parameter θ

With training data and the GB-RBM as the target prior model  we optimize the objective function of
LTP in Eq.(1) or (2) for parameters θ. With the linear decoding function and squared loss function 
the gradient of the ﬁrst term of Eq.(2) can be computed as − 2
i θ). The derivative
of θ over log-likelihood of XT θ with regards to the prior model can be computed  as

(cid:80)m
i=1 Xi(yi − XT

m

∂ log pη(XT θ)

∂θ

=

(cid:88)

h

pη(h|XT θ)

−∂E(XT θ  h)

∂θ

.

(3)

4

Plugging the energy function E into Eq.(3)  we can simplify it to

= X(XT θ − c) + XWT(cid:88)

h

pη(h|XT θ)h 

(4)

∂ log pη(XT θ)

where(cid:80)
given XT θ. Speciﬁcally  assume g = (cid:80)

∂θ

h pη(h|XT θ)h using the property of GB-RBM that the elements of h are independent
h pη(h|XT θ)h  then gi = σ(WiXT θ)  where Wi is
the ith row of W and σ is the logistic function σ(x) = 1/(1 + exp (−x)). The expectation of
the derivative over all sequences  composed of Y successive samples in the training data  can be
expressed as (cid:104) ∂ log pη(XT θ)
4.3 Experimental Settings

(cid:105)data where < · >data stands for expectation over the data.

∂θ

The ECoG data and target ﬁnger movement variables are collected from a clinical setting based on
ﬁve subjects (A-E) who underwent brain surgeries [8]. Each subject had a 48- or 64- electrode grid
placed over the cortex. During the experiment  the subjects are required to repeatedly ﬂex and extend
speciﬁc individual ﬁngers according to visual cues on a video screen. The experiment setup is shown
in Fig. 1. The data collection for each subject lasted 10 minutes  which yielded an average of 30
trials for each ﬁnger. The ﬂexion of each ﬁnger was measured by a data glove. For each channel 
features are extracted based on signal power of three bands (1-60Hz  60-100Hz  100-200Hz) [2] 
which results in 144 or 204 features for subjects with 48 or 64 channels  respectively.
4.4 Learning Target Prior Model and Decoding Function

The training data for the prior model pη(y) are either from other subjects or from the same subject
but were collected at a different time and do not have correspondence with the training input data.
Here we consider the ﬁnger moving traces only composed of ﬂexion and extension as in Fig. 2(A).
This simpliﬁed model is still practically useful since we can ﬁrst classify the trace into movement
state or rest state and then apply the corresponding regressor for each state [4]. Each subject has
around 1400 samples. We model the ﬁnger movement trace using the GB-RBM with 64 hidden
nodes and 12 visible nodes  which is approximately the length of one round extension and ﬂexion.
Then  all segments from 12 successive samples in the data are used to train the prior model.
The GB-RBM is trained with stochastic gradient decent with a mini-batch size of 25 sub-sequences.
We run 5000 epochs with a ﬁxed learning rate 0.001. We ﬁrst validate the prior model by drawing
samples from the learned GB-RBM. Figure 2(B) shows the 9 samples  which seem to capture some
important properties of the temporal dynamics of the ﬁnger trace.

Figure 2: (A) Original trace; (B)samples from GB-RBM. Each sample is a segment with length 12.
With the prior model  the paired features/target variables if they exist and unpaired features  on
which the expectation of Eq.(4) is calculated  are used to learn the parameter θ. θ is randomly
initialized and learned with stochastic gradient decent with the same batch size 25. We run 2000
epochs with ﬁxed learning rate 10−4.
4.5 Generalization Across Subjects

We learn the decoding function for new subjects by deploying the unsupervised LTP learning in Sec-
tion 3. Even though it is difﬁcult to get the corresponded samples from new subjects  we always have
the input ECoG signals  whose features will be used as the input of the unsupervised LTP learning.
We compare the unsupervised LTP learning with linear regression [2] in two ways: 1) the linear
regression (intra subject) in which the corresponded data and target variables are available. The
accuracy of linear regression is calculated based on ﬁve fold cross-validation  that is  4/5 trials (25
trials) are used for training and 1/5 trials (5 trials) are used for testing. 2) the linear regression (inter

5

0123456TIME (s)NORMALIZED AMPLITUDE0-110123456TIME (s)NORMALIZED AMPLITUDE0-11(A)(B)Table 1: Results on thumb of subjects based on 2 fold cross validation (correlation coefﬁcient).

A
0.29
0.38

B
0.26
0.42

C
0.06
0.13

Linear R
Semisupervised LTP

D
0.10
0.15

E
0.11
0.12

subject) trained on the one subject and tested on other subjects. The results for inter subjects are
calculated based on 5 fold cross-validation (each time one subject is used for training and the model
is tested on other four subjects). Linear regression is trained on pairs of features and targets while
LTP only uses the targets to train the prior model. For the linear regression trained and tested on
different subjects  the channels across subjects are aligned by the 3-d position of the sensors.
Figure 3(A) shows the performance comparison of the three models. Note that the performances of
the unsupervised LTP learning is on par with those of the linear regression (intra) on subject A  B  C
and D  which suggests that the decoder learned by unsupervised LTP learning can generalize across
subjects. Figure 3(B) and (C) shows two examples of prediction results from the unsupervised
LTP learning. On the other hand  not surprisingly  the performances of linear regression (inter
subjects) suggest that it cannot be extended across subjects  which is due to brain difference for
different subjects as stated above. The generalization ability gained by unsupervised LTP learning
is mainly because it directly learns decoding functions on the new subject without using brain signal
from existing subjects  which are believed to change dramatically among subjects. One thing we
noticed is that the unsupervised LTP learning does not work well on subject E  which is because the
thumb movement speed of subject E is much slower than subject A  on which the prior model is
trained. This suggests that the quality of the target prior model is critical for the performance.

Figure 3: (A) Comparison among three models across subjects; (B) Sample results for subject A;
(C) Sample results for subject B. The dot line is the ground truth and the solid line is the prediction

4.6 Online Learning for Decoding Functions

i=1 be the training data in the current trial and {Xj}n

In the next set of experiment  we use the learning with target priors framework for learning decoding
functions that generalize over time. This experiment is performed for each subject individually. For
each subject  assume {Xi  yi}m
j=1 be the new
samples unknown in training. We ﬁrst train the prior model on {yi}m
i=1. Then parameter θ is learned
using the semi-supervised learning in section 3.
The new samples come sequentially and thus we want the decoding function to be online updated.
The parameter θ is not updated for every new coming sample  but every batch of data X ∈ RL×Y.
Here we give a brief description of the online batch updating method. For the start  the parameter
θ is learned from the corresponding pairs of samples {Xi  yi}m
i=1. Then the decoding function
with parameter θ is used to decode the ﬁrst batch {Xj}Y
i=1 is decoded 
{Xj}Y
j=1  not including the predicted target variables  is included as part of the unlabeled training
data to update the parameter θ by the semi-supervised learning in section 3. Then the updated θ
is used to decode the second batch {Xj}2Y
j=Y+1 and the process loops. In summary  after the new
coming batch is decoded using the current parameter θ  then it is included as training data to update
parameter θ. Generally  we are trying to maximally use the ”seen” data to get the decoding function
prepared for the ”unseen” coming samples.
The batch size Y is chosen to be 12. The model is tested on the thumb of ﬁve subjects based on 2
fold cross validation  that is  we treat the ﬁrst 15 trials as the paired data/target variables and then
online test the remaining trials. After that in turn we treat the last 15 trials as the paired data/target
variables and use the ﬁrst 15 trials for online testing. The results in Table 1 show the proposed model
with online batch updating can signiﬁcantly improve the results. This means that by regularizing

j=1. After the batch {Xj}Y

6

ABCDE−0.100.10.20.3Correlation CoefficientLinear Regression(intra subject)Unsupervised LTP (inter subject)Linear Regression (inter subject)050100150200250300-1.5-1-0.500.511.5050100150200250300-2-101234(A)(B)(C)the new features with the target prior  the semi-supervised learning in Section 3 successfully obtains
information from the new features and adapts the decoders well for new coming samples.
5 Pose Estimation from Videos
In this section  we apply learning with target priors to the problem of the pose estimation problem 
the goal of which is to extract 3D human pose from images or video sequences. We demonstrate
LTP by applying it to learn a linear mapping from image features to poses while LTP could be used
to learn more sophisticated models. We will show that the algorithms learned by LTP are more
generalizable both across subjects and over time on the same subject respectively.
In this
from CMU MoCap database
(http://mocap.cs.cmu.edu). The data are from 3 subjects  with sequences 1 & 2 from the ﬁrst
subject  sequences 3 & 4 from the second subject and sequences 5 & 6 from the third subject. Each
sequence consists of about 70 frames. Our task is to estimate the 3-D pose from videos  which is
described by 59 dimensional joint angles. The image feature is extracted from the silhouette image
at the side view. For each silhouette image we take 10 dimension moment features [23].
i=1  where X ∈ R10×n are the image features  y ∈
We represent the video sequence as {Xi  yi}n
R59×n are the joint angles  where n is the length of the sequence and n could be different for
different sequences. Instead of directly mapping features to 59 dimensional joint angles  we learn
the function which maps the features to the 3 dimensional subspace of joint angles obtained through
PCA. Then the original space of joint angles is recovered from the low dimensional subspace. All

six walking sequences

experiment  we use

Algorithm 1 learning with target priors

i=1  test features X∗

Input: joint angles {yi}n
Output: y∗ corresponding to X∗
Steps:
1: PCA: y → EZ  where E ∈ R59×3  Z ∈ R3×n
2: learn prior model pη(y) on Z
3: learn mapping function Z∗ = fθ(X∗) using the unsupervised LTP learning in section 3
Output: recover original space y∗ = EZ∗

possible segments composed of successive 60 frames in the sequence are used to train the GB-RBM.
So the length of the vector into the GB-RBM is 180 (the subspace is 3 dimension).
Many methods have been proposed to address the pose estimation problem  among which sGPLVM
[19]  FOLS-GPLVM [15] and imCRBM [22] are the three very competitive ones. sGPLVM models
a shared latent space by pose and image features through GPLVM  while FOLS-GPLVM models a
shared latent space and a private latent space for each part. imCRBM constructs a pose prior for the
Bayesian model using the implicit mixture of CRBM. However  Taylor’s work is not comparable
to our method  because it requires a generative model to directly map a pose to a silhouette  while
our method explicitly uses the extracted moment features  and the comparison here focuses on algo-
rithms instead of features. So we will compare with sGPLVM and FOLS-GPLVM using the same
image features. The training of both sGPLVM and FOLS-GPLVM require corresponded images and
poses (X  y) while LTP does not require this.
For the unsupervised LTP learning  the target prior model is trained on the subspace of the joint
angles {yi}n
i=1 on sequence 1 and tested on the features of all 6 sequences. The implementation
details are shown in algorithm 1. Except for sGPLVM and FOLS-GPLVM  the results are also com-
pared with ridge regression. Ridge regression  sGPLVM and FOLS-GPLVM are trained on the ﬁrst
sequence with paired samples {Xi  yi}n
i=1 and tested on all the 6 sequences. The implementation
of ridge regression is similar to that in algorithm 1  the only difference is that the mapping from
features to the PCA subspace is through ridge regression.
The results are measured in terms of mean absolute joint angle error and are shown in table 2.
We can see that when testing on the sequence from the same subject (sequence 2)  unsupervised
LTP learning is not the best. In contrast  when testing on the sequences from subjects B and C 
unsupervised LTP learning achieves the best results  which is slightly better than sGPLVM. Con-
sidering that only linear dimension reduction and linear function are assumed for unsupervised
LTP learning and paired samples are not required  unsupervised LTP learning is even more com-
petitive. FOLS-GPLVM does not perform well on this data set  which is probably due to limited
training samples. Thus the experiments demonstrate that the algorithm learned by unsupervised

7

Table 2: Train prior model on the ﬁrst sequence and test on all sequences. Results are measured
with mean absolute joint angle error.

B

C

3
8.3
5.6
6.5
5.3

4
8.5
6.1
6.4
6.1

5
10.7
3.0
3.3
2.9

6
10.7
3.1
4.0
2.9

Subject
Sequence Num
Ridge Regression
sGPLVM
FOLS-GPLVM
Unsupervised LTP

A

2
1
2.1
4.8
— 3.1
— 5.3
3.0
4.8

Table 3: For each subject  train on the ﬁrst sequence and test on the second sequence. Results are
measured with absolute joint angle error.

Subject
Ridge Regression
sGPLVM
FOLS-GPLVM
Semi-supervised LTP

A
4.8
3.1
5.3
2.87

B
5.3
5.3
5.8
3.97

C
3.1
3.0
3.8
2.33

LTP learning in section 3 can generalize well across subjects. The reason that ridge regression 
sGPLVM and FOLS-GPLVM do not generalize well is that the relations between poses and images
are solely learned from corresponded poses and images  and these relations may have difﬁculty to
hold for the new subjects due to may factors (i.e  the video for the new subject is recorded from a
slightly different angle). LTP avoids this problem by learning the relations using the generalizable
prior distribution over the targets and the images from the new subjects.
We further demonstrate that the algorithm learned through semi-supervised learning in section 3
generalizes well across time for the same subject. In this experiment  for each subject we treat the
ﬁrst sequence as the paired samples {Xi  yi}m
i=1 and estimate the 3-D pose of the second sequence
{Xi}n
i=1. The algorithm
is similar to that in algorithm 1 except for replacing unsupervised LTP learning with semi-supervised
learning. The results in table 3 show that the semi-supervised learning in section 3 signiﬁcantly
outperforms three other methods.

j=1. The prior model is trained on the joint angles of the ﬁrst sequence {yi}m

6 Conclusion and Discussion

In this work  we describe a new learning scheme for parametric learning  known as learning with
target priors  that uses a prior model over the target variables and a set of uncorresponded data in
training. Compared to the conventional (semi)supervised learning approach  LTP can make efﬁ-
cient use of prior knowledge of the target variables in the form of probabilistic distributions  and
thus removes/reduces the reliance on training data in learning. Compared to the Bayesian approach 
the learned parametric regressor in LTP can be more efﬁciently implemented and deployed in tasks
where running efﬁciency is critical  such as on-line BCI signal decoding. We demonstrate the effec-
tiveness of the proposed approach in terms of generalization on parametric regression tasks for BCI
signal decoding and pose estimation from video.
There are several extensions of this work we would like to further pursue. First  in the current work
we only use a simple target prior model in the form of GB-RBM. There are  however  more ﬂexible
probabilistic models  such as Markov random ﬁelds or dynamic Bayesian networks  that can better
represent statistical properties in the target variables. Therefore  we would like to incorporate such
models into LTP learning to further improve the performance. Second  we would like to investigate
the connection between conventional capacity control methods (e.g.  max margin or regularization)
with LTP learning. This has the potential to unify and shed light on the deeper relation among
different learning methodologies. Last  we would also like to use LTP learning with nonlinear
decoding functions.
Acknowledgement The authors would like to thank Jixu Chen for providing the motion capture
data and feature extraction code. Zuoguan Wang and Qiang Ji are supported in part by a grant from
US Army Research Ofﬁce (W911NF-08-1-0216 (GS)) through Albany Medical College. Gerwin
Schalk is supported by US Army Research Ofﬁce (W911NF-08-1-0216 (GS)) and W911NF-07-1-
0415 (GS)  and the NIH (EB006356(GS) and EB000856 (GS)). Siwei Lyu is supported by an NSF
CAREER Award (IIS-0953373).

8

References
[1] Bashashati  Ali  Fatourechi  Mehrdad  Ward  Rabab K.  and Birch  Gary E. A survey of signal
processing algorithms in brain-computer interfaces based on electrical brain signals. J. Neural
Eng.  4  June 2007.

[2] Bougrain  Laurent and Liang  Nanying. Band-speciﬁc features improve Finger Flexion Pre-
diction from ECoG. In Jornadas Argentinas sobre Interfaces Cerebro Computadora - JAICC 
Paran`a  Argentine  2009.

[3] Chang  Mingwei  Ratinov  Lev  and Roth  Dan. Guiding semi-supervision with constraint-

driven learning. In Proc. of the Annual Meeting of the ACL  2007.

[4] Flamary  R´emi and Rakotomamonjy  Alain. Decoding ﬁnger movements from ECoG signals

using switching linear models. Technical report  September 2009.

[5] Ganchev  Kuzman  Graca  Joao  Gillenwater  Jennifer  and Taskar  Ben. Posterior regulariza-

tion for structured latent variable models. JMLR  11(July):2001–2049  2010.

[6] Hinton  Geoffrey. Training products of experts by minimizing contrastive divergence. Neural

Computation  14(8):2002  Aug 2000.

[7] Krusienski  Dean J  Grosse-Wentrup  Moritz  Galn  Ferran  Coyle  Damien  Miller  Kai J 
Forney  Elliott  and Anderson  Charles W. Critical issues in state-of-the-art brain-computer
interface signal processing. Journal of Neural Engineering  8(2):025002  2011.

[8] Kub´anek  J  Miller  K J  Ojemann  J G  Wolpaw  J R  and Schalk  G. Decoding ﬂexion of
individual ﬁngers using electrocorticographic signals in humans. J Neural Eng  6(6):066001–
066001  Dec 2009.

[9] Lafferty  John. Conditional random ﬁelds: Probabilistic models for segmenting and labeling

sequence data. In NIPS  pp. 282–289. Morgan Kaufmann  2001.

[10] Lefort  Riwal  Fablet  Ronan  and Boucher  Jean-Marc. Weakly supervised classiﬁcation of

objects in images using soft random forests. In ECCV  pp. 185–198  2010.

[11] Liang  Percy  Jordan  Michael I.  and Klein  Dan. Learning from measurements in exponential

families. In ICML ’09  pp. 641–648  New York  NY  USA  2009. ACM.

[12] Mann  Gideon S. and McCallum  Andrew. Simple  robust  scalable semi-supervised learning

via expectation regularization. In ICML  pp. 593–600  2007.

[13] Mann  Gideon S. and Mccallum  Andrew. Generalized expectation criteria for semi-supervised

learning of conditional random ﬁelds. In ACL’08  pp. 870–878  2008.

[14] Mohamed  A.  Dahl  G.  and Hinton  G. Acoustic modeling using deep belief networks. Audio 

Speech  and Language Processing  IEEE Transactions on  PP(99):1  2011.

[15] Salzmann  Mathieu  Henrik  Carl  Raquel  Ek  and Darrell  Urtasun Trevor. Factorized orthog-

[16] Schapire  Robert E.  Rochery  Marie  Rahim  Mazin G.  and Gupta  Narendra. Incorporating

onal latent spaces. JMLR  9:701–708  2010.

prior knowledge into boosting. In ICML  2002.

[17] Shenoy  P.  Miller  K.J.  Ojemann  J.G.  and Rao  R.P.N. Generalized features for electrocor-

ticographic bcis. Biomedical Engineering  IEEE Transactions on  55(1)  jan. 2008.

[18] Shenoy  Pradeep  Krauledat  Matthias  Blankertz  Benjamin  Rao  Rajesh P. N.  and M¨uller 
Klaus-Robert. Towards adaptive classiﬁcation for BCI. Journal of Neural Engineering  2006.
[19] Shon  Aaron P.  Grochow  Keith  Hertzmann  Aaron  and Rao  Rajesh P. N. Learning shared

latent structure for image synthesis and robotic imitation. In NIPS  pp. 1233–1240  2006.

[20] Tarlow  Daniel and S. Zemel  Richard. Structured output learning with high order loss func-

tions. AISTATS  2012.

MIT Press  2003.

[21] Taskar  Ben  Guestrin  Carlos  and Koller  Daphne. Max-margin markov networks. In NIPS.

[22] Taylor  G.W.  Sigal  L.  Fleet  D.J.  and Hinton  G.E. Dynamical binary latent variable models

for 3d human pose tracking. In CVPR  pp. 631 –638  June 2010.

[23] Tian  Tai-Peng  Li  Rui  and Sclaroff  S. Articulated pose estimation in a learned smooth space

of feasible solutions. In CVPR  pp. 50  June 2005.

[24] Wang  Yijun and Jung  Tzyy-Ping. A collaborative brain-computer interface for improving

human performance. PLoS ONE  6(5):e20422  05 2011.

[25] Wang  Zuoguan  Ji  Qiang  Miller  Kai J.  and Schalk  Gerwin. Decoding ﬁnger ﬂexion from
electrocorticographic signals using a sparse gaussian process. In ICPR  pp. 3756–3759  2010.
[26] Wang  Zuoguan  Schalk  Gerwin  and Ji  Qiang. Anatomically constrained decoding of ﬁnger

ﬂexion from electrocorticographic signals. In NIPS  2011.

[27] Yu  C.-N. and Joachims  T. Learning structural SVMs with latent variables. In ICML  2009.
[28] Zhu  Xiaojin. Semi-supervised learning literature survey  2006. URL http://pages.cs.

wisc.edu/˜jerryzhu/pub/ssl_survey.pdf.

9

,Helena Peic Tukuljac
Antoine Deleforge
Remi Gribonval