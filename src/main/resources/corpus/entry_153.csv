2012,A Nonparametric Conjugate Prior Distribution for the Maximizing Argument of a Noisy Function,We propose a novel Bayesian approach to solve stochastic optimization problems that involve ﬁnding extrema of noisy  nonlinear functions. Previous work has focused on representing possible functions explicitly  which leads to a two-step procedure of ﬁrst  doing inference over the function space and second  ﬁnding the extrema of these functions. Here we skip the representation step and directly model the distribution over extrema. To this end  we devise a non-parametric conjugate prior where the natural parameter corresponds to a given kernel function and the sufﬁcient statistic is composed of the observed function values. The resulting posterior distribution directly captures the uncertainty over the maximum of the unknown function.,A Nonparametric Conjugate Prior Distribution for

the Maximizing Argument of a Noisy Function

Pedro A. Ortega

Max Planck Institute for Intelligent Systems
Max Planck Institute for Biolog. Cybernetics
pedro.ortega@tuebingen.mpg.de

Jordi Grau-Moya

Max Planck Institute for Intelligent Systems
Max Planck Institute for Biolog. Cybernetics

jordi.grau@tuebingen.mpg.de

Tim Genewein

Max Planck Institute for Intelligent Systems
Max Planck Institute for Biolog. Cybernetics
tim.genewein@tuebingen.mpg.de

David Balduzzi

Max Planck Institute for Intelligent Systems
david.balduzzi@tuebingen.mpg.de

Daniel A. Braun

Max Planck Institute for Intelligent Systems
Max Planck Institute for Biolog. Cybernetics
daniel.braun@tuebingen.mpg.de

Abstract

We propose a novel Bayesian approach to solve stochastic optimization problems
that involve ﬁnding extrema of noisy  nonlinear functions. Previous work has
focused on representing possible functions explicitly  which leads to a two-step
procedure of ﬁrst  doing inference over the function space and second  ﬁnding
the extrema of these functions. Here we skip the representation step and directly
model the distribution over extrema. To this end  we devise a non-parametric
conjugate prior based on a kernel regressor. The resulting posterior distribution
directly captures the uncertainty over the maximum of the unknown function.
Given t observations of the function  the posterior can be evaluated efﬁciently
in time O(t2) up to a multiplicative constant. Finally  we show how to apply our
model to optimize a noisy  non-convex  high-dimensional objective function.

1 Introduction

Historically  the ﬁelds of statistical inference and stochastic optimization have often developed their
own speciﬁc methods and approaches. Recently  however  there has been a growing interest in
applying inference-based methods to optimization problems and vice versa [1–4]. Here we consider
stochastic optimization problems where we observe noise-contaminated values from an unknown
nonlinear function and we want to ﬁnd the input that maximizes the expected value of this function.

The problem statement is as follows. Let X be a metric space. Consider a stochastic function
f : X   R mapping a test point x ∈ X to real values y ∈ R characterized by the conditional pdf
P (y|x). Consider the mean function

¯f (x) := E[y|x] = Z yP (y|x) dy.

The goal consists in modeling the optimal test point
x∗ := arg max

{ ¯f (x)}.

x

1

(1)

(2)

a)

2

1.5

1

0.5

0

−0.5

−1

−1.5

−2

0

5

4

3

2

1

0

0

0.5

1

1.5

2

2.5

3

0.5

1

1.5

2

2.5

3

b)

Figure 1: a) Given an estimate h of the mean function ¯f (left)  a simple probability density function
over the location of the maximum x∗ is obtained using the transformation P (x∗) ∝ exp{αh(x∗)} 
where α > 0 plays the role of the precision (right). b) Illustration of the Gramian matrix for different
test locations. Locations that are close to each other produce large off-diagonal entries.

Classic approaches to solve this problem are often based on stochastic approximation methods [5].
Within the context of statistical inference  Bayesian optimization methods have been developed
where a prior distribution over the space of functions is assumed and uncertainty is tracked during
the entire optimization process [6  7]. In particular  non-parametric Bayesian approaches such as
Gaussian Processes have been applied for derivative-free optimization [8  9]  also within the context
of the continuum-armed bandit problem [10]. Typically  these Bayesian approaches aim to explicitly
represent the unknown objective function of (1) by entertaining a posterior distribution over the
space of objective functions. In contrast  we aim to model directly the distribution of the maximum
of (2) conditioned on observations.

2 Brief Description

Our model is intuitively straightforward and easy to implement1. Let h(x) : X → R be an estimate
of the mean ¯f (x) constructed from data Dt := {(xi  yi)}t
i=1 (Figure 1a  left). This estimate can
easily be converted into a posterior pdf over the location of the maximum by ﬁrst multiplying it with
a precision parameter α > 0 and then taking the normalized exponential (Figure 1a  right)

P (x∗|Dt) ∝ exp{α · h(x∗)}.

In this transformation  the precision parameter α controls the certainty we have over our estimate of
the maximizing argument: α ≈ 0 expresses almost no certainty  while α → ∞ expresses certainty.
The rationale for the precision is: the more distinct inputs we test  the higher the precision—testing
the same (or similar) inputs only provides local information and therefore should not increase our
knowledge about the global maximum. A simple and effective way of implementing this idea is
given by

P (x∗|Dt) ∝ exp(cid:26)ρ ·(cid:18)ξ + t · Pi K(xi  xi)
PiPj K(xi  xj )(cid:19)
}
{z

effective # of locations

|

· Pi K(xi  x∗)yi + K0(x∗)y0(x∗)
(cid:27) 
}
|

Pi K(xi  x∗) + K0(x∗)

estimate of ¯f (x∗)

{z

(3)

where ρ  ξ  K  K0 and y0 are parameters of the estimator: ρ > 0 is the precision we gain for each
new distinct observation; ξ > 0 is the number of prior points; K : X × X → R+ is a symmetric
kernel function; K0 : X → R+ is a prior precision function; and y0 : X → R is a prior estimate of
¯f .
In (3)  the mean function ¯f is estimated with a kernel regressor [11] that combines the function
observations with a prior estimate of the function  and the total effective number of locations is
calculated as the sum of the prior locations ξ and the number of distinct locations in the data Dt.
The latter is estimated by multiplying the number of data points t with the coefﬁcient

∈ (0  1] 

(4)

1Implementations can be downloaded from http://www.adaptiveagents.org/argmaxprior

Pi K(xi  xi)
PiPj K(xi  xj)

2

Noisy Function

10 Data Points

100 Data Points

1000 Data Points

20

15

10

5

0

−5

−10

−15

−20

20

15

10

5

0

−5

−10

−15

−20

20

15

10

5

0

−5

−10

−15

−20

20

15

10

5

0

−5

−10

−15

−20

0

0.5

1

1.5

2

2.5

3

0

0.5

1

1.5

2

2.5

3

0

0.5

1

1.5

2

2.5

3

0

0.5

1

1.5

2

2.5

3

5

4

3

2

1

0

0

0.5

1

1.5

2

2.5

3

5

4

3

2

1

0

0

0.5

1

1.5

2

2.5

3

5

4

3

2

1

0

0

0.5

1

1.5

2

2.5

3

Figure 2: Illustration of the posterior distribution over the maximizing argument for 10  100 and
1000 observations drawn from a function with varying noise. The top-left panel illustrates the func-
tion and the variance bounds (one standard deviation). The observations in the center region close
to x = 1.5 are very noisy. It can be seen that the prior gets progressively washed out with more
observations.

i.e. the ratio between the trace of the Gramian matrix (K(xi  xj))i j and the sum of its entries.
Inputs that are very close to each other will have overlapping kernels  resulting in large off-diagonal
entries of the Gramian matrix—hence decreasing the number of distinct locations (Figure 1b). For
example  if we have t observations from n ≪ t locations  and each location has t/n observations 
then the coefﬁcient (4) is equal to n/t and hence the number of distinct locations is exactly n  as
expected.

Figure 2 illustrates the behavior of the posterior distribution. The expression for the posterior can
be calculated up to a constant factor in O(t) time. The computation of the normalizing constant
is in general intractable. Therefore  our proposed posterior can be easily combined with Markov
chain Monte Carlo methods (MCMC) to implement stochastic optimizers as will be illustrated in
Section 4.

3 Derivation

3.1 Function-Based  Indirect Model

Our ﬁrst task is to derive an indirect Bayesian model for the optimal test point that builds its estimate
via the underlying function space. Let G be the set of hypotheses  and assume that each hypothesis
g ∈ G corresponds to a stochastic mapping g : X   R. Let P (g) be the prior2 over G and let the

likelihood be P ({yt}|g  {xt}) = Qt P (yt|g  xt). Then  the posterior of g is given by
P (g)Qt P (yt|g  xt)

P (g)P ({yt}|g  {xt})

P (g|{yt}  {xt}) =

P ({yt}|{xt})

P ({yt}|{xt})

=

.

(5)

For each x∗ ∈ X   let G(x∗) ⊂ G be the subset of functions such that for all g ∈ G(x∗)  x∗ =
arg maxx{¯g(x)}3. Then  the posterior over the optimal test point x∗ is given by

P (x∗|{yt}  {xt}) = ZG(x∗)

P (g|{yt}  {xt}) dg 

(6)

This model has two important drawbacks: (a) it relies on modeling the entire function space G 
which is potentially much more complex than necessary; (b) it requires calculating the integral (6) 
which is intractable for virtually all real-world problems.

2For the sake of simplicity  we neglect issues of measurability of G.
3Note that we assume that the mean function ¯g is bounded and that it has a unique maximizing test point.

3

3.2 Domain-Based  Direct Model

We want to arrive at a Bayesian model that bypasses the integration step suggested by (6) and directly
models the location of optimal test point x∗. The following theorem explains how this direct model
relates to the previous model.
Theorem 1. The Bayesian model for the optimal test point x∗ is given by

P (x∗) = ZG(x∗)

P (g) dg

P (yt|x∗  xt  Dt−1) = RG(x∗) P (yt|g  xt)P (g)Qt−1

k=1 P (yk|g  xk) dg

k=1 P (yk|g  xk) dg

where Dt := {(xk  yk)}t

k=1 is the set of past tests.

RG(x∗) P (g)Qt−1

(prior)

 

(likelihood)

Proof. Using Bayes’ rule  the posterior distribution P (x∗|{yt}  {xt}) can be rewritten as

P (x∗)Qt P (yt|x∗  xt  Dt−1)

P ({yt}|{xt})

.

(7)

Since this posterior is equal to (6)  one concludes (using (5)) that

P (x∗)Yt

P (yt|x∗  xt  Dt−1) = ZG(x∗)

P (g)Yt

P (yt|g  xt) dg.

Note that this expression corresponds to the joint P (x∗  {yt}|{xt}). The prior P (x∗) is obtained by
setting t = 0. The likelihood is obtained as the fraction

P (yt|x∗  xt  Dt−1) =

P (x∗  {yk}t
P (x∗  {yk}t−1

k=1|{xk}t
k=1)
k=1|{xk}t−1
k=1)

 

where it shall be noted that the denominator P (x∗  {yk}t−1
condition xt.

k=1|{xk}t−1

k=1) doesn’t change if we add the

From Theorem 1 it is seen that although the likelihood model P (yt|g  xt) for the indirect model
is i.i.d. at each test point  the likelihood model P (yt|x∗  xt  Dt−1) for the direct model depends
on the past tests Dt−1  that is  it is adaptive. More critically though  the likelihood function’s
internal structure of the direct model corresponds to an integration over function space as well—
thus inheriting all the difﬁculties of the indirect model.

3.3 Abstract Properties of the Likelihood Function

There is a way to bypass modeling the function space explicitly if we make a few additional as-
sumptions. We assume that for any g ∈ G(x∗)  the mean function ¯g is continuous and has a unique
maximum. Then  the crucial insight consists in realizing that the value of the mean function ¯g inside
a sufﬁciently small neighborhood of x∗ is larger than the value outside of it (see Figure 3a).
We assume that  for any δ > 0 and any z ∈ X   let Bδ(z) denote the open δ-ball centered on z. The
functions in G fulﬁll the following properties:

a. Continuous: Every function g ∈ G is such that its mean ¯g is continuous and bounded.
b. Maximum: For any x∗ ∈ X   the functions g ∈ G(x∗) are such that for all δ > 0 and all

z /∈ Bδ(x∗)  ¯g(x∗) > ¯g(z).

2 be in X  
Furthermore  we impose a symmetry condition on the likelihood function. Let x∗
and consider their associated equivalence classes G(x∗
2). There is no reason for them to
be very different: in fact  they should virtually be indistinguishable outside of the neighborhoods
of x∗
1) becomes distinguishable from
1) systematically predict higher values
the other equivalence classes because the functions in G(x∗

2. It is only inside of the neighborhood of x∗

1 when G(x∗

1) and G(x∗

1 and x∗

1 and x∗

4

a)

b)

c)

0

Figure 3: Illustration of assumptions. a) Three functions from G(x∗). They all have their maximum
located at x∗ ∈ X . b) Schematic representation of the likelihood function of x∗ ∈ X conditioned
on a few observations. The curve corresponds to the mean and the shaded area to the conﬁdence
bounds. The density inside of the neighborhood is unique to the hypothesis x∗  while the density
outside is shared amongst all the hypotheses. c) The log-likelihood ratio of the hypotheses x∗
1 and
2 as a function of the test point x. The kernel used in the plot is Gaussian.
x∗

than the rest. This assumption is illustrated in Figure 3b. In fact  taking the log-likelihood ratio of
two competing hypotheses

log

P (yt|x∗
P (yt|x∗

1  xt  Dt−1)
2  xt  Dt−1)

for a given test location xt should give a value equal to zero unless xt is inside of the vicinity of x∗
1
2 (see Figure 3c). In other words  the amount of evidence a hypothesis gets when the test point
or x∗
is outside of its neighborhood is essentially zero (i.e. it is the same as the amount of evidence that
most of the other hypotheses get).

3.4 Likelihood and Conjugate Prior

Following our previous discussion  we propose the following likelihood model. Given the previous
data Dt−1 and a test point xt ∈ X   the likelihood of the observation yt is

P (yt|x∗  xt  Dt−1) =

1

Z(xt  Dt−1)

λ(yt|xt  Dt−1) exp(cid:8)αt · ht(x∗) − αt−1 · ht−1(x∗)(cid:9) 

(8)

where: Z(xt  Dt−1) is a normalizing constant; λ(yt|xt  Dt−1) is a posterior probability over yt
given xt and the data Dt−1; αt is a precision measuring the knowledge we have about the whole
function; and and ht is an estimate of the mean function ¯f. We have chosen the precision αt as

αt := ρ ·(cid:16)ξ + Pi K(xi  xi)
PiPj K(xi  xj )(cid:17)

where ρ > 0 is a scaling parameter; ξ > 0 is a parameter representing the number prior locations
tested; and K : X × X → R+ is a symmetric kernel function4. For the estimate ht  we have chosen
a Naradaya-Watson kernel regressor [11]

ht(x∗) := Pt

Pt

i=1 K(xi  x∗)yi + K0(x∗)y0(x∗)

.

i=1 K(xi  x∗) + K0(x∗)

In the last expression  y0 corresponds to a prior estimate of ¯f with prior precision K0. Inspecting (8) 
we see that the likelihood model favours positive changes to the estimated mean function from new 
unseen test locations. The pdf λ(yt|xt  Dt−1) does not need to be explicitly deﬁned  as it will later
drop out when computing the posterior. The only formal requirement is that it should be independent
of the hypothesis x∗.
We propose the conjugate prior

P (x∗) =

1
Z0

exp{α0 · g0(x∗)} =

1
Z0

exp{ξ · y0(x∗)}.

(9)

4We refer the reader to the kernel regression literature for an analysis of the choice of kernel functions.

5

The conjugate prior just encodes a prior estimate of the mean function. In a practical optimization
application  it serves the purpose of guiding the exploration of the domain  as locations x∗ with high
prior value y0(x∗) are more likely to contain the maximizing argument.
Given a set of data points Dt  the prior (9) and the likelihood (8) lead to a posterior given by

k=1 αk · hk(x∗) − αk−1 · hk−1(x∗)(cid:9)Z −1
0 Qt
k=1 αk · hk(x′) − αk−1 · hk−1(x′)(cid:9)Z −1
0 Qt

k=1 Z(xk  Dk−1)−1
k=1 Z(xk  Dk−1)−1 dx′

(10)

k=1 P (yk|x∗  xk  Dk−1)
k=1 P (yk|x′  xk  Dk−1) dx′

P (x∗|Dt) =

=

=

P (x∗)Qt
RX P (x′)Qt
exp(cid:8)Pt
RX exp(cid:8)Pt
exp(cid:8)αt · ht(x∗)(cid:9)
RX exp(cid:8)αt · ht(x′)(cid:9) dx′ .

Thus  the particular choice of the likelihood function guarantees an analytically compact posterior
expression. In general  the normalizing constant in (10) is intractable  which is why the expression is
only practical for relative comparisons of test locations. Substituting the precision αt and the mean
function estimate ht yields

P (x∗|Dt) ∝ exp(cid:26)ρ ·(cid:18)ξ + t · Pi K(xi  xi)

PiPj K(xi  xj )(cid:19) · Pi K(xi  x∗)yi + K0(x∗)y0(x∗)
Pi K(xi  x∗) + K0(x∗)

(cid:27).

4 Experimental Results

4.1 Parameters.

We have investigated the inﬂuence of the parameters on the resulting posterior probability distribu-
tion. We have used the Gaussian kernel

K(x  x∗) = expn−

1

2σ2 (x − x∗)2o.

(11)

In this ﬁgure  7 data points are shown  which were drawn as y ∼ N (f (x)  0.3)  where the mean
function is

f (x) = cos(2x + 3

2 π) + sin(6x + 3

2 π).

The prior precision K0 and the prior estimate of the mean function y0 were chosen as

K0(x) = 1

and

y0(x) = −

1
2σ2
0

(x − µ0)2 

(12)

(13)

0 = 5. This prior favours the region close to µ.

where the latter corresponds to the logarithm of a Gaussian with mean µ0 = 1.5 and vari-
ance σ2
Figure 4 shows how the choice of the precision scale ρ and the kernel width σ affect the shape of
the posterior probability density. Here  it is seen that a larger kernel width σ increases the region of
inﬂuence of a particular data point  and hence produce smoother posterior densities. The precision
scale parameter ρ controls the precision per distinct data point: higher values for ρ lead to sharper
updates of the posterior distribution.

4.2 Application to Optimization.

The main motivation behind our proposed model is its application to the optimization of noisy
functions. Because of the noise  choosing new test locations requires carefully balancing explorative
and exploitative tests—a problem well known in the multiarmed bandits literature. To overcome
this  one can apply the Bayesian control rule/Thompson sampling [12  13]: the next test location
is chosen by sampling it from the posterior. We have carried out two experiments  described in the
following.

6

a)

b)

c)

Figure 4: Effect of the change of parameters on the posterior density over the location of the max-
imizing test point. Panel (a) shows the 7 data points drawn from the noisy function (solid curve).
Panel (b) shows the effect of increasing the width of the kernel (here  Gaussian). The solid and
dotted curves correspond to σ = 0.01 and σ = 0.1 respectively. Panel (c) shows the effect of di-
minishing the precision on the posterior  where solid and shaded curves correspond to ρ = 0.2 and
ρ = 0.1 respectively.

                Average Value

      Average Value

s
b
o

y

1.5

1

0.5

0

−0.5

−1

−1.5

−2

0

s
b
o

y

1.5

1

0.5

0

−0.5

−1

−1.5

−2

0

50

100

150

200

# of samples

50

100

150

200

# of samples

Figure 5: Observation values obtained by sampling from the posterior over the maximizing argument
(left panel) and according to GP-UCB (right panel). The solid blue curve corresponds to the time-
averaged function value  averaged over ten runs. The gray area corresponds to the error bounds
(1 standard deviation)  and the dashed curve in red shows the time-average of a single run.

Comparison to Gaussian Process UCB. We have used the model to optimize the same func-
tion (12) as in our preliminary tests but with higher additive noise equal to one. This is done by sam-
pling the next test point xt directly from the posterior density over the optimum location P (x∗|Dt) 
and then using the resulting pair (xt  yt) to recursively update the model. Essentially  this procedure
corresponds to Bayesian control rule/Thompson sampling.

We compared our method against a Gaussian Process optimization method using an upper con-
ﬁdence bound (UCB) criterion [10]. The parameters for the GP-UCB were set to the following
values: observation noise σn = 0.3 and length scale ℓ = 0.3. For the constant that trades off ex-
ploration and exploitation we followed Theorem 1 in [10] which states βt = 2 log(|D|t2π2/6δ)
with δ = 0.5. We have implemented our proposed method with a Gaussian kernel as in (11) with
width σ2 = 0.05. The prior sufﬁcient statistics are exactly as in (13). The precision parameter was
set to ρ = 0.3.
Simulation results over ten independent runs are summarized in Figure 5. We show the time-
averaged observation values y of the noisy function evaluated at test locations sampled from the
posterior. Qualitatively  both methods show very similar convergence (on average)  however our
method converges faster and with a slightly higher variance.

High-Dimensional Problem. To test our proposed method on a challenging problem  we have
designed a non-convex  high-dimensional noisy function with multiple local optima. This Noisy
Ripples function is deﬁned as

f (x) = − 1

1000 kx − µk2 + cos( 2

3 πkx − µk)

where µ ∈ X is the location of the global maximum  and where observations have additive Gaussian
noise with zero mean and variance 0.1. The advantage of this function is that it generalizes well to
any number of dimensions of the domain. Figure 6a illustrates the function for the 2-dimensional

7

a)

5

0

−5

−10

15

10

5

0

−5

15

10

5

0

−5

−10

−10

−15

−15

b)

0

-100

-200

8000

6000

4000

2000

0

0

Average Value

50

Samples

Regret

100

150

50

Samples

100

150

Figure 6: a) The Noisy Ripples objective function in 2 dimensions. b) The time-averaged value and
the regret obtained by the optimization algorithm on a 50-dimensional version of the Noisy Ripples
function.

input domain. This function is difﬁcult to optimize because it requires averaging the noisy observa-
tions and smoothing the ridged landscape in order to detect the underlying quadratic form.

We optimized the 50-dimensional version of this function using a Metropolis-Hastings scheme to
sample the next test locations from the posterior over the maximizing argument. The Markov chain
was started at [20  20  · · ·   20]T   executing 120 isotropic Gaussian steps of variance 0.07 before
the point was used as an actual test location. For the arg-max prior  we used a Gaussian kernel
with lengthscale l = 2  precision factor ρ = 1.5  prior precision K0(x∗) = 1 and prior mean
estimate y0(x∗) = − 2
The result of one run is presented in Figure 6b. It can be seen that the optimizer manages to quickly
(≈ 100 samples) reach near-optimal performance  overcoming the difﬁculties associated with the
high-dimensionality of the input space and the numerous local optima. Crucial for this success was
the choice of a kernel that is wide enough to accurately estimate the mean function. The authors are
not aware of any method capable of solving a problem of similar characteristics.

1000 kx + 5k2. The goal µ was located at the origin.

5 Conclusions

Our goal was to design a probabilistic model over the maximizing argument that is algorithmically
efﬁcient and statistically robust even for large  high-dimensional noisy functions. To this end  we
have derived a Bayesian model that directly captures the uncertainty over the maximizing argument 
thereby bypassing having to model the underlying function space—a much harder problem.

Our proposed model is computationally very efﬁcient when compared to Gaussian process-based
(which have cubic time complexity) or models based on upper conﬁdence bounds (which require
ﬁnding the input maximizing the bound—a generally intractable operation). In our model  evaluat-
ing the posterior up to a constant factor scales quadratically with the size of the data.

In practice  we have found that one of the main difﬁculties associated with our proposed method is
the choice of the parameters. As in any kernel-based estimation method  choosing the appropriate
kernel bandwidth can signiﬁcantly change the estimate and affect the performance of optimizers that
rely on the model. There is no clear rule on how to choose a good bandwidth.

In a future research  it will be interesting to investigate the theoretical properties of the proposed
nonparametric model  such as the convergence speed of the estimator and its relation to the extensive
literature on active learning and bandits.

8

References

[1] E. Brochu  V. Cora  and N. de Freitas. A tutorial on bayesian optimization of expensive cost
functions  with application to active user modeling and hierarchical reinforcement learning.
Technical Report TR-2009-023  University of British Columbia  Department of Computer Sci-
ence  2009.

[2] K. Rawlik  M. Toussaint  and S. Vijayakumar. Approximate inference and stochastic optimal

control. arXiv:1009.3958  2010.

[3] A. Shapiro. Probabilistic Constrained Optimization: Methodology and Applications  chapter
Statistical Inference of Stochastic Optimization Problems  pages 282–304. Kluwer Academic
Publishers  2000.

[4] H.J. Kappen  V. G´omez  and M. Opper. Optimal control as a graphical model inference prob-

lem. Machine Learning  87(2):159–182  2012.

[5] H.J. Kushner and G.G. Yin. Stochastic Approximation Algorithms and Applications. Springer-

Verlag  1997.

[6] J. Mockus. Application of bayesian approach to numerical methods of global and stochastic

optimization. Journal of Global Optimization  4(4):347–365  1994.

[7] D. Lizotte. Practical Bayesian Optimization. Phd thesis  University of Alberta  2008.
[8] D.R. Jones  M. Schonlau  and W.J. Welch. Efﬁcient global optimization of expensive black-

box functions. Journal of Global Optimization  13(4):455–492  1998.

[9] M.A. Osborne  R. Garnett  and S.J. Roberts. Gaussian processes for global optimization. In

3rd International Conference on Learning and Intelligent Optimization (LION3)  2009.

[10] N. Srinivas  A. Krause  S. Kakade  and M. Seeger. Gaussian process optimization in the bandit
setting: No regret and experimental design. In International Conference on Machine Learning 
2010.

[11] T. Hastie  R. Tbshirani  and J. Friedman. The Elements of Statistical Learning. Springer 

second edition  2009.

[12] P.A. Ortega and D.A. Braun. A minimum relative entropy principle for learning and acting.

Journal of Artiﬁcial Intelligence Research  38:475–511  2010.

[13] B.C. May and D.S. Leslie. Simulation studies in optimistic Bayesian sampling in contextual-
bandit problems. Technical Report 11:02  Statistics Group  Department of Mathematics  Uni-
versity of Bristol  2011.

9

,Özlem Aslan
Hao Cheng
Xinhua Zhang
Dale Schuurmans
Eliya Nachmani
Lior Wolf