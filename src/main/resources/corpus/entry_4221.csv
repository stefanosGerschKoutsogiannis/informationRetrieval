2014,Parallel Successive Convex Approximation for Nonsmooth Nonconvex Optimization,Consider the problem of minimizing the sum of a smooth (possibly non-convex) and a convex (possibly nonsmooth) function involving a large number of variables. A popular approach to solve this problem is the block coordinate descent (BCD) method whereby at each iteration only one variable block is updated while the remaining variables are held fixed. With the recent advances in the developments of the multi-core parallel processing technology  it is desirable to parallelize the BCD method by allowing multiple blocks to be updated simultaneously at each iteration of the algorithm. In this work  we propose an inexact parallel BCD approach where at each iteration  a subset of the variables is updated in parallel by minimizing convex approximations of the original objective function. We investigate the convergence of this parallel BCD method for both randomized and cyclic variable selection rules. We analyze the asymptotic and non-asymptotic convergence behavior of the algorithm for both convex and non-convex objective functions. The numerical experiments suggest that for a special case of Lasso minimization problem  the cyclic block selection rule can outperform the randomized rule.,Parallel Successive Convex Approximation for

Nonsmooth Nonconvex Optimization

Meisam Razaviyayn∗

meisamr@stanford.edu

Mingyi Hong†

mingyi@iastate.edu

Zhi-Quan Luo‡
luozq@umn.edu

Jong-Shi Pang§

jongship@usc.edu

Abstract

Consider the problem of minimizing the sum of a smooth (possibly non-convex)
and a convex (possibly nonsmooth) function involving a large number of variables.
A popular approach to solve this problem is the block coordinate descent (BCD)
method whereby at each iteration only one variable block is updated while the re-
maining variables are held ﬁxed. With the recent advances in the developments of
the multi-core parallel processing technology  it is desirable to parallelize the BCD
method by allowing multiple blocks to be updated simultaneously at each itera-
tion of the algorithm. In this work  we propose an inexact parallel BCD approach
where at each iteration  a subset of the variables is updated in parallel by mini-
mizing convex approximations of the original objective function. We investigate
the convergence of this parallel BCD method for both randomized and cyclic vari-
able selection rules. We analyze the asymptotic and non-asymptotic convergence
behavior of the algorithm for both convex and non-convex objective functions.
The numerical experiments suggest that for a special case of Lasso minimization
problem  the cyclic block selection rule can outperform the randomized rule.

1

Introduction

Consider the following optimization problem

min

x

n(cid:88)

i=1

gi(xi)

h(x) (cid:44) f (x1  . . .   xn) +

where Xi ⊆ Rmi is a closed convex set; the function f :(cid:81)n
sibly non-convex); and g(x) (cid:44)(cid:80)n

s.t. xi ∈ Xi  i = 1  2  . . .   n 
(1)
i=1 Xi → R is a smooth function (pos-
i=1 gi(xi) is a separable convex function (possibly nonsmooth).
The above optimization problem appears in various ﬁelds such as machine learning  signal process-
ing  wireless communication  image processing  social networks  and bioinformatics  to name just a
few. These optimization problems are typically of huge size and should be solved expeditiously.
A popular approach for solving the above multi-block optimization problem is the block coordinate
descent (BCD) approach  where at each iteration of BCD  only one of the block variables is updated 
while the remaining blocks are held ﬁxed. Since only one block is updated at each iteration  the per-
iteration storage and computational demand of the algorithm is low  which is desirable in huge-size
problems. Furthermore  as observed in [1–3]  these methods perform particulary well in practice.

∗Electrical Engineering Department  Stanford University
†Industrial and Manufacturing Systems Engineering  Iowa State University
‡Department of Electrical and Computer Engineering  University of Minnesota
§Department of Industrial and Systems Engineering  University of Southern California

1

The availability of high performance multi-core computing platforms makes it increasingly desir-
able to develop parallel optimization methods. One category of such parallelizable methods is the
(proximal) gradient methods. These methods are parallelizable in nature [4–8]; however  they are
equivalent to successive minimization of a quadratic approximation of the objective function which
may not be tight; and hence suffer from low convergence speed in some practical applications [9].
To take advantage of the BCD method and parallel multi-core technology  different parallel BCD al-
gorithms have been recently proposed in the literature. In particular  the references [10–12] propose
parallel coordinate descent minimization methods for (cid:96)1-regularized convex optimization problems.
Using the greedy (Gauss-Southwell) update rule  the recent works [9 13] propose parallel BCD type
methods for general composite optimization problems. In contrast  references [2  14–20] suggest
randomized block selection rule  which is more amenable to big data optimization problems  in
order to parallelize the BCD method.
Motivated by [1 9 15 21]  we propose a parallel inexact BCD method where at each iteration of the
algorithm  a subset of the blocks is updated by minimizing locally tight approximations of the objec-
tive function. Asymptotic and non-asymptotic convergence analysis of the algorithm is presented in
both convex and non-convex cases for different variable block selection rules. The proposed parallel
algorithm is synchronous  which is different than the existing lock-free methods in [22  23].
The contributions of this work are as follows:

• A parallel block coordinate descent method is proposed for non-convex nonsmooth prob-
lems. To the best of our knowledge  reference [9] is the only paper in the literature that
focuses on parallelizing BCD for non-convex nonsmooth problems. This reference utilizes
greedy block selection rule which requires search among all blocks as well as communica-
tion among processing nodes in order to ﬁnd the best blocks to update. This requirement
can be demanding in practical scenarios where the communication among nodes are costly
or when the number of blocks is huge. In fact  this high computational cost motivated the
authors of [9] to develop further inexact update strategies to efﬁciently alleviating the high
computational cost of the greedy block selection rule.

• The proposed parallel BCD algorithm allows both cyclic and randomized block variable
selection rules. The deterministic (cyclic) update rule is different than the existing parallel
randomized or greedy BCD methods in the literature; see  e.g.  [2  9  13–20]. Based on our
numerical experiments  this update rule is beneﬁcial in solving the Lasso problem.

• The proposed method not only works with the constant step-size selection rule  but also
with the diminishing step-sizes which is desirable when the Lipschitz constant of the ob-
jective function is not known.

• Unlike many existing algorithms in the literature  e.g. [13–15]  our parallel BCD algo-
rithm utilizes the general approximation of the original function which includes the lin-
ear/proximal approximation of the objective as a special case. The use of general approx-
imation instead of the linear/proximal approximation offers more ﬂexibility and results in
efﬁcient algorithms for particular practical problems; see [21  24] for speciﬁc examples.

• We present an iteration complexity analysis of the algorithm for both convex and non-
convex scenarios. Unlike the existing non-convex parallel methods in the literature such
as [9] which only guarantee the asymptotic behavior of the algorithm  we provide non-
asymptotic guarantees on the convergence of the algorithm as well.

2 Parallel Successive Convex Approximation

As stated in the introduction section  a popular approach for solving (1) is the BCD method where at
iteration r +1 of the algorithm  the block variable xi is updated by solving the following subproblem

xr+1
i = arg min
xi∈Xi

h(xr

1  . . .   xr

i−1  xi  xr

i+1  . . .   xr

n).

(2)

In many practical problems  the update rule (2) is not in closed form and hence not computation-
ally cheap. One popular approach is to replace the function h(·) with a well-chosen local convex

2

(3)

xr+1
i = arg min
xi∈Xi

(cid:101)hi(xi  xr) 

(cid:101)hi(xi  y) = (cid:101)fi(xi  y) + gi(xi).

to the i-th block around the current iteration xr. This approach  also known as block successive
convex approximation or block successive upper-bound minimization [21]  has been widely used in
different applications; see [21  24] for more details and different useful approximation functions. In

approximation(cid:101)hi(xi  xr) in (2). That is  at iteration r + 1  the block variable xi is updated by
where(cid:101)hi(xi  xr) is a convex (possibly upper-bound) approximation of the function h(·) with respect
this work  we assume that the approximation function(cid:101)hi(· ·) is of the following form:
Here (cid:101)fi(·  y) is an approximation of the function f (·) around the point y with respect to the i-th
block. We further assume that (cid:101)fi(xi  y) : Xi × X → R satisﬁes the following assumptions:
• (cid:101)fi(·  y) is continuously differentiable and uniformly strongly convex with parameter τ  i.e. 
(cid:101)fi(xi  y) ≥ (cid:101)fi(x(cid:48)
• Gradient consistency assumption: ∇xi(cid:101)fi(xi  x) = ∇xif (x)  ∀x ∈ X
i  y)  xi − x(cid:48)
i ∈ Xi  ∀y ∈ X
i(cid:107)2  ∀xi  x(cid:48)
• ∇xi(cid:101)fi(xi ·) is Lipschitz continuous on X for all xi ∈ Xi with constant (cid:101)L 
(cid:107)∇xi(cid:101)fi(xi  y) − ∇xi(cid:101)fi(xi  z)(cid:107) ≤(cid:101)L(cid:107)y − z(cid:107) 
• (cid:101)f (xi  y) = (cid:104)∇yif (y)  xi − yi(cid:105) + α
• (cid:101)f (xi  y) = f (xi  y−i) + α

For instance  the following traditional proximal/quadratic approximations of f (·) satisfy the above
assumptions when the feasible set is compact and f (·) is twice continuously differentiable:

i  y) + (cid:104)∇xi(cid:101)fi(x(cid:48)

2 (cid:107)xi − yi(cid:107)2  for α large enough.

∀y  z ∈ X   ∀xi ∈ Xi  ∀i.

i(cid:105) + τ

2(cid:107)xi − x(cid:48)

2 (cid:107)xi − yi(cid:107)2.

i.e. 

(4)

For other practical useful approximations of f (·) and the stochastic/incremental counterparts  see
[21  25  26].
With the recent advances in the development of parallel processing machines  it is desirable to take
the advantage of multi-core machines by updating multiple blocks simultaneously in (3). Unfortu-
nately  naively updating multiple blocks simultaneously using the approach (3) does not result in a
convergent algorithm. Hence  we suggest to modify the update rule by using a well-chosen step-size.
More precisely  we propose Algorithm 1 for solving the optimization problem (1).

Algorithm 1 Parallel Successive Convex Approximation (PSCA) Algorithm

ﬁnd a feasible point x0 ∈ X and set r = 0
for r = 0  1  2  . . . do

choose a subset Sr ⊆ {1  . . .   n}

i = arg minxi∈Xi (cid:101)hi(xi  xr)  ∀i ∈ Sr
i + γr((cid:98)xr
i )  ∀i ∈ Sr  and set xr+1

i − xr

calculate(cid:98)xr

set xr+1

i = xr

end for

i = xr

i   ∀ i /∈ Sr

The procedure of selecting the subset Sr is intentionally left unspeciﬁed in Algorithm 1. This
selection could be based on different rules. Reference [9] suggests the greedy variable selection rule
where at each iteration of the algorithm in [9]  the best response of all the variables are calculated
and at the end  only the block variables with the largest amount of improvement are updated. A
drawback of this approach is the overhead caused by the calculation of all of the best responses at
each iteration; this overhead is especially computationally demanding when the size of the problem
is huge. In contrast to [9]  we suggest the following randomized or cyclic variable selection rules:

∅  ∀i (cid:54)= j and(cid:83)m−1

• Cyclic: Given the partition {T0  . . .  Tm−1} of the set {1  2  . . .   n} with Ti

(cid:96)=0 T(cid:96) = {1  2  . . .   n}  we say the choice of the variable selection is

(cid:84)Tj =

cyclic if

Smr+(cid:96) = T(cid:96) 

∀(cid:96) = 0  1  . . .   m − 1 and ∀r 

3

• Randomized: The variable selection rule is called randomized if at each iteration the vari-

ables are chosen randomly from the previous iterations so that

P r(j ∈ Sr | xr  xr−1  . . .   x0) = pr

j ≥ pmin > 0 

∀j = 1  2  . . .   n  ∀r.

3 Convergence Analysis: Asymptotic Behavior
We ﬁrst make a standard assumption that ∇f (·) is Lipschitz continuous with constant L∇f   i.e. 

(cid:107)∇f (x) − ∇f (y)(cid:107) ≤ L∇f(cid:107)x − y(cid:107) 

and assume that −∞ < inf x∈X h(x). Let us also deﬁne ¯x to be a stationary point of (1) if ∃ d ∈
∂g(¯x) such that (cid:104)∇f (¯x)+d  x− ¯x(cid:105) ≥ 0  ∀x ∈ X   i.e.  the ﬁrst order optimality condition is satisﬁed
at the point ¯x. The following lemma will help us to study the asymptotic convergence of the PSCA
algorithm.

Lemma 1 [9  Lemma 2] Deﬁne the mapping(cid:98)x(·) : X (cid:55)→ X as(cid:98)x(y) = ((cid:98)xi(y))n
arg minxi∈Xi(cid:101)hi(xi  y). Then the mapping(cid:98)x(·) is Lipschitz continuous with constant(cid:98)L =

i=1 with(cid:98)xi(y) =

n(cid:101)L

  i.e. 

√

τ

(cid:107)(cid:98)x(y) −(cid:98)x(z)(cid:107) ≤(cid:98)L(cid:107)y − z(cid:107)  ∀y  z ∈ X .

Having derived the above result  we are now ready to state our ﬁrst result which studies the limiting
behavior of the PSCA algorithm. This result is based on the sufﬁcient decrease of the objective
function which has been also exploited in [9] for greedy variable selection rule.

Theorem 1 Assume γr ∈ (0  1]  (cid:80)∞

τ

 

τ +(cid:101)L

lim supr→∞ γr < ¯γ (cid:44)
}. Suppose either cyclic or randomized block selection rule is employed. For
min{ τ
L∇f
cyclic update rule  assume further that {γr}∞
r=1 is a monotonically decreasing sequence. Then ev-
ery limit point of the iterates is a stationary point of (1) – deterministically for cyclic update rule
and almost surely for randomized block selection rule.

r=1 γr = +∞  and that

√
n

Proof Using the standard sufﬁcient decrease argument (see the supplementary materials)  one can
show that

h(xr+1) ≤ h(xr) +

γr(−τ + γrL∇f )

2

(cid:107)(cid:98)xr − xr(cid:107)2

Sr .

Since lim supr→∞ γr < ¯γ  for sufﬁciently large r  there exists β > 0 such that

h(xr+1) ≤ h(xr) − βγr(cid:107)(cid:98)xr − xr(cid:107)2
i(cid:107)(cid:98)xr
i − xr

(cid:34) n(cid:88)

Sr .

Rr

i=1

(cid:35)

 

i(cid:107)2 | xr

E[h(xr+1) | xr] ≤ h(xr) − βγrE

Taking the conditional expectation from both sides implies

where Rr
E[Rr

i | xr] = pr

i is a Bernoulli random variable which is one if i ∈ Sr and it is zero otherwise. Clearly 

i and therefore 

E[h(xr+1) | xr] ≤ h(xr) − βγrpmin(cid:107)(cid:98)xr − xr(cid:107)2  ∀r.

(8)
Thus {h(xr)} is a supermartingale with respect to the natural history; and by the supermartingale
convergence theorem [27  Proposition 4.2]  h(xr) converges and we have

∞(cid:88)

γr(cid:107)(cid:98)xr − xr(cid:107)2 < ∞ 

almost surely.

r=1

(cid:80)∞
r=1 γr(cid:107)(cid:98)xr − xr(cid:107)2 < ∞. Fix a realization in that set. The equation (9) simply implies that 
for the ﬁxed realization  lim inf r→∞ (cid:107)(cid:98)xr − xr(cid:107) = 0  since(cid:80)
Let us now restrict our analysis to the set of probability one for which h(xr) converges and
result by proving that limr→∞ (cid:107)(cid:98)xr − xr(cid:107) = 0. Suppose the contrary that there exists δ > 0 such
r γr = ∞. Next we strengthen this

(5)

(6)

(7)

(9)

4

that ∆r (cid:44) (cid:107)(cid:98)xr − xr(cid:107) ≥ 2δ inﬁnitely often. Since lim inf r→∞ ∆r = 0  there exists a subset of

indices K and {ir} such that for any r ∈ K 

∆r < δ 

2δ < ∆ir  

and δ ≤ ∆j ≤ 2δ  ∀j = r + 1  . . .   ir − 1.

(10)

Clearly 

δ − ∆r

(i)≤ ∆r+1 − ∆r = (cid:107)(cid:98)xr+1 − xr+1(cid:107) − (cid:107)(cid:98)xr − xr(cid:107) (ii)≤ (cid:107)(cid:98)xr+1 −(cid:98)xr(cid:107) + (cid:107)xr+1 − xr(cid:107)
(iii)≤ (1 +(cid:98)L)(cid:107)xr+1 − xr(cid:107) (iv)

= (1 +(cid:98)L)γr(cid:107)(cid:98)xr − xr(cid:107) ≤ (1 +(cid:98)L)γrδ 

(11)

where (i) and (ii) are due to (10) and the triangle inequality  respectively. The inequality (iii)
is the result of Lemma 1; and (iv) is followed from the algorithm iteration update rule. Since
1+(cid:98)L
lim supr→∞ γr < 1

  the above inequality implies that there exists an α > 0 such that

∆r > α 

(12)

limr→∞(cid:80)ir−1

for all r large enough. Furthermore  since the chosen realization satisﬁes (9)  we have that

t=r γt(∆t)2 = 0; which combined with (10) and (12)  implies

ir−1(cid:88)

t=r

lim
r→∞

γt = 0.

(13)

On the other hand  using the similar reasoning as in above  one can write

γt(cid:107)(cid:98)xt − xt(cid:107) ≤ 2δ(1 +(cid:98)L)

δ < ∆ir − ∆r = (cid:107)(cid:98)xir − xir(cid:107) − (cid:107)(cid:98)xr − xr(cid:107) ≤ (cid:107)(cid:98)xir −(cid:98)xr(cid:107) + (cid:107)xir − xr(cid:107)
ir−1(cid:88)
≤ (1 +(cid:98)L)
and hence lim inf r→∞(cid:80)ir−1
does not hold and we must have limr→∞ (cid:107)(cid:98)xr − xr(cid:107) = 0  almost surely. Now consider a limit
j=1 converging to ¯x. Using the deﬁnition of (cid:98)xrj   we have
limj→∞(cid:101)hi((cid:98)xrj
the fact that limr→∞ (cid:107)(cid:98)xr − xr(cid:107) = 0  almost surely  we obtain(cid:101)hi(¯xi  ¯x) ≤ (cid:101)hi(xi  ¯x) 

∀xi ∈ Xi  ∀i. Therefore  by letting j → ∞ and using
∀xi ∈

t=r γt > 0  which contradicts (13). Therefore the contrary assumption

point ¯x with the subsequence {xrj}∞

i   xrj ) ≤ (cid:101)hi(xi  xrj ) 

Xi  ∀i  almost surely; which in turn  using the gradient consistency assumption  implies

t=r

ir−1(cid:88)

t=r

γt 

(cid:104)∇f (¯x) + d  x − ¯x(cid:105) ≥ 0  ∀x ∈ X   almost surely 

for some d ∈ ∂g(¯x)  which completes the proof for the randomized block selection rule.
Now consider the cyclic update rule with a limit point ¯x. Due to the sufﬁcient decrease bound
(6)  we have limr→∞ h(xr) = h(¯x). Furthermore  by taking the summation over (6)  we obtain
k=1 to be the subsequence of
k=1 γrk = ∞ 
i (cid:107) = 0. Repeating the
i − xrk
above argument with some slight modiﬁcations  which are omitted due to lack of space  we can
i (cid:107) = 0 implying that the limit point ¯x is a stationary point of (1). (cid:4)

(cid:80)∞
r=1 γr(cid:107)(cid:98)xr − xr(cid:107)2
iterations that block i is updated in. Clearly (cid:80)∞
Sr < ∞. Consider a ﬁxed block i and deﬁne {rk}∞
since {γr} is monotonically decreasing. Therefore  lim inf k→∞ (cid:107)(cid:98)xrk
i − xrk
show that limk→∞ (cid:107)(cid:98)xrk

i (cid:107)2 < ∞ and(cid:80)∞

k=1 γrk(cid:107)(cid:98)xrk

i − xrk

Remark 1 Theorem 1 covers both diminishing and constant step-size selection rule; or the combi-
nation of the two  i.e.  decreasing the step-size until it is less than the constant ¯γ. It is also worth
noting that the diminishing step-size rule is especially useful when the knowledge of the problem’s
constants L  ˜L  and τ is not available.

4 Convergence Analysis: Iteration Complexity

In this section  we present iteration complexity analysis of the algorithm for both convex and non-
convex cases.

5

4.1 Convex Case
When the function f (·) is convex  the overall objective function will become convex; and as a
result of Theorem 1  if a limit point exists  it is a global minimizer of (1).
In this scenario  it
is desirable to derive the iteration complexity bounds of the algorithm. Note that our algorithm
employs linear combination of the two consecutive points at each iteration and hence it is different
than the existing algorithms in [2  14–20]. Therefore  not only in the cyclic case  but also in the
randomized scenario  the iteration complexity analysis of PSCA is different than the existing results
and should be investigated. Let us make the following assumptions for our iteration complexity
analysis:

L∇f

  ∀r.

• The step-size is constant with γr = γ < τ
• The level set {x | h(x) ≤ h(x0)} is compact and the next two assumptions hold in this set.
• The nonsmooth function g(·) is Lipschitz continuous  i.e.  |g(x) − g(y)| ≤ Lg(cid:107)x −
y(cid:107)  ∀x  y ∈ X . This assumption is satisﬁed in many practical problems such as (group)
Lasso.

Lemma 2 (Sufﬁcient Descent) There exists(cid:98)β (cid:101)β > 0  such that for all r ≥ 1  we have

• The gradient of the approximation function (cid:101)fi(·  y) is uniformly Lipschitz with constant
Li  i.e.  (cid:107)∇xi(cid:101)fi(xi  y) − ∇x(cid:48)
• For randomized rule: E[h(xr+1) | xr] ≤ h(xr) −(cid:98)β(cid:107)(cid:98)xr − xr(cid:107)2.
• For cyclic rule: h(xm(r+1)) ≤ h(xmr) −(cid:101)β(cid:107)xm(r+1) − xmr(cid:107)2.

i  y)(cid:107) ≤ Li(cid:107)xi − x(cid:48)

i(cid:101)fi(x(cid:48)

i(cid:107)  ∀xi  x(cid:48)

i ∈ Xi.

Proof The above result is an immediate consequence of (6) with(cid:98)β (cid:44) βγpmin and(cid:101)β (cid:44) β
Due to the bounded level set assumption  there must exist constants (cid:98)Q  Q  R > 0 such that
for all xr. Next we use the constants Q  (cid:98)Q and R to bound the cost-to-go in the algorithm.

(cid:107)∇xi(cid:101)fi((cid:98)xr  xr)(cid:107) ≤ (cid:98)Q 

(cid:107)xr − x∗(cid:107) ≤ R 

(cid:107)∇f (xr)(cid:107) ≤ Q 

γ .

(cid:4)

(14)

Lemma 3 (Cost-to-go Estimate) For all r ≥ 1  we have

• For randomized rule:(cid:0)E[h(xr+1) | xr] − h(x∗)(cid:1)2 ≤ 2(cid:0)(Q + Lg)2 + nL2R2(cid:1)(cid:107)(cid:98)xr−xr(cid:107)2
• For cyclic rule:(cid:0)h(xm(r+1)) − h(x∗)(cid:1)2 ≤ 3n θ(1−γ)2

(cid:107)xm(r+1) − xmr(cid:107)2

for any optimal point x∗  where L (cid:44) maxi{Li} and θ (cid:44) L2

γ2

g + (cid:98)Q2 + 2nR2 ˜L2

γ2

(1−γ)2 + 2R2L2.

Proof Please see the supplementary materials for the proof.

Lemma 2 and Lemma 3 lead to the iteration complexity bound in the following theorem. The proof
steps of this result are similar to the ones in [28] and therefore omitted here for space reasons.

Theorem 2 Deﬁne σ (cid:44) (γL∇f−τ )γpmin

4((Q+Lg)2+nL2R2) and(cid:101)σ (cid:44) (γL∇f−τ )γ

6nθ(1−γ)2 . Then

• For randomized update rule: E [h(xr)] − h(x∗) ≤ max{4σ−2 h(x0)−h(x∗) 2}
• For cyclic update rule: h(xmr) − h(x∗) ≤ max{4(cid:101)σ−2 h(x0)−h(x∗) 2}

σ

1
r .

1
r .

(cid:101)σ

6

4.2 Non-convex Case

In this subsection we study the iteration complexity of the proposed randomized algorithm for the
general nonconvex function f (·) assuming constant step-size selection rule. This analysis is only
for the randomized block selection rule. Since in the nonconvex scenario  the iterates may not
converge to the global optimum point  the closeness to the optimal solution cannot be considered
for the iteration complexity analysis. Instead  inspired by [29] where the size of the gradient of the
objective function is used as a measure of optimality  we consider the size of the objective proximal
gradient as a measure of optimality. More precisely  we deﬁne

(cid:101)∇h(x) = x − arg min

y∈X

(cid:26)

(cid:27)

1
2

(cid:4)

7

time that

i   we have

∀xi ∈ Xi.

(cid:104)∇f (x)  y − x(cid:105) + g(y) +

(cid:107)y − x(cid:107)2

.

i ) ≥ 0 

∀xi ∈ Xi.

and h∗ = minx∈X h(x).

(cid:98)β
i −(cid:101)yr

i(cid:107)2. Clearly  (cid:101)∇h(xr) = (xr

(cid:44) arg minyi∈Xi(cid:104)∇xi f (xr)  yi −
i=1. The ﬁrst order optimality condition

i

i )n

Theorem 3 Consider randomized block selection rule. Deﬁne T to be the ﬁrst

the objective if g ≡ 0 and X = Rn. The following theorem  which studies the decrease rate of

Clearly  (cid:101)∇h(x) = 0 when x is a stationary point. Moreover  (cid:101)∇h(·) coincides with the gradient of
(cid:107)(cid:101)∇h(x)(cid:107)  could be viewed as an iteration complexity analysis of the randomized PSCA.
E[(cid:107)(cid:101)∇h(xr)(cid:107)2] ≤ . Then T ≤ κ/ where κ (cid:44) 2(L2+2L+2)(h(x0)−h∗)
Proof To simplify the presentation of the proof  let us deﬁne(cid:101)yr
i(cid:105) + gi(yi) + 1
2(cid:107)yi − xr
xr
i (cid:105) + gi(xi) − gi((cid:101)yr
i   xi −(cid:101)yr
(cid:104)∇xif (xr) +(cid:101)yr
of the above optimization problem implies
Furthermore  based on the deﬁnition of(cid:98)xr
i − xr
(cid:104)∇xi(cid:101)fi((cid:98)xr
i   xr)  xi −(cid:98)xr
i(cid:105) + gi(xi) − gi((cid:98)xr
i and(cid:101)yr
Plugging in the points(cid:98)xr
i ) ≥ 0 
(16)
(cid:104)∇xi(cid:101)fi((cid:98)xr
i  (cid:101)yr
i −(cid:101)yr
i −(cid:98)xr
i in (15) and (16); and summing up the two equations will yield to
i   xr) − ∇xif (xr) + xr
i(cid:105) ≥ 0.
(cid:104)∇xi(cid:101)fi((cid:98)xr
i   xr) − ∇xi(cid:101)fi(xr
i  (cid:101)yr
i −(cid:101)yr
i +(cid:98)xr
i −(cid:98)xr
i −(cid:98)xr
Using the gradient consistency assumption  we can write
or equivalently  (cid:104)∇xi(cid:101)fi((cid:98)xr
i   xr) − ∇xi(cid:101)fi(xr
i −(cid:98)xr
i  (cid:101)yr
i −(cid:98)xr
i(cid:105) ≥ (cid:107)(cid:98)xr
(cid:16)(cid:107)∇xi(cid:101)fi((cid:98)xr
i(cid:107)(cid:17)(cid:107)(cid:101)yr
i   xr) − ∇xi(cid:101)fi(xr
i −(cid:98)xr
i −(cid:98)xr
i(cid:107) ≥ (cid:107)(cid:98)xr
i   xr)(cid:107) + (cid:107)xr
Since the function (cid:101)fi(·  x) is Lipschitz  we must have
i −(cid:98)xr
(cid:107)(cid:98)xr
i −(cid:101)yr
i(cid:107)
i (cid:107) ≤ (1 + Li)(cid:107)xr
n(cid:88)
(cid:0)(cid:107)xr
i (cid:107)2(cid:1)
(cid:107)(cid:101)∇h(xr)(cid:107)2 =
i −(cid:101)yr
i −(cid:101)yr
i(cid:107)2 + (cid:107)(cid:98)xr
i −(cid:98)xr
i (cid:107)2 ≤ 2
(cid:0)(cid:107)xr
i(cid:107)2(cid:1) ≤ 2(2 + 2L + L2)(cid:107)(cid:98)xr − xr(cid:107)2.
i −(cid:98)xr
i −(cid:98)xr
i(cid:107)2 + (1 + Li)2(cid:107)xr
E(cid:104)(cid:107)(cid:101)∇h(xr)(cid:107)2(cid:105) ≤ T(cid:88)
T(cid:88)
2(2 + 2L + L2)E(cid:2)(cid:107)(cid:98)xr − xr(cid:107)2(cid:3)
≤ T(cid:88)
E(cid:2)h(xr) − h(xr+1)(cid:3) ≤ 2(2 + 2L + L2)
(cid:98)β
(cid:2)h(x0) − h∗(cid:3) = κ 

i(cid:105) ≥ 0 
i −(cid:101)yr
i (cid:107)2. Applying
i −(cid:101)yr
i (cid:107)2.

i   xr) + xr
Cauchy-Schwarz and the triangle inequality will yield to

Using the inequality (17)  the norm of the proximal gradient of the objective can be bounded by

Combining the above inequality with the sufﬁcient decrease bound in (7)  one can write

E(cid:2)h(x0) − h(xT +1)(cid:3)

(cid:107)xr

n(cid:88)
n(cid:88)

i=1

i=1

≤ 2

r=0

r=1

2(2 + 2L + L2)

i   xr) + xr

(15)

(17)

i=1

(cid:98)β

r=0

(cid:98)β

≤ 2(2 + 2L + L2)
which implies that T ≤ κ
 .

5 Numerical Experiments:

In this short section  we compare the numerical performance of the proposed algorithm with the
classical serial BCD methods. The algorithms are evaluated over the following Lasso problem:

min

x

1
2

(cid:107)Ax − b(cid:107)2

2 + λ(cid:107)x(cid:107)1 

(cid:107)xi − yi(cid:107)2

α
2

where the matrix A is generated according to the Nesterov’s approach [5]. Two problem instances
are considered: A ∈ R2000×10 000 with 1% sparsity level in x∗ and A ∈ R1000×100 000 with 0.1%
sparsity level in x∗. The approximation functions are chosen similar to the numerical experiments
in [9]  i.e.  block size is set to one (mi = 1  ∀i) and the approximation function

(cid:101)f (xi  y) = f (xi  y−i) +
2(cid:107)Ax − b(cid:107)2 is the smooth part of the objective function. We choose
is considered  where f (x) = 1
constant step-size γ and proximal coefﬁcient α. In general  careful selection of the algorithm pa-
rameters results in better numerical convergence rate. The smaller values of step-size γ will result
in less zigzag behavior for the convergence path of the algorithm; however  too small step sizes will
clearly slow down the convergence speed. Furthermore  in order to make the approximation func-
tion sufﬁciently strongly convex  we need to choose α large enough. However  choosing too large α
values enforces the next iterates to stay close to the current iterate and results in slower convergence
speed; see the supplementary materials for related examples.
Figure 1 and Figure 2 illustrate the behavior of cyclic and randomized parallel BCD method as
compared with their serial counterparts. The serial methods “Cyclic BCD” and “Randomized BCD”
are based on the update rule in (2) with the cyclic and randomized block selection rules  respectively.
The variable q shows the number of processors and on each processor we update 40 scalar variables
in parallel. As can be seen in Figure 1 and Figure 2  parallelization of the BCD algorithm results in
more efﬁcient algorithm. However  the computational gain does not grow linearly with the number
of processors. In fact  we can see that after some point  the increase in the number of processors
lead to slower convergence. This fact is due to the communication overhead among the processing
nodes which dominates the computation time; see the supplementary materials for more numerical
experiments on this issue.

Figure 1: Lasso Problem: A ∈ R2 000×10 000

Figure 2: Lasso Problem: A ∈ R1 000×100 000

Acknowledgments: The authors are grateful to the University of Minnesota Graduate School Doc-
toral Dissertation Fellowship and AFOSR  grant number FA9550-12-1-0340 for the support during
this research.

References
[1] Y. Nesterov. Efﬁciency of coordinate descent methods on huge-scale optimization problems. SIAM

Journal on Optimization  22(2):341–362  2012.

[2] P. Richt´arik and M. Tak´aˇc. Efﬁcient serial and parallel coordinate descent methods for huge-scale truss

topology design. In Operations Research Proceedings  pages 27–32. Springer  2012.

8

0123456710−610−510−410−310−210−1100101102Time (seconds)Relative Error Cyclic BCDRandomized BCDCyclic PSCA q=32Randomized PSCA q= 32Cyclic PSCA q=8Randomized PSCA q=8Cyclic PSCA q=4Randomized PSCA q=4010020030040050060010−610−510−410−310−210−1100101102Time (seconds)Relative Error Randomized BCDCyclic BCDRandomized PSCA q=8Cyclic PSCA q=8Randomized PSCA q=16Cyclic PSCA q = 16Randomized PSCA q=32Cyclic PSCA q=32[3] Y. T. Lee and A. Sidford. Efﬁcient accelerated coordinate descent methods and faster algorithms for
solving linear systems. In 54th Annual Symposium on Foundations of Computer Science (FOCS)  pages
147–156. IEEE  2013.

[4] I. Necoara and D. Clipici. Efﬁcient parallel coordinate descent algorithm for convex optimization prob-
lems with separable constraints: application to distributed MPC. Journal of Process Control  23(3):243–
253  2013.

[5] Y. Nesterov. Gradient methods for minimizing composite functions. Mathematical Programming 

140(1):125–161  2013.

[6] P. Tseng and S. Yun. A coordinate gradient descent method for nonsmooth separable minimization.

Mathematical Programming  117(1-2):387–423  2009.

[7] A. Beck and M. Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems.

SIAM Journal on Imaging Sciences  2(1):183–202  2009.

[8] S. J. Wright  R. D. Nowak  and M. Figueiredo. Sparse reconstruction by separable approximation. IEEE

Transactions on Signal Processing  57(7):2479–2493  2009.

[9] F. Facchinei  S. Sagratella  and G. Scutari. Flexible parallel algorithms for big data optimization. arXiv

preprint arXiv:1311.2444  2013.

[10] J. K. Bradley  A. Kyrola  D. Bickson  and C. Guestrin. Parallel coordinate descent for (cid:96)1-regularized loss

minimization. arXiv preprint arXiv:1105.5379  2011.

[11] C. Scherrer  A. Tewari  M. Halappanavar  and D. Haglin. Feature clustering for accelerating parallel

coordinate descent. In NIPS  pages 28–36  2012.

[12] C. Scherrer  M. Halappanavar  A. Tewari  and D. Haglin. Scaling up coordinate descent algorithms for

large (cid:96)1 regularization problems. arXiv preprint arXiv:1206.6409  2012.

[13] Z. Peng  M. Yan  and W. Yin. Parallel and distributed sparse optimization. preprint  2013.
[14] I. Necoara and D. Clipici. Distributed coordinate descent methods for composite minimization. arXiv

preprint arXiv:1312.5302  2013.

[15] P. Richt´arik and M. Tak´aˇc. Parallel coordinate descent methods for big data optimization. arXiv preprint

arXiv:1212.0873  2012.

[16] P. Richt´arik and M. Tak´aˇc. On optimal probabilities in stochastic coordinate descent methods. arXiv

preprint arXiv:1310.3438  2013.

[17] O. Fercoq and P. Richt´arik. Accelerated  parallel and proximal coordinate descent. arXiv preprint

arXiv:1312.5799  2013.

[18] O. Fercoq  Z. Qu  P. Richt´arik  and M. Tak´aˇc. Fast distributed coordinate descent for non-strongly convex

losses. arXiv preprint arXiv:1405.5300  2014.

[19] O. Fercoq and P. Richt´arik. Smooth minimization of nonsmooth functions with parallel coordinate descent

methods. arXiv preprint arXiv:1309.5885  2013.

[20] A. Patrascu and I. Necoara. A random coordinate descent algorithm for large-scale sparse nonconvex

optimization. In European Control Conference (ECC)  pages 2789–2794. IEEE  2013.

[21] M. Razaviyayn  M. Hong  and Z.-Q. Luo. A uniﬁed convergence analysis of block successive minimiza-

tion methods for nonsmooth optimization. SIAM Journal on Optimization  23(2):1126–1153  2013.

[22] F. Niu  B. Recht  C. R´e  and S. J. Wright. Hogwild!: A lock-free approach to parallelizing stochastic

gradient descent. Advances in Neural Information Processing Systems  24:693–701  2011.

[23] J. Liu  S. J. Wright  C. R´e  and V. Bittorf. An asynchronous parallel stochastic coordinate descent algo-

rithm. arXiv preprint arXiv:1311.1873  2013.

[24] J. Mairal. Optimization with ﬁrst-order surrogate functions. arXiv preprint arXiv:1305.3120  2013.
[25] J. Mairal. Incremental majorization-minimization optimization with application to large-scale machine

learning. arXiv preprint arXiv:1402.4419  2014.

[26] M. Razaviyayn  M. Sanjabi  and Z.-Q. Luo. A stochastic successive minimization method for nons-
mooth nonconvex optimization with applications to transceiver design in wireless communication net-
works. arXiv preprint arXiv:1307.4457  2013.

[27] D. P. Bertsekas and J. N. Tsitsiklis. Neuro-dynamic programming. 1996.
[28] M. Hong  X. Wang  M. Razaviyayn  and Z.-Q. Luo. Iteration complexity analysis of block coordinate

descent methods. arXiv preprint arXiv:1310.6957  2013.

[29] Y. Nesterov. Introductory lectures on convex optimization: A basic course  volume 87. Springer  2004.

9

,Alexander Zimin
Gergely Neu
Meisam Razaviyayn
Mingyi Hong
Zhi-Quan Luo
Jie Wang
Jieping Ye
Antti Tarvainen
Harri Valpola
Pei Wang
Nuno Nvasconcelos