2019,Convergence-Rate-Matching Discretization of Accelerated Optimization Flows Through Opportunistic State-Triggered Control,A recent body of exciting work seeks to shed light on the behavior of accelerated methods in optimization via high-resolution differential equations. These differential equations are continuous counterparts of the discrete-time optimization algorithms  and their convergence properties can be characterized using the powerful tools provided by classical Lyapunov stability analysis. An outstanding question of pivotal importance is how to discretize these continuous flows while maintaining their convergence rates. This paper provides a novel approach through the idea of opportunistic state-triggered control. We take advantage of the Lyapunov functions employed to characterize the rate of convergence of high-resolution differential equations to design variable-stepsize forward-Euler discretizations that preserve the Lyapunov decay of the original dynamics. The philosophy of our approach is not limited to forward-Euler discretizations and may be combined with other integration schemes.,Convergence-Rate-Matching Discretization of

Accelerated Optimization Flows Through
Opportunistic State-Triggered Control

Mechanical and Aerospace Engineering

Mechanical and Aerospace Engineering

Jorge Cortés

UC San Diego

San Diego  CA 9500
cortes@ucsd.edu

Miguel Vaquero

UC San Diego

San Diego  CA 9500

mivaquerovallina@ucsd.edu

Abstract

A recent body of exciting work seeks to shed light on the behavior of acceler-
ated methods in optimization via high-resolution differential equations. These
differential equations are continuous counterparts of the discrete-time optimization
algorithms  and their convergence properties can be characterized using the power-
ful tools provided by classical Lyapunov stability analysis. An outstanding question
of pivotal importance is how to discretize these continuous ﬂows while maintaining
their convergence rates. This paper provides a novel approach through the idea of
opportunistic state-triggered control. We take advantage of the Lyapunov functions
employed to characterize the rate of convergence of high-resolution differential
equations to design variable-stepsize forward-Euler discretizations that preserve
the Lyapunov decay of the original dynamics. The philosophy of our approach
is not limited to forward-Euler discretizations and may be combined with other
integration schemes.

1

Introduction

This paper builds on the current research activity that seeks to characterize the convergence properties
of dynamical systems that are continuous-time versions of accelerated algorithms in optimization.
This body of work sits at the intersection of various disciplines  most notably nonlinear systems and
optimization  and has brought to the understanding of acceleration properties a wealth of powerful
techniques from Lyapunov stability analysis  calculus of variations  and geometric methods. This
paper takes another step in this direction by further advancing the synergy between stability analysis
and the study of optimization algorithms. Here  we propose to employ an opportunistic state-triggered
approach to discretize continuous ﬂows in a way that respects the Lyapunov function decay that
explains their accelerated convergence rates.

Summary of Results

The contribution of this paper is the design of a variable-stepsize forward-Euler discretization that
preserves the Lyapunov decay of high-resolution differential equations. A main novelty of our
technical approach is to employ  in the context of the discretization of state-of-the-art optimization
ﬂows  ideas from opportunistic state-triggered control to develop real-time implementations of
closed-loop dynamical systems. We build on the Lyapunov functions employed to characterize
the rate of convergence of high-resolution differential equations to identify triggers that help us
determine the stepsize of the discretization as a function of the current iterate. By design  these
triggers ensure that the discretization retains the decay rate of the Lyapunov function. Since the

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

evaluation of the Lyapunov function relies on knowledge of the problem optimizer  we rely on
well-known bounds available for strongly-convex functions to synthesize triggers that do not require
such knowledge. Various simulations show the superior performance of the proposed method in
comparison with recently proposed constant-stepsize discretizations. The ﬂexibility of the proposed
framework provides a promising path towards the understanding of the acceleration phenomenon and
the design of new adaptive optimization algorithms.

Related Work

State-Triggered Control. The basic idea of opportunistic state-triggered control  see [13  20] and
references therein  is to abandon the paradigm of continuous or periodic sampling/control in exchange
for deliberate  opportunistic aperiodic sampling/control to improve efﬁciency in the use of resources
while maintaining stability. Opportunistic state-triggered control can be roughly divided into event-
triggered and self-triggered designs. In event-triggered control  one continuously monitors certain
conditions whose violation triggers certain desirable action whereas in self-triggered control the
aim is to predict  with the information available at the last triggering time  when the next triggering
condition will take place. Beyond stability  many triggered designs also pay attention to guaranteeing
a desired performance by  for instance  making sure that the system enjoys a certain convergence rate.
This is accomplished through careful analysis of the evolution of a Lyapunov function. Works [6  12]
based on the derivative-based approach ensure the closed-loop system’s stability by monitoring the
time derivative of the Lyapunov function. Other works [7  26] resort to Lyapunov sampling-type
conditions  where triggers are stated in terms of the Lyapunov function by monitoring its decay.
Recent work [6  21] combines the strengths of both types of design. Our technical treatment here
follows the derivative-based approach  albeit we believe that other types of design could also be
combined with our results here.
Accelerated Methods in Optimization. Steepest gradient descent is a keystone in ﬁrst-order opti-
mization methods  but can be very slow. The work [22] introduced the so called heavy-ball method 
which aims to speed up the convergence of the gradient descent algorithm by including a momentum
term. Later on  [18] designed an algorithm similar in form  the so-called Nesterov’s accelerated
gradient  and using the technique known as estimating sequences  showed that the method achieves
black-box oracle bounds  i.e.  it is optimal on the class of smooth convex or strongly convex func-
tions. Ever since its appearance  acceleration has remained mysterious  to a great extent due to the
elegant but unintuitive algebraic arguments used by Nesterov in his derivations. To clarify the ideas
underlying acceleration methods  the literature has explored different viewpoints. Some work [1]
relies on coupling different dynamics  where at any step mirror descent and gradient descent are
interpolated. Other approaches are based on dissipativity theory  [14]  integral quadratic constraints 
[16]  and even geometric arguments [5]. The most relevant line of research for our purposes is the
one initiated in [25]  which introduces a second-order differential equation which is the continuous
limit of Nesterov’s accelerated gradient method. This ODE exhibits approximate equivalence to
Nesterov’s scheme and thus can serve as a tool for its analysis. Especially salient is the fact that
the analysis (both stability and rate of convergence) of the mentioned ODE is carried out using a
Lyapunov function. This work has spurred a lot of activity aimed at uncovering the rationale behind
the phenomenon of acceleration resorting to continuous dynamics  including the variational viewpoint
introduced in [27]  the connections between Lyapunov theory and estimating sequences in [28] and
the Hamiltonian perspective exploited in [8  17]. The work [15] employs a hybrid systems approach
to design a continuous-time dynamics with a feedback regulator of the viscosity of the heavy-ball
ODE  guaranteeing arbitrarily fast exponential convergence. Recently  high-resolution ODEs were
introduced in [23] as more accurate surrogates for the heavy-ball and Nesterov’s algorithms. The
work [3] introduces similar dynamics under the name inertial systems with Hessian-driven damping.
A number of works have also explored the discretization of accelerated continuous models and their
stability. The work [27] shows that the forward Euler method can be inefﬁcient and even become
unstable after a few iterations. Some experimentation using symplectic integrators  without theoretical
guarantees  is given in [4]. The work [29] shows that high-order Runge-Kutta integrators can also be
used to retain acceleration when discretizing Nesterov’s methods for convex functions. The work [24]
analyzes in detail the properties of explicit  implicit  and symplectic integrators when applied to the
high-resolution dynamics corresponding to the heavy-ball and Nesterov’s schemes. The methods
proposed in this paper can be understood as variable-stepsize discretizations  which are a popular
class of methods in numerical analysis. Some examples of their success include line-search methods

2

in optimization [19]  the Runge–Kutta–Fehlberg algorithm [11]  and adaptive-structure-preserving
integrators [10].

2 Preliminaries

2.1 Notation and Assumptions
We denote by R  R>0  and N the sets of real  positive real  and natural numbers  resp. All vectors
are considered column vectors and we denote their scalar product by (cid:104)· ·(cid:105). We use (cid:107)·(cid:107) to denote the
2-norm in Euclidean space. Given µ ∈ R>0  a function f : Rn → R is convex if f (kx + (1− k)y) ≤
kf (x) + (1 − k)f (y) for x  y ∈ Rn and k ∈ [0  1]. A continuously differentiable function f is
µ-strongly convex if f (y) − f (x) ≥ (cid:104)∇f (x)  y − x(cid:105) + µ
2 (cid:107)x − y(cid:107)2 for x  y ∈ Rn. Given L ∈ R>0
and a function f : X → Y between two normed spaces (X (cid:107)·(cid:107)X ) and (Y (cid:107)·(cid:107)Y )  f is L-Lipschitz
if (cid:107)f (x) − f (x(cid:48))(cid:107)Y ≤ L(cid:107)x − x(cid:48)(cid:107)X for x  x(cid:48) ∈ X. We endow the space of Rn×m matrices with
the induced matrix norm  namely (cid:107)A(cid:107) = max(cid:107)x(cid:107)=1 (cid:107)Ax(cid:107). We denote by S 1
µ L(Rn) the set of
continuously differentiable functions on Rn  µ-strongly convex that have L-Lipschitz continuous
gradient. The function class S 2
µ L(Rn) of twice differentiable functions
with Lipschitz Hessian. A function f : Rn → R is positive deﬁnite relative to x∗ if f (x∗) = 0 and
f (x) > 0 for x ∈ Rn \ {x∗}.

µ L(Rn) is the subclass of S 1

2.2 Opportunistic State-Triggered Control

Here we provide a basic account of how real-time implementations of continuous-time controlled
dynamical systems can be developed using opportunistic state-triggered control. We refer to [6  13] for
more complete expositions. We build on these ideas later to develop discretizations of high-resolution
differential equations. Consider the controlled dynamical system on Rn

(1)
where X : Rn × Rm → Rn and X(p∗  0) = 0. Assume we are given a stabilizing feedback law
u = k(p) along with a Lyapunov function V : Rn → R that serves as a certiﬁcate of the asymptotic
stability of the equilibrium p∗ ∈ Rn under the closed-loop system. Formally 

˙p = X(p  u) 

˙V = (cid:104)∇V (p)  X(p  k(p))(cid:105) ≤ −F (p) 

(2)
with F a positive deﬁnite function relative to p∗. For simplicity  we restrict ourselves to the case
F (p) = αV (p)  with α ∈ R>0 (in this case  the convergence of V is exponential). The controller
u = k(p) cannot be implemented in real time  because it requires both continuous sampling and
actuation. The real-time implementation of the closed-loop system can be tackled by considering a
sample-and-hold implementation of (1) of the form

˙p = X(p  k(ˆp)) 

(3)
with p(0) = ˆp  where ˆp is a sampled version of the state p. The most common approach consists
of periodically sampling the state  selecting a stepsize small enough to ensure that the function V
remains monotonically decreasing for the resulting system. However  constant stepsizes are generally
conservative  as they need to deal with worst-case scenarios. Instead  opportunistic state-triggered
control seeks to adjust the stepsize as determined by the current system state. Formally  let {t1  t2  . . .}
be a sequence of triggering times and denote pi = p(ti)  for i ∈ N. Consider

for t ∈ [ti  ti+1] and i ∈ N.

˙p = X(p  k(pi)) 

(4)
The objective is then to identify a criterion to select the sequence of triggering times in a way that
ensures that (i) the triggered dynamics (4) retains the guarantees on the evolution of the Lyapunov
function and (ii) the inter-sampling times are lower bounded. Condition (ii) ensures feasibility and
rules out the possibility of Zeno behavior  cf. [9]  whereas condition (i) ensures that the triggered
dynamics has the same convergence properties as the original dynamics.
Interestingly  both conditions can be met with designs that involve the Lyapunov function V itself.
Event-triggered designs compute the sequence of triggering times by monitoring the evolution of
certain function until a condition is violated. More precisely  assume that we have access to a
continuous function g : Rn × R → R that satisﬁes g(p  0) < 0 for all p ∈ Rn \ {p∗} and

˙V (p(t)) + αV (p(t)) ≤ g(ˆp  t) 

3

holds along the solutions of (3). Then  for each i ∈ N  the next triggering time can be determined by

ti+1 = min{t | t > ti such that g(pi  t) = 0}.

Note that  by design  this choice ensures that ˙V (p(t)) ≤ −αV (p(t)) along the dynamics (4). If g is
such that ti+1  as deﬁned above  can be determined explicitly only with knowledge of pi  one refers
to this design as self-triggered (because it does not require the continuous monitoring of the evolution
of the state under (3) in order to identify it).

2.3 Adaptive-Stepsize Forward-Euler Discretization of Continuous-Time Dynamics via

Opportunistic State Triggering

The ideas described in Section 2.2 can also be applied in the context of discretization of asymptotically
stable continuous-time dynamical systems  as we explain next. Consider a dynamical system on Rn 
(5)
where Y : Rn → Rn. Assume p∗ is a globally asymptotically stable equilibrium point under this
dynamics  and a certiﬁcate  in the form of a Lyapunov function V : Rn → R  is available  meaning
˙V = (cid:104)∇V (p)  Y (p)(cid:105) ≤ −αV (p) for all p ∈ Rn. Following the state-triggered approach
that
described above  consider the sampled implementation of the dynamics described by

˙p = Y (p)

with p(0) = ˆp. Note that  the righthand side being constant  this is equivalent to writing

˙p = Y (ˆp) 

p(t) = ˆp + tY (ˆp) 

(6)

(7)

which exactly corresponds to a forward-Euler discretization of stepsize t. Therefore  a successful
opportunistic state-triggered design would ensure that the monotonic behavior of the Lyapunov
function is respected  in turn guaranteeing convergence to the equilibrium at the same rate as
the original dynamics (5). Given the connection noted above with the Euler discretization  such
state-triggered implementation admits an interesting interpretation from a numerical viewpoint  cf.
Figure 1. In fact  the state-triggered implementation exactly corresponds to a variable stepsize Euler
discretization where  at each iterate  the trigger criteria helps us determine the stepsize according
to the decay criteria speciﬁed by the Lyapunov function. Before this decay condition is violated 
the state is re-sampled  and the process is repeated. By design  the resulting variable-stepsize Euler
discretization retains the convergence rate of the original dynamics.

Figure 1: Equivalence between opportunistic state-triggered implementation and variable-stepsize forward-Euler
discretization. The black lines correspond to the trajectories of the original dynamics (5). The red lines are
trajectories of the family of sampled dynamical systems (6)  which are the same as the iterates of forward Euler
methods with different stepsizes.

We ﬁnish this section by pointing out that continuous models of accelerated optimization algorithms 
particularly high-resolution ODEs  ﬁt the proﬁle described above (i.e.  they are globally asymptotically
stable and their convergence can be characterized via suitable Lyapunov functions). Furthermore  their
acceleration properties are explained as a consequence of the decay rate of the Lyapunov function.
This matches perfectly with our state-triggered approach  which seeks to conserve the decay rate of the
Lyapunov function  consequently ensuring the acceleration properties in the resulting discrete-time
algorithm. An interesting challenge arises because of the fact that the Lyapunov function typically
relies on knowledge of the optimizer  thereby complicating the evaluation of trigger designs based on
them. The rest of this paper shows how we tackle this problem to synthesize trigger designs that do
not rely on such knowledge and still guarantee the desired decay rate of the Lyapunov function.

4

Trigger-New iterationLyapunovLevel setSample-and-hold implementation3 Triggered Discretization of Heavy Ball and Nesterov’s Continuous Models

(cid:21)

(cid:21)

(cid:20) ˙x

(cid:20)

Here we present discretizations  using the methodology described in Section 2.3  of the high-resolution
ordinary differential equations (heavy-ball and Nesterov for strongly convex functions) proposed
in [23] for optimization. Due to space constraints  we discuss in detail the heavy-ball case and refer
the reader to the supplementary material for an analogous discretization of the Nesterov’s accelerated
gradient for strongly convex functions.
Let f belong to S 1
s-dependent family of second-order differential equations 

µ L(Rn) and let x∗ be its unique minimizer. Given s ∈ R>0  consider the following

√
−2

˙v

=

v
µv − (1 +
√
with initial conditions x(0) = x0  v(0) = − 2
as Xhb. The following result characterizes the convergence properties of this dynamics.
Theorem 3.1 ([23]). Let V : Rn × Rn → R be the positive deﬁnite function relative to [x∗  0]T  

. When convenient  we refer to this dynamics

µs)∇f (x))

(8)

s∇f (x0)
1+

√

µs

 

√

V (x  v) = (1 +

√

µs)(f (x) − f (x∗)) +

(cid:107)v(cid:107)2 +

1
4

1
4

√

(cid:107)v + 2

µ(x − x∗)(cid:107)2 .

Then ˙V ≤ −√
stable. Moreover  for s ≤ 1/L  the decay rate of the Lyapunov function V implies

4 V along the dynamics (8) and  as a consequence  [x∗  0]T is globally asymptotically

µ

f (x(t)) − f (x∗) ≤ 7(cid:107)x(0) − x∗(cid:107)2

2s

e− √

µ

4 t.

(9)

Given our discussion in Section 2.2  Theorem 3.1 provides all the necessary ingredients to develop a
discretization that respects the convergence rate  and hence inherits the guarantee (9). For simplicity 
we use the shorthand notation p = [x  v]T . Observe that the Lyapunov function V depends on the
minimizer  x∗  which is unknown. To circumvent this issue  we resort to tight estimates provided by
the convexity properties of the function f.
Consider the sampled-and-hold implementation of (8) given by ˙p = Xhb(ˆp)  p(0) = ˆp or  equiva-
lently  p(t) = ˆp + tXhb(ˆp). Our goal is to determine a stepsize t  as large as possible  that guarantees
√
4 V (p(t) ≤ 0 along the sampled dynamics. The following result provides us with a
d
dt V (p(t)) +
particularly useful upper bound to ensure this. The proof is provided in the supplementary material.
Proposition 3.2. For the sample-and-hold dynamics ˙p = Xhb(ˆp)  p(0) = ˆp  0 ≤ s and 0 ≤ α ≤
√
µ/4. Let

µ

V (p(t)) + αV (p(t)) = (cid:104)∇V (ˆp + tXhb(ˆp))  Xhb(ˆp)(cid:105) + αV (ˆp + tXhb(ˆp))

d
dt

= (cid:104)∇V (ˆp + tXhb(ˆp)) − ∇V (ˆp)  Xhb(ˆp)(cid:105)

+ α(V (ˆp + tXhb(ˆp)) − V (ˆp))

(cid:125)

(cid:124)

(cid:123)(cid:122)

II

(cid:125)

(cid:124)

(cid:124)

(cid:123)(cid:122)

I

(cid:123)(cid:122)

III

+ (cid:104)∇V (ˆp)  Xhb(ˆp)(cid:105) + αV (ˆp)

.

(cid:125)

Then  the following bounds hold:

1. Term I ≤ AET(ˆp  t) ≤ AST(ˆp)t;
2. Term II ≤ BCET(ˆp  t) ≤ BST(ˆp)t + CST(ˆp)t2;
3. Term III ≤ DET(ˆp  t) = DST(ˆp) 

5

where

AET(ˆp  t) = (1 +

BCET(ˆp  t) = α(cid:0)(1 +

+ t(1 +

√

√
µs)(cid:104)∇f (ˆx + tˆv) − ∇f (ˆx)  ˆv(cid:105) + t2
√
µs)2 (cid:107)∇f (ˆx)(cid:107)2  
√
µs)(f (ˆx + tˆv) − f (ˆx)) + t2 1
4
√
√
µs)(cid:104)ˆv ∇f (ˆx)(cid:105) − t
√

√
(cid:107)−2
µ(cid:107)ˆv(cid:107)2 + t2 1
4

√

µ(1 +

µs)(cid:104)∇f (ˆx)  ˆv(cid:105) + t2µ(cid:107)ˆv(cid:107)2

√

µs)∇f (ˆx)(cid:107)2

µˆv − (1 +
(cid:107)(1 +

√

µs)∇f (ˆx)(cid:107)2

DET(ˆp  t) = (α

µ(1 +

− t(1 +
− t
3
4
AST(ˆp) = (1 +

µ)(cid:107)∇f (ˆx)(cid:107)2 /L(cid:1) 
√
µ)(cid:107)ˆv(cid:107)2 +(cid:0)(1 +
− √
√
BST(ˆp) = α(cid:0) − √
µs)L(cid:107)ˆv(cid:107)2 + 2
µ(cid:107)ˆv(cid:107)2 − √
CST(ˆp) = α(cid:0)(1 +
√

µ(1 +
√

(cid:107)ˆv(cid:107)2 +

µ(1 +

µs)

√

L
2

1
4

µ

2L

√

√

√

µ(1 +
2

+ (α2µ −

α − √
µs)
√
(cid:107)∇f (ˆx)(cid:107)2(cid:1) 
µs)(cid:104)∇f (ˆx)  ˆv(cid:105) + 2µ(cid:107)ˆv(cid:107)2 + (1 +
1
µs)
L
√
(cid:107)−2
µˆv − (1 +

µs)∇f (ˆx)(cid:107)2 +

√

µs)µ)
√

(cid:107)−(1 +

1
4

(cid:1)(cid:107)∇f (ˆx)(cid:107)2  

1
)
L2
µs)2 (cid:107)∇f (ˆx)(cid:107)2  

µs)∇f (ˆx)(cid:107)2(cid:1).

√

We deﬁne  with a slight abuse of notation 

gET(ˆp  t) = AET(ˆp  t) + BCET(ˆp  t) + DET(ˆp  t) 
gST(ˆp  t) = CST(ˆp)t2 + (AST(ˆp) + BST(ˆp))t + DST(ˆp) 

(the reason for the subindexes ET  for event-triggered  and ST  for self-triggered  becomes clear
below). With these functions in place  it follows from Proposition 3.2 that
V (p(t)) + αV (p(t)) ≤ gET(ˆp  t) ≤ gST(ˆp  t).

(10)

d
dt

This is all we need to determine the stepsize starting from ˆp. Formally  we set

t

{t > 0 such that g#(ˆp  t) = 0} 

step#(ˆp) = min

(11)
where # ∈ {ET  ST}. Note that  when # = ET  then gET(ˆp  t) = 0 is an implicit equation on t.
Instead  when # = ST  then the solution to the quadratic equation gST(ˆp  t) = 0 can be obtained
DST(ˆp) < 0 when α ≤ √
explicitly (i.e.  determined only with the information about the current state ˆp) since CST(ˆp) > 0 and

−(AST(ˆp) + BST(ˆp)) +(cid:112)(AST(ˆp) + BST(ˆp))2 − 4CST(ˆp)DST(ˆp)

µ/4. In fact  we have

.

stepST(ˆp) =

2CST(ˆp)

Algorithm 1 describes in pseudocode the resulting variable-stepsize integrator.

Algorithm 1: Triggered Forward-Euler algorithm
Initialization: Initial point (p0)  convergence rate (α)  objective function (f)  tolerance ();
Set: k = 0;
while (cid:107)∇f (x)(cid:107) ≥  do

Compute stepsize tk at current point according to (11);
Compute next iterate pk+1 = pk + tkXhb(pk);
Set k = k + 1

end
Theorem 3.3. For 0 < α ≤ √
with the following properties

µ/4 and # ∈ {ET  ST}  Algorithm 1 is a variable-stepsize integrator

(i) the stepsize is uniformly lower bounded by a positive constant. Namely

(cid:113)

−c2 +

2 + c1 ≤ stepST (p)
c2

6

where
c1 = min{

c2 = max{

µ − 3α
√

2(cid:0)√
α(cid:0)4µ + L
(cid:0)2µ +
α(cid:0)4µ + L

2(cid:0)−4αµ + L(cid:0)√
(cid:1)
µs + L(cid:1)  
2(cid:0)√
µ + L(cid:1)(cid:0)√
µs + 1(cid:1)
3α(cid:0)√
µs + L(cid:1)

µ − α(cid:1)(cid:0)√
3αL2(cid:0)√
µs + 1(cid:1)
µs + 1(cid:1)

µ +

√

√

√

4

 

}.

µs + 1(cid:1) + µ3/2(cid:0)√
µs + 1(cid:1)2

µs + 1(cid:1)(cid:1)

}

(ii) d

dt V (pk + tXhb(pk)) ≤ −αV (pk + tXhb(pk)) for all t ∈ [0  tk] and all k ∈ {0} ∪ N.

As a consequence  it follows that f (xk+1) − f (x∗) ≤ 7(cid:107)x(0)−x∗(cid:107)2
i=0 ti for all k ∈ {0} ∪ N.
Proof. Since gET(p  t) ≤ gST(p  t) we have stepST(p) ≤ stepET(p) and therefore it is enough to
prove the ﬁrst claim for the ST-case. We rewrite 
−(AST(p) + BST(p))

e−α(cid:80)k
(cid:115)(cid:18) AST(p) + BST(p)

2s

We bound  using (cid:107)a + b(cid:107)2 ≤ 2(cid:107)a(cid:107)2 + 2(cid:107)b(cid:107)2 

stepST(p) =

2CST(p)

√

CST(p) ≤ α(cid:0)((1 +
µ)(cid:107)v(cid:107)2 −(cid:0)(1 +
α(cid:0)((1 +
≥ −(α 3

4 − √

µs) L

L
2

µs)

√

and therefore
−DST(p)
CST(p)

+

2CST(p)

√

3
4

(1 +

+ 2µ)(cid:107)v(cid:107)2 +
µs) α−√

√
2 + 2µ)(cid:107)v(cid:107)2 + 3

µ

2L + (α2µ − √
√

4 (1 +

.

CST(p)

(cid:19)2 − DST(p)
µs)2 (cid:107)∇f (x)(cid:107)2(cid:1)
µs)2 (cid:107)∇f (x)(cid:107)2(cid:1)

µ(1+
2

) 1
L2

µs)µ)

√

(cid:1)(cid:107)∇f (x)(cid:107)2

.

We observe that if we rename (cid:107)∇f (x)(cid:107) = z1 and (cid:107)v(cid:107) = z2 then the last expression has the form

We show in the supplementary material that such expression is upper and lower bounded by positive
constants  i.e.  there exist (explicit) c1 and c2 ∈ R>0 such that

β1z2
β3z2

1 + β2z2
2
1 + β4z2
2

.

(12)

0 < c1 ≤ β1z2
β3z2

1 + β2z2
2
1 + β4z2
2

≤ c2

for all z1  z2 ∈ R\{0}.

Using this observation  we have

−(AST(p) + BST(p))

2CST(p)

+

≤ −(AST(p) + BST(p))

(cid:115)(cid:18) AST(p) + BST(p)

(cid:19)2
(cid:115)(cid:18) AST(p) + BST(p)

2CST(p)

+ c1

(cid:19)2 − DST(p)

2CST(p)

+
It is easy to see that the function f (z) = −z +
z2 + c1 is monotonically decreasing and positive
everywhere. So  if z is upper bounded  then f (z) is lower bounded by a positive constant. With this
observation  and the form of the last expression  it is clear that if we upper bound z = AST(p)+BST(p)
we are done. To achieve this goal let us use

2CST(p)

CST(p)

2CST(p)

√

.

CST(p) ≥ α(cid:0)(1 +

√

µs)

µs)2 (cid:107)∇f (x)(cid:107)2(cid:1).

√

√

µ(1 +

µs)(cid:107)∇f (x)(cid:107)2

√

(cid:107)v(cid:107)2 +

L
1
2
4
√
µs)L(cid:107)v(cid:107)2 +

(1 +

√

√

+

µ(1 +

µs)(cid:107)v(cid:107)2 + 2µ(cid:107)v(cid:107)2 + (1 +

µs)2 (cid:107)∇f (x)(cid:107)2

and

AST(p) + BST(p) ≤ AST(p) ≤ (1 +
√

where we have used Cauchy-Schwartz and Young’s inequality in the last estimate. Now  the
fraction AST(p)+BST(p)
has the form (12)  and so we can conclude the existence of c2 such that
≤ c2. To ﬁnish now the proof of the ﬁrst part of Theorem 3.3 it is only necessary to
AST(p)+BST(p)
use the explicit expressions of c1 and c2 provided in the supplementary material. The second part
(cid:3)
follows from Proposition 3.2 and the algorithm design.

2CST(p)

2CST(p)

7

logistic regression cost function  namely(cid:80)10

We compare the performance of Algorithm 1 for the event-triggered (ET) and self-triggered (ST)
cases with the explicit and symplectic integrators proposed in [24] in a logistic regression example.
Figure 2 illustrates the evolution of the stepsize  objective and Lyapunov functions. We set α =
µ/4
and s = µ/(36L2) following the values in [24]. The objective function corresponds to the regularized
i=1 log(1 + e−yi(cid:104)vi x(cid:105)) + 1/2(cid:107)x(cid:107)2  where x ∈ R4 and
we have generated the sampled points (vi  yi) randomly. This function is 1-strongly convex. The
value of L = 177.49 can be estimated by straightforward computations. In the plots  we display the
optimal stepsize only for comparison purposes  as the minimizer is in practice unknown. Knowledge
of the minimizer x∗ would enable the explicit computation of the Lyapunov function  cf. Theorem 3.1 
which in turn would allow to solve ˙V + αV by any standard numerical method at any iteration. This
is what we refer to as optimal stepsize.

√

Figure 2: (Top  left) Comparison of stepsizes along the various discrete-time dynamics. The ET and ST
integrators keep a larger stepsize for the ﬁrst 2000 iterations  approaching the optimizer much faster. (Top 
right) Comparison of the evolution of the ET stepsize and optimal stepsize along the ET dynamics. We observe
how the stepsize computed by the ET integrator chases the optimal stepsize as the state evolves. (Bottom  left)
Comparison of the evolution of the objective function along the different dynamics. (Bottom  right) Comparison
of the evolution of the Lyapunov function along the different dynamics.

Figure 3 provides another comparison for a quadratic objective function over R50 deﬁned by an
(ill-conditioned) positive deﬁnite 50 × 50 matrix  where µ = 3.5 and L = 7006.6. We plot the
evolution of the objective and the logarithm of the Lyapunov functions  comparing the proposed
algorithms with forward and symplectic Euler. The supplementary material contains additional
comparisons for various 2-dimensional quadratic cases.

4 Conclusions and Future Work

We have introduced a novel opportunistic state-triggered approach to the discretization of optimization
ﬂows. Our approach relies on the key observation that resource-aware control provides a principled
way of going from continuous-time control design to real-time implementation with stability and
performance guarantees. This is done by opportunistically prescribing when certain action should
occur. In this case  the action amounts to a certain decay of the Lyapunov function. The presented
framework provides a promising path towards the design of adaptive optimization algorithms. We
have provided theoretical guarantees that ensure the implementability of the method and numerical
comparisons with recent discretizations of the heavy-ball dynamics. The supplemental material
contains analogous results for the Nesterov’s accelerated gradient for strongly convex functions.

8

ETIntegratorSTIntegratorForwardEulerSymplecticEuler02004006008001000120014000.0000.0020.0040.0060.0080.010IterationsStepsizeETIntegratorOptimalStepsize02004006008001000120014000.000.020.040.060.080.10IterationsStepsize0100020003000400050000200400600800Iterationsf(x)-f(x*)010002000300040005000050010001500IterationsLyapunovFunctionFigure 3: (Left) Comparison of the evolution of the objective function along the different dynamics. (Right)
Comparison of the evolution of the logarithm of the Lyapunov function along the different dynamics.

We have employed a derivative-based approach to trigger design combined with the forward Euler
method for its simplicity  but believe that other powerful schemes can be synthesized in the future by
resorting to the following ideas.
Use of more complex integrators. The setting presented here is general enough to incorporate other
integrators beyond the forward Euler method that may yield better performance. Additionally  the
sampled information employed in our approach is a zero-order-hold  and possibilities exist within
the theory of resource-aware control to employ higher-order holds that more accurately approximate
the evolution of the continuous-time dynamics. The direct application of the forward Euler method
to Nesterov’s continuous model gives a dynamics that includes the second-order term ∇2f (x)v.
This is a drawback  as precisely the success of Nesterov’s method is the requirement of only ﬁrst-
√
order information. Two promising approaches to circumvent this issue are to approximate the term
s∇2f (x)v by ∇f (xk+1) − ∇f (xk)  cf. [19  24]  and to recast the second-order Nesterov’s ODE
as a ﬁrst-order one  cf. [2  3] and develop analogous schemes for the resulting dynamics.
Convergence rate as a result of Lyapunov decay and uniform lower bound on stepsize. The result in
Theorem 3.3 links the convergence rate of the discrete-time algorithm to the Lyapunov decay and
the stepsize of the state-triggered implementation of the continuous-time dynamics. More explicitly 
if we bound the stepsize by ˆt then f (xk+1) − f (x∗) ∈ O(exp(−√
ˆt)k). Therefore acceleration
can be understood as a consequence of the ability of the state-triggered implementation to maintain
certain Lyapunov decay for a long enough time (i.e.  large stepsize). Although we do not observe
acceleration in the numerical studies presented here  i.e.  exp(−√
L  this is probably due
to the simplicity of the used forward-Euler integrator employed. Nonetheless  the introduced variable
stepsize integrators clearly outperform their equivalent ﬁxed-stepsize counterparts  reinforcing the
importance of extending our design to more complex integrators with which to achieve the desired
convergence rates.
Use of other triggering conditions. Other approaches to trigger design  beyond derivative-based ones 
are promising. For instance  [26] introduces a Lyapunov sampling event-triggered approach whose
main idea is to continuously sample the Lyapunov function until certain decay has been reached.
The trigger takes the form tk+1 = min{t > ti such that V (x(t)) − ηV (xi) = 0}  where η ∈ [0  1]
is a design parameter. The expression is similar to the difference V (xi+1) − V (xi)  which is upper
bounded in [24] for the iterations of explicit and implicit symplectic integrators  and plays a key role
in the convergence analysis. This suggests the use of similar bounds to develop variable-stepsize
integrators. Along the same lines  the use of dynamic triggers [6] to keep track of how much the
Lyapunov function decreases along the evolution is also appealing.
Extensions to convex functions. The work [23] presents another high-resolution ODE for the case of
Nesterov’s method applied to convex functions. The sharp bounds on the evolution of the Lyapunov
function provided by strong convexity that we employ in the trigger design do not hold anymore. It is
therefore challenging and extremely interesting to develop new ideas to tackle this problem.

ˆt) ≥ 1−(cid:112) µ

µ
4

µ
4

Acknowledgments

This work was supported by NSF Award CNS-1446891 and AFOSR Award FA9550-15-1-0108.

9

020004000600080001000005.0×1071.0×1081.5×108IterationsObjectiveFunctionETIntegratorSTIntegratorForwardEulerSymplecticEuler0200040006000800010000141516171819IterationsLogLyapunovFunctionReferences
[1] Z. Allen-Zhu and L. Orecchia. Linear Coupling: An Ultimate Uniﬁcation of Gradient and Mirror Descent.
In 8th Innovations in Theoretical Computer Science Conference (ITCS 2017)  pages 1–22  Dagstuhl 
Germany  2017.

[2] F. Alvarez  H. Attouch  J. Bolte  and P. Redont. A second-order gradient-like dissipative dynamical system
with Hessian-driven damping. Application to optimization and mechanics. Journal de Mathématiques
Pures et Appliquées  81(8):747–779  2002.

[3] H. Attouch  Z. Chbani  J. Fadili  and H. Riahi. First-order optimization algorithms via inertial systems

with Hessian driven damping. arXiv preprint arXiv:1907.10536  2019.

[4] M. Betancourt  M. Jordan  and A. C. Wilson. On symplectic optimization. arXiv preprint arXiv:

1802.03653  2018.

[5] S. Bubeck  Y. Lee  and M. Singh. A geometric alternative to Nesterov’s accelerated gradient descent. arXiv

preprint arXiv:1506.08187  2015.
[6] V. S. Dolk  D. P. Borgers  and W. P. M. H. Heemels. Output-based and decentralized dynamic event-
triggered control with guaranteed Lp-gain performance and Zeno-freeness. IEEE Transactions on Auto-
matic Control  62(1):34–49  2017.

[7] S. Durand  N. Marchand  and J. F. Guerrero-Castellanos. Simple Lyapunov sampling for event-driven

control. IFAC Proceedings Volumes  44(1):8724–8730  2011.

[8] G. França  J. Sulam  D. Robinson  and R. Vidal. Conformal symplectic and relativistic optimization. arXiv

preprint arXiv:1903.04100  2019.

Princeton University Press  2012.

[9] R. Goebel  R. G. Sanfelice  and A. R. Teel. Hybrid Dynamical Systems: Modeling  Stability  and Robustness.

[10] E. Hairer  C. Lubich  and G. Wanner. Geometric numerical integration. Springer  Berlin  Heidelberg  2010.
[11] E. Hairer  S. P. Nørsett  and G. Wanner. Solving Ordinary Differential Equations I (2Nd Revised. Ed.):

Nonstiff Problems. Springer  Berlin  Heidelberg  1993.

[12] W. P. M. H. Heemels  M. C. F. Donkers  and A. R. Teel. Periodic event-triggered control based on state

feedback. In IEEE Conf. on Decision and Control  pages 2571–2576  Dec 2011.

[13] W. P. M. H. Heemels  K. H. Johansson  and P. Tabuada. An introduction to event-triggered and self-triggered

control. In IEEE Conf. on Decision and Control  pages 3270–3285  Maui  HI  2012.

[14] B. Hu and L. Lessard. Dissipativity theory for Nesterov’s accelerated method. In Proceedings of the
34th International Conference on Machine Learning  pages 1549–1557  International Convention Centre 
Sydney  Australia  August 2017.

[15] A. S. Kolarijani  P. M. Esfahani  and T. Keviczky. Fast Gradient-Based Methods with Exponential Rate: A
Hybrid Control Framework. In Proceedings of the 35th International Conference on Machine Learning 
pages 2728–2736  July 2018.

[16] L. Lessard  B. Recht  and A. Packard. Analysis and design of optimization algorithms via integral quadratic

constraints. SIAM Journal on Optimization  26(1):57–95  2016.

[17] C. J. Maddison  D. Paulin  Y. W. Teh  B. O’Donoghue  and A. Doucet. Hamiltonian descent methods.

arXiv preprint arXiv:1809.05042  2018.

[18] Y. E. Nesterov. A method of solving a convex programming problem with convergence rate O(1/k2).

Soviet Mathematics Doklady  27(2):372–376  1983.

[19] J. Nocedal and S. Wright. Numerical optimization. Springer  Berlin  Heidelberg  2006.
[20] C. Nowzari  E. Garcia  and J. Cortés. Event-triggered control and communication of networked systems

for multi-agent consensus. Automatica  105:1–27  2019.

[21] P. Ong and J. Cortés. Event-triggered control design with performance barrier. In IEEE Conf. on Decision

and Control  pages 951–956  Miami Beach  FL  Dec. 2018.

[22] B. T. Polyak. Some methods of speeding up the convergence of iterative methods. USSR Computational

Mathematics and Mathematical Physics  4(5):1–17  1964.

[23] B. Shi  S. S. Du  M. I. Jordan  and W. J. Su. Understanding the acceleration phenomenon via high-resolution

differential equations. arXiv preprint arXiv:1810.08907  2018.

[24] B. Shi  S. S. Du  M. I. Jordan  and W. J. Su. Acceleration via symplectic discretization of high-resolution

differential equations. arXiv preprint arXiv:1902.03694  2019.

[25] W. Su  S. Boyd  and E. J. Candés. A differential equation for modeling Nesterov’s accelerated gradient

method: theory and insights. Journal of Machine Learning Research  17:1–43  2016.

[26] M. Velasco  P. Martí  and E. Bini. On Lyapunov sampling for event-driven controllers. In IEEE Conf. on

Decision and Control  pages 6238–6243  Dec 2009.

[27] A. Wibisono  A. C. Wilson  and M. I. Jordan. A variational perspective on accelerated methods in

optimization. Proceedings of the National Academy of Sciences  113(47):E7351–E7358  2016.

[28] A. C. Wilson  B. Recht  and M. I. Jordan. A Lyapunov analysis of momentum methods in optimization.

arXiv preprint arXiv:1611.02635  2018.

[29] J. Zhang  A. Mokhtari  S. Sra  and A. Jadbabaie. Direct Runge-Kutta discretization achieves acceleration.

In Conference on Neural Information Processing Systems  pages 3904–3913  2018.

10

,Miguel Vaquero
Jorge Cortes