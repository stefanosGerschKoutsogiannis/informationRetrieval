2013,Lexical and Hierarchical Topic Regression,Inspired by a two-level theory that unifies agenda setting and ideological  framing  we propose supervised hierarchical latent Dirichlet allocation  (SHLDA) which jointly captures documents' multi-level topic structure and  their polar response variables. Our model extends the nested Chinese restaurant  process to discover a tree-structured topic hierarchy and uses both per-topic  hierarchical and per-word lexical regression parameters to model the response  variables. Experiments in a political domain and on sentiment analysis tasks  show that SHLDA improves predictive accuracy while adding a new dimension of  insight into how topics under discussion are framed.,Lexical and Hierarchical Topic Regression

Viet-An Nguyen
Computer Science

University of Maryland

College Park  MD

vietan@cs.umd.edu

Jordan Boyd-Graber
iSchool & UMIACS

University of Maryland

College Park  MD

jbg@umiacs.umd.edu

Philip Resnik

Linguistics & UMIACS
University of Maryland

College Park  MD
resnik@umd.edu

Abstract

Inspired by a two-level theory from political science that uniﬁes agenda setting
and ideological framing  we propose supervised hierarchical latent Dirichlet alloca-
tion (SHLDA)  which jointly captures documents’ multi-level topic structure and
their polar response variables. Our model extends the nested Chinese restaurant
processes to discover tree-structured topic hierarchies and uses both per-topic hier-
archical and per-word lexical regression parameters to model response variables.
SHLDA improves prediction on political afﬁliation and sentiment tasks in addition
to providing insight into how topics under discussion are framed.

1

Introduction: Agenda Setting and Framing in Hierarchical Models

How do liberal-leaning bloggers talk about immigration in the US? What do conservative politicians
have to say about education? How do Fox News and MSNBC differ in their language about the gun
debate? Such questions concern not only what  but how things are talked about.
In political communication  the question of “what” falls under the heading of agenda setting theory 
which concerns the issues introduced into political discourse (e.g.  by the mass media) and their
inﬂuence over public priorities [1]. The question of “how” concerns framing: the way the presentation
of an issue reﬂects or encourages a particular perspective or interpretation [2]. For example  the rise
of the “innocence frame” in the death penalty debate  emphasizing the irreversible consequence of
mistaken convictions  has led to a sharp decline in the use of capital punishment in the US [3].
In its concern with the subjects or issues under discussion in political discourse  agenda setting
maps neatly to topic modeling [4] as a means of discovering and characterizing those issues [5].
Interestingly  one line of communication theory seeks to unify agenda setting and framing by viewing
frames as a second-level kind of agenda [1]:
just as agenda setting is about which objects of
discussion are salient  framing is about the salience of attributes of those objects. The key is that
what communications theorists consider an attribute in a discussion can itself be an object  as well.
For example  “mistaken convictions” is one attribute of the death penalty discussion  but it can also
be viewed as an object of discussion in its own right.
This two-level view leads naturally to the idea of using a hierarchical topic model to formalize
both agendas and frames within a uniform setting. In this paper  we introduce a new model to do
exactly that. The model is predictive: it represents the idea of alternative or competing perspectives
via a continuous-valued response variable. Although inspired by the study of political discourse 
associating texts with “perspectives” is more general and has been studied in sentiment analysis 
discovery of regional variation  and value-sensitive design. We show experimentally that the model’s
hierarchical structure improves prediction of perspective in both a political domain and on sentiment
analysis tasks  and we argue that the topic hierarchies exposed by the model are indeed capturing
structure in line with the theory that motivated the work.

1

1. For each node k ∈ [1 ∞) in the tree

(a) Draw topic φk ∼ Dir(βk)
(b) Draw regression parameter ηk ∼ N (µ  σ)

2. For each word v ∈ [1  V ]  draw τv ∼ Laplace(0  ω)
3. For each document d ∈ [1  D]

(a) Draw level distribution θd ∼ GEM(m  π)
(b) Draw table distribution ψd ∼ GEM(α)
(c) For each table t ∈ [1 ∞)  draw a path cd t ∼ nCRP(γ)
(d) For each sentence s ∈ [1  Sd]  draw a table indicator

td s ∼ Mult(ψd)
i. For each token n ∈ [1  Nd s]
A. Draw level zd s n ∼ Mult(θd)
B. Draw word wd s n ∼ Mult(φcd td s
(e) Draw response yd ∼ N (ηT ¯zd + τ T ¯wd  ρ):
I [kd s n = k]
I [wd s n = v]

(cid:80)Nd s
(cid:80)Nd s

i. ¯zd k = 1
Nd ·
ii. ¯wd v = 1
Nd ·

n=1

(cid:80)Sd
(cid:80)Sd

s=1

 zd s n )

n=1

s=1

Figure 1: SHLDA’s generative process and plate diagram. Words w are explained by topic hierarchy φ  and
response variables y are explained by per-topic regression coefﬁcients η and global lexical coefﬁcients τ .
2 SHLDA: Combining Supervision and Hierarchical Topic Structure

Jointly capturing supervision and hierarchical topic structure falls under a class of models called
supervised hierarchical latent Dirichlet allocation. These models take as input a set of D documents 
each of which is associated with a response variable yd  and output a hierarchy of topics which is
informed by yd. Zhang et al. [6] introduce the SHLDA family  focusing on a categorical response.
In contrast  our novel model (which we call SHLDA for brevity)  uses continuous responses. At
its core  SHLDA’s document generative process resembles a combination of hierarchical latent
Dirichlet allocation [7  HLDA] and the hierarchical Dirichlet process [8  HDP]. HLDA uses the nested
Chinese restaurant process (nCRP(γ))  combined with an appropriate base distribution  to induce an
unbounded tree-structured hierarchy of topics: general topics at the top  speciﬁc at the bottom. A
document is generated by traversing this tree  at each level creating a new child (hence a new path)
with probability proportional to γ or otherwise respecting the “rich-get-richer” property of a CRP.
A drawback of HLDA  however  is that each document is restricted to only a single path in the
tree. Recent work relaxes this restriction through different priors: nested HDP [9]  nested Chinese
franchises [10] or recursive CRPs [11]. In this paper  we address this problem by allowing documents
to have multiple paths through the tree by leveraging information at the sentence level using the two-
level structure used in HDP. More speciﬁcally  in the HDP’s Chinese restaurant franchise metaphor 
customers (i.e.  tokens) are grouped by sitting at tables and each table takes a dish (i.e.  topic) from
a ﬂat global menu. In our SHLDA  dishes are organized in a tree-structured global menu by using
the nCRP as prior. Each path in the tree is a collection of L dishes (one for each level) and is called
a combo. SHLDA groups sentences of a document by assigning them to tables and associates each
table with a combo  and thus  models each document as a distribution over combos.1
In SHLDA’s metaphor  customers come in a restaurant and sit at a table in groups  where each group
is a sentence. A sentence wd s enters restaurant d and selects a table t (and its associated combo)
with probability proportional to the number of sentences Sd t at that table; or  it sits at a new table
with probability proportional to α. After choosing the table (indexed by td s)  if the table is new  the
group will select a combo of dishes (i.e.  a path  indexed by cd t) from the tree menu. Once a combo
is in place  each token in the sentence chooses a “level” (indexed by zd s n) in the combo  which
speciﬁes the topic (φkd s n ≡ φcd td s  zd s n) producing the associated observation (Figure 2).
SHLDA also draws on supervised LDA [12  SLDA] associating each document d with an observable
continuous response variable yd that represents the author’s perspective toward a topic  e.g.  positive
vs. negative sentiment  conservative vs. liberal ideology  etc. This lets us infer a multi-level topic
structure informed by how topics are “framed” with respect to positions along the yd continuum.

1We emphasize that  unlike in HDP where each table is assigned to a single dish  each table in our metaphor

is associated with a combo–a collection of L dishes. We also use combo and path interchangeably.

2

 ܰௗ௦ ܦ ݉ ߶௞ ߚ ∞ ߛ ݕௗ ߨ ߠௗ ߟ௞ ߤ ߪ ߩ ߰ௗ ݐௗ௦ ݓௗ௦௡ݖௗ௦௡ܿௗ௧ ߙ ∞ ܵௗ ߬௩ ܸ ߱ Sd
Sd t

Nd s
Nd · l
Nd · >l
Nd · ≥l
Mc l
Cc l v
Cd x l v
φk
ηk
τv
cd t
td s
zd s n
kd s n

L
C+

# sentences in document d
# groups (i.e. sentences) sitting at table t
in restaurant d
# tokens wd s
# tokens in wd assigned to level l
# tokens in wd assigned to level > l
≡ Nd · l + Nd · >l
# tables at level l on path c
# word type v assigned to level l on path c
# word type v in vd x assigned to level l
Topic at node k
Regression parameter at node k
Regression parameter of word type v
Path assignment for table t in restaurant d
Table assignment for group wd s
Level assignment for wd s n
Node assignment for wd s n (i.e.  node at
level zd s n on path cd td s)
Height of the tree
Set of all possible paths (including new
ones) of the tree

Figure 2: SHLDA’s restaurant franchise metaphor.

Table 1: Notation used in this paper

Unlike SLDA  we model the response variables using a normal linear regression that contains both per-
topic hierarchical and per-word lexical regression parameters. The hierarchical regression parameters
are just like topics’ regression parameters in SLDA: each topic k (here  a tree node) has a parameter
ηk  and the model uses the empirical distribution over the nodes that generated a document as the
regressors. However  the hierarchy in SHLDA makes it possible to discover relationships between
topics and the response variable that SLDA’s simple latent space obscures. Consider  for example 
a topic model trained on Congressional debates. Vanilla LDA would likely discover a healthcare
category. SLDA [12] could discover a pro-Obamacare topic and an anti-Obamacare topic. SHLDA
could do that and capture the fact that there are alternative perspectives  i.e.  that the healthcare issue
is being discussed from two ideological perspectives  along with characterizing how the higher level
topic is discussed by those on both sides of that ideological debate.
Sometimes  of course  words are strongly associated with extremes on the response variable continuum
regardless of underlying topic structure. Therefore  in addition to hierarchical regression parameters 
we include global lexical regression parameters to model the interaction between speciﬁc words
and response variables. We denote the regression parameter associated with a word type v in the
vocabulary as τv  and use the normalized frequency of v in the documents to be its regressor.
Including both hierarchical and lexical parameters is important. For detecting ideology in the US 
“liberty” is an effective indicator of conservative speakers regardless of context; however  “cost”
is a conservative-leaning indicator in discussions about environmental policy but liberal-leaning
in debates about foreign policy. For sentiment  “wonderful” is globally a positive word; however 
“unexpected” is a positive descriptor of books but a negative one of a car’s steering. SHLDA captures
these properties in a single model.

3 Posterior Inference and Optimization
Given documents with observed words w = {wd s n} and response variables y = {yd}  the inference
task is to ﬁnd the posterior distribution over: the tree structure including topic φk and regression
parameter ηk for each node k  combo assignment cd t for each table t in document d  table assignment
td s for each sentence s in a document d  and level assignment zd s n for each token wd s n. We
approximate SHLDA’s posterior using stochastic EM  which alternates between a Gibbs sampling
E-step and an optimization M-step. More speciﬁcally  in the E-step  we integrate out ψ  θ and φ to
construct a Markov chain over (t  c  z) and alternate sampling each of them from their conditional
distributions. In the M-step  we optimize the regression parameters η and τ using L-BFGS [13].
Before describing each step in detail  let us deﬁne the following probabilities. For more thorough
derivations  please see the supplement.

3

 ߶ଵ				ߟଵ ߶ଵଵ			ߟଵଵ ߶ଵଵଵ		ߟଵଵଵ ߶ଵଵଶ		ߟଵଵଶ ߶ଵଶ			ߟଵଶ ߶ଵଶଵ		ߟଵଶଵ ߶ଵଶଶ		ߟଵଶଶ ݐ=2 ݐ=1 ݀=1 ݐ=2 ݐ=1 ݐ=1 ݐ=2 ݀=2 ݀=ܦ ܿௗ௧ ݏ=1 ݐ=3 ݏ=2 ݏ=ܵଵ ݏ=1 ݏ=ܵଶ ݏ=3 ݏ=ܵ஽ ݐௗ௦ ݏ=2 ݀=1 ߶ଵ				ߟଵ ߶ଵଵ			ߟଵଵ ߶ଵଵଵ		ߟଵଵଵ ݇ௗ௦௡ݏ=1 group (sentence) restaurant (document) table customer (token) dish combo (path) f

−d x
c

(vd x) =

L(cid:89)

• First  deﬁne vd x as a set of tokens (e.g.  a token  a sentence or a set of sentences) in document d.

−d x
c l · + V βl)

The conditional density of vd x being assigned to path c given all other assignments is
−d x
c l v + Cd x l v + βl)
Γ(C

(1)
where superscript −d x denotes the same count excluding assignments of vd x; marginal counts
−d x
are represented by ·’s. For a new path cnew  if the node does not exist  C
cnew l v = 0 for all word
types v.
• Second  deﬁne the conditional density of the response variable yd of document d given vd x being
assigned to path c and all other assignments as g−d x

Γ(C
−d x
c l · + Cd x l · + V βl)

−d x
c l v + βl)

V(cid:89)

Γ(C

Γ(C

v=1

l=1

(yd) =

c

L(cid:88)

Sd(cid:88)

Nd s(cid:88)

(cid:33)



ηcd td s

 zd s n +

ηc l · Cd x l · +

l=1

s=1

n=1

τwd s n

  ρ

(2)

 1

Nd ·

N

(cid:32) (cid:88)

wd s n∈{wd\vd x}

where Nd · is the total number of tokens in document d. For a new node at level l on a new path
cnew  we integrate over all possible values of ηcnew l.

Sampling t: For each group wd s we need to sample a table td s. The conditional distribution of a
table t given wd s and other assignments is proportional to the number of sentences sitting at t times
the probability of wd s and yd being observed under this assignment. This is P (td s = t| rest) ∝
P (td s = t| t−s

(cid:26) S
α ·(cid:80)

d ) · P (wd s  yd | td s = t  w−d s  t−d s  z  c  η)
−d s
d t

· f−d s
c∈C+ P (cd tnew = c| c−d s) · f−d s

(wd s) · g−d s

(yd) 

cd t

cd t

c

∝

(3)
For a new table tnew  we need to sum over all possible paths C+ of the tree  including new ones. For
example  the set C+ for the tree shown in Figure 2 consists of four existing paths (ending at one of
the four leaf nodes) and three possible new paths (a new leaf off of one of the three internal nodes).
The prior probability of path c is: P (cd tnew = c| c−d s) ∝

(wd s) · g−d s

(yd) 

c

for existing table t;
for new table tnew.

(cid:81)L

l=2



−d s
c l

M
−d s
c l−1 + γl−1

(cid:81)l∗

M
γl∗

−d s
cnew  l∗ + γl∗

M

l=2

 

for an existing path c;

−d s
cnew  l

M
−d s
cnew  l−1 + γl−1

 

M

for a new path cnew which consists of an existing path
from the root to a node at level l∗ and a new node.

(4)

Sampling z: After assigning a sentence wd s to a table  we assign each token wd s n to a level to
choose a dish from the combo. The probability of assigning wd s n to level l is
)P (wd s n  yd | zd s n = l  w−d s n  z−d s n  t  c  η) (5)
P (zd s n = l | rest) ∝ P (zd s n = l | z
The ﬁrst factor captures the probability that a customer in restaurant d is assigned to level l  condi-
tioned on the level assignments of all other customers in restaurant d  and is equal to

−s n
d

P (zd s n = l | z

−s n
d

) =

mπ + N

π + N

−d s n
d · l
−d s n
d · ≥l

(1 − m)π + N
−d s n
d · ≥j

π + N

−d s n
d · >j

 

l−1(cid:89)

j=1

The second factor is the probability of observing wd s n and yd  given that wd s n is assigned to level
l: P (wd s n  yd | zd s n = l  w−d s n  z−d s n  t  c  η) = f−d s n
cd td s

(wd s n) · g−d s n
cd td s

(yd).

Sampling c: After assigning customers to tables and levels  we also sample path assignments for
all tables. This is important since it can change the assignments of all customers sitting at a table 
which leads to a well-mixed Markov chain and faster convergence. The probability of assigning table
t in restaurant d to a path c is

P (cd t = c| rest) ∝ P (cd t = c| c−d t) · P (wd t  yd | cd t = c  w−d t  c−d t  t  z  η)

(6)
where we slightly abuse the notation by using wd t ≡ ∪{s|td s=t}wd s to denote the set of customers
in all the groups sitting at table t in restaurant d. The ﬁrst factor is the prior probability of a path
given all tables’ path assignments c−d t  excluding table t in restaurant d and is given in Equation 4.
The second factor in Equation 6 is the probability of observing wd t and yd given the new path
assignments  P (wd t  yd | cd t = c  w−d t  c−d t  t  z  η) = f−d t

(wd t) · g−d t

(yd).

c

c

4

Optimizing η and τ : We optimize the regression parameters η and τ via the likelihood 

D(cid:88)

d=1

K+(cid:88)

k=1

V(cid:88)

v=1

L(η  τ ) = − 1
2ρ

(yd − ηT ¯zd − τ T ¯wd)2 − 1
2σ

(ηk − µ)2 − 1
ω

|τv| 

(7)

where K + is the number of nodes in the tree.2 This maximization is performed using L-BFGS [13].

4 Data: Congress  Products  Films

We conduct our experiments using three datasets: Congressional ﬂoor debates  Amazon product
reviews  and movie reviews. For all datasets  we remove stopwords  add bigrams to the vocabulary 
and ﬁlter the vocabulary using tf-idf.3
• U.S Congressional ﬂoor debates: We downloaded debates of the 109th US Congress from Gov-
Track4 and preprocessed them as in Thomas et al. [14]. To remove uninterestingly non-polarized
debates  we ignore bills with less than 20% “Yea” votes or less than 20% “Nay” votes. Each
document d is a turn (a continuous utterance by a single speaker  i.e. speech segment [14])  and
its response variable yd is the ﬁrst dimension of the speaker’s DW-NOMINATE score [15]  which
captures the traditional left-right political distinction.5 After processing  our corpus contains 5 201
turns in the House  3 060 turns in the Senate  and 5 000 words in the vocabulary.6
• Amazon product reviews: From a set of Amazon reviews of manufactured products such as
computers  MP3 players  GPS devices  etc. [16]  we focused on the 50 most frequently reviewed
products. After ﬁltering  this corpus contains 37 191 reviews with a vocabulary of 5 000 words.
We use the rating associated with each review as the response variable yd.7
• Movie reviews: Our third corpus is a set of 5 006 reviews of movies [17]  again using review
ratings as the response variable yd  although in this corpus the ratings are normalized to the range
from 0 to 1. After preprocessing  the vocabulary contains 5 000 words.

5 Evaluating Prediction

SHLDA’s response variable predictions provide a formally rigorous way to assess whether it is an
improvement over prior methods. We evaluate effectiveness in predicting values of the response
variables for unseen documents in the three datasets. For comparison we consider these baselines:
• Multiple linear regression (MLR) models the response variable as a linear function of multiple
features (or regressors). Here  we consider two types of features: topic-based features and lexically-
based features. Topic-based MLR  denoted by MLR-LDA  uses the topic distributions learned by
vanilla LDA as features [12]  while lexically-based MLR  denoted by MLR-VOC  uses the frequencies
of words in the vocabulary as features. MLR-LDA-VOC uses both features.
• Support vector regression (SVM) is a discriminative method [18] that uses LDA topic distributions
• Supervised topic model (SLDA): we implemented SLDA using Gibbs sampling. The version of
SLDA we use is slightly different from the original SLDA described in [12]  in that we place a
Gaussian prior N (0  1) over the regression parameters to perform L2-norm regularization.9

(SVM-LDA)  word frequencies (SVM-VOC)  and both (SVM-LDA-VOC) as features.8

For parametric models (LDA and SLDA)  which require the number of topics K to be speciﬁed before-
hand  we use K ∈ {10  30  50}. We use symmetric Dirichlet priors in both LDA and SLDA  initialize

2The superscript + is to denote that this number is unbounded and varies during the sampling process.
3To ﬁnd bigrams  we begin with bigram candidates that occur at least 10 times in the corpus and use Pearson’s
χ2-test to ﬁlter out those that have χ2-value less than 5  which corresponds to a signiﬁcance level of 0.025. We
then treat selected bigrams as single word types and add them to the vocabulary.

4 http://www.govtrack.us/data/us/109/
5Scores were downloaded from http://voteview.com/dwnomin_joint_house_and_senate.htm
6Data will be available after blind review.
7The ratings can range from 1 to 5  but skew positive.
8 http://svmlight.joachims.org/
9This performs better than unregularized SLDA in our experiments.

5

Models

SVM-LDA10
SVM-LDA30
SVM-LDA50
SVM-VOC

SVM-LDA-VOC
MLR-LDA10
MLR-LDA30
MLR-LDA50
MLR-VOC

MLR-LDA-VOC

SLDA10
SLDA30
SLDA50
SHLDA

Amazon
Reviews

Movie
Reviews

House-Senate
PCC ↑
0.173
0.172
0.169
0.336
0.256

Floor Debates
Senate-House
PCC ↑
MSE ↓
0.08
0.861
0.155
0.840
0.215
0.832
1.549
0.131
0.246
0.784

MSE ↓
1.247
1.183
1.135
1.467
1.101

PCC ↑
0.157
0.277
0.245
0.373
0.371

MSE ↓
1.241
1.091
1.130
0.972
0.965

PCC ↑
0.327
0.365
0.395
0.584
0.585

MSE ↓
0.970
0.938
0.906
0.681
0.678

0.163
0.160
0.150
0.322
0.319

0.154
0.174
0.254

0.735
0.737
0.741
0.889
0.873

0.729
0.793
0.897

0.068
0.162
0.248
0.191
0.194

0.090
0.128
0.245

1.151
1.125
1.081
1.124
1.120

1.145
1.188
1.184

0.143
0.258
0.234
0.408
0.410

0.270
0.357
0.241

0.356

0.753

0.303

1.076

0.413

1.034
1.065
1.114
0.869
0.860

1.113
1.146
1.939

0.891

0.328
0.367
0.389
0.568
0.581

0.383
0.433
0.503

0.957
0.936
0.914
0.721
0.702

0.953
0.852
0.772

0.597

0.673

Table 2: Regression results for Pearson’s correlation coefﬁcient (PCC  higher is better (↑)) and mean squared
error (MSE  lower is better (↓)). Results on Amazon product reviews and movie reviews are averaged over 5
folds. Subscripts denote the number of topics for parametric models. For SVM-LDA-VOC and MLR-LDA-VOC 
only best results across K ∈ {10  30  50} are reported. Best results are in bold.

the Dirichlet hyperparameters to 0.5  and use slice sampling [19] for updating hyperparameters. For
SLDA  the variance of the regression is set to 0.5. For SHLDA  we use trees with maximum depth
of three. We slice sample m  π  β and γ  and ﬁx µ = 0  σ = 0.5  ω = 0.5 and ρ = 0.5. We found
that the following set of initial hyperparameters works reasonably well for all the datasets in our
experiments: m = 0.5  π = 100  (cid:126)β = (1.0  0.5  0.25)  (cid:126)γ = (1  1)  α = 1. We also set the regression
parameter of the root node to zero  which speeds inference (since it is associated with every document)
and because it is reasonable to assume that it would not change the response variable.
To compare the performance of different methods  we compute Pearson’s correlation coefﬁcient
(PCC) and mean squared error (MSE) between the true and predicted values of the response variables
and average over 5 folds. For the Congressional debate corpus  following Yu et al. [20]  we use
documents in the House to train and test on documents in the Senate and vice versa.

Results and analysis Table 2 shows the performance of all models on our three datasets. Methods
that only use topic-based features such as SVM-LDA and MLR-LDA do poorly. Methods only based
on lexical features like SVM-VOC and MLR-VOC outperform methods that are based only on topic
features signiﬁcantly for the two review datasets  but are comparable or worse on congressional
debates. This suggests that reviews have more highly discriminative words than political speeches
(Table 3). Combining topic-based and lexically-based features improves performance  which supports
our choice of incorporating both per-topic and per-word regression parameters in SHLDA.
In all cases  SHLDA achieves strong performance results. For the two cases where SHLDA was
second best in MSE score (Amazon reviews and House-Senate)  it outperforms other methods in PCC.
Doing well in PCC for these two datasets is important since achieving low MSE is relatively easier due
to the response variables’ bimodal distribution in the ﬂoor debates and positively-skewed distribution
in Amazon reviews. For the ﬂoor debate dataset  the results of the House-Senate experiment are
generally better than those of the Senate-House experiment  which is consistent with previous
results [20] and is explained by the greater number of debates in the House.

6 Qualitative Analysis: Agendas and Framing/Perspective

Although a formal coherence evaluation [21] remains a goal for future work  a qualitative look at
the topic hierarchy uncovered by the model suggests that it is indeed capturing agenda/framing
structure as discussed in Section 1. In Figure 3  a portion of the topic hierarchy induced from the
Congressional debate corpus  Nodes A and B illustrate agendas—issues introduced into political
discourse—associated with a particular ideology: Node A focuses on the hardships of the poorer
victims of hurricane Katrina and is associated with Democrats  and text associated with Node E
discusses a proposed constitutional amendment to ban ﬂag burning and is associated with Republicans.
Nodes C and D  children of a neutral “tax” topic  reveal how parties frame taxes as gains in terms of
new social services (Democrats) and losses for job creators (Republicans).

6

Figure 3: Topics discovered from
Congressional ﬂoor debates. Many
ﬁrst-level topics are bipartisan (purple) 
while lower level topics are associated
with speciﬁc ideologies (Democrats blue 
Republicans red). For example  the
“tax” topic (B) is bipartisan  but its
Democratic-leaning child (D) focuses on
social goals supported by taxes (“chil-
dren”  “education”  “health care”)  while
its Republican-leaning child (C) focuses
on business implications (“death tax” 
“jobs”  “businesses”). The number below
each topic denotes the magnitude of the
learned regression parameter associated
with that topic. Colors and the numbers
beneath each topic show the regression
parameter η associated with the topic.

Figure 4 shows the topic structure discovered by SHLDA in the review corpus. Nodes at higher levels
are relatively neutral  with relatively small regression parameters.10 These nodes have general topics
with no speciﬁc polarity. However  the bottom level clearly illustrates polarized positive/negative
perspective. For example  Node A concerns washbasins for infants  and has two polarized children
nodes: reviewers take a positive perspective when their children enjoy the product (Node B: “loves” 
“splash”  “play”) but have negative reactions when it leaks (Node C: “leak(s/ed/ing)”).

Figure 4: Topics discovered from Amazon reviews. Higher topics are general  while lower topics are more
speciﬁc. The polarity of the review is encoded in the color: red (negative) to blue (positive). Many of the ﬁrst-
level topics have no speciﬁc polarity and are associated with a broad class of products such as “routers” (Node D).
However  the lowest topics in the hierarchy are often polarized; one child topic of “router” focuses on upgradable
ﬁrmware such as “tomato” and “ddwrt” (Node E  positive) while another focuses on poor “tech support” and
“customer service” (Node F  negative). The number below each topic is the regression parameter learned with
that topic.

In addition to the per-topic regression parameters  SHLDA also associates each word with a lexical
regression parameter τ. Table 3 shows the top ten words with highest and lowest τ. The results are
unsuprising  although the lexical regression for the Congressional debates is less clear-cut than other

10All of the nodes at the second level have slightly negative values for the regression parameters mainly due

to the very skewed distribution of the review ratings in Amazon.

7

 bill speaker time amendment chairman people gentleman legislation congress supportREPUBLICANDEMOCRATR:0 gses credit_rating fannie_mae regulator freddie_mac market ﬁnancial_services agencies competition investors fannie R:1.0 affordable_housing housing manager fund activities funds organizations voter_registration faithbased nonproﬁts D:2.2D:1.7 minimum_wage commission independent_commission investigate hurricane_katrina increase investigation A ﬂag constitution freedom supreme_court elections rights continuity american_ﬂag constitutional_amendment R:1.1ER:0.4 percent tax economy estate_tax capital_gains money taxes businesses families tax_cuts pay tax_relief social_securityB billion budget children cuts debt tax_cuts child_support deﬁcit education students health_care republicans national_debt D:4.5D death_tax jobs businesses business family_businesses equipment productivity repeal_permanency employees capital farmsR:4.3C transmitter ipod car frequency iriver product transmitters live station presets itrip iriver_aft charges international_mode driving leak formula bottles_leak feeding leaked brown frustrating started clothes waste newborn playtex_ventaire soaked matter tried waste batteries tunecast rabbit_ears weak terrible antenna hear returned refund returning item junk return nipple breast nipples dishwasher ring sippy_cups tried breastfeed screwed breastfeeding nipple_confusion avent_system bottle transmitter car static ipod radio mp3_player signal station sound music sound_quality volume stations frequency frequencies comfortable sound phones sennheiser bass px100 px100s phone headset highs portapros portapro price wear koss months loves hammock splash love baby drain eurobath hot ﬁts wash play infant secure slip time bought product easy buy love using price lot able set found purchased money months tub baby water bath sling son daughter sit bathtub sink newborn months bath_tub bathe bottom router setup network expander set signal wireless connect linksys connection house wireless_router laptop computer wre54g monitor radio weather_radio night baby range alerts sound sony house interference channels receiver static alarm tivo adapter series adapters phone_line tivo_wireless transfer plugged wireless_adapter tivos plug dvr tivo_series tivo_box tivo_unit router ﬁrmware ddwrt wrt54gl version wrt54g tomato linksys linux routers ﬂash versions browser dlink stable bottles bottle baby leak nipples nipple avent avent_bottles leaking son daughter formula leaks gas milknoise_canceling noise sony exposed noise_cancellation stopped wires warranty noise_cancelling bud pay white_noise disappointed headphones sound pair bass headset sound_quality ear ears cord earbuds comfortable hear head earphones ﬁt hear feature static monitors set live warning volume counties noise outside alert breathing rechargeable_battery alerts leaks leaked leak leaking hard waste snap suction_cups lock tabs difﬁcult bottom tub_leaks properly ring version hours phone ﬁrmware told spent linksys tech_support technical_supportcustomer_service range_expander support return appointments organized phone lists handheld organizer photos etc pictures memos track bells books purse whistles z22 palm pda palm_z22 calendar software screen contacts computer device sync information outlook data programsNEGATIVEPOSITIVEP:6.6N:8.0P:7.5N:2.7N:2.2N:8.9N:1.0P:5.1N:10.6P:4.8N:0P:6.2N:2.0N:1.3N:7.9P:6.4P:5.7N:7.6N:1.7N:1.9P:5.8ABCDEFdatasets. As we saw in Section 5  for similar datasets  SHLDA’s context-speciﬁc regression is more
useful when global lexical weights do not readily differentiate documents.

Dataset
Floor
Debates

Amazon
Reviews
Movie
Reviews

private property 

Top 10 words with positive weights
bringing 
illegally 
tax relief  regulation  mandates  constitu-
tional  committee report  illegal alien
highly recommend  pleased  love  loves  per-
fect  easy  excellent  amazing  glad  happy
hilarious 
fast  schindler  excellent  mo-
tion pictures  academy award  perfect  jour-
ney  fortunately  ability

Top 10 words with negative weights
bush administration  strong opposition  rank-
ing  republicans  republican leadership  se-
cret  discriminate  majority  undermine
waste  returned  return  stopped  leak  junk 
useless  returning  refund  terrible
bad  unfortunately  supposed  waste  mess 
worst  acceptable  awful  suppose  boring

Table 3: Top words based on the global lexical regression coefﬁcient  τ. For the ﬂoor debates  positive τ’s are
Republican-leaning while negative τ’s are Democrat-leaning.

7 Related Work

SHLDA joins a family of LDA extensions that introduce hierarchical topics  supervision  or both.
Owing to limited space  we focus here on related work that combines the two. Petinot et al. [22]
propose hierarchical Labeled LDA (hLLDA)  which leverages an observed document ontology to learn
topics in a tree structure; however  hLLDA assumes that the underlying tree structure is known a
priori. SSHLDA [23] generalizes hLLDA by allowing the document hierarchy labels to be partially
observed  with unobserved labels and topic tree structure then inferred from the data. Boyd-Graber
and Resnik [24] used hierarchical distributions within topics to learn topics across languages. In
addition to these “upstream” models [25]  Perotte et al. [26] propose a “downstream” model called
HSLDA  which jointly models documents’ hierarchy of labels and topics. HSLDA’s topic structure
is ﬂat  however  and the response variable is a hierarchy of labels associated with each document 
unlike SHLDA’s continuous response variable. Finally  another body related body of work includes
models that jointly capture topics and other facets such as ideologies/perspectives [27  28] and
sentiments/opinions [29]  albeit with discrete rather than continuously valued responses.
Computational modeling of sentiment polarity is a voluminous ﬁeld [30]  and many computational
political science models describe agendas [5] and ideology [31]. Looking at framing or bias at
the sentence level  Greene and Resnik [32] investigate the role of syntactic structure in framing 
Yano et al. [33] look at lexical indications of sentence-level bias  and Recasens et al. [34] develop
linguistically informed sentence-level features for identifying bias-inducing words.

8 Conclusion

We have introduced SHLDA  a model that associates a continuously valued response variable with
hierarchical topics to capture both the issues under discussion and alternative perspectives on those
issues. The two-level structure improves predictive performance over existing models on multiple
datasets  while also adding potentially insightful hierarchical structure to the topic analysis. Based on
a preliminary qualitative analysis  the topic hierarchy exposed by the model plausibly captures the
idea of agenda setting  which is related to the issues that get discussed  and framing  which is related
to authors’ perspectives on those issues. We plan to analyze the topic structure produced by SHLDA
with political science collaborators and more generally to study how SHLDA and related models can
help analyze and discover useful insights from political discourse.

Acknowledgments

This research was supported in part by NSF under grant #1211153 (Resnik) and #1018625 (Boyd-
Graber and Resnik). Any opinions  ﬁndings  conclusions  or recommendations expressed here are
those of the authors and do not necessarily reﬂect the view of the sponsor.

8

References
[1] McCombs  M. The agenda-setting role of the mass media in the shaping of public opinion. North 

2009(05-12):21  2002.

[2] McCombs  M.  S. Ghanem. The convergence of agenda setting and framing. In Framing public life. 2001.
[3] Baumgartner  F. R.  S. L. De Boef  A. E. Boydstun. The decline of the death penalty and the discovery of

innocence. Cambridge University Press  2008.

[4] Blei  D. M.  A. Ng  M. Jordan. Latent Dirichlet allocation. JMLR  3  2003.
[5] Grimmer  J. A Bayesian hierarchical topic model for political texts: Measuring expressed agendas in

Senate press releases. Political Analysis  18(1):1–35  2010.

[6] Zhang  J. Explore objects and categories in unexplored environments based on multimodal data. Ph.D.

thesis  University of Hamburg  2012.

[7] Blei  D. M.  T. L. Grifﬁths  M. I. Jordan. The nested Chinese restaurant process and Bayesian nonparametric

inference of topic hierarchies. J. ACM  57(2)  2010.

[8] Teh  Y. W.  M. I. Jordan  M. J. Beal  et al. Hierarchical Dirichlet processes. JASA  101(476)  2006.
[9] Paisley  J. W.  C. Wang  D. M. Blei  et al. Nested hierarchical Dirichlet processes. arXiv:1210.6738  2012.
[10] Ahmed  A.  L. Hong  A. Smola. The nested Chinese restaurant franchise process: User tracking and

document modeling. In ICML. 2013.

[11] Kim  J. H.  D. Kim  S. Kim  et al. Modeling topic hierarchies with the recursive Chinese restaurant process.

In CIKM  pages 783–792. 2012.

[12] Blei  D. M.  J. D. McAuliffe. Supervised topic models. In NIPS. 2007.
[13] Liu  D.  J. Nocedal. On the limited memory BFGS method for large scale optimization. Math. Prog.  1989.
[14] Thomas  M.  B. Pang  L. Lee. Get out the vote: Determining support or opposition from Congressional

ﬂoor-debate transcripts. In EMNLP. 2006.

[15] Lewis  J. B.  K. T. Poole. Measuring bias and uncertainty in ideal point estimates via the parametric

bootstrap. Political Analysis  12(2)  2004.

[16] Jindal  N.  B. Liu. Opinion spam and analysis. In WSDM. 2008.
[17] Pang  B.  L. Lee. Seeing stars: Exploiting class relationships for sentiment categorization with respect to

rating scales. In ACL. 2005.

[18] Joachims  T. Making large-scale SVM learning practical. In Adv. in Kernel Methods - SVM. 1999.
[19] Neal  R. M. Slice sampling. Annals of Statistics  31:705–767  2003.
[20] Yu  B.  D. Diermeier  S. Kaufmann. Classifying party afﬁliation from political speech. JITP  2008.
[21] Chang  J.  J. Boyd-Graber  C. Wang  et al. Reading tea leaves: How humans interpret topic models. In

NIPS. 2009.

[22] Petinot  Y.  K. McKeown  K. Thadani. A hierarchical model of web summaries. In HLT. 2011.
[23] Mao  X.  Z. Ming  T.-S. Chua  et al. SSHLDA: A semi-supervised hierarchical topic model. In EMNLP.

2012.

[24] Boyd-Graber  J.  P. Resnik. Holistic sentiment analysis across languages: Multilingual supervised latent

Dirichlet allocation. In EMNLP. 2010.

[25] Mimno  D. M.  A. McCallum. Topic models conditioned on arbitrary features with Dirichlet-multinomial

regression. In UAI. 2008.

[26] Perotte  A. J.  F. Wood  N. Elhadad  et al. Hierarchically supervised latent Dirichlet allocation. In NIPS.

2011.

[27] Ahmed  A.  E. P. Xing. Staying informed: Supervised and semi-supervised multi-view topical analysis of

ideological perspective. In EMNLP. 2010.

[28] Eisenstein  J.  A. Ahmed  E. P. Xing. Sparse additive generative models of text. In ICML. 2011.
[29] Jo  Y.  A. H. Oh. Aspect and sentiment uniﬁcation model for online review analysis. In WSDM. 2011.
[30] Pang  B.  L. Lee. Opinion Mining and Sentiment Analysis. Now Publishers Inc  2008.
[31] Monroe  B. L.  M. P. Colaresi  K. M. Quinn. Fightin’words: Lexical feature selection and evaluation for

identifying the content of political conﬂict. Political Analysis  16(4):372–403  2008.

[32] Greene  S.  P. Resnik. More than words: Syntactic packaging and implicit sentiment. In NAACL. 2009.
[33] Yano  T.  P. Resnik  N. A. Smith. Shedding (a thousand points of) light on biased language. In NAACL-HLT

Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk. 2010.

[34] Recasens  M.  C. Danescu-Niculescu-Mizil  D. Jurafsky. Linguistic models for analyzing and detecting

biased language. In ACL. 2013.

9

,Viet-An Nguyen
Jordan Ying
Philip Resnik