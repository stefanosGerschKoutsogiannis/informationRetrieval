2018,Analysis of Krylov Subspace Solutions of  Regularized Non-Convex Quadratic Problems,We provide convergence rates for Krylov subspace solutions to the trust-region and cubic-regularized (nonconvex) quadratic problems. Such solutions may be efficiently computed by the Lanczos method and have long been used in practice. We prove error bounds of the form $1/t^2$ and $e^{-4t/\sqrt{\kappa}}$  where $\kappa$ is a condition number for the problem  and $t$ is the Krylov subspace order (number of Lanczos iterations). We also provide lower bounds showing that our analysis is sharp.,Analysis of Krylov Subspace Solutions of Regularized

Nonconvex Quadratic Problems

Department of Electrical Engineering

Departments of Statitstics and Electrical Engineering

Yair Carmon

Stanford University

yairc@stanford.edu

John C. Duchi

Stanford University

jduchi@stanford.edu

Abstract

We provide convergence rates for Krylov subspace solutions to the trust-region
and cubic-regularized (nonconvex) quadratic problems. Such solutions may be
efﬁciently computed by the Lanczos method and have long been used in practice.
We prove error bounds of the form 1/t2 and e4t/p  where  is a condition
number for the problem  and t is the Krylov subspace order (number of Lanczos
iterations). We also provide lower bounds showing that our analysis is sharp.

1

Introduction

Consider the potentially nonconvex quadratic function

fA b(x) :=

1
2

xT Ax + bT x 

minimize

x

where A 2 Rd⇥d and b 2 Rd. We wish to solve regularized minimization problems of the form

fA b(x) subject tokxk  R and minimize

(1)
where R and ⇢  0 are regularization parameters. These problems arise primarily in the fam-
ily of trust-region and cubic-regularized Newton methods for general nonlinear optimization prob-
lems [11  29  18  9]  which optimize a smooth function g by sequentially minimizing local models
of the form

fA b(x) +

⇢
3 kxk3  

x

g(xi +) ⇡ g(xi) + rg(xi)T +

1
2

Tr2g(xi) = g(xi) + fr2g(xi) rg(xi)() 

where xi is the current iterate and  2 Rd is the search direction. Such models tend to be unreliable
for large kk  particularly when r2g(xi) ⌥ 0. Trust-region and cubic regularization methods
address this by constraining and regularizing the direction   respectively.
Both classes of methods and their associated subproblems are the subject of substantial ongoing re-
search [19  21  5  1  25]. In the machine learning community  there is growing interest in using these
methods for minimizing (often nonconvex) training losses  handling the large ﬁnite-sum structure of
learning problems by means of sub-sampling [32  23  3  38  36].
The problems (1) are challenging to solve in high-dimensional settings  where direct decomposition
(or even storage) of the matrix A is infeasible. In some scenarios  however  computing matrix-vector
products v 7! Av is feasible. Such is the case when A is the Hessian of a neural network  where d
may be in the millions and A is dense  and yet we can compute Hessian-vector products efﬁciently
on batches of training data [31  33].
In this paper we consider a scalable approach for approximately solving (1)  which consists of
minimizing the objective in the Krylov subspace of order t 

Kt(A  b) := span{b  Ab  . . .   At1b}.

(2)

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

This requires only t matrix-vector products  and the Lanczos method allows one to efﬁciently ﬁnd
the solution to problems (1) over Kt(A  b) (see  e.g. [17  9  Sec. 2]). Krylov subspace methods
are familiar in numerous large-scale numerical problems  including conjugate gradient methods 
eigenvector problems  or solving linear systems [20  26  35  14].
It is well-known that  with exact arithmetic  the order d subspace Kd(A  b) generically contains
the global solutions to (1). However  until recently the literature contained no guarantees on the
rate at which the suboptimality of the solution approaches zero as the subspace dimension t grows.
This is in contrast to the two predominant Krylov subspace method use-cases—convex quadratic
optimization [14  27  28] and eigenvector ﬁnding [24]—where such rates of convergence have been
known for decades. Zhang et al. [39] make substantial progress on this gap  establishing bounds
implying a linear rate of convergence for the trust-region variant of problem (1).
In this work we complete the picture  proving that the optimality gap of the order t Krylov subspace
solution to either of the problems (1) is bounded by both e4t/p and t2 log2(kbk/|uT
minb|). Here
 is a condition number for the problem that naturally generalizes the classical condition number
of the matrix A  and umin is an eigenvector of A corresponding to its smallest eigenvalue. Using
minb| with a term proportional to 1/pd  circumventing the well-
randomization  we may replace |uT
known “hard case” of the problem (1) (see Section 2.5). Our analysis both leverages and uniﬁes the
known results for convex quadratic and eigenvector problems  which constitute special cases of (1).

Related work Zhang et al. [39] show that the error of certain polynomial approximation problems
bounds the suboptimality of Krylov subspace solutions to the trust region-variant of the problems (1) 
implying convergence at a rate exponential in t/p. Based on these bounds  the authors propose
novel stopping criteria for subproblem solutions in the trust-region optimization method  showing
good empirical results. However  the bounds of [39] become weak for large  and vacuous in the
hard case where  = 1.
Prior works develop algorithms for solving (1) with convergence guarantees that hold in the hard
case. Hazan and Koren [19]  Ho-Nguyen and Kılınc˛-Karzan [21]  and Agarwal et al. [1] propose
algorithms that obtain error roughly t2 after computing t matrix-vector products. The different
algorithms these papers propose all essentially reduce the problems (1) to a sequence of eigenvector
and convex quadratic problems to which standard algorithms apply. In previous work [5]  we analyze
gradient descent—a direct  local method—for the cubic-regularized problem. There  we show a rate
of convergence roughly t1  reﬂecting the well-known complexity gap between gradient descent
(respectively  the power method) and conjugate gradient (respectively  Lanczos) methods [35  14].
Our development differs from this prior work in the following ways.

1. We analyze a practical approach  implemented in efﬁcient optimization libraries [16  25]  with
essentially no tuning parameters. Previous algorithms [19  21  1] are convenient for theoretical
analysis but less conducive to efﬁcient implementation; each has several parameters that require
tuning  and we are unaware of numerical experiments with any of the approaches.

2. We provide both linear (e4t/p) and sublinear (t2) convergence guarantees. In contrast  the

papers [19  21  1] provide only a sublinear rate; Zhang et al. [39] provide only the linear rate.

3. Our analysis applies to both the trust-region and cubic regularization variants in (1)  while [19 

21  39] consider only the trust-region problem  and [39  5] consider only cubic regularization.

4. We provide lower bounds—for adversarially constructed problem instances—showing our con-
vergence guarantees are tight to within numerical constants. By a resisting oracle argument [27] 
these bounds apply to any deterministic algorithm that accesses A via matrix-vector products.

5. Our arguments are simple and transparent  and we leverage established results on convex opti-

mization and the eigenvector problem to give short proofs of our main results.

Paper organization In Section 2 we state and prove our convergence rate guarantees for the trust-
region problem. Then  in Section 3 we quickly transfer those results to the cubic-regularized problem
by showing that it always has a smaller optimality gap. Section 4 gives our lower bounds  stated for
cubic regularization but immediately applicable to the trust-region problem by the same optimality
gap bound. Finally  in Section 5 we illustrate our analysis with some numerical experiments.

2

Notation For a symmetric matrix A 2 Rd⇥d and vector b we let fA b(x) := 1
2 xT Ax + bT x.
We let min(A) and max(A) denote the minimum and maximum eigenvalues of A  and let
umin(A)  umax(A) denote their corresponding (unit) eigenvectors  dropping the argument A when
clear from context. For integer t  1 we let Pt := c0 + c1x + ··· + ct1xt1 | ci 2 R be the
polynomials of degree at most t1  so that the Krylov subspace (2) is Kt(A  b) = {p(A)b | p 2P t}.
We use k·k to denote Euclidean norm on Rd and `2-operator norm on Rd⇥d. Finally  we denote
(z)+ := max{z  0} and (z) := min{z  0}.
2 The trust-region problem
Fixing a symmetric matrix A 2 Rd⇥d  vector b 2 Rd and trust-region radius R > 0  we let

str
? 2 argmin

x2Rd  kxkR

fA b(x) =

1
2

xT Ax + bT x

denote a solution (global minimizer) of the trust region problem. Letting min  max denote the ex-
tremal eigenvalues of A  str
? solves problem (1)
if and only if there exists ? such that

? admits the following characterization [11  Ch. 7]: str

(A + ?I)str

? = b  ?  (min)+ 

(3)
The optimal Lagrange multiplier ? always exists and is unique  and if ? > min the solution str
is unique and satisﬁes str
? = (A + ?I)1b. Letting umin denote the eigenvector of A correspond-
ing to min  the characterization (3) shows that uT
Now  consider the Krylov subspace solutions  and for t > 0  let

minb 6= 0 implies ? > min.

and ?(R str

?) = 0.

?

str
t 2

argmin

x2Kt(A b)  kxkR

fA b(x) =

1
2

xT Ax + bT x

denote a minimizer of the trust-region problem in the Krylov subspace of order t . Gould et al. [17]
show how to compute the Krylov subspace solution str
t in time dominated by the cost of computing
t matrix-vector products using the Lanczos method (see also Section A of the supplement).

2.1 Main result
With the notation established above  our main result follows.
Theorem 1. For every t > 0 

fA b(str

t )  fA b(str

and

max + ?)  
? )⇤ exp(4tr min + ?
? )  36⇥fA b(0)  fA b(str
minb)2!# .
log2 4kbk2
"4 +
?k2
(max  min)kstr

I{min<0}

(uT

8

(t  1
2 )2

(4)

(5)

fA b(str

t )  fA b(str

? ) 

Theorem 1 characterizes two convergence regimes: linear (4) and sublinear (5). Linear convergence
occurs when t & pk  where  = max+?
min+?  1 is the condition number for the problem. There 
the error decays exponentially and falls beneath ✏ in roughly p log 1
✏ Lanczos iteration. Sublinear
convergence occurs when t . pk  and there the error decays polynomially and falls beneath ✏ in
roughly 1p✏ iterations. For worst-case problem instances this characterization is tight to constant
factors  as we show in Section 4.
The guarantees of Theorem 1 closely resemble the well-known guarantees for the conjugate gradient
method [35]  including them as the special case R = 1 and min  0. For convex problems  the
radius constraint kxk  R always improves the conditioning of the problem  as max
;
min  max+?
min+?
the smaller R is  the better conditioned the problem becomes. For non-convex problems  the sublin-
ear rate features an additional logarithmic term that captures the role of the eigenvector umin. The

3

ﬁrst rate (4) is similar to those of Zhang et al. [39  Thm. 4.11]  though with somewhat more explicit
dependence on t.
In the “hard case ” which corresponds to uT
minb = 0 and min + ? = 0 (cf. [11  Ch. 7])  both the
bounds in Theorem 1 become vacuous  and indeed str
t may not converge to the global minimizer in
this case. However  as the bound (5) depends only logarithmically on uT
minb  it remains valid even
extremely close to the hard case. In Section 2.5 we describe two simple randomization techniques
with convergence guarantees that are valid in the hard case as well.

2.2 Proof sketch
Our analysis reposes on two elementary observations. First  we note that Krylov subspaces are
invariant to shifts by scalar matrices  i.e. Kt(A  b) = Kt(A  b) for any A  b  t where  2 R  and

A := A + I.

Second  we observe that for every point x and  2 R


2

(str
?2  kxk2)

? ) +

2 (kstr

fA b(x)  fA b(str

? ) = fA b(x)  fA b(str

(6)
Our strategy then is to choose  such that A ⌫ 0  and then use known results to ﬁnd yt 2
Kt(A  b) = Kt(A  b) that rapidly reduces the “convex error” term fA b(yt)  fA b(str
? ). We then
?k2  kxtk2) is small.
adjust yt to obtain a feasible point xt such that the “norm error” term 
To establish linear convergence  we take  = ? and adjust the norm of yt by taking xt = (1 ↵)yt
for some small ↵ that guarantees xt is feasible and that the “norm error” term is small. To establish
sublinear convergence we set  = min and take xt = yt + ↵ · zt  where zt is an approximation
for umin within Kt(A  b)  and ↵ is chosen to make kxtk = kstr
?k. This means the “norm error”
vanishes  while the “convex error” cannot increase too much  as Aminzt ⇡ Aminumin = 0.
Our approach for proving the sublinear rate of convergence is inspired by Ho-Nguyen and Kılınc˛-
Karzan [21]  who also rely on Nesterov’s method in conjunction with Lanczos-based eigenvector
approximation. The analysis in [21] uses an algorithmic reduction  proposing to apply the Lanc-
zos method (with a random vector instead of b) to approximate umin and min  then run Nesterov’s
method on an approximate version of the “convex error” term  and then use the approximated eigen-
vector to adjust the norm of the result. We instead argue that all the ingredients for this reduction
already exist in the Krylov subspace Kt(A  b)  obviating the need for explicit eigenvector estimation
or actual application of accelerated gradient descent.

2.3 Building blocks
Our proof uses the following classical results.
Lemma 1 (Approximate matrix inverse). Let ↵   satisfy 0 <↵    and let  = /↵. For
any t  1 there exists a polynomial p of degree at most t  1  such that for every M satisfying
↵I  M  I  

kI  M p(M )k  2e2t/p.

Lemma 2 (Convex trust-region problem). Let t  1  M ⌫ 0  v 2 Rd and r  0  and let fM v(x) =
2 xT M x + vT x. There exists xt 2K t(M  v) such that

1

kxtk  r and fM v(xt)  min
kxkr

fM v(x) 

4max(M ) · r2

(t + 1)2

.

Lemma 3 (Finding eigenvectors  [24  Theorem 4.2]). Let M ⌫ 0 be such that uT M u = 0 for some
unit vector u 2 Rd  and let v 2 Rd. For every t  1 there exists zt 2K t(M  v) such that

kztk = 1 and zT

t M zt 

2 )2 log2 2 + 4 kvk2
(uT v)2! .

kMk
16(t  1

While these lemmas are standard  their explicit forms are useful  and we prove them in Section C.1
in the supplement. Lemmas 1 and 3 are consequences of uniform polynomial approximation results
(cf. supplement  Sec. B). To prove Lemma 2 we invoke Tseng’s results on a variant of Nesterov’s
accelerated gradient method [37]  arguing that its iterates lie in the Krylov subspace.

4

2.4 Proof of Theorem 1
Linear convergence Recalling the notation A? = A+?I  let yt = p(A?)b = p(A?)A?str
?  
for the p 2P t which Lemma 1 guarantees to satisfy kp(A?)A?  Ik  2e2t/p(A? ). Let

xt = (1  ↵)yt  where ↵ = kytk  kstr
?k

max{kstr

?k  kytk}
?k for any value of kytk. Moreover
= k(p(A?)A?  I)str
?k

so that we are guaranteed kxtk  kstr

|↵| = |k ytk  kstr
?k|

?k  kytk}  kyt  str
?k
kstr
?k

max{kstr

where the last transition used kp(A?)A?  Ik  2e2t/p(A? ).
2kA1/2
Since b = A?str
 = ? and kxtk  kstr

?   we have fA?  b(x) = fA?  b(str

?k therefore implies

? ) + 1

?

kstr
?k

 

 2e2t/p(A? ) 

(x  str

? )k2. The equality (6) with

2

1

?

?

kstr

str

?

? ) 

(7)

(8)

(xt  str

(xt  str

We also have 

? )

When kytk  kstr

fA b(xt)  fA b(str

?k we have kxtk = kstr

?  kxtk).

?k and the second term vanishes. When kytk < kstr
?k 

2A1/2
? (str
+ ?str
? ↵2  4e4t/p(A? )str
?  kytk) =str
? .
?  kytk  kytk
?k · (str
str
?  kxtk =str
?
? ) =([1  ↵]p(A?)A?  I) A1/2
A1/2
? e2t/p(A? ) 
?  6A1/2
? + |↵|A1/2
 (1 + |↵|)(p(A?)A?  I) A1/2
?2⌘ e4t/p(A? ) 
? ) ⇣18str

(9)
where in the ﬁnal transition we used our upper bounds on ↵ and kp(A?)A?  Ik  as well as
|↵| 1. Substituting the bounds (8) and (9) into inequality (7)  we have

(10)
?k2
and the ﬁnal bound follows from recalling that fA b(0)  fA b(str
2 kstr
and substituting (A?) = (max + ?)/(min + ?). To conclude the proof we note that (1 
↵)p(A?) = (1  ↵)p(A + ?I) = ˜p(A) for some ˜p 2P t  so that xt 2K t(A  b) and kxtk  R 
and therefore fA b(str
Sublinear convergence Let A0 := A  minI ⌫ 0 and apply Lemma 2 with M = A0  v = b and
r = kstr

?k to obtain yt 2K t(A0  b) = Kt(A  b) such that

? + 4?str

fA b(xt)  fA b(str

t )  fA b(xt).

T A?str

T A?str

? + ?

? ) = 1

2 str
?

str

?

str

?

str

?

?

kytk str

? and fA0 b(yt)  fA0 b(str

? )  fA0 b(yt)  min
kxkkstr
?k

fA0 b(x) 

?k2
4kA0kkstr
(t + 1)2

. (11)

If min  0  equality (6) with  = min along with (11) means we are done  recalling that
kA0k = max  min. For min < 0  apply Lemma 3 with M = A0 and v = b to obtain
zt 2K t(A  b) such that

kztk = 1 and zT

t A0zt  kA0k
16(t  1

2 )2 log2 4 kbk2

minb)2! .

(uT

(12)

We form the vector

and choose ↵ to satisfy

xt = yt + ↵ · zt 2K t(A  b) 

kxtk =str

? and ↵ · zT

t (A0yt + b) = ↵ · zT

t rfA0 b(yt)  0.

We may always choose such ↵ because kytk  kstr
?k has both
a non-positive and a non-negative solution in ↵. Moreover because kztk = 1 we have that |↵|

?k and therefore kyt + ↵ztk = kstr

5

2kstr
gives us 

?k. The property ↵ · zT

t rfA0 b(yt)  0 of our construction of ↵ along with r2fA0 b = A0 

fA0 b(xt) = fA0 b(yt) + ↵ · zT

t rfA0 b(yt) +

↵2
2

zT
t A0zt  fA0 b(yt) +

↵2
2

zT
t A0zt.

Substituting this bound along with kxtk = kstr

?k and ↵2  4kstr

?k2 into (6) with  = min gives

t A0zt.
Substituting in the bounds (11) and (12) concludes the proof for the case min < 0.

? )  fA0 b(yt)  fA0 b(str

fA b(xt)  fA b(str

? ) + 2str

?2 zT

2.5 Randomizing away the hard case
Krylov subspace solutions may fail to converge to global solution when both ? = min and
minb = 0  the so-called hard case [11  30]. Yet as with eigenvector methods [24  14]  simple
uT
randomization approaches allow us to handle the hard case with high probability  at the modest
cost of introducing to the error bounds a logarithmic dependence on d. Here we describe two such
approaches.
In the ﬁrst approach  we draw a spherically symmetric random vector v  and consider the joint
Krylov subspace

K2t(A {b  v}) := span{b  Ab  . . .   At1b  v  Av  . . .   At1v}.

The trust-region and cubic-regularized problems (1) can be solved efﬁciently in K2t(A {b  v}) using
the block Lanczos method [12  15]; we survey this technique in Section A.1 in the supplement. The
analysis in the previous section immediately implies the following convergence guarantee.
Corollary 2. Let v be uniformly distributed on the unit sphere in Rd  and

ˆstr
t 2

argmin

x2Kbt/2c(A {b v}) kxkR

fA b(x).

For any > 0 

fA b(ˆstr

t )  fA b(str

? ) 

(max  min)R2

(t  1)2

"16 + 2 · I{min<0} log2 2pd
 !#

(13)

2   d1

with probability at least 1   with respect to the random choice of v.
Proof. In the preceding proof of sublinear convergence  apply Lemma 2 on Kbt/2c(A  b)
and Lemma 3 on Kbt/2c(A  v);
the constructed solution is in Kbt/2c(A {b  v}). To bound
minv|2/kvk2  note that its distribution is Beta( 1
minv|2/kvk2  2/d with
|uT
probability greater than 1   (cf. [5  Lemma 4.6]).
Corollary 2 implies we can solve the trust-region problem to ✏ accuracy in roughly ✏1/2 log d
matrix-vector products  even in the hard case. The main drawback of this randomization approach
is that half the matrix-vector products are expended on the random vector; when the problem is
well-conditioned or when |uT
minb|/kbk is not extremely small  using the standard subspace solution
is nearly twice as fast.
The second approach follows the proposal [5] to construct a perturbed version of the linear term b 
denoted ˜b  and solve the problem instance (A  ˜b  R) in the Krylov subspace Kt(A  ˜b).
Corollary 3. Let v be uniformly distributed on the unit sphere in Rd  let > 0 and let

2 ) and therefore |uT

Let ˜str

t 2 argminx2Kt(A ˜b) kxkR fA ˜b(x) := 1
(max  min)R2
fA b(˜str

t )  fA b(str

? ) 

(t  1
2 )2

˜b = b +  · v.
"4 +

with probability at least 1   with respect to the random choice of v.

2 xT Ax + ˜bT x. For any > 0 

I{min<0}

2

log2 2k˜bkpd

 !# + 2R

(14)

6

min

See section C.2 in the supplement for a short proof  which consists of arguing that fA b and fA ˜b
˜b|. For
deviate by at most R at any feasible point  and applying a probabilistic lower bound on |uT
any desired accuracy ✏  using Corollary 3 with  = ✏/(4R) shows we can achieve this accuracy  with
constant probability  in a number of Lanczos iterations that scales as ✏1/2 log(d/✏2). Compared to
the ﬁrst approach  this rate of convergence is asymptotically slightly slower (by a factor of log 1
✏ ) 
and moreover requires us to decide on a desired level of accuracy in advance. However  the second
approach avoids the 2x slowdown that the ﬁrst approach exhibits on easier problem instances. In
Section 5 we compare the two approaches empirically.
We remark that the linear convergence guarantee (4) continues to hold for both randomization ap-
proaches. For the second approach  this is due to the fact that small perturbations to b do not
drastically change the condition number  as shown in [5]. However  this also means that we can-
not expect a good condition number when perturbing b in the hard case. Nevertheless  we believe
it is possible to show that  with randomization  Krylov subspace methods exhibit linear conver-
gence even in the hard case  where the condition number is replaced by the normalized eigen-gap
(max  min)/(2  min)  with 2 the smallest eigenvalue of A larger than min.
3 The cubic-regularized problem

We now consider the cubic-regularized problem

minimize

x2Rd

ˆfA b ⇢ (x) := fA b(x) +

⇢
3 kxk3 =

1
2

xT Ax + bT x +

⇢
3 kxk3 .

Any global minimizer of ˆfA b ⇢  denoted scr
? ) = (A + ⇢kscr

r ˆfA b ⇢(scr

?   admits the characterization [9  Theorem 3.1]
? k I) scr

? + b = 0 and ⇢kscr

? k  min.

(15)

Comparing this characterization to its counterpart (3) for the trust-region problem  we see that any
instance (A  b  ⇢) of cubic regularization has an equivalent trust-region instance (A  b  R)  with R =
? k. Theses instances are equivalent in that they have the same set of global minimizers. Evidently 
kscr
the equivalent trust-region instance has optimal Lagrange multiplier ? = ⇢kscr
? k. Moreover  at
?k)  the cubic-regularization
any trust-region feasible point x (satisfying kxk  R = kscr
optimality gap is smaller than its trust-region equivalent 
?k3  fA b(x)  fA b(str

? k = kstr
3kxk3  kstr
t denote the minimizer of ˆfA b ⇢ in Kt(A  b) and letting str

Letting scr
solution of the equivalent trust-region problem  we conclude that

? ) = fA b(x)  fA b(str

ˆfA b ⇢(x)  ˆfA b ⇢(scr

t denote the Krylov subspace

? ) +

? ).

⇢

ˆfA b ⇢(scr

t )  ˆfA b ⇢(scr

? )  ˆfA b ⇢(str

t )  ˆfA b ⇢(scr

? )  fA b(str

t )  fA b(str
? );

(16)

cubic regularization Krylov subspace solutions always have a smaller optimality gap than their trust-
region equivalents. The guarantees of Theorem 1 therefore apply to ˆfA b ⇢(scr
? ) as well 
and we arrive at the following
Corollary 4. For every t > 0 

t ) ˆfA b ⇢(scr

ˆfA b ⇢(scr

t )  ˆfA b ⇢(scr

and

? )i exp(4ts min + ⇢kscr
? k)  
? )  36h ˆfA b ⇢(0)  ˆfA b ⇢(scr
minb)2!# .
log2 4kbk2
"4 +

? k
max + ⇢kscr

? k2
(max  min)kscr

I{min<0}

? ) 

(uT

8

(t  1
2 )2

(17)

(18)

ˆfA b ⇢(scr

t )  ˆfA b ⇢(scr

Proof. Use the slightly stronger bound (10) derived in the proof of Theorem 1 with the inequality
18str
?

? k3] = 36[ ˆfA b ⇢(0)  ˆfA b ⇢(scr
? )].

?k2  36[ 1

? + 4? kstr

6 ⇢kscr

T A?str

? + 1

T Ascr

2 scr
?

7

Here too it is possible to randomly perturb b and obtain a guarantee for cubic regularization that
In [5] we carry out such analysis for gradient descent  and show that
applies in the hard case.
? k2 by at most 2/⇢ [5  Lemma 4.6]. Thus the
perturbations to b with norm  can increase kscr
? k2 + 2/⇢ in (14).
cubic-regularization equivalent of Corollary 3 amounts to replacing R2 with kscr
We note brieﬂy—without giving a full analysis—that Corollary 4 shows that the practically success-
ful Adaptive Regularization using Cubics (ARC) method [9] can ﬁnd ✏-stationary points in roughly
✏7/4 Hessian-vector product operations (with proper randomization and subproblem stopping cri-
teria). Researchers have given such guarantees for a number of algorithms that are mainly theoreti-
cal [1  8]  as well as variants of accelerated gradient descent [6  22]  which while more practical still
require careful parameter tuning. In contrast  ARC requires very little tuning and it is encouraging
that it may also exhibit the enhanced Hessian-vector product complexity ✏7/4  which is at least
near-optimal [7].

4 Lower bounds

We now show that the guarantees in Theorem 1 and Corollary 4 are tight up to numerical constants
for adversarially constructed problems. We state the result for the cubic-regularization problem;
corresponding lower bounds for the trust-region problem are immediate from the optimality gap
relation (16).1
To state the result  we require a bit more notation. Let L map cubic-regularization problem instances
of the form (A  b  ⇢) to the quadruple (min  max  ?  ) = L(A  b  ⇢) such that min  max are
the extremal eigenvalues of A and the solution scr
? k = ? 
and ˆfA b ⇢(0)  ˆfA b ⇢(scr
? ) = . Similarly let L0 map an instance (A  b  ⇢) to the quadruple
(min  max ⌧  R ) where now kscr
minb| = ⌧  with umin an eigenvector of A
corresponding to eigenvalue min.
With this notation in hand  we state our lower bounds. (See supplemental section D for a proof.)
Theorem 5. Let d  t 2 N with t < d and min  max  ?   be such that min  max  ? >
(min)+  and  > 0. There exists (A  b  ⇢) such that L(A  b  ⇢) = (min  max  ?  ) and for
all s 2K t(A  b) 

ˆfA b ⇢(x) satisﬁes ⇢kscr

? k = R and kbk /|uT

? = argminx

ˆfA b ⇢(s)  ˆfA b ⇢(scr

? ) >

1

Kh ˆfA b ⇢(0)  ˆfA b ⇢(scr

? )i exp⇢

4t

p  1  

. Alternatively  for any ⌧  1 and R > 0  there exists

?

3(?+min) and  = ?+max
?+min

where K = 1 +
(A  b  ⇢) such that L0(A  b  ⇢) = (min  max ⌧  R ) and for s 2K t(A  b) 
ˆfA b ⇢(s) ˆfA b ⇢(scr
and

? ) > min((max)  min 

max  min
16(t  1

2 )2 log2 kbk2

(uT

minb)2!) kscr
? k2
32

(19)

  (20)

(21)

ˆfA b ⇢(s)  ˆfA b ⇢(scr

? ) >

? k2
(max  min)kscr

.

16(t + 1

2 )2

The lower bounds (19) matches the linear convergence guarantee (17) to within a numerical constant 
as we may choose max  min and ? so that  is arbitrary and K < 2. Similarly  lower bounds (20)
and (21) match the sublinear convergence rate (18) for min < 0 and min  0 respectively. Our
proof ﬂows naturally from minimax characterizations of uniform polynomial approximations (Lem-
mas 4 and 5 in the supplement)  which also play a crucial role in proving our upper bounds.
One consequence of the lower bound (19) is the existence of extremely badly conditioned instances 
say with  = (100d)2 and K = 3/2  such that in the ﬁrst d 1 iterations it is impossible to decrease
the initial error by more than a factor of 2 (the initial error may be chosen arbitrarily large as well).
However  since these instances have ﬁnite condition number we have scr
? 2K d(A  b)  and so the
error supposedly drops to 0 at the dth iteration. This seeming discontinuity stems from the fact that
1To obtain the correct prefactor in the trust-region equivalent of lower bound (19) we may use the fact that

ˆfA b ⇢(0)  ˆfA b ⇢(scr

? ) = 1

2 bT A1

? b + ⇢

6 kscr

? k3  1

3 ( 1

2 bT A1

? b + ?

2 R2) = 1

3 (fA b(0)  fA b(str

? )).

8

(a)

(b)

Figure 1: Optimality gap of Krylov subspace solutions on random cubic-regularization problems 
versus subspace dimension t. (a) Columns show ensembles with different condition numbers   and
rows differ by scaling of t. Thin lines indicate results for individual instances  and bold lines indicate
ensemble median and maximum suboptimality. (b) Each line represents median suboptimality  and
shaded regions represent inter-quartile range. Different lines correspond to different randomization
settings.

in this case scr
? depends on the Lanczos basis of Kd(A  b) through a very badly conditioned linear
system and cannot be recovered with ﬁnite-precision arithmetic. Indeed  running Krylov subspace
methods for d iterations with inexact arithmetic often results in solutions that are very far from exact 
while guarantees of the form (17) are more robust to roundoff errors [4  13  35].
While we state the lower bounds in Theorem 5 for points in the Krylov subspace Kt(A  b)  a clas-
sical “resisting oracle” construction due to Nemirovski and Yudin [27  Chapter 7.2] (see also [26 
§10.2.3]) shows that (for d > 2t) these lower bounds hold also for any deterministic method that
accesses A only through matrix-vector products  and computes a single matrix-vector product per
iteration. The randomization we employ in Corollaries 2 and 3 breaks the lower bound (20) when
min < 0 and kbk /|uT
minb| is very large  so there is some substantial power from randomization in
this case. However  Simchowitz [34] recently showed that randomization cannot break the lower
bounds for convex quadratics (min  0 and ⇢ = 0).
5 Numerical experiments

? k)/(min + ⇢kscr

To see whether our analysis applies to non-worst case problem instances  we generate 5 000 ran-
dom cubic-regularization problems with d = 106 and controlled condition number  = (max +
? k) (see Section E in the supplement for more details). We repeat the ex-
⇢kscr
periment three times with different values of  and summarize the results in Figure 1a. As seen
in the ﬁgure  about 20 Lanczos iterations sufﬁce to solve even the worst-conditioned instances to
about 10% accuracy  and 100 iterations give accuracy better than 1%. Moreover  for t ' p  the
approximation error decays exponentially with precisely the rate 4/p predicted by our analysis 
for almost all the generated problems. For t ⌧ p  the error decays approximately as t2. We
conclude that the rates characterized by Theorem 1 are relevant beyond the worst case.
We conduct an additional experiment to test the effect of randomization for “hard case” instances 
where  = 1. We generate such problem instances (see details in Section E)  and compare the joint
subspace randomization scheme (Corollary 2) to the perturbation scheme (Corollary 3) with different
perturbation magnitudes ; the results are shown in Figure 1b. For any ﬁxed target accuracy  some
choices of  yield faster convergence than the joint subspace scheme. However  for any ﬁxed 
optimization eventually hits a noise ﬂoor due to the perturbation  while the joint subspace scheme
continues to improve. Choosing  requires striking a balance: if too large the noise ﬂoor is high
and might even be worse than no perturbation at all; if too small  escaping the unperturbed error
level will take too long  and the method might falsely declare convergence. A practical heuristic for
safely choosing  is an interesting topic for future research.

9

Acknowledgments

We thank the anonymous reviewers for several helpful questions and suggestions. Both authors were
supported by NSF-CAREER Award 1553086 and the Sloan Foundation. YC was partially supported
by the Stanford Graduate Fellowship.

References
[1] N. Agarwal  Z. Allen-Zhu  B. Bullins  E. Hazan  and T. Ma. Finding approximate local minima
faster than gradient descent. In Proceedings of the Forty-Ninth Annual ACM Symposium on
the Theory of Computing  2017.

[2] Z. Allen-Zhu and L. Orecchia. Linear coupling: An ultimate uniﬁcation of gradient and mirror
descent. In Proceedings of the 8th Innovations in Theoretical Computer Science  ITCS ’17 
2017.

[3] J. Blanchet  C. Cartis  M. Menickelly  and K. Scheinberg. Convergence rate analysis of a
stochastic trust region method for nonconvex optimization. arXiv:1609.07428 [math.OC] 
2016.

[4] A. S. Cameron Musco  Christopher Musco. Stability of the Lanczos method for matrix function

approximation. arXiv:1708.07788 [cs.DS]  2017.

[5] Y. Carmon and J. C. Duchi. Gradient descent efﬁciently ﬁnds the cubic-regularized non-convex

Newton step. arXiv:1612.00547 [math.OC]  2016.

[6] Y. Carmon  J. C. Duchi  O. Hinder  and A. Sidford. Convex until proven guilty: dimension-
In Proceedings of the 34th

free acceleration of gradient descent on non-convex functions.
International Conference on Machine Learning  2017.

[7] Y. Carmon  J. C. Duchi  O. Hinder  and A. Sidford. Lower bounds for ﬁnding stationary points

II: First order methods. arXiv:1711.00841 [math.OC]  2017.

[8] Y. Carmon  J. C. Duchi  O. Hinder  and A. Sidford. Accelerated methods for non-convex
optimization. SIAM Journal on Optimization  28(2):1751–1772  2018. URL https://arXiv.
org/abs/1611.00756.

[9] C. Cartis  N. I. M. Gould  and P. L. Toint. Adaptive cubic regularisation methods for uncon-
strained optimization. Part I: motivation  convergence and numerical results. Mathematical
Programming  Series A  127:245–295  2011.

[10] E. S. Coakley and V. Rokhlin. A fast divide-and-conquer algorithm for computing the spectra
of real symmetric tridiagonal matrices. Applied and Computational Harmonic Analysis  34(3):
379–414  2013.

[11] A. R. Conn  N. I. M. Gould  and P. L. Toint. Trust Region Methods. MPS-SIAM Series on

Optimization. SIAM  2000.

[12] J. Cullum and W. E. Donath. A block Lanczos algorithm for computing the q algebraically
largest eigenvalues and a corresponding eigenspace of large  sparse  real symmetric matrices.
In Decision and Control including the 13th Symposium on Adaptive Processes  1974 IEEE
Conference on  volume 13  pages 505–509. IEEE  1974.

[13] V. Druskin and L. Knizhnerman. Error bounds in the simple Lanczos procedure for computing
functions of symmetric matrices and eigenvalues. U.S.S.R. Computational Mathematics and
Mathematical Physics  31(7):970–983  1991.

[14] G. Golub and C. V. Loan. Matrix computations. John Hopkins University Press  1989.
[15] G. H. Golub and R. Underwood. The block Lanczos method for computing eigenvalues. In

Mathematical software  pages 361–377. Elsevier  1977.

[16] N. I. Gould  D. Orban  and P. L. Toint. GALAHAD  a library of thread-safe Fortran 90 pack-
ages for large-scale nonlinear optimization. ACM Transactions on Mathematical Software
(TOMS)  29(4):353–372  2003.

10

[17] N. I. M. Gould  S. Lucidi  M. Roma  and P. L. Toint. Solving the trust-region subproblem using

the Lanczos method. SIAM Journal on Optimization  9(2):504–525  1999.

[18] A. Griewank. The modiﬁcation of Newton’s method for unconstrained optimization by bound-

ing cubic terms. Technical report  Technical report NA/12  1981.

[19] E. Hazan and T. Koren. A linear-time algorithm for trust region problems. Mathematical

Programming  Series A  158(1):363–381  2016.

[20] M. Hestenes and E. Stiefel. Methods of conjugate gradients for solving linear systems. Journal

of Research of the National Bureau of Standards  49(6)  1952.

[21] N. Ho-Nguyen and F. Kılınc˛-Karzan. A second-order cone based approach for solving the

trust-region subproblem and its variants. arXiv:1603.03366 [math.OC]  2016.

[22] C. Jin  P. Netrapalli  and M. I. Jordan. Accelerated gradient descent escapes saddle points

faster than gradient descent. arXiv:1711.10456 [cs.LG]  2017.

[23] J. M. Kohler and A. Lucchi. Sub-sampled cubic regularization for non-convex optimization.

In Proceedings of the 34th International Conference on Machine Learning  2017.

[24] J. Kuczynski and H. Wozniakowski. Estimating the largest eigenvalue by the power and Lanc-
zos algorithms with a random start. SIAM Journal on Matrix Analysis and Applications  13(4):
1094–1122  1992.

[25] F. Lenders  C. Kirches  and A. Potschka.

trlib: A vector-free implementation of the GLTR
method for iterative solution of the trust region problem. Optimization Methods and Software 
33(3):420–449  2018.

[26] A. Nemirovski. Efﬁcient methods in convex programming. Technion: The Israel Institute of

Technology  1994.

[27] A. Nemirovski and D. Yudin. Problem Complexity and Method Efﬁciency in Optimization.

Wiley  1983.

[28] Y. Nesterov. Introductory Lectures on Convex Optimization. Kluwer Academic Publishers 

2004.

[29] Y. Nesterov and B. Polyak. Cubic regularization of Newton method and its global performance.

Mathematical Programming  Series A  108:177–205  2006.

[30] J. Nocedal and S. J. Wright. Numerical Optimization. Springer  2006.
[31] B. A. Pearlmutter. Fast exact multiplication by the Hessian. Neural computation  6(1):147–

160  1994.

[32] J. Regier  M. I. Jordan  and J. McAuliffe. Fast black-box variational inference through stochas-
tic trust-region optimization. In Advances in Neural Information Processing Systems 31  2017.
[33] N. N. Schraudolph. Fast curvature matrix-vector products for second-order gradient descent.

Neural computation  14(7):1723–1738  2002.

[34] M. Simchowitz. On the randomized complexity of minimizing a convex quadratic function.

arXiv:1807.09386 [cs.LG]  2018.

[35] L. N. Trefethen and D. Bau III. Numerical Linear Algebra. SIAM  1997.
[36] N. Tripuraneni  M. Stern  C. Jin  J. Regier  and M. I. Jordan. Stochastic cubic regularization

for fast nonconvex optimization. arXiv:1711.02838 [cs.LG]  2017.

[37] P. Tseng. On accelerated proximal gradient methods for convex-concave optimization. 2008.

URL http://www.mit.edu/~dimitrib/PTseng/papers/apgm.pdf.

[38] Z. Yao  P. Xu  F. Roosta-Khorasani  and M. W. Mahoney. Inexact non-convex newton-type

methods. arXiv:1802.06925 [math.OC]  2018.

[39] L.-H. Zhang  C. Shen  and R.-C. Li. On the generalized Lanczos trust-region method. SIAM

Journal on Optimization  27(3):2110–2142  2017.

11

,Yair Carmon
John Duchi