2016,Privacy Odometers and Filters: Pay-as-you-Go Composition,In this paper we initiate the study of adaptive composition in differential privacy when the length of the composition  and the privacy parameters themselves can be chosen adaptively  as a function of the outcome of previously run analyses. This case is much more delicate than the setting covered by existing composition theorems  in which the algorithms themselves can be chosen adaptively  but the privacy parameters must be fixed up front. Indeed  it isn't even clear how to define differential privacy in the adaptive parameter setting. We proceed by defining two objects which cover the two main use cases of composition theorems. A privacy filter is a stopping time rule that allows an analyst to halt a computation before his pre-specified privacy budget is exceeded. A privacy odometer allows the analyst to track realized privacy loss as he goes  without needing to pre-specify a privacy budget. We show that unlike the case in which privacy parameters are fixed  in the adaptive parameter setting  these two use cases are distinct. We show that there exist privacy filters with bounds comparable (up to constants) with existing privacy composition theorems. We also give a privacy odometer that nearly matches non-adaptive private composition theorems  but is sometimes worse by a small asymptotic factor. Moreover  we show that this is inherent  and that any valid privacy odometer in the adaptive parameter setting must lose this factor  which shows a formal separation between the filter and odometer use-cases.,Privacy Odometers and Filters: Pay-as-you-Go

Composition

Ryan Rogers∗

Aaron Roth†

Jonathan Ullman‡

Salil Vadhan§

Abstract

In this paper we initiate the study of adaptive composition in differential privacy
when the length of the composition  and the privacy parameters themselves can
be chosen adaptively  as a function of the outcome of previously run analyses.
This case is much more delicate than the setting covered by existing composition
theorems  in which the algorithms themselves can be chosen adaptively  but the
privacy parameters must be ﬁxed up front. Indeed  it isn’t even clear how to deﬁne
differential privacy in the adaptive parameter setting. We proceed by deﬁning two
objects which cover the two main use cases of composition theorems. A privacy
ﬁlter is a stopping time rule that allows an analyst to halt a computation before his
pre-speciﬁed privacy budget is exceeded. A privacy odometer allows the analyst
to track realized privacy loss as he goes  without needing to pre-specify a privacy
budget. We show that unlike the case in which privacy parameters are ﬁxed  in the
adaptive parameter setting  these two use cases are distinct. We show that there
exist privacy ﬁlters with bounds comparable (up to constants) with existing pri-
vacy composition theorems. We also give a privacy odometer that nearly matches
non-adaptive private composition theorems  but is sometimes worse by a small
asymptotic factor. Moreover  we show that this is inherent  and that any valid
privacy odometer in the adaptive parameter setting must lose this factor  which
shows a formal separation between the ﬁlter and odometer use-cases.

1

Introduction

Differential privacy [DMNS06] is a stability condition on a randomized algorithm  designed to guar-
antee individual-level privacy during data analysis. Informally  an algorithm is differentially private
if any pair of close inputs map to similar probability distributions over outputs  where similarity is
measured by two parameters ε and δ. Informally  ε measures the amount of privacy and δ measures
the failure probability that the privacy loss is much worse than ε. A signature property of differential
privacy is that it is preserved under composition—combining many differentially private subroutines
into a single algorithm preserves differential privacy and the privacy parameters degrade gracefully.
Composability is essential for both privacy and for algorithm design. Since differential privacy is
composable  we can design a sophisticated algorithm and prove it is private without having to rea-
∗Department of Applied Mathematics and Computational Science  University of Pennsylvania.
†Department

Pennsylvania.
Supported in part by an NSF CAREER award  NSF grant CNS-1513694 

ryrogers@sas.upenn.edu.

of

Computer

University

of

aaroth@cis.upenn.edu.
and a grant from the Sloan Foundation.

and

Information

Sciences 

‡College of Computer and Information Science  Northeastern University. jullman@ccs.neu.edu
§Center for Research on Computation & Society and John A. Paulson School of Engineering & Applied Sci-
ences  Harvard University. salil@seas.harvard.edu. Work done while visiting the Department of Applied
Mathematics and the Shing-Tung Yau Center at National Chiao-Tung University in Taiwan. Also supported by
NSF grant CNS-1237235  a grant from the Sloan Foundation  and a Simons Investigator Award.

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

son directly about its output distribution. Instead  we can rely on the differential privacy of the basic
building blocks and derive a privacy bound on the whole algorithm using the composition rules.
The composition theorem for differential privacy is very strong  and holds even if the choice of
which differentially private subroutine to run is adaptive—that is  the choice of the next algorithm
may depend on the output of previous algorithms. This property is essential in algorithm design 
but also more generally in modeling unstructured sequences of data analyses that might be run
by a human data analyst  or even by many data analysts on the same data set  while only loosely
coordinating with one another. Even setting aside privacy  it can be very challenging to analyze
the statistical properties of general adaptive procedures for analyzing a dataset  and the fact that
adaptively chosen differentially private algorithms compose has recently been used to give strong
guarantees of statistical validity for adaptive data analysis [DFH+15  BNS+16].
However  all the known composition theorems for differential privacy [DMNS06  DKM+06 
DRV10  KOV15  MV16] have an important and generally overlooked caveat. Although the choice
of the next subroutine in the composition may be adaptive  the number of subroutines called and
choice of the privacy parameters ε and δ for each subroutine must be ﬁxed in advance. Indeed  it is
not even clear how to deﬁne differential privacy if the privacy parameters are not ﬁxed in advance.
This is generally acceptable when designing a single algorithm (that has a worst-case analysis) 
since worst-case eventualities need to be anticipated and budgeted for in order to prove a theorem.
However  it is not acceptable when modeling the unstructured adaptivity of a data analyst  who may
not know ahead of time (before seeing the results of intermediate analyses) what he wants to do with
the data. When controlling privacy loss across multiple data analysts  the problem is even worse.
As a simple stylized example  suppose that A is some algorithm (possibly modeling a human data
analyst) for selecting statistical queries5 as a function of the answers to previously selected queries.
It is known that for any one statistical query q and any data set x  releasing the perturbed answer
ˆa = q(x)+Z where Z ∼ Lap(1/ε) is a Laplace random variable  ensures (ε  0)-differential privacy.
Composition theorems allow us to reason about the composition of k such operations  where the
queries can be chosen adaptively by A  as in the following simple program.
Example1(x):

For i = 1 to k: Let qi = A(ˆa1  . . .   ˆai−1) and let ˆai = qi(x) + Lap(1/ε).
Output (ˆa1  . . .   ˆak).

The “basic” composition theorem [DMNS06] asserts that Example1 is (εk  0)-differentially private.
The “advanced” composition theorem [DRV10] gives a more sophisticated bound and asserts that

(provided that ε is sufﬁciently small)  the algorithm satisﬁes (ε(cid:112)8k ln(1/δ)  δ)-differential privacy

for any δ > 0. There is even an “optimal” composition theorem [KOV15] too complicated to de-
scribe here. These analyses crucially assume that both the number of iterations k and the parameter
ε are ﬁxed up front  even though it allows for the queries qi to be adaptively chosen.6
Now consider a similar example where the number of iterations is not ﬁxed up front  but actually
depends on the answers to previous queries. This is a special case of a more general setting where the
privacy parameter εi in every round may be chosen adaptively—halting in our example is equivalent
to setting εi = 0 in all future rounds.
Example2(x  τ ):

Let i ← 1  ˆa1 ← q1(x) + Lap(1/ε).
While ˆai ≤ τ: Let i ← i + 1  qi = A(ˆa1  . . .   ˆai−1)  and let ˆai = qi(x) + Lap(1/ε).
Output (ˆa1  . . .   ˆai).

Example2 cannot be said to be differentially private ex ante for any non-trivial ﬁxed values of ε and δ 
because the computation might run for an arbitrarily long time and privacy may degrade indeﬁnitely.
What can we say about privacy after we run the algorithm? If the algorithm/data-analyst happens to
stop after k rounds  can we apply the composition theorem ex post to conclude that it is (εk  0)- and

5A statistical query is parameterized by a predicate φ  and asks “how many elements of the dataset satisfy

φ?” Changing a single element of the dataset can change the answer to the statistical query by at most 1.

they are all ﬁxed in advance. For basic composition εk is replaced with(cid:80)k

6The same analysis holds for hetereogeneous parameters (ε1  . . .   εk) are used in each round as long as
i=1 εi and for advanced composition

√
k is replaced with

ε

(cid:113)(cid:80)k

i .
i=1 ε2

2

(ε(cid:112)8k log(1/δ)  δ)-differentially private  as we could if the algorithm were constrained to always

run for at most k rounds?
In this paper  we study the composition properties of differential privacy when everything—the
choice of algorithms  the number of rounds  and the privacy parameters in each round—may be
adaptively chosen. We show that this setting is much more delicate than the settings covered by
previously known composition theorems  but that these sorts of ex post privacy bounds do hold
with only a small (but in some cases unavoidable) loss over the standard setting. We note that the
conceptual discussion of differential privacy focuses a lot on the idea of arbitrary composition and
our results give more support for this conceptual interpretation.

1.1 Our Results

We give a formal framework for reasoning about the adaptive composition of differentially private
algorithms when the privacy parameters themselves can be chosen adaptively. When the parameters
are chosen non-adaptively  a composition theorem gives a high probability bound on the worst case
privacy loss that results from the output of an algorithm. In the adaptive parameter setting  it no
longer makes sense to have ﬁxed bounds on the privacy loss. Instead  we propose two kinds of
primitives capturing two natural use cases for composition theorems:

1. A privacy odometer takes as input a global failure parameter δg. After every round i in the
composition of differentially private algorithms  the odometer outputs a number τi that may
depend on the realized privacy parameters εi  δi in the previous rounds. The privacy odometer
guarantees that with probability 1 − δg  for every round i  τi is an upper bound on the privacy
loss in round i.

2. A privacy ﬁlter is a way to cut off access to the dataset when the privacy loss is too large. It
takes as input a global privacy “budget” (εg  δg). After every round  it either outputs CONT (“con-
tinue”) or HALT depending on the privacy parameters from the previous rounds. The privacy ﬁlter
guarantees that with probability 1 − δg  it will output HALT before the privacy loss exceeds εg.
When used  it guarantees that the resulting interaction is (εg  δg)-DP.

A tempting heuristic is to take the realized privacy parameters ε1  δ1  . . .   εi  δi and apply one of the
existing composition theorems to those parameters  using that value as a privacy odometer or im-
plementing a privacy ﬁlter by halting when getting a value that exceeds the global budget. However
this heuristic does not necessarily give valid bounds.
We ﬁrst prove that the heuristic does work for the basic composition theorem [DMNS06] in which
the parameters εi and δi add up. We prove that summing the realized privacy parameters yields both
a valid privacy odometer and ﬁlter. The idea of a privacy ﬁlter was also considered in [ES15]  who
show that basic composition works in the privacy ﬁlter application.
We then show that the heuristic breaks for the advanced composition theorem [DRV10]. However 
we give a valid privacy ﬁlter that gives the same asymptotic bound as the advanced composition
theorem  albeit with worse constants. On the other hand  we show that  in some parameter regimes 
the asymptotic bounds given by our privacy ﬁlter cannot be achieved by a privacy odometer. This
result gives a formal separation between the two models when the parameters may be chosen adap-
tively  which does not exist when the privacy parameters are ﬁxed. Finally  we give a valid privacy
odometer with a bound that is only slightly worse asymptotically than the bound that the advanced
composition theorem would give if it were used (improperly) as a heuristic. Our bound is worse

by a factor that is never larger than(cid:112)log log(n) (here  n is the size of the dataset) and for some

parameter regimes is only a constant.

2 Privacy Preliminaries

Differential privacy is deﬁned based on the following notion of similarity between two distributions.
Deﬁnition 2.1 (Indistinguishable). Two random variables X and Y taking values from domain
D are (ε  δ)-indistinguishable  denoted as X ≈ε δ Y   if ∀S ⊆ D  P [X ∈ S] ≤ eεP [Y ∈ S] +
δ and P [Y ∈ S] ≤ eεP [X ∈ S] + δ.

3

eεε

There is a slight variant of indistinguishability  called point-wise indistinguishability  which is nearly
equivalent  but will be the more convenient notion for the generalizations we give in this paper.
Deﬁnition 2.2 (Point-wise Indistinguishable). Two random variables X and Y taking values from
D are (ε  δ)-point-wise indistinguishable if with probability at least 1 − δ over either a ∼ X or
a ∼ Y   we have
Lemma 2.3 ([KS14]). Let X and Y be two random variables taking values from D. If X and
Y are (ε  δ)-point-wise indistinguishable  then X ≈ε δ Y . Also  if X ≈ε δ Y then X and Y are

(cid:17)(cid:12)(cid:12)(cid:12) ≤ ε.
(cid:1)-point-wise indistinguishable.

(cid:16) P[X=a]

(cid:0)2ε  2δ

(cid:12)(cid:12)(cid:12)log

P[Y =a]

(cid:17)

(cid:16) P[M(x)=a]

We say two databases x  x(cid:48) ∈ X n are neighboring if they differ in at most one entry  i.e. if there
exists an index i ∈ [n] such that x−i = x(cid:48)
−i. We can now state differential privacy in terms of
indistinguishability.
Deﬁnition 2.4 (Differential Privacy [DMNS06]). A randomized algorithm M : X n → Y with
arbitrary output range Y is (ε  δ)-differentially private (DP) if for every pair of neighboring databases
x  x(cid:48): M(x) ≈ε δ M(x(cid:48)).
We then deﬁne the privacy loss LossM(a; x  x(cid:48)) for outcome a ∈ Y and neighboring datasets
x  x(cid:48) ∈ X n as LossM(a; x  x(cid:48)) = log
if we can bound
LossM(a; x  x(cid:48)) for any neighboring datasets x  x(cid:48) with high probability over a ∼ M(x)  then
Theorem 2.3 tells us that M is differentially private. Moreover  Theorem 2.3 also implies that
this approach is without loss of generality (up to a small difference in the parameters). Thus  our
composition theorems will focus on bounding the privacy loss with high probability.
A useful property of differential privacy is that it is preserved under post-processing without degrad-
ing the parameters:
Theorem 2.5 (Post-Processing [DMNS06]). Let M : X n → Y be (ε  δ)-DP and f : Y → Y(cid:48) be
any randomized algorithm. Then f ◦ M : X n → Y(cid:48) is (ε  δ)-DP.
We next recall a useful characterization from [KOV15]: any DP algorithm can be written as the
post-processing of a simple  canonical algorithm which is a generalization of randomized response.
Deﬁnition 2.6. For any ε  δ ≥ 0  we deﬁne the randomized response algorithm RRε δ : {0  1} →
{0 (cid:62) ⊥  1} as the following (Note that if δ = 0  we will simply write the algorithm RRε δ as RRε.)

. We note that

P[M(x(cid:48))=a]

P [RRε δ(0) = 0] = δ
P [RRε δ(0) = (cid:62)] = (1 − δ) eε
P [RRε δ(0) = ⊥] = (1 − δ)
P [RRε δ(0) = 1] = 0

1

1+eε

1+eε

P [RRε δ(1) = 0] = 0
P [RRε δ(1) = (cid:62)] = (1 − δ)
P [RRε δ(1) = ⊥] = (1 − δ) eε
P [RRε δ(1) = 1] = δ

1

1+eε

1+eε

Kairouz  Oh  and Viswanath [KOV15] show that any (ε  δ)–DP algorithm can be viewed as a post-
processing of the output of RRε δ for an appropriately chosen input.
Theorem 2.7 ([KOV15]  see also [MV16]). For every (ε  δ)-DP algorithm M and for all neighbor-
ing databases x0 and x1  there exists a randomized algorithm T where T (RRε δ(b)) is identically
distributed to M(xb) for b ∈ {0  1}.
This theorem will be useful in our analyses  because it allows us to without loss of generality analyze
compositions of these simple algorithms RRε δ with varying privacy parameters.
We now deﬁne the adaptive composition of differentially private algorithms in the setting introduced
by [DRV10] and then extended to heterogenous privacy parameters in [MV16]  in which all of the
privacy parameters are ﬁxed prior to the start of the computation. The following “composition
game” is an abstract model of composition in which an adversary can adaptively select between
neighboring datasets at each round  as well as a differentially private algorithm to run at each round
– both choices can be a function of the realized outcomes of all previous rounds. However  crucially 
the adversary must select at each round an algorithm that satisﬁes the privacy parameters which
have been ﬁxed ahead of time – the choice of parameters cannot itself be a function of the realized
outcomes of previous rounds. We deﬁne this model of interaction formally in Algorithm 1 where
the output is the view of the adversary A which includes any random coins she uses RA and the
outcomes A1 ···   Ak of every round.

4

Algorithm 1 FixedParamComp(A E = (E1 ···  Ek)  b)  where A is a randomized algorithm 
E1 ···  Ek are classes of randomized algorithms  and b ∈ {0  1}.

Select coin tosses RbA for A uniformly at random.
for i = 1 ···   k do
A = A(RbA  Ab
A receives Ab

1 ···   Ab
i = Mi(xi b)
return view V b = (RbA  Ab

i−1) gives neighboring datasets xi 0  xi 1  and Mi ∈ Ei
1 ···   Ab
k)

Deﬁnition 2.8 (Adaptive Composition [DRV10]  [MV16]). We say that the sequence of parameters
ε1 ···   εk ≥ 0  δ1 ···   δk ∈ [0  1) satisﬁes (εg  δg)-differential privacy under adaptive composition
if for every adversary A  and E = (E1 ···  Ek) where Ei is the class of (εi  δi)-DP algorithms  we
have FixedParamComp(A E ·) is (εg  δg)-DP in its last argument  i.e. V 0 ≈εg δg V 1.
We ﬁrst state a basic composition theorem which shows that the adaptive composition satisﬁes dif-
ferential privacy where “the parameters just add up.”
Theorem 2.9 (Basic Composition [DMNS06]  [DKM+06]). The sequence ε1 ···   εk and δ1 ··· δk
i=1 εi  and δg =

satisﬁes (εg  δg)-differential privacy under adaptive composition where εg = (cid:80)k
(cid:80)k

i=1 δi.

We now state the advanced composition bound from [DRV10] which gives a quadratic improvement
to the basic composition bound.
Theorem 2.10 (Advanced Composition). For any ˆδ > 0  the sequence ε1 ···   εk and δ1 ··· δk
where ε = εi and δ = δi for all i ∈ [k] satisﬁes (εg  δg)-differential privacy under adaptive
composition where εg = ε (eε − 1) k + ε

2k log(1/ˆδ)  and δg = kδ + ˆδ.

(cid:113)

This theorem can be easily generalized to hold for values of εi that are not all equal (as done in
[KOV15]). However  this is not as all-encompassing as it would appear at ﬁrst blush  because this
straightforward generalization would not allow for the values of εi and δi to be chosen adaptively by
the data analyst. Indeed the deﬁnition of differential privacy itself (Deﬁnition 2.4) does not straight-
forwardly extend to this case. The remainder of this paper is devoted to laying out a framework for
sensibly talking about the privacy parameters εi and δi being chosen adaptively by the data analyst 
and to prove composition theorems (including an analogue of Theorem 2.10) in this model.

3 Composition with Adaptively Chosen Parameters

We now introduce the model of composition with adaptive parameter selection  and deﬁne privacy
in this setting.
We want to model composition as in the previous section  but allow the adversary the ability to also
choose the privacy parameters (εi  δi) as a function of previous rounds of interaction. We will deﬁne
the view of the interaction  similar to the view in FixedParamComp  to be the tuple that includes A’s
random coin tosses RA and the outcomes A = (A1 ···   Ak) of the algorithms she chose. Formally 
we deﬁne an adaptively chosen privacy parameter composition game in Algorithm 2 which takes as
input an adversary A  a number of rounds of interaction k 7 and an experiment parameter b ∈ {0  1}.

We then deﬁne the privacy loss with respect to AdaptParamComp(A  k  b) in the following way
for a ﬁxed view v = (r  a) where r represents the random coin tosses of A and we write v<i =

7Note that in the adaptive parameter composition game  the adversary has the option of effectively stopping
the composition early at some round k(cid:48) < k by simply setting εi = δi = 0 for all rounds i > k(cid:48). Hence  the
parameter k will not appear in our composition theorems the way it does when privacy parameters are ﬁxed.
This means that we can effectively take k to be inﬁnite. For technical reasons  it is simpler to have a ﬁnite
parameter k  but the reader should imagine it as being an enormous number.

5

i−1) gives neighboring xi 0  xi 1  parameters (εi  δi)  Mi that is

Algorithm 2 AdaptParamComp(A  k  b)

Select coin tosses RbA for A uniformly at random.
for i = 1 ···   k do
A = A(RbA  Ab
(εi  δi)-DP
A receives Ab

1 ···   Ab
i = Mi(xi b)
return view V b = (RbA  Ab

1 ···   Ab
k)
(cid:33)
k(cid:88)

=

i=1

(r  a1 ···   ai−1):

Loss(v) = log

(cid:32)P(cid:2)V 0 = v(cid:3)

P [V 1 = v]

(cid:32)P(cid:2)Mi(xi 0) = vi|v<i

P [Mi(xi 1) = vi|v<i]

(cid:33)

(cid:3)

log

k(cid:88)

i=1

def
=

Lossi(v≤i).

(1)

Note that the privacy parameters (εi  δi) depend on the previous outcomes that A receives. We will
frequently shorten our notation εt = εt(v<t) and δt = δt(v<t) when the outcome is understood.
It no longer makes sense to claim that the privacy loss of the adaptive parameter composition ex-
periment is bounded by any ﬁxed constant  because the privacy parameters (with which we would
presumably want to use to bound the privacy loss) are themselves random variables. Instead  we
deﬁne two objects which can be used by a data analyst to control the privacy loss of an adaptive
composition of algorithms.
The ﬁrst object  which we call a privacy odometer will be parameterized by one global parameter
δg and will provide a running real valued output that will  with probability 1 − δg  upper bound the
privacy loss at each round of any adaptive composition in terms of the realized values of εi and δi
selected at each round.
Deﬁnition 3.1 (Privacy Odometer). A function COMPδg : R2k≥0 → R ∪ {∞} is a valid privacy
odometer if for all adversaries in AdaptParamComp(A  k  b)  with probability at most δg over v ∼
V 0: |Loss(v)| > COMPδg (ε1  δ1 ···   εk  δk) .
The second object  which we call a privacy ﬁlter  is a stopping time rule. It takes two global parame-
ters (εg  δg) and will at each round either output CONT or HALT. Its guarantee is that with probability
1 − δg  it will output HALT if the privacy loss has exceeded εg.
: R2k≥0 → {HALT  CONT} is a valid
Deﬁnition 3.2 (Privacy Filter). A function COMPεg δg
privacy ﬁlter for εg  δg ≥ 0 if for all adversaries A in AdaptParamComp(A  k  b) 
the fol-
|Loss(v)| >
lowing “bad event” occurs with probability at most δg when v ∼ V 0:
εg

COMPεg δg (ε1  δ1 ···   εk  δk) = CONT.

and

the usage of these objects.

We note two things about
First  a valid privacy odometer
can be used to provide a running upper bound on the privacy loss at each intermediate
the privacy loss at round k(cid:48) < k must with high probability be upper bounded by
round:
COMPδg (ε1  δ1  . . .   εk(cid:48)  δk(cid:48)  0  0  . . .   0  0) – i.e.
the bound that results by setting all future pri-
vacy parameters to 0. This is because setting all future privacy parameters to zero is equiv-
alent to stopping the computation at round k(cid:48)  and is a feasible choice for the adaptive ad-
versary A. Second  a privacy ﬁlter can be used to guarantee that with high probability  the
stated privacy budget εg is never exceeded – the data analyst at each round k(cid:48) simply queries
COMPεg δg (ε1  δ1  . . .   εk(cid:48)  δk(cid:48)  0  0  . . .   0  0) before she runs algorithm k(cid:48)  and runs it only if the
ﬁlter returns CONT. Again  this is guaranteed because the continuation is a feasible choice of the
adversary  and the guarantees of both a ﬁlter and an odometer are quantiﬁed over all adversaries.
We ﬁrst give an adaptive parameter version of the basic composition in Theorem 2.9. See the full
version for the proof.
Theorem 3.3. For each nonnegative δg  COMPδg

COMPδg (ε1  δ1 ···   εk  δk) = ∞ if (cid:80)k
(cid:80)k
COMPεg δg (ε1  δ1 ···   εk  δk) = HALT if (cid:80)k

i=1 εi. Additionally 

for any εg  δg ≥ 0  COMPεg δg

is a valid privacy odometer where
i=1 δi > δg and otherwise COMPδg (ε1  δ1 ···   εk  δk) =
is a valid privacy ﬁlter where
i=1 εi > εg and CONT otherwise.

t=1 δt > δg or (cid:80)k

6

4 Concentration Preliminaries

We give a useful concentration bound that will be pivotal in proving an improved valid privacy
odometer and ﬁlter from that given in Theorem 3.3. To set this up  we present some notation: let
(Ω F  P) be a probability triple where ∅ = F0 ⊆ F1 ⊆ ··· ⊆ F is an increasing sequence of
σ-algebras. Let Xi be a real-valued Fi-measurable random variable  such that E [Xi|Fi−1] = 0 a.s.
∀k ≥ 1. We
for each i. We then consider the martingale where M0 = 0
use results from [dlPKLL04] and [vdG02] to prove the following (see supplementary ﬁle).
Theorem 4.1. For Mk given above  if there exists two random variables Ci < Di which are Fi−1
measurable for i ≥ 1 such that Ci ≤ Xi ≤ Di almost surely ∀i ≥ 1. and we deﬁne U 2
0 = 0 
i=1 (Di − Ci)2  ∀k ≥ 1  then for any ﬁxed k ≥ 1  β > 0 and δ ≤ 1/e  we have
and U 2
P
4 + β

k = (cid:80)k
(cid:114)(cid:16) U 2

and Mk =(cid:80)k

(cid:16) U 2

|Mk| ≥

(cid:17)(cid:16)

(cid:17)(cid:17)

i=1 Xi 

4β + 1

log(1/δ)

≤ δ.

2 + log

(cid:20)

(cid:21)

k

k

We will use this martingale inequality in our analysis for deriving composition bounds for both
privacy ﬁlters and odometers. The martingale we form will be the sum of the privacy loss from
a sequence of randomized response algorithms from Deﬁnition 2.6. Note that for pure-differential
privacy (where δi = 0) the privacy loss at round i is then ±εi  which are ﬁxed given the previous
outcomes. See the supplementary ﬁle for the case when δi > 0 at each round i.
We then use the result from Theorem 2.7 to conclude that every differentially private algorithm is
a post processing function of randomized response. Thus determining a high probability bound on
the martingale formed from the sum of the privacy losses of a sequence of randomized response
algorithms sufﬁces for computing a valid privacy ﬁlter or odometer.

5 Advanced Composition for Privacy Filters

j=1

ε2
g

(cid:118)(cid:117)(cid:117)(cid:116)2

εj (eεj − 1) /2

i=1 δi > δg/2 or if εg is smaller than

We next show that we can essentially get the same asymptotic bound as Theorem 2.10 for the privacy
ﬁlter setting using the bound in Theorem 4.1 for the martingale based on the sum of privacy losses
COMPεg δg (ε1  δ1 ···   εk  δk) = HALT if(cid:80)k
from a sequence of randomized response algorithms (see the supplementary ﬁle for more details).
Theorem 5.1. COMPεg δg is a valid privacy ﬁlter for δg ∈ (0  1/e) and εg > 0 where
k(cid:88)
(cid:33)(cid:32)

(cid:32) k(cid:88)
Note that if we have(cid:80)k
bound on the privacy loss of ε(cid:112)8k log(1/δg). Note that there may be better choices for the constant
g by in (2)  but for the case when εg = ε(cid:112)8k log(1/δg) and εi = ε for every

in (2) 
we are then getting the same asymptotic bound on the privacy loss as in [KOV15] and in Theo-
rem 2.10 for the case when εi = ε for i ∈ [k]. If kε2 ≤
8 log(1/δg)  then Theorem 2.10 gives a

and otherwise COMPεg δg (ε1  δ1 ···   εk  δk) = CONT.

log(1/δg)(cid:80)k

i = O (1/ log(1/δg)) and set εg = Θ

(cid:18)(cid:113)(cid:80)k

(cid:33)(cid:33)

i log(1/δg)

log(2/δg)

log(1/δg)

i=1 ε2

i=1 ε2
i

i=1 ε2

(cid:32)

1 +

log

1
2

(cid:19)

+

ε2
i +

i=1

ε2
g

1

+ 1

(2)

28.04 that we divide ε2
i ∈ [n]  it is nearly optimal.

6 Advanced Composition for Privacy Odometers

One might hope to achieve the same sort of bound on the privacy loss from Theorem 2.10 when
the privacy parameters may be chosen adversarially. However we show that this cannot be the
case for any valid privacy odometer. In particular  even if an adversary selects the same privacy

parameter ε = o((cid:112)log(log(n)/δg)/k) each round but can adaptively select a time to stop interacting

7

(cid:19)

with AdaptParamComp (which is a restricted special case of the power of the general adversary –
stopping is equivalent to setting all future εi  δi = 0)  then we show that there can be no valid

privacy odometer achieving a bound of o(ε(cid:112)k log (log(n)/δg)). This gives a separation between

the achievable bounds for a valid privacy odometers and ﬁlters. But for privacy applications  it is
worth noting that δg is typically set to be (much) smaller than 1/n  in which case this gap disappears
(since log(log(n)/δg) = (1 + o(1)) log(1/δg) ). We prove the following with an anti-concentration
bound for random walks from [LT91] (see full version).
Theorem 6.1. For any δg ∈ (0  O(1)) there is no valid COMPδg privacy odometer where

(cid:16) eεi−1

(cid:18)(cid:113)(cid:80)k
COMPδg (ε1  0 ···   εk  0) =(cid:80)k
that the bound incurs an additive 1/n2 loss to the(cid:80)

i=1 εi

(cid:17)

eεi +1

+ o

i ε2

We now give our main positive result for privacy odometers  which is similar to our privacy ﬁlter
in Theorem 5.1 except that δg is replaced by δg/ log(n)  as is necessary from Theorem 6.1. Note
i term that is present without privacy. In
any reasonable setting of parameters  this translates to at most a constant-factor multiplicative loss 
because there is no utility running any differentially private algorithm with εi < 1
10n (we know
that if A is (εi  0)-DP then A(x) and A(x(cid:48)) for neighboring inputs have statistical distance at most
eεin − 1 < 0.1  and hence the output is essentially independent of the input - note that a similar
statement holds for (εi  δi)-DP.) The proof of the following result uses Theorem 4.1 along with a
i ∈ [1/n2  1]. See
the full version for the complete proof.
Theorem 6.2 (Advanced Privacy Odometer). COMPδg is a valid privacy odometer for δg ∈ (0  1/e)
i ∈ [1/n2  1] then

union bound over log(n2) choices for β  which are discretized values for(cid:80)k
where COMPδg (ε1  δ1 ···   εk  δk) = ∞ if(cid:80)k
i=1 δi > δg/2  otherwise if(cid:80)k
(cid:19)
(cid:18) eεi − 1
(cid:16)√

(cid:17)(cid:17)

i=1 ε2

i=1 ε2

(cid:16)

k(cid:88)

i=1 ε2

i log(log(n)/δg)

(cid:118)(cid:117)(cid:117)(cid:116) k(cid:88)
(cid:32)

i=1

1
2

εi

i=1

2

+ 2

ε2
i

1 + log

3

log(4 log2(n)/δg).

(3)

COMPδg (ε1  δ1 ···   εk  δk) =
(cid:32)

and if(cid:80)k
k(cid:88)

(cid:18) eεi − 1

i=1 ε2

(cid:118)(cid:117)(cid:117)(cid:116)2

+

εi

i=1

2

i /∈ [1/n2  1] then COMPδg (ε1  δ1 ···   εk  δk) is equal to
(cid:19)
k(cid:88)

(cid:33)(cid:32)

k(cid:88)

1 +

log

1 + n2

(cid:33)(cid:33)

1/n2 +

ε2
i

i=1

ε2
i

log(4 log2(n))/δg).

i=1

(4)

Acknowledgements

The authors are grateful Jack Murtagh for his collaboration in the early stages of this work  and for
sharing his preliminary results with us. We thank Andreas Haeberlen  Benjamin Pierce  and Daniel
Winograd-Cort for helpful discussions about composition. We further thank Daniel Winograd-Cort
for catching an incorrectly set constant in an earlier version of Theorem 5.1.

8

References

[BNS+16] Raef Bassily  Kobbi Nissim  Adam D. Smith  Thomas Steinke  Uri Stemmer  and
In Proceedings

Jonathan Ullman. Algorithmic stability for adaptive data analysis.
of the 48th Annual ACM on Symposium on Theory of Computing  STOC  2016.

[DFH+15] Cynthia Dwork  Vitaly Feldman  Moritz Hardt  Toniann Pitassi  Omer Reingold  and
Aaron Leon Roth. Preserving statistical validity in adaptive data analysis. In Proceed-
ings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing  pages
117–126. ACM  2015.

[DKM+06] Cynthia Dwork  Krishnaram Kenthapadi  Frank McSherry  Ilya Mironov  and Moni
Naor. Our data  ourselves: Privacy via distributed noise generation. In Advances in
Cryptology-EUROCRYPT 2006  pages 486–503. Springer  2006.

[dlPKLL04] Victor H. de la Pea  Michael J. Klass  and Tze Leung Lai. Self-normalized processes:
exponential inequalities  moment bounds and iterated logarithm laws. Ann. Probab. 
32(3):1902–1933  07 2004.

[DMNS06] Cynthia Dwork  Frank McSherry  Kobbi Nissim  and Adam Smith. Calibrating noise

to sensitivity in private data analysis. In TCC ’06  pages 265–284  2006.

[DRV10] Cynthia Dwork  Guy N. Rothblum  and Salil P. Vadhan. Boosting and differential
privacy. In 51th Annual IEEE Symposium on Foundations of Computer Science  FOCS
2010  October 23-26  2010  Las Vegas  Nevada  USA  pages 51–60  2010.

[ES15] Hamid Ebadi and David Sands. Featherweight PINQ. CoRR  abs/1505.02642  2015.
[KOV15] Peter Kairouz  Sewoong Oh  and Pramod Viswanath. The composition theorem for
differential privacy. In Proceedings of the 32nd International Conference on Machine
Learning  ICML 2015  Lille  France  6-11 July 2015  pages 1376–1385  2015.

[KS14] S.P. Kasiviswanathan and A. Smith. On the ‘Semantics’ of Differential Privacy: A
Bayesian Formulation. Journal of Privacy and Conﬁdentiality  Vol. 6: Iss. 1  Article
1  2014.

[LT91] M. Ledoux and M. Talagrand. Probability in Banach Spaces: Isoperimetry and Pro-

cesses. A Series of Modern Surveys in Mathematics Series. Springer  1991.

[MV16] Jack Murtagh and Salil P. Vadhan. The complexity of computing the optimal compo-
sition of differential privacy. In Theory of Cryptography - 13th International Confer-
ence  TCC 2016-A  Tel Aviv  Israel  January 10-13  2016  Proceedings  Part I  pages
157–175  2016.

[vdG02] Sara A van de Geer. On Hoeffding’s inequality for dependent random variables.

Springer  2002.

9

,Xiaoxiao Guo
Satinder Singh
Richard Lewis
Ryan Rogers
Aaron Roth
Jonathan Ullman
Salil Vadhan