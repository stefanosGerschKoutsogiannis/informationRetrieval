2019,Identification of Conditional Causal Effects under Markov Equivalence,Causal identification is the problem of deciding whether a post-interventional distribution is computable from a combination of qualitative knowledge about the data-generating process  which is encoded in a causal diagram  and an observational distribution. A generalization of this problem restricts the qualitative knowledge to a class of Markov equivalent causal diagrams  which  unlike a single  fully-specified causal diagram  can be inferred from the observational distribution.
Recent work by (Jaber et al.  2019a) devised a complete algorithm for the identification of unconditional causal effects given a Markov equivalence class of causal diagrams. However  there are identifiable conditional causal effects that cannot be handled by that algorithm. In this work  we derive an algorithm to identify conditional effects  which are particularly useful for evaluating conditional plans or policies.,Identiﬁcation of Conditional Causal Effects

under Markov Equivalence

Amin Jaber

Purdue University

jaber0@purdue.edu

Jiji Zhang

Lingnan University

jijizhang@ln.edu.hk

Elias Bareinboim
Columbia University
eb@cs.columbia.edu

Abstract

Causal identiﬁcation is the problem of deciding whether a post-interventional
distribution is computable from a combination of qualitative knowledge about the
data-generating process  which is encoded in a causal diagram  and an observational
distribution. A generalization of this problem restricts the qualitative knowledge to
a class of Markov equivalent causal diagrams  which  unlike a single  fully-speciﬁed
causal diagram  can be inferred from the observational distribution. Recent work
by (Jaber et al.  2019a) devised a complete algorithm for the identiﬁcation of
unconditional causal effects given a Markov equivalence class of causal diagrams.
However  there are identiﬁable conditional causal effects that cannot be handled by
that algorithm. In this work  we derive an algorithm to identify conditional effects 
which are particularly useful for evaluating conditional plans or policies.

1

Introduction

The graphical approach to causal inference is becoming an important tool for assessing the efﬁcacy
of actions or policies (Pearl  2000; Bareinboim and Pearl  2016). In this approach  data from an
observational probability distribution P is associated with a causal diagram (e.g.  Fig. 1a) in which
nodes correspond to measured variables  directed edges represent direct causal relations  and bi-
directed edges encode spurious associations due to unmeasured confounding variables. Performing
an action do(X = x) eliminates the impact of other variables on those in X by ﬁxing the values of
the latter and induces an interventional distribution  denoted Px. Whether  and if so how  aspects of
Px can be determined from the observational distribution together with the causal diagram is known
as the problem of causal identiﬁcation.
In this work  we focus on conditional causal effects  of the form Px(y|z)  which denotes the
conditional probability of Y = y given Z = z according to the interventional distribution Px. Such
conditional effects are particularly useful when what is at stake is the consequence of conditional
plans or policies  in which what value or probability distribution to impose on X is contingent on
the value of Z (Pearl and Robins  1995). When the available knowledge is sufﬁcient to delineate
the causal diagram  a number of criteria  including a complete algorithm  for identifying conditional
effects are known (Pearl  1995; Spirtes et al.  2000; Tian  2004; Shpitser and Pearl  2006). However 
we are usually in a position where background knowledge is not nearly enough to give us conﬁdence
on a single causal diagram. In such situations  forcing a single diagram easily leads to false modeling
assumptions and  consequently  misleading inferences.

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

V2

V1

V2

V1

V4

V3

v

v

X

(b)

X

(a)

◦
◦

◦
V4
◦
V3

Figure 1: Causal diagram (left) and the inferred
PAG (right).

Instead of specifying the causal diagram based
on expert knowledge  one may adopt a more
data-driven approach and attempt to learn it
from data. However  from observational data 
it is common that only a Markov equivalence
class of causal diagrams can be consistently esti-
mated (Verma  1993; Spirtes et al.  2001; Zhang 
2008b). A distinguished characterization of the
Markov equivalence class uses partial ancestral
graphs (PAGs). Fig. 1b shows the PAG learnable
from observational data that is consistent with the causal diagram depicted in Fig. 1a. The directed
edges in a PAG represent causal relations (that are not necessarily direct) and the circle marks stand
for structural uncertainty. Labeled edges (with v) signify the absence of unmeasured confounders.
In this work  we study the problem of using invariant structural features in a Markov equivalence
class (learnable from observational data) to identify conditional causal effects. Identiﬁcation from an
equivalence class is considerably more challenging than from a single diagram due to the structural
uncertainties. Zhang (2007) extended Pearl’s do-calculus to PAGs. However  it is computationally
hard to decide whether there exists (and  if so  to ﬁnd) a sequence of derivations in the generalized
calculus to identify the effect of interest. More recently  a complete algorithm was devised for
identifying unconditional causal effects given a PAG (Jaber et al.  2019a). This algorithm can be used
to identify conditional effects of the form Px(y|z) whenever the joint effect Px(y  z) is identiﬁable.
However  as we will show  many conditional effects are identiﬁable while the corresponding joint
effect is not.1 Speciﬁcally  we make the following contributions:

1. We establish a novel decomposition that serves to reduce a targeted conditional causal

distribution into components that are easier to identify.

2. Based on the decomposition  we develop an algorithm to compute the effect of an arbitrary
set of intervention variables on an arbitrary outcome set while conditioning on a third disjoint
set  from a PAG and an observational distribution. We show that this algorithm subsumes
that of (Jaber et al.  2019a).

2 Preliminaries

In this section  we introduce the basic setup and notations. Boldface capital letters denote sets of
variables  while boldface lowercase letters stand for value assignments to those variables.

Structural Causal Models. We use Structural Causal Models (SCMs) (Pearl  2000  pp. 204-207)
as our basic semantical framework. Formally  an SCM M is a 4-tuple (cid:104)U  V  F  P (U)(cid:105)  where U is
a set of exogenous (latent) variables and V is a set of endogenous (measured) variables. F represents
a collection of functions F = {fi} such that each endogenous variable Vi ∈ V is determined by a
function fi ∈ F  where fi is a mapping from the respective domain of Ui ∪ Pai to Vi  Ui ⊆ U 
Pai ⊆ V \ Vi. The uncertainty is encoded through a probability distribution over the exogenous
variables  P (U). Every SCM is associated with one causal diagram where every variable V ∪ U is
a node  and an arrow is drawn from each member of Ui ∪ Pai to Vi. Following standard practice 
when drawing a causal diagram  we omit the exogenous nodes and add a bi-directed arc between
two endogenous nodes if they share an exogenous parent. We restrict our study to recursive systems 
which means that the corresponding diagram will be acyclic. The marginal distribution induced
over the endogenous variables P (V) is called observational  and factorizes according to the causal
diagram  i.e.:

(cid:88)

(cid:89)

P (v) =

P (vi|pai  ui)P (u)

(1)

u

i

Within the structural semantics  performing an action X=x is represented through the do-operator 
do(X = x)  which encodes the operation of replacing the original equation for X by the constant x
and induces a submodel Mx. The resulting distribution is denoted by Px  which is the main target for
identiﬁcation in this paper. For details on structural models  we refer readers to (Pearl  2000).

1Another approach is based on SAT (Boolean constraint satisfaction) solvers (Hyttinen et al.  2015). Given

its somewhat distinct nature  a closer comparison lies outside the scope of this paper.

2

Ancestral Graphs. We now introduce a graphical representation of equivalence classes of causal
diagrams. A mixed graph can contain directed and bi-directed edges. A is an ancestor of B if there
is a directed path from A to B. A is a spouse of B if A ↔ B is present. An almost directed cycle
happens when A is both a spouse and an ancestor of B. An inducing path is a path on which every
node (except for the endpoints) is a collider on the path (i.e.  both edges incident to the node are
into it) and is an ancestor of an endpoint of the path. A mixed graph is ancestral if it does not
contain directed or almost directed cycles. It is maximal if there is no inducing path between any
two non-adjacent nodes. A Maximal Ancestral Graph (MAG) is a graph that is both ancestral and
maximal (Richardson and Spirtes  2002).
In general  a causal MAG represents a set of causal diagrams with the same set of observed variables
that entail the same conditional independence and ancestral relations among the observed variables.
Different MAGs may be Markov equivalent in that they entail the exact same independence model.
A partial ancestral graph (PAG) represents an equivalence class of MAGs [M]  which shares the
same adjacencies as every MAG in [M] and displays all and only the invariant edge marks (i.e.  edge
marks that are shared by all members of [M]). A circle indicates an edge mark that is not invariant.
A PAG is learnable from the independence model over the observed variables  and the FCI algorithm
is a standard method to learn such an object (Zhang  2008b). In short  a PAG represents a class of
causal diagrams with the same observed variables that entail the same independence model over the
observed variables.

Graphical Notions. Given a causal diagram  a MAG  or a PAG  a path between X and Y is
potentially directed (causal) from X to Y if there is no arrowhead on the path pointing towards X. Y
is called a possible descendant of X and X a possible ancestor of Y if there is a potentially directed
path from X to Y . Y is called a possible child of X and X a possible parent of Y if they are adjacent
and the edge is not into X. For a set of nodes X  let Pa(X) (Ch(X)) denote the union of X and the
set of possible parents (children) of X  and let An(X) denote the union of X and the set of possible
ancestors of X. Let Pa∗(X) denote Pa(X) excluding the possible parents of X due to circle edges
(◦−◦). Similarly  Ch∗(X) denotes Ch(X) excluding the possible children of X due to circle edges.
For convenience  we use an asterisk (*) as a wildcard to denote any possible mark of a PAG (◦  > −)
or a MAG (> −). If the edge marks on a path between X and Y are all circles  we call the path a
circle path. We refer to the closure of nodes connected with circle paths as a bucket. Obviously  given
a PAG  nodes are partitioned into a unique set of buckets.
A directed edge X → Y in a MAG or a PAG is visible if there exists no causal diagram in the
corresponding equivalence class where there is an inducing path between X and Y that is into X.
This implies that a visible edge is not confounded (X ←−→ Y doesn’t exist). Which directed edges
are visible is easily decidable by a graphical condition (Zhang  2008a)  so we simply mark visible
edges by v. For brevity  we refer to any edge that is not a visible directed edge as invisible.

Identiﬁcation in Causal Diagrams. Tian and Pearl (2002) introduced a decomposition of a causal
diagram into a set of so-called c-components (confounded components).
Deﬁnition 1 (C-Component). In a causal diagram  two nodes are said to be in the same c-component
iff they are connected by a bi-directed path  i.e.  a path composed solely of bi-directed edges.

The signiﬁcance of c-components and their decomposition is evident from (Tian  2004  Lemmas 2 
3)  which are the basis for the proposed algorithm for identifying conditional causal effects. For any
set C ⊆ V  Q[C] denotes the post-intervention distribution of C under an intervention on V \ C.
(2)

P (vi|pai  ui)P (u)

(cid:89)
(cid:88)
of the causal diagram D over C. That is  Q[C] =(cid:81)

Q[C] = Pv\c(c) =

u

{i|Vi∈C}

Obviously  Q[C] functionally depends on C and the corresponding parents  i.e.  Pa(C). Moreover 
Q[C] decomposes into a product of sub-queries over the c-components in DC  the induced subgraph

i Q[Ci]  where Ci is a c-component in DC.

3 Unconditional Causal Effect

In this section  we review the techniques developed in (Jaber et al.  2019a) for identifying uncondi-
tional causal effects. The notion of pc-component (Def. 2) in MAGs and PAGs generalizes that of

3

Algorithm 1 IDP(x  y) given PAG P
Input: two disjoint sets X  Y ⊂ V
Output: Expression for Px(y) or FAIL

2: Px(y) =(cid:80)

1: Let D = An(Y)PV\X

d\y IDENTIFY(D  V  P )
3: function IDENTIFY(C  T  Q = Q[T])
4:
5:

if C = ∅ then return 1
if C = T then return Q

/* In PT  let B denote a bucket  and let C B denote the pc-component of B */

6:
7:
8:
9:

10:
11:
12:

if ∃B ⊂ T \ C such that C B ∩ Ch(B) ⊆ B then

Compute Q[T \ B] from Q;
return IDENTIFY(C T \ B Q[T \ B])

else if ∃B ⊂ C such that RB (cid:54)= C then

return IDENTIFY(RB T Q) · IDENTIFY(RC\RB  T Q)

IDENTIFY(RB∩RC\RB  T Q)

else

throw FAIL

(cid:46) via Proposition 2

(cid:46) by Proposition 3

c-component in a causal diagram. Being in the same pc-component is a necessary condition for two
nodes to be in the same c-component in some causal diagram in the corresponding equivalence class
(Prop. 1). As a special case of Def. 2  two nodes are in the same deﬁnite c-component (dc-component)
if they are connected with a bi-directed path  i.e.  a path composed solely of bi-directed edges.
Deﬁnition 2 (PC-Component). In a MAG  a PAG  or any induced subgraph thereof  two nodes are
in the same possible c-component (pc-component) if there is a path between them such that (1) all
non-endpoint nodes along the path are colliders  and (2) none of the edges is visible.
Proposition 1. Let P be a MAG or a PAG over V  and D be any causal diagram in the equivalence
class represented by P. For any X  Y ∈ A ⊆ V  if X and Y are in the same c-component in DA 
then X and Y are in the same pc-component in PA.
Using the above notions  the following identiﬁcation criterion is derived where the intervention is on
a bucket rather than a single node and the input distribution is possibly interventional. The expression
depends on a partial topological order (PTO) over the nodes  which is a topological order over the
buckets. A detailed discussion can be found in (Jaber et al.  2018).
Proposition 2. Let P denote a PAG over V  T be a union of a subset of the buckets in P  and X ⊂ T
be a bucket. Given Pv\t (i.e.  Q[T])  and a partial topological order B1 < ··· < Bm with respect
to PT  Q[T \ X] is identiﬁable if and only if  in PT  there does not exist Z ∈ X such that Z has a
possible child C /∈ X that is in the pc-component of Z. If identiﬁable  then the expression is given by

(cid:81){i|Bi⊆SX} Pv\t(Bi|B(i−1))

Pv\t

×(cid:88)

(cid:89)

x

{i|Bi⊆SX}

Pv\t(Bi|B(i−1)) 

Z∈X SZ  SZ being the dc-component of Z in PT  and B(i−1) denoting the set of

nodes preceding bucket Bi in the partial order.
For example  given the PAG in Fig. 1b  X is not in the same pc-component with any of its possible
children V3  V4  hence Px(v1  . . .   v4) is computable from the observational distribution P (v). An-
other important result is decomposing a target quantity Q[C] into a product of smaller quantities.
Such a decomposition is obtained in Proposition 3 using the Region construct (Def. 3).
Deﬁnition 3 (Region RC
A). Given a PAG or a MAG P over V  and A ⊆ C ⊆ V. Let the region of
A with respect to C  denoted RC
A  be the union of the buckets that contain nodes in the pc-component
of A in the induced subgraph PC.
Proposition 3. Given a PAG P over V and set C ⊆ V  Q[C] can be decomposed as follows.

Q[T \ X] =

where SX =(cid:83)

where A ⊂ C and R(.) = RC
(.).

Q[C] =

Q[RA].Q[RC\RA]
Q[RA ∩ RC\RA ]

4

X

Z

◦ ◦ ◦ ◦
(a) Px(y|z).

Y

◦
◦
◦
◦
X
Y
◦ ◦
◦ ◦
◦
◦
Z
W
(b) Px(y|z  w).

X

◦
Z2

◦ ◦

W

◦

Z2

v

Z1

◦
(c) Px(y|z1  z2).

◦

X

Y

Z1

v

Y

(d) Px(y|z1  z2).

Figure 2: Sample PAGs with identiﬁable conditional causal effects.

Propositions 2 and 3 are utilized in Algorithm 1 which is sound and complete for identifying
unconditional causal effects given a PAG (Jaber et al.  2019a).

4 Conditional Causal Effects

We formalize the notion of identiﬁability from a PAG using the following deﬁnition  which generalizes
the causal-diagram-speciﬁc notion (Tian  2004).
Deﬁnition 4 (Causal-Effect Identiﬁability). The causal effect of a set of variables X on a disjoint set
of variables Y conditioned on another set Z is said to be identiﬁable from a PAG P if the quantity
Px(y|z) can be computed uniquely from the observational distribution P (V) given every causal
diagram D (represented by a MAG) in the Markov equivalence class represented by P.
Given a PAG P and a conditional causal effect Px(y|z)  we can rewrite the quantity as follows.
Hence  if Px(y  z) is identiﬁable  then Px(y|z) is identiﬁable as well.

(cid:80)

Px(y|z) =

Px(y  z)
y Px(y  z)

For example  Pz1(y  z2) is identiﬁable in the PAG of Figure 2c with the following (simpliﬁed)
expression via Algorithm 1. Hence  both Pz1(y|z2) and Pz1(z2|y) are identiﬁable.

Pz1(y  z2) = Q[Y  Z2] = P (y|z1  z2)P (z2)

However  not all identiﬁable conditional effects can be identiﬁed this way. Consider the PAG in Fig. 2d
and the conditional effect Px(y|z1  z2). Whereas Px(y  z1  z2) is not identiﬁable by Algorithm 1 and
hence the conditional effect is not identiﬁable simpliciter  Px(y|z1  z2) turns out to be identiﬁable
as we show later. Therefore  Algorithm 1  though complete for identifying unconditional effects  is
unable to compute many identiﬁable conditional effects.
To do better  we start by generalizing the notion of Q[·] to accommodate conditioning.
Deﬁnition 5. For any pair of disjoint sets C  Z ⊆ V  we deﬁne the quantity Q[C|Z]  given below  to
be the post-intervention distribution of C conditional on Z under an intervention on V \ (C ∪ Z).

Q[C|Z] =

(cid:80)
Q[C ∪ Z]
c Q[C ∪ Z]

In what follows  we utilize Deﬁnition 5 to derive an algorithm for conditional causal effect identiﬁ-
cation. The following proposition shows a way to rewrite a given conditional effect in terms of the
notion in Deﬁnition 5.2
Proposition 4. Given distribution P (V)  causal PAG P over V  and target effect Px(y|z) where
X  Y  Z are disjoint subsets of V  we have the following.

Q[D|Z]

(3)

Px(y|z) =

where D = An(Y ∪ Z)PV\X \ Z.

2The proofs can be found in (Jaber et al.  2019b).

(cid:88)

d\y

5

Algorithm 2 Recursive routine to decompose Q[T|Z].
1: function DECOMPOSE(P  T  Z)
2:

if T = ∅ then return ∅

/* In PT∪Z  let C (·) denote the pc-component of (·) in PT∪Z. */

Initialize X to an arbitrary node in T
Let A = Pa∗(C X) ∩ Pa∗(C T∪Z\CX
)
while A (cid:54)⊆ Z do

X = X ∪ Ch∗(A ∩ T)
A = Pa∗(C X) ∩ Pa∗(C T∪Z\CX

)
/* Let T1 = C X ∩ T and T2 = T \ T1 */

3:
4:
5:
6:
7:

8:

return (cid:104)T1 RX \ T1(cid:105) ∪ DECOMPOSE(P  T2 RT∪Z\CX \ T2)

causal effect as(cid:80)

w Q[Y  W|Z1  Z2].

For example  given the PAG in Figure 2d and query Px(y|z1  z2)  we can rewrite the conditional

The following fact plays a crucial role in the derivation of our algorithm.
Lemma 1. Given a PAG P over V and any causal diagram D in the equivalence class represented
by P  suppose X ⊂ A ⊆ V  and let SX and C X denote the c-component and pc-component of X in
DA and PA  respectively. Then  for every Y ∈ A  if Y ∈ Pa(SX) in DA  then Y ∈ Pa∗(C X) in PA 
where Pa∗(·) is (the union of the input set and) the set of possible parents due to directed or partially
directed edges (→   ◦→).
In words  given a PAG P and any diagram D in the equivalence class  if a node Y is a parent of the
c-component of X in DA  then Y must be either in the pc-component of X in PA or a possible parent
of the pc-component by a non-circle edge. For example  given the PAG in Figure 2a  C X = {X  Z}
and Y (cid:54)∈ Pa∗(C X )  hence Y (cid:54)∈ Pa(SX ) in any causal diagram in the equivalence class. It is easy
to see why in this simple example. First  X is not in the pc-component of Y so they are not in the
same c-component in any causal diagram  by Proposition 1. If X and Z are in the same c-component
in some diagram D and Y is a parent of Z  then we have an (unshielded) collider at Z in D  which
would contradict the given PAG. This observation generalizes to more complex cases. Note that the
property does not necessarily hold if the input to Pa(·) and Pa∗(·) are arbitrary subsets of V rather
than a c-component and a pc-component.
Next  we derive a sufﬁcient condition for decomposing Q[T|Z] into two sub-queries.
Proposition 5. Given a PAG P over V and Q[T|Z]  let X ⊂ T ∪ Z. The following decomposition
holds if Pa∗(C X) ∩ Pa∗(C T∪Z\CX
) ⊆ Z  where C (·) is the set of nodes in the pc-component of (·)
in PT∪Z  R(·) is with respect to T ∪ Z  T1 = C X ∩ T  and T2 = T \ T1.
Q[T|Z] = Q[T1|RX \ T1] · Q[T2|RT∪Z\CX \ T2]

For example  given Q[Y  W|Z1  Z2] and the PAG in Figure 2d  C Y = {Y  Z2}  Pa∗(C Y ) =
{Y  Z2  Z1}  and Pa∗(C{W Z1}) = {W  Z1  Z2}. Hence  Pa∗(C Y ) ∩ Pa∗(C{W Z1}) = {Z1  Z2}
and the condition of Prop. 5 is satisﬁed. So  we have the following decomposition.

Q[Y  W|Z1  Z2] = Q[Y |Z2  W ] · Q[W|Z1  Z2]

(4)
It is important to note that the condition is based on the pc-component of X ⊂ T ∪ Z while the Q[·]
decomposition uses the region of X (Def. 3). The decomposition would still be valid by using the
pc-component instead of the region  but using the region has the advantage of keeping together nodes
in the same bucket (i.e.  nodes that share circle edges). For instance  using the region allows us to
keep W and Z2 together in each sub-query. This will be useful in the ﬁnal algorithm.
Algorithm 2 decomposes Q[T|Z] into a product of sub-queries by applying Prop. 5 recursively.
In each iteration  the routine ﬁnds a subset X that satisﬁes the criterion in the proposition (cf.
line 5). The ﬁrst line checks for a base case where T = ∅. For example  given Q[Y |Z1  Z2]
and the PAG in Figure 2c  the function assigns X to {Y }. Since Pa∗(C X) = {Y  Z2  Z1} and
Pa∗(C Z1) = {Z1  Z2}  their intersection satisﬁes the criterion. Hence  Q[Y |Z1  Z2] = Q[Y |Z2] ×

6

Algorithm 3 CIDP(x  y  z) given PAG P
Input: three disjoint sets X  Y  Z ⊂ V
Output: Expression for Px(y|z) or FAIL

1: Let D = An(Y ∪ Z)PV\X \ Z
d\y Q[D|Z]
3: F = DECOMPOSE(P  D  Z)

2: Px(y|z) =(cid:80)
/* At this point  Px(y|z) =(cid:80)

4: Let F∗ = ∅
5: for each (cid:104)Di  Zi(cid:105) ∈ F do
if Di ∩ Y (cid:54)= ∅ then
6:
7:

8: Px(y|z) =(cid:81){i|(cid:104)Di Zi(cid:105)∈F∗}(cid:80)

9: function DO-SEE(P  T  Z)

F∗ = F∗ ∪ DO-SEE(P  Di  Zi)

(cid:81)
i Q[Di|Zi] =(cid:81)

i

(cid:46) Expand query via Prop. 4
(cid:46) F is a set of pairs (cid:104)Di  Zi(cid:105)

(cid:80)
di\y Q[Di|Zi] */

d\y

(cid:80)

di\y

IDENTIFY(Di ∪ Zi  V  P )

IDENTIFY(Di ∪ Zi  V  P )

di

/* Let B denote a bucket in P and C (·) denote the pc-component of (·) in PT∪Z∪B */

if ∃B | B ∩ (T ∪ Z) (cid:54)= ∅ ∧ B (cid:54)⊆ (T ∪ Z) then

10:
11:
12:
13:
14:
15:

if Pa∗(C B\(T∪Z)) ∩ T = ∅ then
else

return DO-SEE(P  T  Z ∪ B \ T)

throw FAIL

return (cid:104)T  Z(cid:105)

Q[∅|Z1  Z2] where Q[∅|Z1  Z2] = 1 by deﬁnition. The base case accounts for the recursive call
DECOMPOSE(P ∅ {Z1  Z2}) which yields Q[∅|Z1  Z2] = 1. In general  this step simpliﬁes a target
Q[·] and facilitates its computation.
To derive our identiﬁcation algorithm  we use one more trick. Lemma 2 below provides a sufﬁcient
criterion where given Q[T|Z] and a causal diagram D  we can move a subset X from the intervention
set V \ (T ∪ Z) to the conditioning set.
Lemma 2. Given causal diagram D and Q[T|Z]  let X ⊆ V \ (T ∪ Z) and let SX denote the
c-component of X in DT∪Z∪X. If Pa(SX) ∩ T = ∅  then Q[T|Z] = Q[T|Z ∪ X].
The following proposition generalizes the result in Lemma 2 to PAGs using the property in Lemma 1.
Proposition 6. Given PAG P and Q[T|Z]  let X ⊆ V\(T∪Z) and let C X denote the pc-component
of X in PT∪Z∪X. If Pa∗(C X) ∩ T = ∅  then Q[T|Z] = Q[T|Z ∪ X].
Proof. Let D be any diagram in the equivalence class represented by P. By Lemma 1  if Pa∗(C X) ∩
T = ∅ in PT∪Z∪X  then Pa(SX) ∩ T = ∅ in DT∪Z∪X. Hence  the proposition follows by Lemma 2
since the equation is valid for all the diagrams in the equivalence class.
For example  given Q[Y |Z] and the PAG in Figure 2a  Pa∗(C X ) ∩ {Y } = Pa∗({X  Z}) ∩ {Y } = ∅ 
hence Q[Y |Z] = Q[Y |Z  X]. Similarly  given the PAG in Fig. 2b  Q[Y |Z  W ] = Q[Y |Z  W  X].
Finally  we use the above results to construct Algorithm 3 which identiﬁes conditional causal effects.
The algorithm is sound by Theorem 1. It starts by computing set D then expanding the query
accordingly in lines 1-2. Then  CIDP calls Alg. 2 which decomposes Q[D|Z] to sub-queries as the
comment below line 3 elaborates. Lines 4-7 achieve two things. First  we drop every unnecessary
Q[Di|Zi] = 1. For each remaining query Q[Di|Zi] 
function DO-SEE(· · ·) searches recursively for a bucket B in P such that a strict subset of B is
in Di ∪ Zi  and then tries to apply Prop. 6 to obtain Q[Di|Zi ∪ B \ Di]. Finally  in line 8  we try
to compute the target conditional effect by computing each Q[Di|Zi] = Q[Di∪Zi]
Q[Di∪Zi] and calling
IDENTIFY(Di ∪ Zi  V P) from Alg. 1. CIDP does not identify the target effect if either DO-SEE(·)
or IDENTIFY(·) throws a FAIL.
Theorem 1. CIDP (Algorithm 3) is sound.

query Q[Di|Zi] where Di ∩ Y = ∅ since(cid:80)

(cid:80)

di

di

7

6 drops from F∗ every Q[Di|Zi] where Y ∩ Di = ∅ since(cid:80)

Proof Sketch. Line 2 follows from Proposition 4. Function DECOMPOSE(· · ·) is sound by Proposi-
tion 5. The second equivalence in the comment after line 3 is justiﬁed by the proof of Prop. 5. Line
Q[Di|Zi] = 1. The soundness of
DO-SEE(· · ·) follows from Proposition 6. Finally  line 8 is sound by Deﬁnition 5 and the correctness
of IDENTIFY(· · ·) in (Jaber et al.  2019a).

di

Illustrative Example

4.1
Consider the effect Px(y|z1  z2) and the PAG in Figure 2d. We have the following from Eq. 4 and
Lines 4-7 of the algorithm. Since {Y } {Z2  W} are buckets in the PAG  DO-SEE(·) does nothing.

(cid:88)

Q[Y  W|Z1  Z2] = Q[Y |Z2  W ] ·(cid:88)

Q[W|Z1  Z2] = Q[Y |Z2  W ]

Px(y|z1  z2) =

w

w

×(cid:88)

Then  we call IDENTIFY({Y  Z2  W}  V  P ) to compute Q[{Y  Z2  W}] from P (V). Node Z1 is
not in the same pc-component with its only child Y in P. Hence  Q[{Y  Z2  W  X}] is identiﬁable
from P (V) by Proposition 2 using the order X < {W  Z2} < Z1 < Y .
Q[{Y  Z2  W  X}] =
Next  X does not have any possible children in PV\{Z1}  hence Q[{Y  Z2  W}] is identiﬁable from
Q[{Y  Z2  W  X}] (Eq. 5) using the partial order X < {W  Z2} < Y . The last equivalence is a
simpliﬁcation obtained by considering the independence relation (X ⊥⊥ {W  Z2}).
Q[{Y  Z2  W}] =

1|x  w  z2) = P (x  w  z2) · P (y|x  w  z2  z1)

P (x  w  z2)P (y|x  w  z2  z1)

= P (w  z2)P (y|w  z2  z1)

P (z1|x  w  z2)

P (z(cid:48)

P (v)

Pz1

(5)

z(cid:48)

1

Pz1(x)

P (x)

Pz1(x(cid:48)) =

×(cid:88)
(cid:80)
Q[{Y  Z2  W}]
y Q[{Y  Z2  W}]

x(cid:48)

Finally  the conditional effect simpliﬁes as follows.

(cid:80)
P (w  z2) · P (y|w  z2  z1)
y P (w  z2) · P (y|w  z2  z1)

=

= P (y|z2  z1)

Px(y|z1  z2) =

4.2 Expressiveness

Theorem 2 below establishes that CIDP subsumes IDP. Conversely  IDP cannot compute some
conditional effects that are identiﬁable by CIDP  such as the cases depicted in Fig. 2  because the
corresponding joint effects are not identiﬁable. Hence  CIDP is strictly more powerful than IDP.
Theorem 2. CIDP (Alg. 3) subsumes IDP (Alg. 1) − if CIDP fails to identify Px(y)  IDP fails too.
Proof. Suppose Z = ∅. The query expansion reduces to that in Alg. 1. Alg. 2 will decompose Q[D]
only if the subsets are disjoint in PD since any adjacency implies the condition of Proposition 5
would fail. Such a decomposition is valid for IDP using Prop. 3 where the denominator set would be
empty. Whenever set B in DO-SEE(·) exists (line 10)  the function fails. We then have B ∩ X (cid:54)= ∅
and there exists a potentially causal path from X to Y that starts with an invisible edge. Hence  Px(y)
is not identiﬁable by (Jaber et al.  2019a  Th. 3)  and consequently IDP fails. Finally  CIDP fails if a
call to IDENTIFY(·) fails. It follows that IDP would fail as well which concludes the proof.

5 Conclusion

The problem of identifying conditional causal effects is of great interest due to its role in evaluating
conditional plans or policies (Pearl and Robins  1995). We have investigated a challenging version of
this problem where in addition to the observational distribution  the available causal information is
not a fully speciﬁed causal diagram  but a PAG which represents a Markov equivalence class of causal
diagrams and which can be inferred from the observational distribution. We develop an algorithm
to compute the effect of an arbitrary set of intervention variables X on an arbitrary outcome set Y
while conditioning on a third disjoint set Z  denoted Px(y|z). We show that the proposed algorithm
subsumes the state-of-the-art algorithm in (Jaber et al.  2019a)  which is complete for unconditional
effects. Moreover  CIDP identiﬁes all the examples in the literature that we are aware of  including
the one in Fig. 2b which is not identiﬁable by the generalized do-calculus (Zhang  2008a). Based on
these observations  we conjecture that our algorithm is complete.

8

Acknowledgements

Bareinboim and Jaber are supported in parts by grants from NSF IIS-1704352  IIS-1750807 (CA-
REER)  IBM Research  and Adobe Research. Zhang’s research was supported in part by the Research
Grants Council of Hong Kong under the General Research Fund LU13602818.

References
Bareinboim  E. and Pearl  J. (2016). Causal inference and the data-fusion problem. Proceedings of

the National Academy of Sciences  113:7345–7352.

Hyttinen  A.  Eberhardt  F.  and Järvisalo  M. (2015). Do-calculus when the true graph is unknown.

In UAI  pages 395–404.

Jaber  A.  Zhang  J.  and Bareinboim  E. (2018). A graphical criterion for effect identiﬁcation in
equivalence classes of causal diagrams. In Proceedings of the 27th International Joint Conference
on Artiﬁcial Intelligence  IJCAI’18  pages 5024–5030.

Jaber  A.  Zhang  J.  and Bareinboim  E. (2019a). Causal identiﬁcation under Markov equivalence:
Completeness results. In Proceedings of the 36th International Conference on Machine Learning 
ICML’19.

Jaber  A.  Zhang  J.  and Bareinboim  E. (2019b). Identiﬁcation of conditional causal effects under
Markov equivalence. Technical report  R-50  Columbia CausalAI Lab  Department of Computer
Science  Columbia University.

Pearl  J. (1995). Causal diagrams for empirical research. Biometrika  82(4):669–688.

Pearl  J. (2000). Causality: Models  Reasoning  and Inference. Cambridge University Press  New

York. 2nd edition  2009.

Pearl  J. and Robins  J. M. (1995). Probabilistic evaluation of sequential plans from causal models

with hidden variables. In UAI  volume 95  pages 444–453. Citeseer.

Richardson  T. and Spirtes  P. (2002). Ancestral graph Markov models. Annals of Statistics  pages

962–1030.

Shpitser  I. and Pearl  J. (2006). Identiﬁcation of conditional interventional distributions. In Proceed-
ings of the 22nd Conference on Uncertainty in Artiﬁcial Intelligence  UAI 2006  pages 437–444.

Spirtes  P.  Glymour  C. N.  and Scheines  R. (2001). Causation  prediction  and search  volume 81.

MIT press.

Spirtes  P.  Glymour  C. N.  Scheines  R.  Heckerman  D.  Meek  C.  Cooper  G.  and Richardson  T.

(2000). Causation  prediction  and search. MIT press.

Tian  J. (2004). Identifying conditional causal effects. In Proceedings of the 20th conference on

Uncertainty in artiﬁcial intelligence  pages 561–568. AUAI Press.

Tian  J. and Pearl  J. (2002). A general identiﬁcation condition for causal effects. In AAAI/IAAI 

pages 567–573.

Verma  T. (1993). Graphical aspects of causal models. Technical R eport R-191  UCLA.

Zhang  J. (2007). Generalized do-calculus with testable causal assumptions.

Conference on Artiﬁcial Intelligence and Statistics  pages 667–674.

In International

Zhang  J. (2008a). Causal reasoning with ancestral graphs. Journal of Machine Learning Research 

9(Jul):1437–1474.

Zhang  J. (2008b). On the completeness of orientation rules for causal discovery in the presence of

latent confounders and selection bias. Artiﬁcial Intelligence  172(16):1873–1896.

9

,Amin Jaber
Jiji Zhang
Elias Bareinboim