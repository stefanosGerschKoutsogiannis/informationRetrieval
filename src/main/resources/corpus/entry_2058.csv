2007,Fast and Scalable Training of Semi-Supervised CRFs with Application to Activity Recognition,We present a new and efficient semi-supervised training method for parameter estimation and feature selection in conditional random fields (CRFs). In real-world applications such as activity recognition  unlabeled sensor traces are relatively easy to obtain whereas labeled examples are expensive and tedious to collect. Furthermore  the ability to automatically select a small subset of discriminatory features from a large pool can be advantageous in terms of computational speed as well as accuracy. In this paper  we introduce the semi-supervised virtual evidence boosting (sVEB) algorithm for training CRFs -- a semi-supervised extension to the recently developed virtual evidence boosting (VEB) method for feature selection and parameter learning. Semi-supervised VEB takes advantage of the unlabeled data via minimum entropy regularization -- the objective function combines the unlabeled conditional entropy with labeled conditional pseudo-likelihood. The sVEB algorithm reduces the overall system cost as well as the human labeling cost required during training  which are both important considerations in building real world inference systems. In a set of experiments on synthetic data and real activity traces collected from wearable sensors  we illustrate that our algorithm benefits from both the use of unlabeled data and automatic feature selection  and outperforms other semi-supervised training approaches.,Fast and Scalable Training of Semi-Supervised CRFs

with Application to Activity Recognition

Maryam Mahdaviani

Computer Science Department
University of British Columbia

Vancouver  BC  Canada

Tanzeem Choudhury

Intel Research

1100 NE 45th Street

Seattle  WA 98105 USA

Abstract

We present a new and efﬁcient semi-supervised training method for parameter es-
timation and feature selection in conditional random ﬁelds (CRFs). In real-world
applications such as activity recognition  unlabeled sensor traces are relatively
easy to obtain whereas labeled examples are expensive and tedious to collect.
Furthermore  the ability to automatically select a small subset of discriminatory
features from a large pool can be advantageous in terms of computational speed as
well as accuracy. In this paper  we introduce the semi-supervised virtual evidence
boosting (sVEB) algorithm for training CRFs – a semi-supervised extension to the
recently developed virtual evidence boosting (VEB) method for feature selection
and parameter learning. The objective function of sVEB combines the unlabeled
conditional entropy with labeled conditional pseudo-likelihood.
It reduces the
overall system cost as well as the human labeling cost required during training 
which are both important considerations in building real-world inference systems.
Experiments on synthetic data and real activity traces collected from wearable
sensors  illustrate that sVEB beneﬁts from both the use of unlabeled data and au-
tomatic feature selection  and outperforms other semi-supervised approaches.

1 Introduction

Conditional random ﬁelds (CRFs) are undirected graphical models that have been successfully ap-
plied to the classiﬁcation of relational and temporal data [1]. Training complex CRF models with
large numbers of input features is slow  and exact inference is often intractable. The ability to select
the most informative features as needed can reduce the training time and the risk of over-ﬁtting of
parameters. Furthermore  in complex modeling tasks  obtaining the large amount of labeled data
necessary for training can be impractical. On the other hand  large unlabeled datasets are often easy
to obtain  making semi-supervised learning methods appealing in various real-world applications.
The goal of our work is to build an activity recognition system that is not only accurate but also scal-
able  efﬁcient  and easy to train and deploy. An important application domain for activity recognition
technologies is in health-care  especially in supporting elder care  managing cognitive disabilities 
and monitoring long-term health. Activity recognition systems will also be useful in smart environ-
ments  surveillance  emergency and military missions. Some of the key challenges faced by current
activity inference systems are the amount of human effort spent in labeling and feature engineering
and the computational complexity and cost associated with training. Data labeling also has privacy
implications because it often requires human observers or recording of video. In this paper  we intro-
duce a fast and scalable semi-supervised training algorithm for CRFs and evaluate its classiﬁcation
performance on extensive real world activity traces gathered using wearable sensors. In addition
to being computationally efﬁcient  our proposed method reduces the amount of labeling required
during training  which makes it appealing for use in real world applications.

1

Several supervised techniques have been proposed for feature selection in CRFs. For discrete fea-
tures  McCallum [2] suggested an efﬁcient method for feature induction by iteratively increasing
conditional log-likelihood. Dietterich [3] applied gradient tree boosting to select features in CRFs
by combining boosting with parameter estimation for 1D linear-chain models. Boosted random
ﬁelds (BRFs) [4] combine boosting and belief propagation for feature selection and parameter esti-
mation for densely connected graphs that have weak pairwise connections. Recently  Liao et.al. [5]
developed a more general version of BRFs  called virtual evidence boosting (VEB) that does not
make any assumptions about graph connectivity or the strength of pairwise connections. The ob-
jective function in VEB is a soft version of maximum pseudo-likelihood (MPL)  where the goal is
to maximize the sum of local log-likelihoods given soft evidence from its neighbors. This objective
function is similar to that used in boosting  which makes it suitable for uniﬁed feature selection and
parameter estimation. This approximation applies to any CRF structures and leads to a signiﬁcant
reduction in training complexity and time. Semi-supervised training techniques have been exten-
sively explored in the case of generative models and naturally ﬁt under the expectation maximization
framework [6]. However  it is not straight forward to incorporate unlabeled data in discriminative
models using the traditional conditional likelihood criteria. A few semi-supervised training meth-
ods for CRFs have been proposed that introduce dependencies between nearby data points [7  8].
More recently  Grandvalet and Bengio [9] proposed a minimum entropy regularization framework
for incorporating unlabeled data. Jiao et.al. [10] used this framework and proposed an objective
function that combines the conditional likelihood of the labeled data with the conditional entropy of
the unlabeled data to train 1D CRFs  which was extended to 2D lattice structures by Lee et.al. [11].
In our work  we combine the minimum entropy regularization framework for incorporating unla-
beled data with VEB for training CRFs. The contributions of our work are: (i) semi-supervised
virtual evidence boosting (sVEB) - an efﬁcient technique for simultaneous feature selection and
semi-supervised training of CRFs  which to the best of our knowledge is the ﬁrst method of its
kind  (ii) experimental results that demonstrate the strength of sVEB  which consistently outper-
forms other training techniques on synthetic data and real-world activity classiﬁcation tasks  and
(iii) analysis of the time and complexity requirements of our algorithm  and comparison with other
existing techniques that highlight the signiﬁcant computational advantages of our approach. The
sVEB algorithm is fast and easy to implement and has the potential of being broadly applicable.

2 Approaches to training of Conditional Random Fields

Maximum likelihood parameter estimation in CRFs involves maximizing the overall conditional
log-likelihood  where x is the observation sequence and y is the hidden state sequence:

L(θ) = log(p(y|x  θ)) − (cid:107)θ(cid:107)/2 = log

− (cid:107)θ(cid:107)/2

(1)

K(cid:80)
K(cid:80)

k=1

k=1

exp(

θkfk(x  y))

exp(

θkfk(x  y(cid:48)))

(cid:80)

y(cid:48)

The conditional distribution is deﬁned by a log-linear combination of k features functions fk asso-
ciated with weight θk. A regularizer on θ is used to keep the weights from getting too large and
to avoid overﬁtting1. For large CRFs exact inference is often intractable and approximate methods
such as mean ﬁeld approximation or loopy belief propagation [12  13] are used.
An alternative to approximating the conditional likelihood is to change the objective function.
MPL [14] and VEB [5] are such techniques. For MPL the CRF is cut into a set of independent
patches; each patch consists of a hidden node or class label yi  the true value of its direct neighbors
and the observations  i.e.  the Markov Blanket(M Byi) of the node. The parameter estimation then
becomes maximizing the pseudo log-likelihood:

Lpseudo(θ) =

log(p(yi|M Byi   θ)) =

log

N(cid:80)

i=1

exp(

θkfk(M Byi  yi))

exp(

θkfk(M By(cid:48)

i

 y(cid:48)

i))

K2k=1
K2k=1

2y(cid:48)

i

N(cid:80)

i=1

MPL has been known to over-estimate the dependency parameters in some cases and there is no
general guideline on when it can be safely used [15].

1When a prior is used in the maximum likelihood objective function as a regularizer – the second term in eq. (1)  the method is in fact

called maximum a posteriori.

2

2.1 Virtual evidence boosting
By extending the standard LogitBoost algorithm [16]  VEB integrates boosting based feature se-
lection into CRF training. The objective function used in VEB is very similar to MPL  except that
VEB uses the messages from the neighboring nodes as virtual evidence instead of using the true
labels of neighbors. The use of virtual evidence helps to reduce over-estimation of neighborhood
dependencies. We brieﬂy explain the approach here but please refer to [5] for more detail.
VEB incorporates two types of observations nodes: (i) hard evidence corresponding to the observa-
tions ve(xi)  which are indicator functions at the observation values and (ii) soft evidence  corre-
sponding to the messages from neighboring nodes ve(n(yi))  which are discrete distributions over
the hidden states. Let vei (cid:44) {ve(xi)  ve(n(yi))}. The objective function of VEB is as follows:

(cid:80)
(cid:80)
(cid:80)

vei

y(cid:48)

i

vei

K(cid:80)
K(cid:80)

k=1

k=1

vei exp(

θkfk(vei  yi))

vei exp(

(2)

θkfk(vei  y(cid:48)
i))

N(cid:88)

i=1

LV EB(θ) =

log(p(yi|vei  θ))  where p(yi|vei  θ) =

VEB learns a set weak learners fts iteratively and estimates the combined feature Ft = Ft−1 + ft
by solving the following weighted least square error(WLSE) problem:

N(cid:88)
where wi = p(yi|vei)(1 − p(yi|vei))  zi = yi − 0.5
p(yi|vei)

wiE(f(vei) − zi)2 = arg min

(cid:88)

N(cid:88)

i=1

i=1

vei

[

f

wip(yi|vei)(f(vei) − zi)2]

(3)

(4)

ft(vei) = arg min

f

The wi and zi in equation 4 are the boosting weight and working response respectively for the ith
data point  exactly as in LogitBoost. However  the least square problem for VEB (eq.3) involves
N X points because of virtual evidence as opposed to N points in LogitBoost. Although eq. 4 is
given for the binary case (i.e. yi ∈ {0  1})  it is easily extendible to the multi-class case and we have
done that in our experiments. At each iteration  vei is updated as messages from n(yi) changes with
the addition of new features. We run belief propagation (BP) to obtain the virtual evidence before
each iteration. The CRF feature weights  θ’s are computed by solving the WLSE problem  where
the local features  nki is the count of feature k in data instance i and the compatibility features  nki
is the virtual evidence from the neighbors.: θk =

wizinki/

N(cid:80)

N(cid:80)

winki.

i=1

i=1

2.2 Semi-supervised training
For semi-supervised training of CRFs  Jiao et.al. [10] have proposed an algorithm that utilizes unla-
beled data via entropy regularization – an extension of the approach proposed by [9] to structured
CRF models. The objective function that is maximized during semi-supervised training of CRFs is
given below  where (xl  yl) and (xu  yu) represent the labeled and unlabeled data respectively:

LSS(θ) = log p(yl|xl  θ) + α

p(yu|xu  θ)log p(yu|xu  θ) − (cid:107)θ(cid:107)/2

(cid:80)

yu

By minimizing the conditional entropy of the unlabeled data  the algorithm will generally ﬁnd la-
beling of the unlabeled data that mutually reinforces the supervised labels. One drawback of this
objective function is that it is no longer concave and in general there will be local maxima. The
authors [10] showed that this method is still effective in improving an initial supervised model.

3 Semi-supervised virtual evidence boosting

In this work  we develop semi-supervised virtual evidence boosting (sVEB) that combines feature
selection with semi-supervised training of CRFs. sVEB extends the VEB framework to take advan-
tage of unlabeled data via minimum entropy regularization similar to [9  10  11]. The new objective
function LsV EB we propose is as follows  where (i = 1··· N) are labeled and (i = N + 1··· M)
are unlabled examples:

M(cid:88)

(cid:88)

LsV EB =

log p(yi|vei) + α

p(y(cid:48)

i|vei) log p(y(cid:48)

i|vei)

(5)

N(cid:88)

i=1

i=N +1

y(cid:48)

i

3

The sVEB aglorithm  similar to VEB  maximizes the conditional soft pseudo-likelihood of the la-
beled data but in addition minimizes the conditional entropy over unlabeled data. The α is a tuning
parameter for controlling how much inﬂuence the unlabeled data will have.
By considering the soft pseudo-likelihood in LsV EB and using BP to estimate p(yi|vei)  sVEB can
use boosting to learn the parameters of CRFs. The virtual evidence from the neighboring nodes
captures the label dependencies. There are three different types of feature functions fs that’s used:
for continuous observations f1(xi) is a linear combination of decision stumps  for discrete obser-
vations the learner f2(xi) is expressed as indicator functions  and for virtual evidences the weak
learner f3(xi) is the weighted sum of two indicator functions (for binary case). These functions are
computed as follows  where δ is an indicator function  h is a threshold for the decision stump  and
D is the number of dimensions of the observations:
f1(xi) = θ1δ(xi ≥ h) + θ2δ(xi < h)  f2(xi) =

θkδ(xi = d)  f3(yi) =

θkδ(yi = k) (6)

1(cid:88)

D(cid:88)

k=1

k=0

Similar to LogitBoost and VEB  the sVEB algorithm estimates a combined feature function F that
maximizes the objective by sequentially learning a set of weak learners  ft’s (i.e. iteratively selecting
features). In other words  sVEB solves the following weighted least-square error (WLSE) problem
to learn fts:

N(cid:88)

(cid:88)

(cid:88)

(cid:88)

M(cid:88)

wip(yi|vei)(f(xi) − zi)2 +

wip(y(cid:48)

i|vei)(f(xi) − zi)2]

(7)

ft = arg min

[

f

i=1

vei

i=N +1

y(cid:48)

i

vei

For labeled data (ﬁrst term in eq.7)  boosting weights  wi’s  and working responses  zi’s  are com-
puted as described in equation 4. But for the case of unlabeled data the expression for wi and zi
becomes more complicated because of the entropy term. We present the equations for wi and zi
below  please refer to the Appendix for the derivations:

wi = α2(1 − p(yi|vei))[p(yi|vei)(1 − p(yi|vei)) + log p(yi|vei)]

zi =

(yi − 0.5)p(yi|vei)(1 − log p(yi|vei))

α[p(yi|vei)(1 − p(yi|vei)) + log p(yi|vei)]

(8)

M(cid:80)

(cid:80)

M(cid:80)

(cid:80)

The soft evidence corresponding to messages from the neighboring nodes is obtained by running BP
on the entire training dataset (labeled and unlabeled). The CRF feature weights θks are computed
by solving the WLSE problem (e.q.(7))  θk =

wizinki/

winki

i=1

yi

i=1

yi

Algorithm 1 gives the pseudo-code for sVEB. The main difference between VEB and sVEB are
steps 7 − 10  where we compute wi’s and zi’s for all possible values of yi based on the virtual
evidence and observations of unlabeled training cases. The boosting weights and working responses
are computed using equation (8). The weighted least-square error (WLSE) equation (eq. 7) in step
10 of sVEB is different from that of VEB and the solution results in slightly different CRF feature
weights  θ’s. One of the major advantages of VEB and sVEB over ML and sML is that the parameter
estimation is done by mainly performing feature counting. Unlike ML and sML  we do not need to
use an optimizer to learn the model parameters which results in a huge reduction in the time required
to train the CRF models. Please refer to the complexity analysis section for details.

4 Experiments

We conduct two sets of experiments to evaluate the performance of the sVEB method for training
CRFs and the advantage of performing feature selection as part of semi-supervised training.
In
the ﬁrst set of experiments  we analyze how much the complexity of the underlying CRF and the
tuning parameter α effect the performance using synthetic data. In the second set of experiments  we
evaluate the beneﬁt of feature selection and using unlabeled data on two real-world activity datasets.
We compare the performance of the semi-supervised virtual evidence boosting(sVEB) presented in
this paper to the semi-supervised maximum likelihood (sML) method [10]. In addition  for the ac-
tivity datasets  we also evaluate an alternative approach (sML+Boost)  where a subset of features
is selected in advance using boosting. To benchmark the performance of the semi-supervised tech-
niques  we also evaluate three different supervised training approaches  namely maximum likelihood

4

for t = 1  2 ···   T do

Algorithm 1: Training CRFs using semi-supervised VEB
inputs : structure of CRF and training data (xi  yi)  with yi ∈ {0  1}  1 ≤ i ≤ M  and F0 = 0
output: Learned FT and their corresponding weights  θ
1
2
3
4
5
6
7
8
9
10
11
12

end
Obtain “best” weak learner ft according to equation (7) and update Ft = Ft−1 + ft ;

Compute likelihood p(yi|vei);
Compute wi and zi using equation (8)

Run BP using Ft to get virtual evidences vei;
for i = 1  2 ···   N do

Compute likelihood p(yi|vei);
Compute wi and zi using equation (4)

end
for i = N + 1  ...  M and yi = 0  1 do

end

Figure 1: Accuracy of sML and sVEB for different number of states  local features and different values of α.

method using all observed features(ML)  (ML+Boost) using a subset of features selected in advance 
and virtual evidence boosting (VEB). All the learned models are tested using standard maximum a
posteriori(MAP) estimate and belief propagation. We used a l2-norm shrinkage prior as a regularizer
for the ML and sML methods.

4.1 Synthetic data
The synthetic data is generated using a ﬁrst-order Markov Chain with self-transition probabilities
set to 0.9. For each model  we generate ﬁve sequences of length 4 000 and divide each trace into
sequences of length 200. We randomly choose 50% of them as the labeled and the other 50% as un-
labeled training data. We perform leave-one-out cross-validation and report the average accuracies.
To measure how the complexity of the CRFs affects the performance of the different semi-supervised
methods  we vary the number of local features and the number of states. First  we compare the per-
formance of sVEB and sML on CRFs with increasing the number of features. The number of states
is set to 10 and the number of observation features is varied from 20 to 400 observations. Figure
(1a) shows the average accuracy for the two semi-supervised training methods and their conﬁdence
intervals. The experimental results demonstrate that sVEB outperforms sML as we increase the di-
mension of observations (i.e. the number of local features). In the second experiment  we increase
the number of classes and keep the dimension of observations ﬁxed to 100. Figure (1b) demonstrates
that sVEB again outperforms sML as we increase the number of states. Given the same amount of
training data  sVEB is less likely to overﬁt because of the feature selection step. In both these ex-
periments we set the value of tuning parameter  α  to 1.5. To explore the effect of tuning parameter
α  we vary the value of α from 0.1 to 10   while setting the number of states to 10 and the number
of dimensions to 100. Figure (1c) shows that the performance of both sML and sVEB depends on
the value of α but the accuracy decreases for large α’s similar to the sML results presented in [10].

5

0102030400.60.650.70.750.80.850.9Number of statesAccuracysMLsVEB(b)01002003004005000.50.60.70.80.9Dimension of ObservationsAccuracysMLsVEB(a)02468100.70.750.80.850.90.951Values of αsMLsVEBAccuracy(c)ML+all obs ML+Boost VEB

ML+all obs ML+Boost VEB

Figure 2: An example of a sensor trace and a classiﬁcation trace

Labeled Average Accuracy (%) - Dataset 1
60% 62.7 ± 6.6 69.4 ± 3.9 82.6 ± 7.3
80% 73.0 ± 4.2 81.8 ± 4.7 90.3 ± 4.7
100% 77.8 ± 3.4 87.0 ± 2.3 91.5 ± 3.8

Labeled Average Accuracy (%) - Dataset 2
60% 74.3 ± 3.7 75.8 ± 3.3 88.5 ± 5.1
80% 80.6 ± 2.9 84.8 ± 2.9 93.4 ± 3.8
100% 86.2 ± 3.1 87.5 ± 3.1 93.8 ± 4.6
Table 1: Accuracy ± 95% conﬁdence interval of the supervised algorithms on activity datasets 1 and 2

4.2 Activity dataset
We collected two activity datasets using wearable sensors  which include audio  acceleration  light 
temperature  pressure  and humidity. The ﬁrst dataset contains instances of 8 basic physical activities
(e.g. walking  running  going up/down stairs  going up/down elevator  sitting  standing  and brushing
teeth) from 7 different users. There is on average 30 minutes of data per user and a total of 3.5 hours
of data that is manually labeled for training and testing purposes. The data is segmented into 0.25s
chunks resulting in a total of 49613 data points. For each chunk  we compute 651 features  which
include signal energy in log and linear frequency bands  autocorrelation  different entropy measures 
mean  variances etc. The features are chosen based on what is used in existing activity recognition
literature and a few additional ones that we felt could be useful. During training  the data from
each person is divided into sequences of length 200 and fed into linear chain CRFs as observations.
The second dataset contains instances of 5 different indoor activities (e.g. computer usage  meal 
meeting  watching TV and sleeping) from a single user. We recorded 15 hours of sensor traces over
12 days. As this set contains longer time-scale activities  the data is segmented into 1 minute chunks
and 321 different features are computed  similar to the ﬁrst dataset. There are a total of 907 data
points. These features are fed into CRFs as observations  one linear chain CRF is created per day.
We evaluate the performance of supervised and semi-supervised training algorithms on these two
datasets. For the semi-supervised case  we randomly select 40% of the sequences for a given person
or a given day as labeled and a different subset as the unlabeled training data. We compare the
performance of sML and sVEB as we incorporate more unlabeled data (20%  40% and 60%) into
the training process. We also compare the supervised techniques  ML  ML+Boost  and VEB  with
increasing amount of labeled data. For all the experiments  the tuning parameter α is set to 1.5. We
perform leave-one-person-out cross-validation on dataset 1 and leave-one-day-out cross-validation
on dataset 2 and report the average the accuracies. The number of features chosen (i. e. through
the boosting iterations) is set to 50 for both datasets – including more features did not signiﬁcantly
improve the classiﬁcation performance.
For both datasets  incorporating more unlabeled data improves accuracy. The sML estimate of the
CRF parameters performs the worst. Even with the shrinkage prior  the high dimensionality can still
cause over-ﬁtting and lower the accuracy. Whereas parameter estimation and feature selection via
sVEB consistently results in the highest accuracy. The (sML+Boost) method performs better than
sML but does not perform as well as when feature selection and parameter estimation is done within
a uniﬁed framework as in sVEB. Table 2 summarize our results. The results of supervised learn-

Average Accuracy (%) - Dataset 1
Un-
sVEB
labeled sML+all obs sML+Boost
20% 60.8 ± 5.4 66.4 ± 4.2 72.6 ± 2.3
40% 68.1 ± 4.8 76.8 ± 3.4 78.5 ± 3.4
60% 74.9 ± 3.1 81.3 ± 3.9 85.3 ± 4.1

Average Accuracy (%) - Dataset 2
Un-
sVEB
labeled sML+all obs sML+Boost
20% 71.4 ± 3.2 70.5 ± 5.3 79.9 ± 4.2
40% 73.5 ± 5.8 74.1 ± 4.6 83.5 ± 6.3
60% 75.6 ± 3.9 77.8 ± 3.2 87.4 ± 4.7

Table 2: Accuracy ± 95% conﬁdence interval of semi-supervised algorithms on activity datasets 1 and 2

6

TimeClasses1000200030004000500012345678Sensor TracesTimeGround truthInferenceML+all obs ML+Boost VEB

Labeled Average Accuracy (%) - Dataset 2
5% 59.2 ± 6.5 65.7 ± 8.3 71.2 ± 5.7
20% 66.9 ± 5.9 67.3 ± 8.5 77.4 ± 3.6

Labeled Average Accuracy (%) - Dataset 2
5% 71.2 ± 4.1 68.3 ± 6.7 79.7 ± 7.9
20% 71.4 ± 6.3 73.8 ± 5.2 83.1 ± 6.4
Table 3: Accuracy ± 95% conﬁdence interval of semi-supervised algorithms on activity datasets 1 and 2

ML+all obs ML+Boost VEB

ing algorithms are presented in Table 1. Similar to the semi-supervised results  the VEB method
performs the best  the ML is the worst performer  and the accuracy numbers for the (ML+Boost)
method is in between. The accuracy increases if we incorporate more labeled data during training.
To evaluate sVEB when a small amount of labeled data is available  we performed another set of
experiments on datasets 1 and 2  where only 5% and 20% of the training data is labeled respec-
tively. We used all the available unlabeled data during training. The results are shown in table 3.
These experiments clearly demonstrate that although adding more unlabeled data is not as helpful
as incorporating more labeled data  the use of cheap unlabeled data along with feature selection can
signiﬁcantly boost the performance of the models.
4.3 Complexity Analysis
The sVEB and VEB algorithm are signiﬁcantly faster than ML and sML because they do not need
to use optimizers such as quasi-newton methods to learn the weight parameters. For each training
iteration in sML the cost of running BP is O(clns2 + cun2s3) [10] whereas the cost of each boosting
iteration in sVEB is O((cl + cu)ns2). An efﬁcient entropy gradient computation is proposed in [17] 
which reduces the cost of sML to O((cl + cu)ns2) but still requires an optimizer to maximize the
log-likelihood. Moreover  the number of training iterations needed is usually much higher than the
number of boosting iterations because optimizers such as L-BFGS require many more iterations to
reach convergence in high dimensional spaces. For example  for dataset 1  we needed about 1000
iterations for sML to converge but we ran sVEB for only 50 iterations. Table 4 shows the time for
performing the experiments on activity datasets (as described in the previous section) 2. On the
other hand the space complexity of sVEB is linearly smaller than sML and ML. Similar to ML  sML
has the space complexity of O(ns2D) in the best case [10]. VEB and sVEB have a lower space
cost of O(ns2Db)  because of the feature selection step Db (cid:191) D usually. Therefore  the difference
becomes signiﬁcant when we are dealing with high dimensional data  particularly if they include a
large number of redundant features.

Time (hours)

ML ML+Boost VEB sML sML+Boost sVEB

Dataset 1 34
Dataset 2 7.5

18
4.25

5 Conclusion

2.5 96
0.4 10.5
Table 4: Training time for the different algorithms.

4
0.6

D  Db

48
8

n
cl
cu
s

length of training sequence
number of labeled training sequences
number of unlabeled training sequences
number of states
dimension of observations

We presented sVEB  a new semi-supervised training method for CRFs  that can simultaneously
select discriminative features via modiﬁed LogitBoost and utilize unlabeled data via minimum-
entropy regularization. Our experimental results demonstrate the sVEB signiﬁcantly outperforms
other training techniques in real-world activity recognition problems. The uniﬁed framework for
feature selection and semi-supervised training presented in this paper reduces the computational and
human labeling costs  which are often the major bottlenecks in building large classiﬁcation systems.

Acknowledgments
The authors would like to thank Nando de Freitas and Lin Liao for many helpful discussions. This work was
supported by the NSF under grant number IIS 0433637 and NSERC Canada Graduate Scholarship.

References
[1] J. Lafferty  A. McCallum  and F. Pereira. Conditional random ﬁelds: Probabilistic models for segmenting
and labeling sequence data. In Proc. of the International Conference on Machine Learning (ICML)  2001.

2The experiments were run in Matlab environment and as a result they took longer.

7

[2] Andrew McCallum. Efﬁciently inducing features or conditional random ﬁelds. In Proc. of the Conference

on Uncertainty in Artiﬁcial Intelligence (UAI)  2003.

[3] T. Dietterich  A. Ashenfelter  and Y. Bulatov. Training conditional random ﬁelds via gradient tree boost-

ing. In Proc. of the International Conference on Machine Learning (ICML)  2004.

[4] A. Torralba  K. P. Murphy  and W. T. Freeman. Contextual models for object detection using boosted

random ﬁelds. In Advances in Neural Information Processing Systems (NIPS)  2004.

[5] L. Liao  T. Choudhury  D. Fox  and H Kautz. Training conditional random ﬁelds using virtual evidence

boosting. In Proc. of the International Joint Conference on Artiﬁcial Intelligence (IJCAI)  2007.

[6] K. Nigam  A. McCallum  A. Thrun  and T. Mitchell. Text classiﬁcation from labeled and unlabeled

documents using em. Machine learning  2000.

[7] A. Zhu  Z. Ghahramani  and J. Lafferty. Semi-supervised learning using gaussian ﬁelds and harmonic

functions. In Proc. of the International Conference on Machine Learning (ICML)  2003.

[8] W. Li and M. Andrew. Semi-supervised sequence modeling with syntactic topic models. In Proc. of the

National Conference on Artiﬁcial Intelligence (AAAI)  2005.

[9] Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. In Advances in Neural

Information Processing Systems (NIPS)  2004.

[10] F. Jiao  W. Wang  C. H. Lee  R. Greiner  and D. Schuurmans. Semi-supervised conditional random
ﬁelds for improved sequence segmentation and labeling. In International Committee on Computational
Linguistics and the Association for Computational Linguistics  2006.

[11] C. Lee  S. Wang  F. Jiao  Schuurmans D.  and R. Greiner. Learning to Model Spatial Dependency: Semi-

Supervised Discriminative Random Fields. In NIPS  2006.

[12] J.S. Yedidia  W.T. Freeman  and Y. Weiss. Constructing free-energy approximations and generalized

belief propagation algorithms. IEEE Transactions on Information Theory  51(7):2282–2312  2005.

[13] Y. Weiss. Comparing mean ﬁeld method and belief propagation for approximate inference in mrfs. 2001.
[14] J. Besag. Statistical analysis of non-lattice data. The Statistician  24  1975.
[15] C. J. Geyer and E. A. Thompson. Constrained Monte Carlo Maximum Likelihood for dependent data.

Journal of Royal Statistical Society  1992.

[16] Jerome Friedman  Trevor Hastie  and Robert Tibshirani. Additive logistic regression: a statistical view of

boosting. The Annals of Statistics  38(2):337–374  2000.

[17] G. Mann and A. McCullum. Efﬁcient computation of entropy gradient for semi-supervised conditional

random ﬁelds. In Human Language Technologies  2007.

6 Appendix

In this section  we show how we derived the equations for wi and zi (eq. 8):
LF = LsV EB = LV EB − αHemp =
p(y(cid:48)

log p(yi|vei) + α

i|vei) log p(y(cid:48)

i|vei)

As in LogitBoost  the likelihood function LF is maximized by learning an ensemble of weak learners. We start
with an empty ensemble F = 0 and iteratively add the next best weak learner  ft  by computing the Newton
update s
F (vei  yi)) ← F (vei  yi) − s

H   where s and H are the ﬁrst and second derivative respectively of LF with respect to f (vei  yi).

|f =0 and H = ∂2LF +f

H   where s = ∂LF +f

∂f

2(2yi − 1)(1 − p(yi|vei)) + α

[2(2y(cid:48)

i − 1)(1 − p(y(cid:48)

i|vei)(1 − log p(y(cid:48)

i|vei))]

∂f 2

|f =0
i|vei))p(y(cid:48)

M2i=N +12y(cid:48)

i

N2i=1

M2i=N +12y(cid:48)

i

i|vei)) + log p(y(cid:48)

s =

p(y(cid:48)

N2i=1
H = − N2i=1
N2i=1
N2i=1

F ← F +

ziwi+

ziwi

i|vei)]
M2i=N+12y(cid:48)
M2i=N+12y(cid:48)
α2(1 − p(y(cid:48)

wi+

i

i

wi

and wi = p(yi|vei)(1 − p(yi|vei))

i|vei))[p(y(cid:48)

4p(yi|vei)(1 − p(yi|vei))(2yi − 1)2 + α2

4(2y(cid:48)

i − 1)2(1 − p(y(cid:48)

i|vei))[p(y(cid:48)

i|vei)(1 −

M2i=N +12y(cid:48)

i

where zi = yi−0.5

p(yi|vei)
(y(cid:48)
α[p(y(cid:48)

i−0.5)p(y(cid:48)
i|vei)(1−p(y(cid:48)

i|vei)(1−log p(y(cid:48)

i|vei))+log p(y(cid:48)

i|vei))

i|vei)]

if 1 ≤ i ≤ N
eq. (4)
if N < i ≤ M eq. (8)

i|vei)(1 − p(y(cid:48)

i|vei)) + log p(y(cid:48)

i|vei)]

if 1 ≤ i ≤ N eq. (4)
if N < i ≤ M eq. (8)

At iteration t we get the best weak learner  ft  by solving the WLSE problem in eq. 7.

8

,Hyun Oh Song
Yong Jae Lee
Stefanie Jegelka
Trevor Darrell