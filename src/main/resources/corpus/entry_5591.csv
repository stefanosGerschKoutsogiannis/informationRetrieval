2018,TopRank: A practical algorithm for online stochastic ranking,Online learning to rank is a sequential decision-making problem where in each round the learning agent chooses a list of items and receives feedback in the form of clicks from the user. Many sample-efficient algorithms have been proposed for this problem that assume a specific click model connecting rankings and user behavior. We propose a generalized click model that encompasses many existing models  including the position-based and cascade models. Our generalization motivates a novel online learning algorithm based on topological sort  which we call TopRank. TopRank is (a) more natural than existing algorithms  (b) has stronger regret guarantees than existing algorithms with comparable generality  (c) has a more insightful proof that leaves the door open to many generalizations  (d) outperforms existing algorithms empirically.,TopRank: A Practical Algorithm for Online

Stochastic Ranking

Tor Lattimore

DeepMind

Branislav Kveton

Google

Shuai Li

The Chinese University of Hong Kong

Csaba Szepesvári

DeepMind and University of Alberta

Abstract

Online learning to rank is a sequential decision-making problem where in each
round the learning agent chooses a list of items and receives feedback in the form
of clicks from the user. Many sample-efﬁcient algorithms have been proposed
for this problem that assume a speciﬁc click model connecting rankings and user
behavior. We propose a generalized click model that encompasses many existing
models  including the position-based and cascade models. Our generalization
motivates a novel online learning algorithm based on topological sort  which we
call TopRank. TopRank is (a) more natural than existing algorithms  (b) has
stronger regret guarantees than existing algorithms with comparable generality  (c)
has a more insightful proof that leaves the door open to many generalizations  and
(d) outperforms existing algorithms empirically.

1

Introduction

Learning to rank is an important problem with numerous applications in web search and recommender
systems [11]. Broadly speaking  the goal is to learn an ordered list of K items from a larger collection
of size L that maximizes the satisfaction of the user  often conditioned on a query. This problem has
traditionally been studied in the ofﬂine setting  where the ranking policy is learned from manually-
annotated relevance judgments. It has been observed that the feedback of users can be used to
signiﬁcantly improve existing ranking policies [1  16]. This is the main motivation for online learning
to rank  where the goal is to adaptively maximize the user satisfaction.
Numerous methods have been proposed for online learning to rank  both in the adversarial [12  13]
and stochastic settings. Our focus is on the stochastic setup where recent work has leveraged click
models to mitigate the curse of dimensionality that arises from the combinatorial nature of the
action-set. A click model is a model for how users click on items in rankings and is widely studied by
the information retrieval community [2]. One popular click model in learning to rank is the cascade
model (CM)  which assumes that the user scans the ranking from top to bottom  clicking on the ﬁrst
item they ﬁnd attractive [6  3  7  18  10  5]. Another model is the position-based model (PBM)  where
the probability that the user clicks on an item depends on its position and attractiveness  but not on
the surrounding items [8].
The cascade and position-based models have relatively few parameters  which is both a blessing and
a curse. On the positive side  a small model is easy to learn. More negatively  there is a danger that a
simplistic model will have a large approximation error. In fact  it has been observed experimentally
that no single existing click model captures the behavior of an entire population of users [4]. Zoghi
et al. [17] recently showed that under reasonable assumptions a single online learning algorithm can

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

learn the optimal list of items in a much larger class of click models that includes both the cascade
and position-based models.
We build on the work of Zoghi et al. [17] and generalize it non-trivially in multiple directions. First 
we propose a general model of user interaction where the problem of ﬁnding most attractive list
can be posed as a sorting problem with noisy feedback. An interesting characteristic of our model
is that the click probability does not factor into the examination probability of the position and the
attractiveness of the item at that position. Second  we propose an online learning algorithm for ﬁnding
the most attractive list  which we call TopRank. The key idea in the design of the algorithm is to
maintain a partial order over the items that is reﬁned as the algorithm observes more data. The new
algorithm is simultaneously simpler  more principled and empirically outperforms the algorithm of
Zoghi et al. [17]. We also provide an analysis of the cumulative regret of TopRank that is simple 
insightful and strengthens the results by Zoghi et al. [17]  despite the weaker assumptions.

2 Online learning to rank

We assume the total numbers of items L is larger than the number of available slots K and that the
collection of items is [L] = {1  2  . . .   L}. A permutation on ﬁnite set X is an invertible function
σ : X → X and the set of all permutations on X is denoted by Π(X). The set of actions A is the set
of permutations Π([L])  where for each a ∈ A the value a(k) should be interpreted as the identity
of the item placed at the kth position. Equivalently  item i is placed at position a−1(i). The user
does not observe items in positions k > K so the order of a(k + 1)  . . .   a(L) is not important and is
included only for notational convenience. We adopt the convention throughout that i and j represent
items while k represents a position.
The online ranking problem proceeds over n rounds. In each round t the learner chooses an action
At ∈ A based on its observations so far and observes binary random variables Ct1  . . .   CtL where
Cti = 1 if the user clicked on item i. We assume a stochastic model where the probability that the
user clicks on position k in round t only depends on At and is given by

P(CtAt(k) = 1 | At = a) = v(a  k)

(cid:34) n(cid:88)

K(cid:88)

t=1

k=1

with v : A × [L] → [0  1] an unknown function. Another way of writing this is that the conditional
probability that the user clicks on item i in round t is P(Cti = 1 | At = a) = v(a  a−1(i)).
The performance of the learner is measured by the expected cumulative regret  which is the deﬁcit
suffered by the learner relative to the omniscient strategy that knows the optimal ranking in advance.

K(cid:88)

(cid:34) n(cid:88)

L(cid:88)

(cid:35)

(cid:35)

Rn = n max
a∈A

v(a  k) − E

k=1

t=1

i=1

Cti

= max
a∈A

E

(v(a  k) − v(At  k))

.

Remark 1. We do not assume that Ct1  . . .   CtL are independent or that the user can only click on
one item.

3 Modeling assumptions

In previous work on online learning to rank it was assumed that v factors into v(a  k) =
α(a(k))χ(a  k) where α : [L] → [0  1] is the attractiveness function and χ(a  k) is the probability
that the user examines position k given ranking a. Further restrictions are made on the examination
function χ. For example  in the document-based model it is assumed that χ(a  k) = 1{k ≤ K}. In
this work we depart from this standard by making assumptions directly on v. The assumptions are
sufﬁciently relaxed that the model subsumes the document-based  position-based and cascade models 
as well as the factored model studied by Zoghi et al. [17]. See the supplementary material for a proof
of this. Our ﬁrst assumption uncontroversially states that the user does not click on items they cannot
see.
Assumption 1. v(a  k) = 0 for all k > K.

Although we do not assume an explicit factorization of the click probability into attractiveness and
examination functions  we do assume there exists an unknown attractiveness function α : [L] → [0  1]
that satisﬁes the following assumptions. In all classical click models the optimal ranking is to sort the

2

2)

erf(

d ← 0

while [L] \(cid:83)d

Algorithm 1 TopRank
√
1: G1 ← ∅ and c ← 4
√
2/π
2: for t = 1  . . .   n do
3:
4:
5:
6:
7:
8:
9:

d ← d + 1
Ptd ← minGt

10:

Utij ←

Stij ←(cid:80)t
12: Gt+1 ← Gt ∪(cid:110)

11:

Choose At uniformly at random from A(Pt1  . . .  Ptd)
Observe click indicators Cti ∈ {0  1} for all i ∈ [L]
for all (i  j) ∈ [L]2 do

(cid:17)

c=1 Ptc

[L] \(cid:83)d−1

(cid:16)
c=1 Ptc (cid:54)= ∅ do
(cid:26)Cti − Ctj
s=1 Usij and Ntij ←(cid:80)t
(j  i) : Stij ≥(cid:113)

if i  j ∈ Ptd for some d
otherwise
s=1 |Usij|

2Ntij log(cid:0) c

0

δ

(cid:112)Ntij

(cid:111)
(cid:1) and Ntij > 0

items in order of decreasing attractiveness. Rather than deriving this from other assumptions  we will
simply assume that v satisﬁes this criteria. We call action a optimal if α(a(k)) = maxk(cid:48)≥k α(a(k(cid:48)))
for all k ∈ [K]. The optimal action need not be unique if α is not injective  but the sequence
α(a(1))  . . .   α(a(K)) is the same for all optimal actions.

Assumption 2. Let a∗ ∈ A be an optimal action. Then maxa∈A(cid:80)K

k=1 v(a  k) =(cid:80)K

k=1 v(a∗  k).

a

a(cid:48)

The next assumption asserts that if a is an action and i is more
attractive than j  then exchanging the positions of i and j can
only decrease the likelihood of clicking on the item in slot a−1(i).
Fig. 1 illustrates the two cases. The probability of clicking on
the second position is larger in a than in a(cid:48). On the other hand 
the probability of clicking on the fourth position is larger in a(cid:48)
than in a. The assumption is actually slightly stronger than this
Figure 1: The probability of clicking
because it also speciﬁes a lower bound on the amount by which
on the second position is larger in a
than a(cid:48). The pattern reverses for the
one probability is larger than another in terms of the attractiveness
function.
fourth position.
Assumption 3. Let i and j be items with α(i) ≥ α(j) and let σ : A → A be the permutation that
exchanges i and j and leaves other items unchanged. Then for any action a ∈ A 

1
2
3
4
5

j

i

j

i

v(a  a−1(i)) ≥ α(i)
α(j)

v(σ ◦ a  a−1(i)) .

Our ﬁnal assumption is that for any action a with α(a(k)) = α(a∗(k)) the probability of clicking on
the kth position is at least as high as the probability of clicking on the kth position for the optimal
action. This assumption makes sense if the user is scanning the items from the ﬁrst position until
the last  clicking on items they ﬁnd attractive until some level of satisfaction is reached. Under this
assumption the user is least likely to examine position k under the optimal ranking.
Assumption 4. For any action a and optimal action a∗ with α(a(k)) = α(a∗(k)) it holds that
v(a  k) ≥ v(a∗  k).

4 Algorithm
Before we present our algorithm  we introduce some basic notation. Given a relation G ⊆ [L]2 and
X ⊆ [L]  let minG(X) = {i ∈ X : (i  j) /∈ G for all j ∈ X}. When X is nonempty and G does not
have cycles  then minG(X) is nonempty. Let P1  . . .  Pd be a partition of [L] so that ∪c≤dPc = [L]
and Pc ∩ Pc(cid:48) = ∅ for any c (cid:54)= c(cid:48). We refer to each subset in the partition  Pc for c ≤ d  as a block.
Let A(P1  . . .  Pd) be the set of actions a where the items in P1 are placed at the ﬁrst |P1| positions 

3

the items in P2 are placed at the next |P2| positions  and so on. Speciﬁcally 

A(P1  . . .  Pd) =(cid:8)a ∈ A : maxi∈Pc a−1(i) ≤ mini∈Pc+1 a−1(i) for all c ∈ [d − 1](cid:9) .

Our algorithm is presented in Algorithm 1. We call it TopRank  because it maintains a topological
order of items in each round. The order is represented by relation Gt  where G1 = ∅. In each round 
TopRank computes a partition of [L] by iteratively peeling off minimum items according to Gt. Then
it randomizes items in each block of the partition and maintains statistics on the relative number of
clicks between pairs of items in the same block. A pair of items (j  i) is added to the relation once
item i receives sufﬁciently more clicks than item j during rounds where the items are in the same
block. The reader should interpret (j  i) ∈ Gt as meaning that TopRank collected enough evidence
up to round t to conclude that α(j) < α(i).
Remark 2. The astute reader will notice that the algorithm is not well deﬁned if Gt contains cycles.
The analysis works by proving that this occurs with low probability and the behavior of the algorithm
may be deﬁned arbitrarily whenever a cycle is encountered. Assumption 1 means that items in
position k > K are never clicked. As a consequence  the algorithm never needs to actually compute
the blocks Ptd where minItd > K because items in these blocks are never shown to the user.
Shortly we give an illustration of the algorithm  but ﬁrst introduce the notation to be used in the
analysis. Let Itd be the slots of the ranking where items in Ptd are placed 

Itd = [|∪c≤dPtc|] \ [|∪c<dPtc|] .

Furthermore  let Dti be the block with item i  so that i ∈ PtDti. Let Mt = maxi∈[L] Dti be the
number of blocks in the partition in round t.

4

2

Illustration Suppose L = 5 and K = 4 and in round
t the relation is Gt = {(3  1)  (5  2)  (5  3)}. This indi-
cates the algorithm has collected enough data to believe
that item 3 is less attractive than item 1 and that item
5 is less attractive than items 2 and 3. The relation is
depicted in Fig. 2 where an arrow from j to i means
that (j  i) ∈ Gt. In round t the ﬁrst three positions in
the ranking will contain items from Pt1 = {1  2  4} 
but with random order. The fourth position will be item
3 and item 5 is not shown to the user. Note that Mt = 3
here and Dt2 = 1 and Dt5 = 3.
Remark 3. TopRank is not an elimination algorithm. In the scenario described above  item 5 is not
shown to the user  but it could happen that later (4  2) and (4  3) are added to the relation and then
TopRank will start randomizing between items 4 and 5 for the fourth position.

Pt1
Pt2
Pt3
Figure 2: Illustration of partition produced by
topological sort

It1 = {1  2  3}
It2 = {4}
It3 = {5}

1

3

5

5 Regret analysis
Theorem 1. Let function v satisfy Assumptions 1–4 and α(1) > α(2) > ··· > α(L). Let ∆ij =
α(i) − α(j) and δ ∈ (0  1). Then the n-step regret of TopRank is bounded from above as

Furthermore  Rn ≤ δnKL2 + KL +

4K 3Ln log

By choosing δ = n−1 the theorem shows that the expected regret is at most

 L(cid:88)

min{K j−1}(cid:88)

Rn = O

j=1

i=1



α(i) log(n)

∆ij

(cid:16)(cid:112)K 3Ln log(n)
(cid:17)

.

and

Rn = O

4

Rn ≤ δnKL2 +

L(cid:88)

j=1

min{K j−1}(cid:88)
(cid:115)

i=1

1 +
(cid:18) c

6(α(i) + α(j)) log

∆ij

(cid:19)

.

n

√

δ

(cid:16) c

√

δ

n

(cid:17)

 .

The algorithm does not make use of any assumed ordering on α(·)  so the assumption is only used
to allow for a simple expression for the regret. The only algorithm that operates under comparably
general assumptions is BatchRankfor which the problem-dependent regret is a factor of K 2 worse and
the dependence on the suboptimality gap is replaced by a dependence on the minimal suboptimality
gap.
The core idea of the proof is to show that (a) if the algorithm is suffering regret as a consequence
of misplacing an item  then it is gaining information about the relation of the items so that Gt
will gain elements and (b) once Gt is sufﬁciently rich the algorithm is playing optimally. Let
Ft = σ(A1  C1  . . .   At  Ct) and Pt(·) = P(· | Ft) and Et[·] = E [· | Ft]. For each t ∈ [n] let Ft to
be the failure event that there exists i (cid:54)= j ∈ [L] and s < t such that Nsij > 0 and

Eu−1 [Uuij | Uuij (cid:54)= 0]|Uuij|

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥(cid:113)

2Nsij log(c(cid:112)Nsij/δ) .

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Ssij − s(cid:88)

u=1

Lemma 1. Let i and j satisfy α(i) ≥ α(j) and d ≥ 1. On the event that i  j ∈ Psd and d ∈ [Ms]
and Usij (cid:54)= 0  the following hold almost surely:

(a) Es−1[Usij | Usij (cid:54)= 0] ≥

∆ij

α(i) + α(j)

(b) Es−1[Usji | Usji (cid:54)= 0] ≤ 0 .

Proof. For the remainder of the proof we focus on the event that i  j ∈ Psd and d ∈ [Ms] and
Usij (cid:54)= 0. We also discard the measure zero subset of this event where Ps−1(Usij (cid:54)= 0) = 0.
From now on we omit the ‘almost surely’ qualiﬁcation on conditional expectations. Under these
circumstances the deﬁnition of conditional expectation shows that

Es−1[Usij | Usij (cid:54)= 0] =

Ps−1(Csi = 1  Csj = 0) − Ps−1(Csi = 0  Csj = 1)
Ps−1(Csi (cid:54)= Csj)
≥ Ps−1(Csi = 1) − Ps−1(Csj = 1)
Ps−1(Csi = 1) + Ps−1(Csj = 1)

Ps−1(Csi = 1) − Ps−1(Csj = 1)

Ps−1(Csi (cid:54)= Csj)

=

=

Es−1[v(As  A−1
Es−1[v(As  A−1

s (i)) − v(As  A−1
s (i)) + v(As  A−1

s (j))]
s (j))]

 

(1)

where in the second equality we added and subtracted Ps−1(Csi = 1  Csj = 1). By the design of
TopRank  the items in Ptd are placed into slots Itd uniformly at random. Let σ be the permutation
that exchanges the positions of items i and j. Then using Assumption 3 
Es−1[v(As  A−1

Ps−1(As = a)v(σ ◦ a  a−1(i))

Ps−1(As = a)v(a  a−1(i)) ≥ α(i)
α(j)

(cid:88)

(cid:88)

s (i))] =

a∈A

(cid:88)

a∈A

=

α(i)
α(j)

Ps−1(As = σ ◦ a)v(σ ◦ a  (σ ◦ a)−1(j)) =

a∈A
Es−1[v(As  A−1

s (j))]  

α(i)
α(j)

where the second equality follows from the fact that a−1(i) = (σ ◦ a)−1(j) and the deﬁnition of the
algorithm ensuring that Ps−1(As = a) = Ps−1(As = σ ◦ a). The last equality follows from the fact
that σ is a bijection. Using this and continuing the calculation in Eq. (1) shows that
Es−1
Es−1

s (j))(cid:3)
s (j))(cid:3) = 1 −

s (j))(cid:3)
(cid:2)v(As  A−1

(cid:2)v(As  A−1
(cid:2)v(As  A−1

s (i)) − v(As  A−1
s (i)) + v(As  A−1

s (i))(cid:3) /Es−1

(cid:2)v(As  A−1

2

1 + Es−1
2

1 + α(i)/α(j)

≥ 1 −

α(i) − α(j)
α(i) + α(j)

=

=

∆ij

α(i) + α(j)

.

The second part follows from the ﬁrst since Usji = −Usij.

The next lemma shows that the failure event occurs with low probability.
Lemma 2. It holds that P(Fn) ≤ δL2.

Proof. The proof follows immediately from Lemma 1  the deﬁnition of Fn  the union bound over all
pairs of actions  and a modiﬁcation of the Azuma-Hoeffding inequality in Lemma 6.

5

Lemma 3. On the event F c

Proof. Let i < j so that α(i) ≥ α(j). On the event F c

t either Nsji = 0 or

t it holds that (i  j) /∈ Gt for all i < j.
(cid:16) c

(cid:114)

2Nsji log

δ

Eu−1[Uuji | Uuji (cid:54)= 0]|Uuji| <

(cid:17)

(cid:112)Nsji

Ssji − s(cid:88)

u=1

for all s < t .

When i and j are in different blocks in round u < t  then Uuji = 0 by deﬁnition. On the other hand 
when i and j are in the same block  Eu−1[Uuji | Uuji (cid:54)= 0] ≤ 0 almost surely by Lemma 1. Based
on these observations 

(cid:114)

(cid:17)

(cid:112)Nsji

(cid:16) c

δ

Ssji <

2Nsji log

for all s < t  

which by the design of TopRank implies that (i  j) /∈ Gt.
Lemma 4. Let I∗
I∗

td ≤ 1 +(cid:80)
Proof. Let i∗ = min∪c≥dPtc. Then i∗ ≤ 1 +(cid:80)

c<d |Ptd| for all d ∈ [Mt].

td = minPtd be the most attractive item in Ptd. Then on event F c

t   it holds that

c<d |Ptd| holds trivially for any Pt1  . . .  PtMt and
d ∈ [Mt]. Now consider two cases. Suppose that i∗ ∈ Ptd. Then it must be true that i∗ = I∗
td and
our claim holds. On other hand  suppose that i∗ ∈ Ptc for some c > d. Then by Lemma 3 and the
design of the partition  there must exist a sequence of items id  . . .   ic in blocks Ptd  . . .  Ptc such
that id < ··· < ic = i∗. From the deﬁnition of I∗

td ≤ id < i∗. This concludes our proof.

td  I∗

Lemma 5. On the event F c

n and for all i < j it holds that Snij ≤ 1 +

6(α(i) + α(j))

∆ij

log

(cid:18) c

(cid:19)

.

√

δ

n

Proof. The result is trivial when Nnij = 0. Assume from now on that Nnij > 0. By the deﬁnition
of the algorithm arms i and j are not in the same block once Stij grows too large relative to Ntij 
which means that

(cid:114)

Snij ≤ 1 +

2Nnij log

On the event F c

n and part (a) of Lemma 1 it also follows that

Combining the previous two displays shows that

Snij ≥ ∆ijNnij
α(i) + α(j)

−

(cid:114)

(cid:16) c

δ

(cid:112)Nnij

∆ijNnij

α(i) + α(j)

−

2Nnij log

.

δ

δ

(cid:17)
(cid:112)Nnij
(cid:114)

(cid:16) c

2Nnij log

(cid:112)Nnij
(cid:114)
(cid:16) c
(cid:17) ≤ Snij ≤ 1 +
(cid:114)
(cid:18) c

≤ (1 +

√

√

n

log

δ

(cid:17)

.

(cid:19)

.

2Nnij log

(cid:17)

(cid:16) c
(cid:112)Nnij
(cid:17)
(cid:112)Nnij

δ

(cid:16) c

.
Using the fact that Nnij ≤ n and rearranging the terms in the previous display shows that

Nnij log

2)

δ

(2)

√

Nnij ≤ (1 + 2

2)2(α(i) + α(j))2

∆2
ij

The result is completed by substituting this into Eq. (2).

Proof of Theorem 1. The ﬁrst step in the proof is an upper bound on the expected number of clicks
in the optimal list a∗. Fix time t  block Ptd  and recall that I∗
td = minPtd is the most attractive
item in Ptd. Let k = A−1
td and σ be the permutation that exchanges
td ≤ k; and then from Assumptions 3 and 4  we have that
items k and I∗

td) be the position of item I∗

td. By Lemma 4  I∗

t (I∗

6

v(At  k) ≥ v(σ ◦ At  k) ≥ v(a∗  k). Based on this result  the expected number of clicks on I∗
bounded from below by those on items in a∗ 
t (I∗

td) = k)Et−1[v(At  k) | A−1

(cid:2)CtI∗

Pt−1(A−1

(cid:3) =

(cid:88)

t (I∗

td) = k]

Et−1

td

td is

Et−1[v(At  k) | A−1

t (I∗

td) = k] ≥ 1
|Itd|

v(a∗  k)  

(cid:88)

k∈Itd

where we also used the fact that TopRank randomizes within each block to guarantee that
Pt−1(A−1

td) = k) = 1/|Itd| for any k ∈ Itd. Using this and the design of TopRank 

t (I∗

k∈Itd
1
|Itd|

=

(cid:88)

k∈Itd

v(a∗  k) =

Therefore  under event F c

t   the conditional expected regret in round t is bounded by

k=1

K(cid:88)
 L(cid:88)

j=1

(CtI∗

td

K(cid:88)

v(a∗  k) − Et−1

 Mt(cid:88)

d=1

(cid:88)

j∈Ptd

k=1

= Et−1

Ctj

− Ctj)

td

d=1

d=1

k∈Itd

(cid:3) .

|Ptd|CtI∗

|Itd|Et−1

(cid:88)
Mt(cid:88)
v(a∗  k) ≤ Mt(cid:88)
 ≤ Et−1
 Mt(cid:88)
 =
(cid:88)
Mt(cid:88)

(cid:2)CtI∗

− L(cid:88)
min{K j−1}(cid:88)
tdj] ≤ L(cid:88)
tdj] ≤(cid:80)min{K j−1}
min{K j−1}(cid:88)

Et−1[UtI∗

L(cid:88)

j∈Ptd

Ctj

d=1

d=1

j=1

j=1

i=1

td

E [1{F c

n} Snij]  

j=1

i=1

Rn ≤ nKP(Fn) +

The last inequality follows by noting that Et−1[UtI∗
part (a) of Lemma 1 to show that Et−1[Utij] ≥ 0 for i < j and Lemma 4 to show that when I∗
then neither I∗
in Eq. (3) into the regret leads to

Et−1[Utij]. To see this use
td > K 
tdj = 0. Substituting the bound

td nor j are not shown to the user in round t so that UtI∗

i=1

Et−1 [Utij] .

(3)

(4)

where we used the fact that the maximum number of clicks over n rounds is nK. The proof of the
ﬁrst part is completed by using Lemma 2 to bound the ﬁrst term and Lemma 5 to bound the second.
The problem independent bound follows from Eq. (4) and by stopping early in the proof of Lemma 5.
The details are given in the supplementary material.

Lemma 6. Let (Ft)n

variables with Xt ∈ {−1  0  1} and µt = E[Xt | Ft−1  Xt (cid:54)= 0]. Then with St = (cid:80)t
µs|Xs|) and Nt =(cid:80)t
exists t ≤ n : |St| ≥
4(cid:112)2/π

t=0 be a ﬁltration and X1  X2  . . .   Xn be a sequence of Ft-adapted random
s=1(Xs −
(cid:115)
s=1 |Xs| 

 ≤ δ   where c =

and Nt > 0

≈ 3.43 .

(cid:18) c

2Nt log

(cid:19)

√

P

√
erf(

2)

Nt
δ

See the supplementary material for the proof.
We also provide a minimax lower bound  the proof of which is deferred to the supplementary material.
Theorem 2. Suppose that L = N K with N an integer and n ≥ K and n ≥ N and N ≥ 8. Then
for any algorithm there exists a ranking problem such that E[Rn] ≥ √

√
KLn/(16

2).

The proof of this result only makes use of ranking problems in the document-based model. This also
corresponds to a lower bound for m-sets in online linear optimization with semi-bandit feedback.
Despite the simple setup and abundant literature  we are not aware of any work where a lower bound
of this form is presented for this unstructured setting.

7

6 Experiments

We experiment with the Yandex dataset [15]  a dataset of 167 million search queries. In each query 
the user is shown 10 documents at positions 1 to 10 and the search engine records the clicks of the
user. We select 60 frequent search queries from this dataset  and learn their CMs and PBMs using
PyClick [2]. The parameters of the models are learned by maximizing the likelihood of observed
clicks. Our goal is to rerank L = 10 most attractive items with the objective of maximizing the
expected number of clicks at the ﬁrst K = 5 positions. This is the same experimental setup as in
Zoghi et al. [17]. This is a realistic scenario where the learning agent can only rerank highly attractive
items that are suggested by some production ranker [16].
TopRank is compared to BatchRank [17] and CascadeKL-UCB [6]. We used the implementation of
BatchRank by Zoghi et al. [17]. We do not compare to ranked bandits [12]  because they have already
been shown to perform poorly in stochastic click models  for instance by Zoghi et al. [17] and Katariya
et al. [5]. The parameter δ in TopRank is set as δ = 1/n  as suggested in Theorem 1. Fig. 3 illustrates

Figure 3: The n-step regret of TopRank (red)  CascadeKL-UCB (blue)  and BatchRank (gray) in three problems.
The results are averaged over 10 runs. The error bars are the standard errors of our regret estimates.

Figure 4: The n-step regret of TopRank (red)  CascadeKL-UCB (blue)  and BatchRank (gray) in two click
models. The results are averaged over 60 queries and 10 runs per query. The error bars are the standard errors of
our regret estimates.

the general trend on speciﬁc queries. In the cascade model  CascadeKL-UCB outperforms TopRank.
This should not come as a surprise because CascadeKL-UCB heavily exploits the knowledge of the
model. Despite being a more general algorithm  TopRank consistently outperforms BatchRank
in the cascade model. In the position-based model  CascadeKL-UCB learns very good policies in
about two thirds of queries  but suffers linear regret for the rest. In many of these queries  TopRank
outperforms CascadeKL-UCB in as few as one million steps. In the position-based model  TopRank
typically outperforms BatchRank.
The average regret over all queries is reported in Fig. 4. We observe similar trends to those in Fig. 3.
In the cascade model  the regret of CascadeKL-UCB is about three times lower than that of TopRank 
which is about three times lower than that of BatchRank. In the position-based model  the regret
of CascadeKL-UCB is higher than that of TopRank after 4 million steps. The regret of TopRank is
about 30% lower than that of BatchRank. In summary  we observe that TopRank improves over
BatchRank in both the cascade and position-based models. The worse performance of TopRank
relative to CascadeKL-UCB in the cascade model is offset by its robustness to multiple click models.

8

200k400k600k800k1MStep n01k2k3k4k5kRegretCM on query 101524200k400k600k800k1MStep n01k2k3k4k5kPBM on query 101524200k400k600k800k1MStep n01k2k3k4k5kPBM on query 286581M2M3M4M5MStep n02k4k6k8kRegretCM1M2M3M4M5MStep n02k4k6k8kPBM7 Conclusions

We introduced a new click model for online ranking that subsumes previous models. Despite
the increased generality  the new algorithm enjoys stronger regret guarantees  an easier and more
insightful proof and improved empirical performance. We hope the simpliﬁcations can inspire even
more interest in online ranking. We also proved a lower bound for combinatorial linear semi-bandits
with m-sets that improves on the bound by Uchiya et al. [14]. We do not currently have matching
upper and lower bounds. The key to understanding minimax lower bounds is to identify what
makes a problem hard. In many bandit models there is limited ﬂexibility  but our assumptions are
so weak that the space of all v satisfying Assumptions 1–4 is quite large and we do not yet know
what is the hardest case. This difﬁculty is perhaps even greater if the objective is to prove instance-
dependent or asymptotic bounds where the results usually depend on solving a regret/information
optimization problem [9]. Ranking becomes increasingly difﬁcult as the number of items grows. In
most cases where L is large  however  one would expect the items to be structured and this should
then be exploited. This has been done for the cascade model by assuming a linear structure [18  10].
Investigating this possibility  but with more relaxed assumptions seems like an interesting future
direction.

References
[1] E. Agichtein  E. Brill  and S. Dumais. Improving web search ranking by incorporating user
behavior information. In Proceedings of the 29th Annual International ACM SIGIR Conference 
pages 19–26  2006.

[2] A. Chuklin  I. Markov  and M. de Rijke. Click Models for Web Search. Morgan & Claypool

Publishers  2015.

[3] R. Combes  S. Magureanu  A. Proutiere  and C. Laroche. Learning to rank: Regret lower
bounds and efﬁcient algorithms. In Proceedings of the 2015 ACM SIGMETRICS International
Conference on Measurement and Modeling of Computer Systems  2015.

[4] A. Grotov  A. Chuklin  I. Markov  L. Stout  F. Xumara  and M. de Rijke. A comparative study
of click models for web search. In Proceedings of the 6th International Conference of the CLEF
Association  2015.

[5] S. Katariya  B. Kveton  Cs. Szepesvári  and Z. Wen. DCM bandits: Learning to rank with
multiple clicks. In Proceedings of the 33rd International Conference on Machine Learning 
pages 1215–1224  2016.

[6] B. Kveton  Cs. Szepesvári  Z. Wen  and A. Ashkan. Cascading bandits: Learning to rank in the
cascade model. In Proceedings of the 32nd International Conference on Machine Learning 
2015.

[7] B. Kveton  Z. Wen  A. Ashkan  and Cs. Szepesvári. Combinatorial cascading bandits. In

Advances in Neural Information Processing Systems 28  pages 1450–1458  2015.

[8] P. Lagree  C. Vernade  and O. Cappe. Multiple-play bandits in the position-based model. In

Advances in Neural Information Processing Systems 29  pages 1597–1605  2016.

[9] T. Lattimore and Cs. Szepesvári. The End of Optimism? An Asymptotic Analysis of Finite-
Armed Linear Bandits. In A. Singh and J. Zhu  editors  Proceedings of the 20th International
Conference on Artiﬁcial Intelligence and Statistics  volume 54 of Proceedings of Machine
Learning Research  pages 728–737  Fort Lauderdale  FL  USA  20–22 Apr 2017. PMLR.

[10] S. Li  B. Wang  S. Zhang  and W. Chen. Contextual combinatorial cascading bandits. In
Proceedings of the 33rd International Conference on Machine Learning  pages 1245–1253 
2016.

[11] T. Liu. Learning to Rank for Information Retrieval. Springer  2011.
[12] F. Radlinski  R. Kleinberg  and T. Joachims. Learning diverse rankings with multi-armed
bandits. In Proceedings of the 25th International Conference on Machine Learning  pages
784–791  2008.

[13] A. Slivkins  F. Radlinski  and S. Gollapudi. Ranked bandits in metric spaces: Learning diverse
rankings over large document collections. Journal of Machine Learning Research  14(1):
399–436  2013.

9

[14] Taishi Uchiya  Atsuyoshi Nakamura  and Mineichi Kudo. Algorithms for adversarial bandit
problems with multiple plays. In Proceedings of the 21st International Conference on Algo-
rithmic Learning Theory  ALT’10  pages 375–389  Berlin  Heidelberg  2010. Springer-Verlag.
ISBN 3-642-16107-3.

[15] Yandex. Yandex personalized web search challenge. https://www.kaggle.com/c/yandex-

personalized-web-search-challenge  2013.

[16] M. Zoghi  T. Tunys  L. Li  D. Jose  J. Chen  C. Ming Chin  and M. de Rijke. Click-based hot
ﬁxes for underperforming torso queries. In Proceedings of the 39th International ACM SIGIR
Conference on Research and Development in Information Retrieval  pages 195–204  2016.

[17] M. Zoghi  T. Tunys  M. Ghavamzadeh  B. Kveton  Cs. Szepesvári  and Z. Wen. Online learning
to rank in stochastic click models. In Proceedings of the 34th International Conference on
Machine Learning  pages 4199–4208  2017.

[18] S. Zong  H. Ni  K. Sung  N. Rosemary Ke  Z. Wen  and B. Kveton. Cascading bandits for
large-scale recommendation problems. In Proceedings of the 32nd Conference on Uncertainty
in Artiﬁcial Intelligence  2016.

10

,Cho-Jui Hsieh
Si Si
Inderjit Dhillon
John Schulman
Nicolas Heess
Theophane Weber
Pieter Abbeel
Abdul-Saboor Sheikh
Jörg Lücke
Tor Lattimore
Branislav Kveton
Shuai Li
Csaba Szepesvari