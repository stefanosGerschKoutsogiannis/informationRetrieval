2016,Optimal spectral transportation with application to music transcription,Many spectral unmixing methods rely on the non-negative decomposition of spectral data onto a dictionary of spectral templates. In particular  state-of-the-art music transcription systems decompose the spectrogram of the input signal onto a dictionary of representative note spectra. The typical measures of fit used to quantify the adequacy of the decomposition compare the data and template entries frequency-wise. As such  small displacements of energy from a frequency bin to another as well as variations of timber can disproportionally harm the fit. We address these issues by means of optimal transportation and propose a new measure of fit that treats the frequency distributions of energy holistically as opposed to frequency-wise. Building on the harmonic nature of sound  the new measure is invariant to shifts of energy to harmonically-related frequencies  as well as to small and local displacements of energy. Equipped with this new measure of fit  the dictionary of note templates can be considerably simplified to a set of Dirac vectors located at the target fundamental frequencies (musical pitch values). This in turns gives ground to a very fast and simple decomposition algorithm that achieves state-of-the-art performance on real musical data.,Optimal spectral transportation with application to

music transcription

Rémi Flamary

Université Côte d’Azur  CNRS  OCA

remi.flamary@unice.fr

Nicolas Courty

Université de Bretagne Sud  CNRS  IRISA

courty@univ-ubs.fr

Cédric Févotte

CNRS  IRIT  Toulouse

cedric.fevotte@irit.fr

Valentin Emiya

Aix-Marseille Université  CNRS  LIF
valentin.emiya@lif.univ-mrs.fr

Abstract

Many spectral unmixing methods rely on the non-negative decomposition of spec-
tral data onto a dictionary of spectral templates. In particular  state-of-the-art
music transcription systems decompose the spectrogram of the input signal onto
a dictionary of representative note spectra. The typical measures of ﬁt used to
quantify the adequacy of the decomposition compare the data and template entries
frequency-wise. As such  small displacements of energy from a frequency bin
to another as well as variations of timbre can disproportionally harm the ﬁt. We
address these issues by means of optimal transportation and propose a new measure
of ﬁt that treats the frequency distributions of energy holistically as opposed to
frequency-wise. Building on the harmonic nature of sound  the new measure is
invariant to shifts of energy to harmonically-related frequencies  as well as to
small and local displacements of energy. Equipped with this new measure of ﬁt 
the dictionary of note templates can be considerably simpliﬁed to a set of Dirac
vectors located at the target fundamental frequencies (musical pitch values). This in
turns gives ground to a very fast and simple decomposition algorithm that achieves
state-of-the-art performance on real musical data.

1 Context

Many of nowadays spectral unmixing techniques rely on non-negative matrix decompositions. This
concerns for example hyperspectral remote sensing (with applications in Earth observation  astronomy 
chemistry  etc.) or audio signal processing. The spectral sample vn (the spectrum of light observed at
a given pixel n  or the audio spectrum in a given time frame n) is decomposed onto a dictionary W of
elementary spectral templates  characteristic of pure materials or sound objects  such that vn ≈ Whn.
The composition of sample n can be inferred from the non-negative expansion coefﬁcients hn. This
paradigm has led to state-of-the-art results for various tasks (recognition  classiﬁcation  denoising 
separation) in the aforementioned areas  and in particular in music transcription  the central application
of this paper.
In state-of-the-art music transcription systems  the spectrogram V (with columns vn) of a musical
signal is decomposed onto a dictionary of pure notes (in so-called multi-pitch estimation) or chords. V
typically consists of (power-)magnitude values of a regular short-time Fourier transform (Smaragdis
and Brown  2003). It may also consists of an audio-speciﬁc spectral transform such as the Mel-
frequency transform  like in (Vincent et al.  2010)  or the Q-constant based transform  like in (Oudre
et al.  2011). The success of the transcription system depends of course on the adequacy of the
time-frequency transform & the dictionary to represent the data V. In particular  the matrix W must

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

be able to accurately represent a diversity of real notes. It may be trained with individual notes using
annotated data (Boulanger-Lewandowski et al.  2012)  have a parametric form (Rigaud et al.  2013)
or be learnt from the data itself using a harmonic subspace constraint (Vincent et al.  2010).
One important challenge of such methods lies in their ability to cope with the variability of real notes.
A simplistic dictionary model will assume that one note characterised by fundamental frequency ν0
(e.g.  ν0 = 440 Hz for note A4) will be represented by a spectral template with non-zero coefﬁcients
placed at ν0 and at its multiples (the harmonic frequencies). In reality  many instruments  such as the
piano  produce musical notes with either slight frequency misalignments (so-called inharmonicities)
with respect to the theoretical values of the fundamental and harmonic frequencies  or amplitude
variations at the harmonic frequencies with respect to recording conditions or played instrument
(variations of timbre). Handling these variabilities by increasing the dictionary with more templates
is typically unrealistic and adaptive dictionaries have been considered in (Vincent et al.  2010; Rigaud
et al.  2013). In these papers  the spectral shape of the columns of W is adjusted to the data at hand 
using speciﬁc time-invariant semi-parametric models. However  the note realisations may vary in time 
something which is not handled by these approaches. This work presents a new spectral unmixing
method based on optimal transportation (OT) that is fully ﬂexible and remedies the latter difﬁculties.
Note that Typke et al. (2004) have previously applied OT to notated music (e.g.  score sheets) for
search-by-query in databases while we address here music transcription from audio spectral data.

2 A relevant baseline: PLCA

Before presenting our contributions  we start by introducing the PLCA method of Smaragdis et al.
(2006) which is heavily used in audio signal processing. It is based on the Probabilistic Latent
Semantic Analysis (PLSA) of Hofmann (2001) (used in text retrieval) and is a particular form of non-
negative matrix factorisation (NMF). Simplifying a bit  in PLCA the columns of V are normalised
to sum to one. Each vector vn is then treated as a discrete probability distribution of “frequency
quanta” and is approximated as V ≈ WH. The matrices W and H are of size M × K and K × N 
respectively  and their columns are constrained to sum to one. As a result  the columns of the
approximate ˆV = WH sum to one as well and each distribution vector vn is as such approximated
by the counterpart distribution ˆvn in ˆV. Under the assumption that W is known  the approximation
is found by solving the optimisation problem deﬁned by

where DKL(v|ˆv) =(cid:80)
extension DKL(V| ˆV) =(cid:80)

n DKL(vn|ˆvn).

DKL(V|WH)

s.t ∀n (cid:107)hn(cid:107)1 = 1 

min
H≥0

(1)

i vi log(vi/ˆvi) is the KL divergence between discrete distributions  and by

An important characteristic of the KL divergence is its separability with respect to the entries of its
arguments. It operates a frequency-wise comparison in the sense that  at every frame n  the spectral
coefﬁcient vin at frequency i is compared to its counterpart ˆvin  and the results of the comparisons
are summed over i. In particular  a small displacement in the frequency support of one observation
may disproportionally harm the divergence value. For example  if vn is a pure note with fundamental
frequency ν0  a small inharmonicity that shifts energy from ν0 to an adjacent frequency bin will
unreasonably increase the divergence value  when vn is compared with a purely harmonic spectral
template with fundamental frequency ν0. As explained in Section 1 such local displacements of
frequency energy are very common when dealing with real data. A measure of ﬁt invariant to small
perturbations of the frequency support would be desirable in such a setting  and this is precisely what
OT can bring.

3 Elements of optimal transportation

Given a discrete probability distribution v (a non-negative real-valued column vector of dimension M
and summing to one) and a target distribution ˆv (with same properties)  OT computes a transportation
matrix T belonging to the set Θ
i=1 tij =
ˆvj}. T establishes a bi-partite graph connecting the two distributions. In simple words  an amount
(or  in typical OT parlance  a “mass”) of every coefﬁcient of vector v is transported to an entry of ˆv.
The sum of transported amounts to the jth entry of ˆv must equal ˆvj. The value of tij is the amount

|∀i  j = 1  . . .   N (cid:80)M

j=1 tij = vi (cid:80)M

= {T ∈ RM×M
def

+

2

transported from the ith entry of v to the jth entry of ˆv. In our particular setting  the vector v is a
distribution of spectral energies v1  . . .   vM at sampling frequencies f1  . . .   fM .
Without additional constraints  the problem of ﬁnding a non-negative matrix T ∈ Θ has an inﬁnite
number of solutions. As such  OT takes into account the cost of transporting an amount from the ith
entry of v to the jth entry of ˆv  denoted cij (a non-negative real-valued number). Endorsed with this
cost function  OT involves solving the optimisation problem deﬁned by

(cid:88)

ij

J(T|v  ˆv  C) =

min

T

cijtij

s.t T ∈ Θ 

(2)

where C is the non-negative square matrix of size M with elements cij. Eq. (2) deﬁnes a convex
linear program. The value of the function J(T|v  ˆv  C) at its minimum is denoted DC(v|ˆv). When
C is a symmetric matrix such that cij = (cid:107)fi− fj(cid:107)p
p  where we recall that fi and fj are the frequencies
in Hertz indexed by i and j  DC(v|ˆv) deﬁnes a metric (i.e.  a symmetric divergence that satisﬁes
the triangle inequality) coined Wasserstein distance or earth mover’s distance (Rubner et al.  1998;
Villani  2009). In other cases  in particular when the matrix C is not even symmetric like in the next
section  DC(v|ˆv) is not a metric in general  but is still a valid measure of ﬁt. For generality  we will
refer to it as the “OT divergence”.
By construction  the OT divergence can explicitly embed a form of invariance to displacements of
support  as deﬁned by the transportation cost matrix C. For example  in the spectral decomposition
setting  the matrix with entries of the form cij = (fi − fj)2 will increasingly penalise frequency
displacements as the distance between frequency bins increases. This precisely remedies the limitation
of the separable KL divergence presented in Section 2. As such  the next section addresses variants
of spectral unmixing based on the Wasserstein distance.

4 Optimal spectral transportation (OST)

Unmixing with OT.
In light of the above discussion  a direct solution to the sensibility of PLCA to
small frequency displacements consists in replacing the KL divergence with the OT divergence. This
amounts to solving the optimisation problem given by

DC(V|WH)

s.t ∀n (cid:107)hn(cid:107)1 = 1 

min
H≥0

where DC(V| ˆV) = (cid:80)

(3)
n DC(vn|ˆvn)  W is ﬁxed and populated with pure note spectra and C
penalises large displacements of frequency support. This approach is a particular case of NMF with
the Wasserstein distance  which has been considered in a face recognition setting by Sandler and
Lindenbaum (2011)  with subsequent developments by Zen et al. (2014) and Rolet et al. (2016).
This approach is relevant to our spectral unmixing scenario but as will be discussed in Section 5 is
on the downside computationally intensive. It also requires the columns of W to be set to realistic
note templates  which is still constraining. The next two sections describes a computationally more
friendly approach which additionally removes the difﬁculty of choosing W appropriately.

Harmonic-invariant transportation cost.
In the approach above  the harmonic modelling is
conveyed by the dictionary W (consisting of comb-like pure note spectra) and the invariance to small
frequency displacements is introduced via the matrix C. In this section we propose to model both
harmonicity and local invariance through the transportation cost matrix C. Loosely speaking  we
want to deﬁne a class of equivalence between musical spectra  that takes into account their inherent
harmonic nature. As such  we essentially impose that a harmonic frequency (i.e.  a close multiple
of its fundamental) can be considered equivalent to its fundamental  the only target of multi-pitch
estimation. As such  we assume that a mass at one frequency can be transported to a divisor frequency
with no cost. In other words  a mass at frequency fi can be transported with no cost to fi/2  fi/3 
fi/4  and so on until sampling resolution. One possible cost matrix that embeds this property is

cij = min

q=1 ... qmax

(fi − qfj)2 +  δq(cid:54)=1 

(4)

where qmax is the ceiling of fi/fj and  is a small value. The term  δq(cid:54)=1 favours the discrimination
of octaves. Indeed  it penalises the transportation of a note of fundamental frequency 2ν0 or ν0/2 to
the spectral template with fundamental frequency ν0  which would be costless without this additive
term. Let us denote by Ch the transportation cost matrix deﬁned by Eq. (4). Fig. 1 compares Ch

3

Figure 1: Comparison of transportation cost matrices C2 and Ch (full matrices and selected columns).

Measure of ﬁt D(cid:96)2
1.13
1.13
0.91

D(v1|ˆv)
D(v2|ˆv)
D(v3|ˆv)

DKL
72.92
5.42
2.02

DC2
145.00
10.00
1042.67

DCh
134.32
10.00
1.00

Figure 2: Three example spectra vn compared to a given template ˆv (left) and computed divergences
(right). The template is a mere Dirac vector placed at a particular frequency ν0. D(cid:96)2 denotes the
standard quadratic error (cid:107)x− y(cid:107)2
2. By construction of DCh  sample v3 which is harmonically related
to the template returns a very good ﬁt with the latter OT divergence. Note that it does not make sense
to compare output values of different divergences; only the relative comparison of output values of
the same divergence for different input samples is meaningful.

to the more standard quadratic cost C2 deﬁned by cij = (fi − fj)2. With the quadratic cost  only
local displacements are permissible. In contrast  the harmonic-invariant cost additionally permits
larger displacements to divisor frequencies  improving robustness to variations of timbre besides to
inharmonicities.

Dictionary of Dirac vectors. Having designed an OT divergence that encodes inherent properties of
musical signals  we still need to choose a dictionary W that will encode the fundamental frequencies
of the notes to identify. Typically  these will consist of the physical frequencies of the 12 notes of the
chromatic scale (from note A to note G  including half-tones)  over several octaves. As mentioned
in Section 1  one possible strategy is to populate W with spectral note templates. However  as also
discussed  the performance of the resulting unmixing method will be capped by the representativeness
of the chosen set of templates.
A most welcome consequence of using the OT divergence built on the harmonic-insensitive cost
matrix Ch is that we may use for W a mere set of Dirac vectors placed at the fundamental frequencies
ν1  . . .   νK of the notes to identify and separate. Indeed  under the proposed setting  a real note
spectra (composed of one fundamental and multiple harmonic frequencies) can be transported with
no cost to its fundamental. Similarly  a spectral sample composed of several notes can be transported
to mixture of Dirac vectors placed at their fundamental frequencies. This simply eliminates the
problem of choosing a representative dictionary! This very appealing property is illustrated in Fig. 2.
Furthermore  the particularly simple structure of the dictionary leads to a very efﬁcient unmixing
algorithm  as explained in the next section. In the following  the unmixing method consisting of the
combined use of the harmonic-invariant cost matrix Ch and of the dictionary of Dirac vectors will be
coined “optimal spectral transportation” (OST).
At this level  we assume for simplicity that the set of K fundamental frequencies {ν1  . . .   νK} is
contained in the set of sampled frequencies {f1  . . .   fM}. This means that wk (the kth column of
W) is zero everywhere except at some entry i such that fi = νk where wik = 1. This is typically
not the case in practice  where the sampled frequencies are ﬁxed by the sampling rate  of the form
fi = 0.5(i/T )fs  and where the fundamental frequencies νk are ﬁxed by music theory. Our approach
can actually deal with such a discrepancy and this will be explained later in Section 5.

4

QuadraticcostC2(logscale)j=1...100i=1...100j=1...100cijSelectedcolumnsofC2i=20i=25i=30i=35HarmoniccostCh(logscale)j=1...100i=1...100j=1...100cijSelectedcolumnsofChi=20i=25i=30i=35010203040506070809000.51OneDiracspectraltemplateandthreedatasamplesˆvv1v2v35 Optimisation

OT unmixing with linear programming. We start by describing optimisation for the state-of-the-
art OT unmixing problem described by Eq. (3) and proposed by Sandler and Lindenbaum (2011).
First  since the objective function is separable with respect to samples  the optimisation problem
decouples with respect to the activation columns hn. Dropping the sample index n and combining
Eqs. (2) and (3)  optimisation thus reduces to solving for every sample a problem of the form

min

h≥0 T≥0

(5)
where 1M is a vector of dimension M containing only ones and (cid:104)· ·(cid:105) is the Frobenius inner product.
Vectorising the variables T and h into a single vector of dimension M 2 + K  problem (5) can be
turned into a canonical linear program. Because of the large dimension of the variable (typically in
the order of 105)  resolution can however be very demanding  as will be shown in experiments.

s.t. T1M = v  T

1M = Wh 

tijcij

ij

(cid:62)

(cid:88)

(cid:104)T  C(cid:105) =

Optimisation for OST. We now assume that W is a set of Dirac vectors as explained at the end
of Section 4. We also assume that K < M  which is the usual scenario. Indeed  K is typically
in the order of a few tens  while M is in the order of a few hundreds. In such a setting ˆv = Wh
contains by design at most K non-zero coefﬁcients  located at the entries such that fi = νk. We
i tij = 0  by
the second constraint of Eq. (5). Additionally  by the non-negativity of T this also implies that T has

denote this set of frequency indices by S. Hence  for j /∈ S  we have ˆvj = 0 and thus(cid:80)
only K non-zero columns  indexed by j ∈ S. Denoting by(cid:101)T this subset of columns  and by (cid:101)C the

corresponding subset of columns of C  problem (5) reduces to

(cid:104)(cid:101)T (cid:101)C(cid:105)

s.t.

(cid:101)T1K = v 

(cid:101)T

(cid:62)

h≥0 (cid:101)T≥0

min

1M = h.

(6)

k

(7)

s.t.

˜tik˜cik

min
˜ti≥0

˜tik = vi.

This is an optimisation problem of signiﬁcantly reduced dimension (M + 1)K. Even more appealing 
the problem has a simple closed-form solution. Indeed  the variable h has a virtual role in problem (6).
It only appears in the second constraint  which de facto becomes a free constraint. Thus problem (6)

can be solved with respect to (cid:101)T regardless of h  and h is then simply obtained by summing the
columns of(cid:101)T(cid:62) at the solution. Now  the problem
(cid:104)(cid:101)T (cid:101)C(cid:105)
min(cid:101)T≥0
decouples with respect to the rows ˜ti of(cid:101)T  and becomes  ∀i = 1  . . .   M 
(cid:88)

(cid:101)T1K = v
s.t. (cid:88)

(8)
i = arg mink{˜cik}  and ˜tik = 0 for k (cid:54)= k(cid:63)
The solution is simply given by ˜tik(cid:63)
i .
Introducing the labelling matrix L which is everywhere zero except for indices (i  k(cid:63)
i ) where it is
equal to 1  the solution to OST is trivially given by ˆh = L(cid:62)v. Thus  under the speciﬁc assumption
that W is a set of Dirac vectors  the challenging problem (5) has been reduced to an effortless
assignment problem to solve for T and a simple sum to solve for h. Note that the algorithm is
independent of the particular structure of C. In the end  the complexity per frame of OST reduces to
O(M )  which starkly contrasts with the complexity of PLCA  in the order O(KM ) per iteration.
In Section 4  we assumed for simplicity that the set of fundamental frequencies {νk}k was contained
in the set of sampled frequencies {fi}i. As a matter of fact  this assumption can be trivially lifted in

the proposed setting of OST. Indeed  we may construct the cost matrix (cid:101)C (of dimensions M × K)
Namely  we may simply set the coefﬁcients of (cid:101)C to be(cid:101)cik = minq(fi − qνk)2 +  δq(cid:54)=1  in the
implementation. Then  the matrix(cid:101)T indicates how each sample v is transported to the Dirac vectors

by replacing the target frequencies fj in Eq. (4) by the theoretical fundamental frequencies νk.

placed at fundamental frequencies {νk}k  without the need for the actual Dirac vectors themselves 
which elegantly solves the frequency sampling problem.

i = vi for k(cid:63)

k

OST with entropic regularisation (OSTe). The procedure described above leads to a winner-
takes-all transportation of all of vi to its cost-minimum target entry k(cid:63)
i . We found it useful in

5

ik

practice to relax this hard assignment and distribute energies more evenly by using the entropic

regularisation of Cuturi (2013). It consists of penalising the ﬁt (cid:104)(cid:101)T (cid:101)C(cid:105) in Eq. (6) with an additional
term Ωe((cid:101)T) =(cid:80)
˜tik log(˜tik)  weighted by the hyper-parameter λe. The negentropic term Ωe((cid:101)T)
promotes the transportation of vi to several entries  leading to a smoother estimate of(cid:101)T. As explained
M × K matrix with coefﬁcients lik = exp(−˜cik/λe)/(cid:80)
in the supplementary material  one can show that the negentropy-regularised problem is a Bregman
projection (Benamou et al.  2015) and has again a closed-form solution ˆh = L(cid:62)
e v where Le is the
p exp(−˜cip/λe). Limiting cases λe = 0
and λe = ∞ return the unregularised OST estimate and the maximum-entropy estimate hk = 1/K 
respectively. Because Le becomes a full matrix  the complexity per frame of OSTe becomes O(KM ).

which promotes group-sparsity at column level (Huang et al.  2009). Unlike OST or OSTe  OSTg
does not offer a closed-form solution. Following Courty et al. (2014)  a majorisation-minimisation

OST with group regularisation (OSTg). We have explained above that the transportation matrix
T has a strong group structure in the sense that it contains by construction M − K null columns 

and that only the subset (cid:101)T needs to be considered. Because a small number of the K possible
notes will be played at every time frame  the matrix (cid:101)T will additionally have a signiﬁcant number
of null columns. This heavily suggests using group-sparse regularisation in the estimation of (cid:101)T.
(cid:113)(cid:107)(cid:101)tk(cid:107)1
As such  we also consider problem (6) penalised by the additional term Ωg((cid:101)T) = (cid:80)
procedure based on the local linearisation of Ωg((cid:101)T) can be employed and the details are given in
OST  as of Eq. (6)  with the iteration-dependent transportation cost matrix (cid:101)C(iter) = (cid:101)C + (cid:101)R(iter) 
where (cid:101)R(iter) is the M × K matrix with coefﬁcients(cid:101)r(iter)
2(cid:107)(cid:101)t(iter)
group-regularisation of(cid:101)T corresponds to a sparse regularisation of h. This is because hk = (cid:107)(cid:101)tk(cid:107)1
and thus  Ωg((cid:101)T) =(cid:80)
(cid:104)(cid:101)T (cid:101)C(cid:105) + λe Ωe((cid:101)T) + λg Ωg((cid:101)T)  addressed in the supplementary material.

hk. Finally  note that OSTe and OSTg can be implemented simultaneously 
leading to OSTe+g  by considering the optimisation of the doubly-penalised objective function

the supplementary material. The resulting algorithm consists in iteratively applying unregularised

. Note that the proposed

= 1

k

√

k

k

ik

(cid:107)− 1

2

1

6 Experiments

Toy experiments with simulated data.
In this section we illustrate the robustness  the ﬂexibility
and the efﬁciency of OST on two simulated examples. The top plots of Fig. 3 display a synthetic
dictionary of 8 harmonic spectral templates  referred to as the “harmonic dictionary”. They have
been generated as Gaussian kernels placed at a fundamental frequency and its multiples  and using
exponential dampening of the amplitudes. As everywhere in the paper  the spectral templates are
normalised to sum to one. Note that the 8th template is the upper octave of the ﬁrst one. We compare
the unmixing performance of ﬁve methods in two different scenarios. The ﬁve methods are as follows.
PLCA is the method described in Section 2  where the dictionary W is the harmonic dictionary.
Convergence is stopped when the relative difference of the objective function between two iterations
falls below 10−5 or the number of iterations (per frame) exceeds 1000. OTh is the unmixing method
with the OT divergence  as in the ﬁrst paragraph of Section 4  using the harmonic transportation cost
matrix Ch and the harmonic dictionary. OST is like OTh  but using a dictionary of Dirac vectors
(placed at the 8 fundamental frequencies characterising the harmonic dictionary). OSTe  OSTg and
OSTe+g are the regularised variants of OST  described at the end of Section 4. The iterative procedure
in the group-regularised variants is run for 10 iterations (per frame).
In the ﬁrst experimental scenario  reported in Fig. 3 (a)  the data sample is generated by mixing the
1st and 4th elements of the harmonic dictionary  but introducing a small shift of the true fundamental
frequencies (with the shift being propagated to the harmonic frequencies). This mimics the effect
of possible inharmonicities or of an ill-tuned instrument. The middle plot of Fig. 3 (a)  displays
the generated sample  together with the “theoretical sample”  i.e.  without the frequencies shift.
This shows how a slight shift of the fundamental frequencies can greatly impact the overall spectral
distribution. The bottom plot displays the true activation vector and the estimates returned by the ﬁve
methods. The table reports the value of the (arbitrary) error measure (cid:107)ˆh − htrue(cid:107)1 together with the
run time (on an average desktop PC using a MATLAB implementation) for every method. The results
show that group-regularised variants of OST lead to best performance with very light computational

6

(a) Unmixing with shifted fundamental frequencies

(b) Unmixing with wrong harmonic amplitudes

Method
(cid:96)1 error
Time (s)

PLCA OTh
0.340
0.900
0.057
6.541

OST OSTg OSTe OSTe+g
0.015
0.534
0.006
0.013

0.660
0.007

0.021
0.007

Method
(cid:96)1 error
Time (s)

PLCA OTh
0.430
0.791
0.019
6.529

OST OSTg OSTe OSTe+g
0.048
0.971
0.006
0.010

0.911
0.005

0.045
0.006

Figure 3: Unmixing under model misspeciﬁcation. See text for details.

burden  and without using the true harmonic dictionary. In the second experimental scenario  reported
in Fig. 3 (b)  the data sample is generated by mixing the 1st and 6th elements of the harmonic
dictionary  with the right fundamental and harmonic frequencies  but where the spectral amplitudes at
the latters do not follow the exponential dampening of the template dictionary (variation of timbre).
Here again the group-regularised variants of OST outperforms the state-of-the-art approaches  both
in accuracy and run time.

Transcription of real musical data. We consider in this section the transcription of a selection
of real piano recordings  obtained from the MAPS dataset (Emiya et al.  2010). The data comes
with a ground-truth binary “piano-roll” which indicates the active notes at every time. The note
fundamental frequencies are given in MIDI  a standard musical integer-valued frequency scale that
matches the keys of a piano  with 12 half-tones (i.e.  piano keys) per octave. The spectrogram of
each recording is computed with a Hann window of size 93-ms and 50% overlap (fs = 44.1Hz). The
columns (time frames) are then normalised to produce V. Each recording is decomposed with PLCA 
OST and OSTe  with K = 60 notes (5 octaves). Half of the recording is used for validation of the
hyper-parameters and the other half is used as test data. For PLCA  we validated 4 and 3 values of the
width and amplitude dampening of the Gaussian kernels used to synthesise the dictionary. For OST 
we set  = q0 in Eq. (4)  which was found to satisfactorily improve the discrimination of octaves
increasingly with frequency  and validated 5 orders of magnitude of 0. For OSTe  we additionally
validated 4 orders of magnitude of λe. Each of the three methods returns an estimate of H. The
estimate is turned into a 0/1 piano-roll by only retaining the support of its Pn maximum entries at
every frame n  where Pn is the ground-truth number of notes played in frame n. The estimated
piano-roll is then numerically compared to its ground truth using the F-measure  a global recognition
measure which accounts both for precision and recall and which is bounded between 0 (critically
wrong) and 1 (perfect recognition). Our evaluation framework follows standard practice in music
transcription evaluation  see for example (Daniel et al.  2008). As detailed in the supplementary
material  it can be shown that OSTg and OSTe+g do not change the location of the maximum entries
in the estimates of H returned by OST and OSTe  respectively  but only their amplitude. As such  they
lead to the same F-measures than OST and OSTe  and we did not include them in the experiments of
this section.
We ﬁrst illustrate the complexity of real-data spectra in Fig. 4  where the amplitudes of the ﬁrst
six partials (the components corresponding to the harmonic frequencies) of a single piano note are
represented along time. Depending on the partial order q  the amplitude evolves with asynchronous
beats and with various slopes. This behaviour is characteristic of piano sounds in which each note
comes from the vibration of up to three coupled strings. As a consequence  the spectral envelope
of such notes cannot be well modelled by a ﬁxed amplitude pattern. Fig. 4 shows that  thanks to
its ﬂexibility  OSTe can perfectly recover the true fundamental frequency (MIDI 50) while PLCA

7

(a) Thresholded OSTe transcription

(b) Thresholded PLCA transcription

Time (s)

Figure 4: First 6 partials and transcription of a single piano note (note D3  ν0 = 147 Hz  MIDI 50).

Table 1: Recognition performance (F-measure values) and average computational unmixing times.

MAPS dataset ﬁle IDs
chpn_op25_e4_ENSTDkAm
mond_2_SptkBGAm
mond_2_SptkBGCl
muss_1_ENSTDkAm 4
muss_2_AkPnCGdD
mz_311_1_ENSTDkCl
mz_311_1_StbgTGd2
Average
Time (s)

PLCA PLCA+noise
0.679
0.616
0.645
0.613
0.587
0.561
0.663
0.624
14.861

0.671
0.713
0.687
0.478
0.574
0.593
0.617
0.619
15.420

OST
0.566
0.470
0.583
0.513
0.531
0.580
0.701
0.563
0.004

OST+noise OSTe OSTe+noise

0.564
0.534
0.676
0.550
0.611
0.628
0.718
0.612
0.005

0.695
0.610
0.695
0.671
0.667
0.625
0.747
0.673
0.210

0.695
0.607
0.730
0.667
0.675
0.665
0.747
0.684
0.202

is prone to octave errors (confusions between MIDI 50 and MIDI 62). Then  Table 1 reports the
F-measures returned by the three competing approaches on seven 15-s extracts of pieces from Chopin 
Beethoven  Mussorgski and Mozart. For each of the three methods  we have also included a variant
that incorporates a ﬂat component in the dictionary that can account for noise or non-harmonic
components. In PLCA  this merely consists in adding a constant vector wf (K+1) = 1/M to W. In

OST or OSTe this consists in adding a constant column to(cid:101)C  whose amplitude has also been validated

over 3 orders of magnitude. OST performs comparably or slightly inferiorly to PLCA but with an
impressive gain in computational time (∼3000× speedup). Best overall performance is obtained with
OSTe+noise with an average ∼10% performance gain over PLCA and ∼750× speedup.
A Python implementation of OST and real-time demonstrator are available at https://github.
com/rflamary/OST

7 Conclusions

In this paper we have introduced a new paradigm for spectral dictionary-based music transcription.
As compared to state-of-the-art approaches  we have proposed a holistic measure of ﬁt which is
robust to local and harmonically-related displacements of frequency energies. It is based on a
new form of transportation cost matrix that takes into account the inherent harmonic structure of
musical signals. The proposed transportation cost matrix allows in turn to use a simplistic dictionary
composed of Dirac vectors placed at the target fundamental frequencies  eliminating the problem
of choosing a meaningful dictionary. Experimental results have shown the robustness and accuracy
of the proposed approach  which strikingly does not come at the price of computational efﬁciency.
Instead  the particular structure of the dictionary allows for a simple algorithm that is way faster
than state-of-the-art NMF-like approaches. The proposed approach offers new foundations  with
promising results and room for improvement. In particular  we believe exciting avenues of research
concern the learning of Ch from examples and extensions to other areas such as in remote sensing 
using application-speciﬁc forms of C.

Acknowledgments. This work is supported in part by the European Research Council (ERC) under
the European Union’s Horizon 2020 research & innovation programme (project FACTORY) and by
the French ANR JCJC program MAD (ANR-14-CE27-0002). Many thanks to Antony Schutz for
generating & providing some of the musical data.

8

0.811.21.41.61.822.22.42.62.8Pitch (MIDI)4060800.811.21.41.61.822.22.42.62.8Pitch (MIDI)406080References
J.-D. Benamou  G. Carlier  M. Cuturi  L. Nenna  and G. Peyré. Iterative Bregman projections for
regularized transportation problems. SIAM Journal on Scientiﬁc Computing  37(2):A1111–A1138 
2015.

N. Boulanger-Lewandowski  Y. Bengio  and P. Vincent. Discriminative non-negative matrix factoriza-
tion for multiple pitch estimation. In Proc. International Society for Music Information Retrieval
Conference (ISMIR)  2012.

N. Courty  R. Flamary  and D. Tuia. Domain adaptation with regularized optimal transport. In
Proc. European Conference on Machine Learning and Principles and Practice of Knowledge
Discovery in Databases (ECML PKDD)  2014.

M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transportation. In Advances on

Neural Information Processing Systems (NIPS)  2013.

A. Daniel  V. Emiya  and B. David. Perceptually-based evaluation of the errors usually made when
automatically transcribing music. In Proc. International Society for Music Information Retrieval
Conference (ISMIR)  2008.

V. Emiya  R. Badeau  and B. David. Multipitch estimation of piano sounds using a new probabilistic
spectral smoothness principle. IEEE Trans. Audio  Speech  and Language Processing  18(6):
1643–1654  2010.

T. Hofmann. Unsupervised learning by probabilistic latent semantic analysis. Machine Learning  42

(1):177–196  2001.

J. Huang  S. Ma  H. Xie  and C.-H. Zhang. A group bridge approach for variable selection. Biometrika 

96(2):339–355  2009.

L. Oudre  Y. Grenier  and C. Févotte. Chord recognition by ﬁtting rescaled chroma vectors to chord

templates. IEEE Trans. Audio  Speech and Language Processing  19(7):2222 – 2233  2011.

F. Rigaud  B. David  and L. Daudet. A parametric model and estimation techniques for the inhar-
monicity and tuning of the piano. The Journal of the Acoustical Society of America  133(5):
3107–3118  2013.

A. Rolet  M. Cuturi  and G. Peyré. Fast dictionary learning with a smoothed Wasserstein loss. In

Proc. International Conference on Artiﬁcial Intelligence and Statistics (AISTATS)  2016.

Y. Rubner  C. Tomasi  and L. Guibas. A metric for distributions with applications to image databases.

In Proc. International Conference in Computer Vision (ICCV)  1998.

R. Sandler and M. Lindenbaum. Nonnegative matrix factorization with earth mover’s distance metric
for image analysis. IEEE Trans. Pattern Analysis and Machine Intelligence  33(8):1590–1602 
2011.

P. Smaragdis and J. C. Brown. Non-negative matrix factorization for polyphonic music transcription.
In Proc. IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA) 
2003.

P. Smaragdis  B. Raj  and M. V. Shashanka. A probabilistic latent variable model for acoustic

modeling. In Proc. NIPS workshop on Advances in models for acoustic processing  2006.

R. Typke  R. C. Veltkamp  and F. Wiering. Searching notated polyphonic music using transportation

distances. In Proc. ACM International Conference on Multimedia  2004.

C. Villani. Optimal transport: old and new. Springer  2009.

E. Vincent  N. Bertin  and R. Badeau. Adaptive harmonic spectral decomposition for multiple pitch

estimation. IEEE Trans. Audio  Speech and Language Processing  18:528 – 537  2010.

G. Zen  E. Ricci  and N. Sebe. Simultaneous ground metric learning and matrix factorization with
earth mover’s distance. In Proc. International Conference on Pattern Recognition (ICPR)  2014.

9

,Rajesh Ranganath
Andrew Gelman
David Blei
Rémi Flamary
Cédric Févotte
Nicolas Courty
Valentin Emiya
Simon Du
Jayanth Koushik
Aarti Singh
Barnabas Poczos