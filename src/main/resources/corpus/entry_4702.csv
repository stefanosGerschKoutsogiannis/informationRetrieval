2010,Rescaling  thinning or complementing? On goodness-of-fit procedures for point process models and Generalized Linear Models,Generalized Linear Models (GLMs) are an increasingly popular framework for modeling neural spike trains. They have been linked to the theory of stochastic point processes and researchers have used this relation to assess goodness-of-fit using methods from point-process theory  e.g. the time-rescaling theorem. However  high neural firing rates or coarse discretization lead to a breakdown of the assumptions necessary for this connection. Here  we show how goodness-of-fit tests from point-process theory can still be applied to GLMs by constructing equivalent surrogate point processes out of time-series observations. Furthermore  two additional tests based on thinning and complementing point processes are introduced. They augment the instruments available for checking model adequacy of point processes as well as discretized models.,Rescaling  thinning or complementing? On

goodness-of-ﬁt procedures for point process models

and Generalized Linear Models

Felipe Gerhard

Brain Mind Institute

Wulfram Gerstner
Brain Mind Institute

Ecole Polytechnique F´ed´erale de Lausanne

Ecole Polytechnique F´ed´erale de Lausanne

1015 Lausanne EPFL  Switzerland
felipe.gerhard@epfl.ch

1015 Lausanne EPFL  Switzerland
wulfram.gerstner@epfl.ch

Abstract

Generalized Linear Models (GLMs) are an increasingly popular framework for
modeling neural spike trains. They have been linked to the theory of stochastic
point processes and researchers have used this relation to assess goodness-of-ﬁt
using methods from point-process theory  e.g. the time-rescaling theorem. How-
ever  high neural ﬁring rates or coarse discretization lead to a breakdown of the as-
sumptions necessary for this connection. Here  we show how goodness-of-ﬁt tests
from point-process theory can still be applied to GLMs by constructing equiva-
lent surrogate point processes out of time-series observations. Furthermore  two
additional tests based on thinning and complementing point processes are intro-
duced. They augment the instruments available for checking model adequacy of
point processes as well as discretized models.

1

Introduction

Action potentials are stereotyped all-or-nothing events  meaning that their amplitude is not consid-
ered to transmit any information and only the exact time of occurrence matters. This view suggests
to model neurons’ responses in the mathematical framework of point processes. An observation
is a sequence of spike times and their stochastic properties are captured by a single function  the
conditional intensity [1]. For point processes on the time line  several approaches for evaluating
goodness-of-ﬁt have been proposed [2]. The most popular in the neuroscientiﬁc community has
been a test based on the time-rescaling theorem [3].

In practice  neural data is binned such that a spike train is represented as a sequence of spike counts
per time bin. Speciﬁcally  Generalized Linear Models (GLMs) are built on this representation. Such
discretized models of time series have mostly been seen as an approximation to continuous point
processes and hence  the time-rescaling theorem was also applied to such models [4  5  6  7  8].

Here we ask the question whether the time-rescaling theorem can be translated to discrete time. We
review the approximations necessary for the transition to discrete time and point out a procedure
to create surrogate point processes even when these approximations do not hold (section 2). Two
novel tests based on two different operations on point processes are introduced: random thinning
and random complementing. These ideas are applied to a series of examples (section 3)  followed
by a discussion (section 4).

1

Figure 1: Spike train representations. (A) A trace of the membrane potential of a spiking neuron.
(B) Information is conveyed in the timings and number of action potentials. This supports the
representation of neural activity as a point process in which each spike is assumed to be a singular
event in time. (C) When time is divided into large bins  the spike train is represented as a time series
of discrete counts. (D) If the bin width is chosen small enough  the spike train corresponds to a
binary time series  indicating the presence of a single spike inside a given time bin.

2 Methods

2.1 Representations of neural activity

We characterize a neuron by its response in terms of trains of action potentials using the theory of
point processes (Figures 1A and 1B). An observation consists of a list of times  each denoting the
time point of one action potential. Following a common notation [3  9]  let (0  T ] be the time interval
of the measurement and {ui} be the set of n event times. The stochastic properties of a point process
are characterized by its conditional intensity function λ(t|H(t))  deﬁned as [1]:

λ(t|Ht) = lim
∆→0

∆

where Ht is the history of the stochastic process up to time t and possibly includes other covariates
of interest. For ﬁtting and evaluating different parameter sets of the conditional intensity function  a
maximum-likelihood approach is followed [10  11]. The log-likelihood of a point process model is
given by [1]:

P [spike in (t  t + ∆)|Ht]

 

(1)

log L(point process) =

n

Xi=1

log λ(ui|Hui ) − Z T

0

λ(t|Ht)dt.

(2)

One possibility are binning-free models (like renewal processes or other parametric models). Alter-
natively  λ(t|Ht) can be modeled as a piece-wise constant function with each piece having length ∆.
In this case  the history term Ht covers the history up to the time of the left edge of the current bin.
Inside the bin  the process locally behaves like a Poisson process with constant rate λk = λ(tk|Hk)
with tk = ∆k and Hk = Htk. Using the number of spikes ck per bin as a representation of the obser-
vation  the discretized version of Equation 2 is equivalent to the log-likelihood of a series of Poisson
samples (apart from terms that are not dependent on λ(t|Ht)). Hence  for ﬁnding the maximum-
likelihood solution for the point process  it is equivalently sufﬁcient to maximize the likelihood of
such a Poisson regression model. The result of ﬁtting will be a sequence of µi for each bin  where
µi is the expected number of counts. Since a local Poisson process is assumed within the bins  µi is
related to λi via: λi = µi/∆.
A complementary approach to the point process framework is to see spike trains as time series 
e. g. as a sequence of counts {ci} or binary events {bi} (Figures 1C and 1D). For Poisson-GLMs 
a sequence of Poisson-distributed count variables ci is modeled and the linear sum of covariates
is linked to the expected mean of the Poisson distribution µi. Binary time series can be modeled
as a sequence of conditionally independent Bernoulli trials with outcomes 0 and 1 and success
probabilities {pi}. For Bernoulli-GLMs  the pis are linked via a non-linear transfer function to
a linear sum of covariates. Deﬁned this way  the likelihood for an observed sequence bi given a
+ Pk log(1 − pk). In the
approximation of µi (cid:28) 1  µi becomes approximately pi and the likelihoods of the Bernoulli and
Poisson series become equivalent. Moreover  using the same approximation  it is possible to link
the Bernoulli series to the conditional intensity function λ(t|Ht) via λi ≈ pi/∆ . Traditionally 
this path was chosen to relate the time series to the theory of point processes and to be able to use
goodness-of-ﬁt analyses available for such point processes [9].

particular model of pi is given by log L(Bernoulli) = Pk bk log pk

1−pk

2

A

(cid:79)
(cid:79)

time

-

rescaling

B

(cid:79)
(cid:79)

B

random

 thinning

C

(cid:79)
(cid:79)
C

complement

ing

i(cid:79)

B

original

spiketrain

t

i

(cid:179)(cid:32)
' (cid:79)

dtHt
|(

)

t

it
i

0

rescaled

spiketrain

t
t

t

original

spiketrain

(cid:32)

p
i

B
B
(cid:79)

i

thinned

spiketrain

t
t

t

original

spiketrain

C(cid:79)
C(cid:79)

complement

ary

process

complement

ed

spiketrain

t
t

t

t

Figure 2: Overview of goodness-of-ﬁt tests for point-process models. (A) Using the time-rescaling
theorem  the time of each spike is rescaled according to the integral of the conditional intensity
function. (B) Assuming that the conditional intensity function has a lower limit B  spikes of the
original spike train are thinned by keeping a spike only with probability Bλ−1
. (C) Assuming that
the conditional intensity function has an upper limit C  a complementary process λC = C − λ can
be constructed. Adding samples from this inhomogeneous Poisson process to the observed spikes
results in a homogeneous Poisson process with rate C.

i

2.2 Goodness-of-ﬁt tests for point processes

Statistical tests are usually evaluated using two measures: The speciﬁcity (fraction of correct models
that pass the test) and the sensitivity or test power (fraction of wrong models that are properly
rejected by the test). The speciﬁcity is set by the signiﬁcance level: With signiﬁcance level α  the
speciﬁcity is 1 − α. The sensitivity of a given test depends on the strength of the departure from the
modeled intensity function to the true intensity.

2.2.1 The time-rescaling theorem

A popular way for verifying point-process-based models has been the time-rescaling theorem [3  12].
It states that if {ui} is a realization of events from a point process with conditional intensity λ(t|Ht) 
then rescaling via the transformation u0
We call the following transformation the na¨ıve time-rescaling when it is applied to binary sequences.
The spike time ui falling into bin j  is transformed into: u0

0 λ(t|Ht)dt will yield a unit-rate Poisson process.

i = R ui

i = Pj

k=1 pk.

2.2.2 Thinning point processes

It is well known that an inhomogeneous point process can be simulated by generating a homo-
geneous Poisson process with constant intensity C with C ≥ max λ(t) (the so-called dominant
process) and keeping every spike at time ti with probability p = λ(ti)
In reverse  this
can be used to do model-checking [14]: Let B be a lower bound of the ﬁtted conditional intensity
λ(t|H(t)). Now take λ(t|H(t)) as the dominant process with samples ui. Thin the process by keep-
λ(ti|Ht) . For a correctly speciﬁed model λ(t|Ht)  the thinned process
ing a spike with probability
will be a homogeneous Poisson process with rate B (Figure 2B).

C [13  2].

B

3

Typically  B = min λ(t) (cid:28) ¯λ(t) (due to absolute refractoriness in most renewal process models
and GLMs)  such that the thinned process will have a prohibitively low rate and only very few spikes
will be selected. Testing the Poisson hypothesis on a handful of spikes will result in a vanishingly
low power.

To circumvent this problem  we propose the following remedy: Let B∗ be a threshold which may
be higher than the lower bound B. Then consider only the intervals of λ for which λ > B∗ and
concatenate those into a new point process. After applying the thinning procedure on all spikes of
the stitched process  the thinned process should be a Poisson process with rate B∗. This procedure
can be repeated K times for a range of uniformly spaced B∗s ranging from B to C (upper bound).
Stretching each thinned process by a factor of B∗ creates a set of K unit-rate processes. Each of
them is tested for the Poisson hypothesis by a Kolmogorov-Smirnov test on the inter-spike intervals.
The model is rejected when there is at least one signiﬁcant rejected null hypothesis. To correct for
the multiple tests  we employ Simes’ procedure. It tests the global null hypothesis that all tested
sub-hypotheses are true against the alternative hypothesis that at least one hypothesis is false. To
this end  it transforms the ordered list of p-values p(1)  ...  p(K) into Kp(1)
K . If any
of the transformed p-values is less than the signiﬁcance level α = .05  the model is rejected [15]1.

  ...  Kp(K)

1

  Kp(2)

2

2.2.3 Complementing point processes

The idea of thinning might also be used the other way round. Assume the observations ui have been
generated by thinning a homogeneous Poisson process with rate C using the modeled conditional
intensity λ(t|Ht) as the lower bound. Then we can deﬁne a complementary process λc(t) = C −
λ(t|Ht) such that adding spikes from the complementary point process to the observed spikes  the
resulting process will be a homogeneous Poisson process with rate C. This algorithm is a straight-
forward inversion of the thinning algorithms discussed in [2  1].

It might happen that the upper bound C of the modeled intensity is much larger than the average
λ(t). In that case  the observed spike pattern would be distorted with high number of Poisson spikes
from the complementary process and the test power would be low. To avoid this  a similar technique
as for the thinning procedure can be employed. Deﬁne a threshold C ∗ ≤ C and consider only the
region of the spike train for which λ(t|H(t)) < C ∗. Apply the complementing procedure on these
parts of the spike train to obtain a point process with rate C ∗ when concatenating the intervals. This
process can be repeated K times with values C ∗ ranging from B to C. A multiple-test correction
has to be used  again we propose Simes’ method (see previous section).

2.3 Creating surrogate point processes from time series

Since the time-rescaling theorem can only be used when λ(t|Ht) the exact spike times {ui} are
known  it is not a priori clear how it applies to discretized time-series models. For such cases 
we propose to generate surrogate point process samples that are equivalent to the observed time
series. To apply the time-rescaling theorem on discretized models such as GLMs  the integral of the
time transformation is replaced by a discrete sum over bins (the na¨ıve time-rescaling). Taking the
simplest example of a homogeneous Poisson process  it is evident that the possible values for the
rescaled intervals form a ﬁnite set. This contradicts the time-rescaling theorem that states that the
intervals are (continuously) exponentially distributed. Hence  using the time-rescaling theorem on
discretized data produces a bias [17].

While Haslinger et al. considered a modiﬁcation of the time-rescaling theorem to explicitly ac-
count for the discrete nature of the model [17]  we propose a general  simple scheme how to form
surrogate point processes from Poisson- and Bernoulli-GLMs that can be used for the continuous
time-rescaling theorem as well as for any other goodness-of-ﬁt test designed for point-process data
(Figure 3).
Poisson-GLMs: The observation consists of a sequence of count variables ci that is modeled as
a sample from Poisson distributions with mean µi. Hence  the modeled process can be regarded
as a piecewise-constant intensity function. The expected number of spikes of a Poisson process is
related to its intensity via µi = λi∆ such that we can construct the conditional intensity function as

1The K tests contain overlapping regions of the same spike train  hence  we expect the statistical tests to be

correlated. In these cases  a simple Bonferroni-correction would be too conservative [16].

4

binning

-

free

model

Bernoulli

GLM-

Poisson

GLM-

spike

 times

ui
{

};

conditiona

l

intensity

(cid:79)

tHt
(
|(

))

binary

observatio

{ns

ib

};

spiking

probabilit

ies

}{p

i

spike

counts

ic
{

};

expected

counts

i(cid:80)
}{

(cid:80)

i

(cid:16)(cid:32)

1ln(

(cid:16)

p
i

)

draw

c
from}{
i

poisson

(
P
i(cid:80)

)
(c
i

(cid:32)

kk

|

(cid:116)

)1

draw

spiketimes

from}{u

i

Unif(

0

(cid:39)
) 

inside

each

bin;

set

(cid:540)

i

(cid:32)

i

(cid:541)
(cid:507)

apply

goodness

-of-

fit

procedures

based

on

point

process

}{u

i

and

conditiona

l

intensity

(cid:79)

|(t

H(t))

Figure 3: Creating surrogate point processes from time series. For bin-free point process models
for which the spike times and a conditional intensity λ(t|H(t)) is available  goodness-of-ﬁt tests
for point processes can be readily applied. For Poisson-GLMs  exact spike times are drawn inside
each bin for the speciﬁed number of spikes that were observed. The piece-wise constant conditional
intensity function is linked to the modeled number of counts per bin via λi = ∆−1µi. For Bernoulli-
GLMs  the probability of obtaining at least one spike per bin pi is modeled. For each bin with spikes
(bi = 1) – assuming a local Poisson process – a sample ci from a biased Poisson distribution with
mean µi = − ln(1 − pi) is drawn together with corresponding spike times. Finally  point-process
based goodness-of-ﬁt tests may be applied to this surrogate spike train.

piece-wise constant with values λi = ∆−1µi. Conditioned on the number of spikes that occurred in
a homogeneous Poisson process of rate λi  the exact spike times are uniformly distributed inside bin
i. A surrogate point process can be constructed from a Poisson-GLM by generating random spike
times (i − 1 + U nif (0  1))∆ for each spike within bin i (1 ≤ i ≤ N) for all bins with ci > 0. One
can then proceed to the point-process-based goodness-of-ﬁt tools using the surrogate spike train and
its conditional intensity λi.
Bernoulli-GLMs: Based on the observed binary spike train {bi}  the sequence of probabilities pi
of spiking within bin i is modeled. We can relate this to the point process framework using the
following observations: Assume that pi denotes the probability of ﬁnding at least one spike within
each bin2 and that locally  the process behaves like a Poisson process. Then  pi = P (poisson)
(X ≥
1) = 1 − P (poisson)
(X = 0) = 1 − exp(−µi). The conditional intensity is given by λi = ∆−1µi =
−∆−1 ln(1 − pi). In practice  for each bin with bi = 1  we draw the amount of spikes within the
bin by ﬁrst sampling from the distribution P (poisson)
(X = k|k ≥ 1) and sample exact spike times
µi
uniformly as in the case of the Poisson-GLMs.

µi

µi

3 Results

Here  we compare the performance of the three different approaches in detecting wrongly speciﬁed
models  using examples of models that are commonly applied in neural data analysis. For the
thinning and complementing procedure  K = 10 partitions were chosen (see section 2.2.2). Unless
otherwise noted  we report the test power at a speciﬁcity of 1 − α = .95. The Poisson hypothesis in
the proposed procedures is tested by a Kolmogorov-Smirnov test on the inter-spike intervals of the
transformed process.

3.1 Example: Inhomogeneous Poisson process

20 Hz + PJ=40

Consider an inhomogeneous Poisson process with band-limited intensity: λ(t|Ht) = λ(t) =
with f = 1 Hz and J = 40 coefﬁcients that were randomly
drawn from a uniform distribution on the interval [0  20]. The process was simulated over a length
of T = 20 s and the intensity was discretized with ∆ = 1 ms. Negative intensities were clipped

j=1 uj

sin(2πf (t− j
J T )

π(t− j

J T ))

2Such clipping is implicitly performed in many studies  e. g. in [18  19  20].

5

150

100

50

n
o

i
t
c
n
u

f
 
y
t
i
s
n
e

t

n

i

0
 
0

 

no jitter
medium jitter
high jitter

5

10

time [s]

15

20

(a) intensity function

r
e
w
o
p

 
t
s
e

t

1

0.8

0.6

0.4

0.2

0
 
0

 

1

0.8

0.6

0.4

0.2

r
e
w
o
p

 
t
s
e

t

40

 

0
0

 

1

complementing
thinning
rescaling
naive rescaling

0.5

1−specificity

(c) ROC curve

complementing
thinning
rescaling
naive rescaling

20

30

10

jitter strength
(b) test power

Figure 4: Inhomogeneous Poisson process. (A) Sample intensity functions for an undistorted inten-
sity (black line) and two models with jitters in the coefﬁcients (β = 12  medium jitter and β = 30 
large jitter). (B) The test power of each test as a function of the jitter strength. The dashed line
indicates the level of the medium jitter strength (red line in ﬁgure A). (C) ROC curve analysis for
an intermediate jitter strength of β = 12. The intersection of the curves with the dashed line corre-
sponds to the test power at a signiﬁcance level of α = .05.

to zero. A binary spike train was generated by calculating the probability of at least one spike in
each time bin as pi = 1 − exp(−λ(ti)∆) and drawing samples from a Bernoulli distribution with
speciﬁed probabilities pi.
For evaluating the different algorithms  wrong models for the intensity were created with jittered
coefﬁcients u0
k = uk + βUnif(−1  1) where β indicates the strength of the deviation from the true
model. For each jitter strength  N = 1000 spike trains were generated from the true model and
λ(t|Ht) was constructed using the wrong model (Figure 4A). For any β > 0  the fraction of rejected
models deﬁnes the sensitivity or test power. For β = 0  the fraction of accepted models deﬁnes the
speciﬁcity which was controlled to be at 1 − α = .95 for each test.
All three methods (rescaling  thinning  complementing) show a speciﬁed type-I error of approx-
imately 5% (β = 0) and progressively detect the wrong models. Notably  the complementing
and thinning procedures detect a departure from the correct model earlier than the classical rescal-
ing (Figure 4B). For comparison  also the na¨ıve implementation of the rescaling transformation is
shown. The signiﬁcance level for the KS test used for the na¨ıve time-rescaling was adjusted to
α = .015 to achieve a 95% speciﬁcity. The adjustment was necessary due to the discretization bias
(see section 2.3).

For models with an intermediate jitter strength (β = 12)  ROC curves were constructed. Here  for a
given signiﬁcance level α  a pair of true and false positive rates can be calculated and plotted for each
test (taking N = 1000 repetitions using the true model and the model with jittered coefﬁcients). It
can be seen that especially for intermediate jitter strengths  complementing and thinning outperform
time-rescaling (Figure 4C)  independent of the chosen signiﬁcance level.

3.2 Example: Renewal process

In a second example  we consider renewal processes  i. e. inter-spike intervals are an i. i. d. sample
from a speciﬁc probability distribution p(∆t). In this case  the conditional intensity is given by
where t∗ denotes the time of the last spike prior to time t. For this
λ(t|Ht) =

p(t−t∗)

1−R t−t∗

0

p(u)du

example  we chose the Gamma distribution as it is commonly used to model real spike trains [4  3  7].

The spike train was generated from a true model  following a Gamma distribution with scale param-
eter A = 0.032 and shape parameter B = 6.25: p(∆t) = (∆t)B−1 e− ∆t
AB Γ(B) . Wrong models were
generated by scaling the shape and scale parameter by a factor of 1 + β (”jitter”) while keeping the
expected value of the distribution constant (i. e. B0 = (1 + β)B  A0 = (1 + β)−1A) (Figure 5A).
For each jitter strength  N = 1000 data sets of length T = 20 s were generated from the true model
and the wrong model and the tests were applied.

A

6

n
o

i
t
c
n
u

f
 
y
t
i
s
n
e
d

 
y
t
i
l
i

b
a
b
o
r
p

30

20

10

0
 
0

 

sample ISI distribution
no jitter
medium jitter
high jitter

1

0.8

0.6

0.4

0.2

r
e
w
o
p

 
t
s
e

t

0.1

0.05
0.15
inter−spike interval [s]
(a) intensity function

0.2

0
 
0

 

rescaling
thinning
complementing
naive rescaling

0.5
1
jitter strength
(b) test power

1.5

r
e
w
o
p

 
t
s
e

t

1

0.8

0.6

0.4

0.2

0
 
0

 

1

rescaling
thinning
complementing
naive rescaling

0.5

1−specificity

(c) ROC curve

Figure 5: Renewal process. (A) Inter-spike interval distributions for the undistorted (black line) and
distorted models (medium jitter  β = 0.5 and strong jitter  β = 1.0). For comparison  a sample ISI
histogram from one of the simulations is shown in gray. Note that the mean of the three distributions
is matched to be the same (vertical dashed line). (B) The test power of each test as a function of the
jitter strength. The dashed line indicates the level of the medium jitter strength (red line in ﬁgure A).
(C) ROC curve analysis for an intermediate jitter strength of β = 0.5. The intersection of the curves
with the dashed line corresponds to the test power at a signiﬁcance level of α = .05.

The analysis of test power for each test and the ROC curve analysis for an intermediate jitter strength
reveal that time-rescaling is slightly superior to thinning and complementing (Figure 5B and C). The
na¨ıve time-rescaling performs worst (adjusted signiﬁcance level for the KS test  α = .017).

3.3 Example: Inhomogeneous Spike Response Model

example as a band-limited function rti = r(ti) = PJ=40

We model an inhomogeneous spike response model with escape noise using a Bernoulli-GLM [21].
The spiking probability is modulated by an inhomogeneous rate r(t). Additionally  for each spike 
a post-spike kernel is added to the process intensity. The rate function is modeled like in the ﬁrst
with f = 1 Hz
and J = 40 coefﬁcients that were randomly drawn from a uniform distribution on the interval
[−0.2  0.2]. The post-spike kernel η(∆t) is modeled as a sum of three exponential functions (τ =
5 ms  25 ms and 1 s) with appropriate amplitudes as to mimick a relative refractory period  a small
rebound and a slow (inhibitory) adaptation. To construct the Bernoulli-GLM  the spiking probability
pi per bin of length ∆ = 1 ms is pi =

η(uj − ti).

sin(2πf (ti− j
J T )

π(ti− j

1

1+exp(−si) with si = −3 + rti + P{uj }<ti

j=1 uj

J T ))

A binary time series (the spike train) was generated for a duration of T = 20 s. The jittered models
were constructed by adding a jitter β on the coefﬁcients of the inhomogeneous rate modulation
(Figure 6A). For each jitter strength  N = 1000 data sets were generated from the true model and
the wrong model and the tests were applied.

Both thinning and complementing are able to detect smaller distortions than both the time-rescaling
on the surrogate and discrete data (Figure 6B  adjusted signiﬁcance level for the na¨ıve rescaling 
α = .018). A ROC curve analysis for an intermediate jitter strength (β = 0.4) supports this ﬁnding
(Figure 6C).

4 Discussion

Assessing goodness-of-ﬁt for Generalized Linear Models has mostly been done by applying the
time-rescaling transformation that is deﬁned for point processes  assuming a match between those
approaches. When the per-bin probability of spiking cannot be regarded as low  this approximation
breaks down and creates a bias when applying the time-rescaling transformation [17]. In a ﬁrst
step  we proposed a procedure to create surrogate point processes from discretized models  such as
Bernoulli- and Poisson-GLMs  that do not exhibit this bias. Throughout all the examples  the time-
rescaling theorem applied to the surrogate point process was systematically better than applying the
na¨ıve time-rescaling on the discrete data. Since only the adjusted time-rescaling procedure allows

7

80

n
o

i
t
c
n
u

f
 
y
t
i
s
n
e

t

n

i

60

40

20

0
 
7

 

no jitter
medium jitter
high jitter

7.5

8

time [s]

8.5

9

(a) intensity function

r
e
w
o
p

 
t
s
e

t

1

0.8

0.6

0.4

0.2

0
 
0

 

1

r
e
w
o
p

 
t
s
e

t

1

0.8

0.6

0.4

0.2

0
 
0

 

1

thinning
complementing
rescaling
naive rescaling

0.5

1−specificity

(c) ROC curve

thinning
complementing
rescaling
naive rescaling

0.5

jitter strength
(b) test power

Figure 6: Inhomogeneous Spike Response Model. (A) Sample intensity functions for an undistorted
intensity (black line) and two misspeciﬁed models (medium jitter  β = 0.4 and strong jitter  β =
1.0). (B) The test power of each test as a function of the jitter strength. The dashed line indicates the
level of the medium jitter strength (red line in ﬁgure A). (C) ROC curve analysis for an intermediate
jitter strength of β = 0.4. The intersection of the curves with the dashed line corresponds to the test
power at a signiﬁcance level of α = .05.

to reliably control the speciﬁcity of the test  it should be preferred over the classical time-rescaling
in all cases where discretized models are used.

We have presented two alternatives to an application of the time-rescaling theorem: For the ﬁrst
procedure  the observed spike train is thinned according to the value of the conditional intensity at
the time of spikes. The resulting process is then a homogeneous Poisson process with a rate that is
equal to the lower bound on the conditional intensity. The second proposed method builds on the
idea that an intensity function λ(t) with an upper bound C can be ﬁlled up to a homogeneous Poisson
process of rate C by adding spike samples from the complementary process C − λ(t). The proposed
tests work best if the lower and upper bounds are tight. However  in most practical cases  especially
the lower bound will be prohibitively low to apply any statistical test on the thinned process. As a
remedy  we proposed to consider only regions of λ(t|H(t)) for which the intensity exceeds a given
threshold and repeat the thinning for different thresholds. This successfully overcomes the limitation
that may have – up to now – prevented the use of the thinning algorithm as a goodness-of-ﬁt measure
for neural models.

The three tests are complementary in the sense that they are sensitive to different deviations of the
modeled and true intensity function. Time-rescaling is only sensitive to the total integral of the
intensity function between spikes  while thinning exclusively considers the intensity function at the
time of spikes and is insensitive to its value at places where no spikes occurred. Complementing is
sensitive to the exact shape of λ(t) regardless of where the spikes from the original observations are.
For the examples of an inhomogeneous Poisson process and the Spike Response Model  thinning
and complementing outperform the sensitivity of the simple time-rescaling procedure. They can
detect deviations from the model that are only half as large as the ones necessary to alert the test
based on time-rescaling. For modeling renewal processes  time-rescaling was slightly advantageous
compared to the to other methods. This should not come as a surprise since the time-rescaling test
is known to be sensitive to modeling the distribution of inter-spike intervals [3].

Beside from likelihood criteria [12  22  23]  there exist few goodness-of-ﬁt tools for neural mod-
els based on Generalized Linear Models [2  24]. With the proposed procedure for surrogate point
processes  we bridge the gap between such discrete models and point processes. That enables to
make use of additional tests from this domain  such as thinning and complementing procedures. We
expect these to be valuable contributions to the general practice of statistical evaluation in modeling
single neurons as well as neural populations.

Acknowledgments

Felipe Gerhard thanks Gordon Pipa and Robert Haslinger for helpful discussions. Felipe Gerhard
is supported by the Swiss National Science Foundation (SNSF) under the grant number 200020-
117975.

8

References
[1] Daley  D. J.  & Vere-Jones  D. (2002). An Introduction to the Theory of Point Processes  Volume 1 (2nd

ed.). New York: Springer.

[2] Ogata  Y. (1981). On Lewis’ simulation method for point processes. IEEE Transactions on Information

Theory  27(1).

[3] Brown  E. N.  Barbieri  R.  Ventura  V.  Kass  R. E.  & Frank  L. M. (2002). The time-rescaling theorem

and its application to neural spike train data analysis. Neural Computation  14(2)  325–346.

[4] Barbieri  R.  Quirk  M. C.  Frank  L. M.  Wilson  M. A.  & Brown  E. N. (2001). Construction and analysis
of non-Poisson stimulus-response models of neural spiking activity. Journal of Neuroscience Methods 
105(1)  25–37.

[5] Koyama  S.  & Kass  R. E. (2008). Spike train probability models for stimulus-driven leaky integrate-

and-ﬁre neurons. Neural computation  20(7)  1776–1795.

[6] Rigat  F.  de Gunst  M.  & van Pelt  J. (2006). Bayesian modelling and analysis of spatio-temporal

neuronal networks. Bayesian Analysis  1(4)  733–764.

[7] Shimokawa  T.  & Shinomoto  S. (2009). Estimating instantaneous irregularity of neuronal ﬁring. Neural

Computation  21(7)  1931–1951.

[8] Wojcik  D. K.  Mochol  G.  Jakuczan  W.  Wypych  M.  & Waleszczyk  W. (2009). Direct estimation of

inhomogeneous Markov interval models of spike trains. Neural Computation  21(8)  2105–2113.

[9] Truccolo  W.  Eden  U. T.  Fellows  M. R.  Donoghue  J. P.  & Brown  E. N. (2005). A point process
framework for relating neural spiking activity to spiking history  neural ensemble  and extrinsic covariate
effects. J Neurophysiol  93(2)  1074–1089.

[10] Pawitan  Y. (2001). In all likelihood: statistical modelling and inference using likelihood. Oxford: Oxford

University Press.

[11] Doya  K.  Ishii  S.  Pouget  A.  & Rao  R. P. N. (2007). Bayesian brain: Probabilistic approaches to

neural coding. Cambridge  MA: MIT Press.

[12] Pillow  J. W. (2009). Time-rescaling methods for the estimation and assessment of non-Poisson neural
encoding models.
In Y. Bengio  D. Schuurmans  J. Lafferty  C. K. I. Williams  & A. Culotta (Eds.)
Advances in Neural Information Processing Systems 22  (pp. 1473–1481). Cambridge  MA: MIT Press.
[13] Lewis  P. A. W.  & Shedler  G. S. (1979). Simulation of nonhomogeneous Poisson processes by thinning.

Nav. Res. Logist. Q.  26  403–413.

[14] Schoenberg  F. P. (2003). Multidimensional residual analysis of point process models for earthquake

occurrences. Journal of the American Statistical Association  98(464)  789–795.

[15] Simes  R. J. (1986). An improved Bonferroni procedure for multiple tests of signiﬁcance. Biometrika 

73(3)  751–754.

[16] Rodland  E. A. (2006). Simes’ procedure is ’valid on average’. Biometrika  93(3)  742–746.
[17] Haslinger  R.  Pipa  G.  & Brown  E. (2010). Discrete time rescaling theorem: Determining goodness of

ﬁt for discrete time statistical models of neural spiking. Neural Computation  22(10)  2477–2506.

[18] Schneidman  E.  Berry  M. J.  Segev  R.  & Bialek  W. (2006). Weak pairwise correlations imply strongly

correlated network states in a neural population. Nature  440(7087)  1007–1012.

[19] Pillow  J. W.  Shlens  J.  Paninski  L.  Sher  A.  Litke  A. M.  Chichilnisky  E. J.  & Simoncelli  E. P.
(2008). Spatio-temporal correlations and visual signalling in a complete neuronal population. Nature 
454(7207)  995–999.

[20] Tang  A.  Jackson  D.  Hobbs  J.  Chen  W.  Smith  J. L.  Patel  H.  Prieto  A.  Petrusca  D.  Grivich  M. I. 
Sher  A.  Hottowy  P.  Dabrowski  W.  Litke  A. M.  & Beggs  J. M. (2008). A maximum entropy model
applied to spatial and temporal correlations from cortical networks in vitro. Journal of Neuroscience 
28(2)  505–518.

[21] Gerstner  W.  & Kistler  W. M. (2002). Spiking Neuron Models. Cambridge: Cambridge University Press.
[22] Wood  F.  Roth  S.  & Black  M. (2006). Modeling neural population spiking activity with Gibbs distri-
butions. In Y. Weiss  B. Sch¨olkopf  & J. Platt (Eds.) Advances in Neural Information Processing Systems
18  (pp. 1537–1544). Cambridge  MA: MIT Press.

[23] Pillow  J.  Berkes  P.  & Wood  F. (2009). Characterizing neural dependencies with copula models. In
D. Koller  D. Schuurmans  Y. Bengio  & L. Bottou (Eds.) Advances in Neural Information Processing
Systems 21  (pp. 129–136). Cambridge  MA: MIT Press.

[24] Brown  E. N.  Barbieri  R.  Eden  U. T.  & Frank  L. M. (2003). Likelihood methods for neural spike train
data analysis. In J. Feng (Ed.) Computational Neuroscience: A comprehensive approach  (pp. 253–286).
London: Chapman and Hall.

9

,David Barrett
Sophie Denève
Christian Machens
Tae-Hyun Oh
Yasuyuki Matsushita
In Kweon
David Wipf
Brandon Yang
Gabriel Bender
Quoc Le
Jiquan Ngiam