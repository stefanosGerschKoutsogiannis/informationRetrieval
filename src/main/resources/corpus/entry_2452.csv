2011,Hierarchical Topic Modeling for Analysis of Time-Evolving Personal Choices,The nested Chinese restaurant process is extended to design a nonparametric  topic-model tree for representation of human choices. Each tree branch corresponds  to a type of person  and each node (topic) has a corresponding probability  vector over items that may be selected. The observed data are assumed to have  associated temporal covariates (corresponding to the time at which choices are  made)  and we wish to impose that with increasing time it is more probable that  topics deeper in the tree are utilized. This structure is imposed by developing  a new “change point" stick-breaking model that is coupled with a Poisson and  product-of-gammas construction. To share topics across the tree nodes  topic distributions  are drawn from a Dirichlet process. As a demonstration of this concept   we analyze real data on course selections of undergraduate students at Duke University   with the goal of uncovering and concisely representing structure in the  curriculum and in the characteristics of the student body.,Hierarchical Topic Modeling for Analysis of

Time-Evolving Personal Choices

XianXing Zhang
Duke University

xianxing.zhang@duke.edu

David B. Dunson
Duke University

dunson@stat.duke.edu

Lawrence Carin
Duke University

lcarin@ee.duke.edu

Abstract

The nested Chinese restaurant process is extended to design a nonparametric
topic-model tree for representation of human choices. Each tree path corresponds
to a type of person  and each node (topic) has a corresponding probability vector
over items that may be selected. The observed data are assumed to have associ-
ated temporal covariates (corresponding to the time at which choices are made) 
and we wish to impose that with increasing time it is more probable that topics
deeper in the tree are utilized. This structure is imposed by developing a new
“change point" stick-breaking model that is coupled with a Poisson and product-
of-gammas construction. To share topics across the tree nodes  topic distributions
are drawn from a Dirichlet process. As a demonstration of this concept  we ana-
lyze real data on course selections of undergraduate students at Duke University 
with the goal of uncovering and concisely representing structure in the curriculum
and in the characteristics of the student body.

1

Introduction

As time progresses  the choices humans make often change. For example  the types of products
one purchases  as well as the types of people one befriends  often change or evolve with time.
However  the choices one makes later in life are typically statistically related to choices made earlier.
Such behavior is of interest when considering marketing to particular groups of people  at different
stages of their lives  and it is also relevant for analysis of time-evolving social networks. In this
paper we seek to develop a hierarchical tree structure for representation of this phenomena  with
each tree path characteristic of a type of person  and a tree node deﬁned by a distribution over
choices (characterizing a type of person at a “stage of life”). As time proceeds  each person moves
along layers of a tree branch  making choices based on the node at a given layer  thereby yielding
a hierarchical representation of behavior with time. Note that as one moves deeper in the tree  the
number of nodes at a given tree layer increases as a result of sequential branching; this appears to be
well matched to the modeling of choices made by individuals  who often become more distinctive
and specialized with increasing time. The number of paths (types of people)  nodes (stages of
development) and the statistics of the time dependence are to be inferred nonparametrically based
on observed data  which are typically characterized by a very sparse binary matrix (most individuals
only select a tiny fraction of the choices that are available to them).
To demonstrate this concept using real data  we consider selections of classes made by undergraduate
students at Duke University  with the goal of uncovering structure in the students and classes  as
inferred by time-evolving student choices. For each student  the data presented to the model are a
set of indices of selected classes (but not class names or subject matter)  as well as the academic
year in which each class was selected (e.g.  sophomore year). While the student majors and class
names are not used by the model  they are known  and this information provides “truth” with which
model-inferred structure may be assessed. This study therefore also provides the opportunity to
examine the quality of the inferred hierarchical-tree structure in models of the type considered in

1

[1  4  5  8  7  12  13  6  21  15  22] (such structure is difﬁcult to validate with documents  for which
there is no “truth”). We seek to impose that as time progresses it is more probable that an individual’s
choices are based on nodes deeper in the tree  so that as one moves from the tree root to the leaves 
we observe the evolution of choices as people age. Such temporal tree-structure could be meaningful
by itself  e.g.  in our particular case it will allow university administrators and faculty to examine
if objectives in curriculum design are manifested in the actual usage/choices of students. Further 
the results of such an analysis may be of interest to applicants at a given school (e.g.  high school
students)  as the inferred structure concisely describes both the student body and the curriculum.
Also the uncovered structure may be used to aid downstream applications [17  2  11].
The basic form of the nonparametric tree developed here is based on the the nested Chinese restau-
rant process (nCRP) topic model [4  5]. However  to achieve the goals of the unique problem con-
sidered  we make the following new modeling contributions. We develop a new “change-point”
stick-breaking process (cpSBP)  which is a stick-breaking process that induces probabilities that
stochastically increase to an unknown changepoint and then decrease. This construction is concep-
tually related to the “umbrella” placed on dose response curves [9]. In the proposed model each
individual has a unique cpSBP  that evolves with time such that choices at later times are encour-
aged to be associated with deeper nodes in the tree. Time is a covariate  and within the change-point
model a new product-of-gammas construction is developed  and coupled to the Poisson distribution.
Another novel aspect of the proposed model concerns drawing the node-dependent topics from a
Dirichlet process  sharing topics across the tree. This is motivated by the idea that different types
of people (paths) may be characterized by similar choices at different nodes in the respective paths
(e.g.  person Type A may make certain types of choices early in life  while person Type B may make
similar choices later in life). Such sharing of topics allows the inference of relationships between
choices different people make over time.

2 Model Formulation

2.1 Nested Chinese Restaurant Process

The nested Chinese restaurant process (nCRP) [4  5] is a generative probabilistic model that deﬁnes
a prior distribution over a tree-structured hierarchy with inﬁnitely many paths. In an nCRP model of
personal choice each individual picks a tree path by walking from the root node down the tree  from
node to node. Speciﬁcally  when situated at a particular parent node  the child node ci individual
i chooses is modeled as a random variable that can be either an existing node or a new node: (i)
the probability that ci is an existing child node k is proportional to the number of persons who
already chose node k from the same parent  (ii) and a new node can be created and chosen with
probability proportional to γ0 > 0  which is the nCRP concentration parameter. This process is
deﬁned recursively such that each individual is allocated to one speciﬁc path of the tree hierarchy 
through a sequence of probabilistic parent-child steps.
The tree hierarchy implied by the nCRP provides a natural framework to capture the structure of
personal choices  where each node is characterized by a distribution on the items that may be se-
lected (e.g.  each node is a “choice topic"). Similar constructions have been considered for document
analysis [5  21  4]  in which the model captures the structure of word usage in documents. How-
ever  there are unique aspects of the time-evolving personal-choice problem  particularly the goal
motivated above that one should select topics deeper in the tree as time evolves  to capture the
specialized characteristics of people as they age. Hierarchical topic models proposed previously
[4  7] have employed a stick-breaking process (SBP) to guide selection of the tree depth at which
a node/topic is selected  with an unbounded number of path layers  but these models do not pro-
vide a means of imposing the above temporal dynamics (which were not relevant for the document
problems considered there).

2.2 Change Point Stick Breaking Process

In the proposed model  instead of constraining the SBP construction to start at the root node  we
model the starting-point depth of the SBP as a random variable and infer it from data  while still
maintaining a valid distribution over each layer of any path. To do this we replace the single SBP
over path layers with two statistically dependent SBPs: one begins from layer p + 1 and moves down

2

Figure 1: Illustrative comparison of the stick lengths between change point stick breaking process
(cpSBP) and stick breaking process (SBP) with different value of α; typical draws from cpSBP and
SBP are depicted. aω and bω are both set to 1  the change point is set to p = 30 and the truncation
of both stick breaking constructions are set to 60.

the tree away from the root  and the other begins from layer p and moves upward to the root; the
latter SBP is truncated when it hits the root  while the former is in principle of inﬁnite length. The
tree depth p which relates these two SBPs is modeled as a random variable  drawn from a Poisson
distribution  and is denoted the change point. In this way we encourage the principal stick weight to
be placed heavily around the change point p  instead of restricting it to the top layers as in [4  7]. To
model the time dependence  and encourage use of greater tree depths with increasing time  we seek
a formulation that imposes that the Poisson parameter grows (statistically) with increasing time.
The temporal information is represented as covariate t(i  n)  denoting the time at which the the nth
selection/choice is made by individual i; in many applications t(i  n) ∈ {1  . . .   T}  and for the
student class-selection problem T = 4  corresponding to the freshman through senior years; below
we drop the indices (i  n) on the time  for notational simplicity. When individual i makes selections
at time t  she employs a corresponding change point pi t. To integrate the temporal covariate into the
model  we develop a product-of-gammas and Poission conjugate pair to model pi t which encourages
pi t associated with larger t to locate deeper in the tree. Speciﬁcally  consider

γi l = Ga(γi l|ai l  bi l) 

λi t =

γi l 

pi t ∼ Poi(pi t|λi t)

(1)

t(cid:89)

l=1

The product-of-gammas construction in (1) is inspired by the multiplicative-gamma process (MGP)
developed in [3] for sparse factor analysis. Although each draw of γi l from a gamma distribution is
not guaranteed to be greater than one  and thus λi t will not increase with probability one  in practice
we ﬁnd γi l is often inferred to be greater than one when (ai l − 1)/bi l > 1. However  an MGP
based on a left-truncated gamma distribution can be readily derived.
Given the change point pi t = p  the cpSBP constructs the stick-weight vector θp
path bi by dividing it to into two parts: ˆθp
i t = {ˆθp
ˆθp
notation simplicity  we denote Vh = Vi t(h) when constructing θp

i t over layers of
i t  modeling them separately as two SBPs  where
i t = {˜θp
i t(∞)}. For
d−1(cid:89)

i t and ˜θp
i t(1)} and ˜θp

i t(p − 1)  . . .   ˆθp

i t(p + 1)  ˜θp

i t(p + 2)  . . .   ˜θp

i t  yielding

i t(p)  ˆθp

p(cid:89)

(1 − Vh) 

Vh ∼ beta(Vh|1  α)

(2)

ˆθp
i t(u) = Vu

(1 − Vh) 

˜θp
i t(d) = Vd

h=u+1

h=p+1

Note that the above SBP contains two constructions: When d > p the stick weight ˜θp
i t(d) is con-
structed as a classic SBP but with the stick-breaking construction starting at layer p + 1. On the
other hand when u ≤ p the stick weight ˆθp
i t(u) is constructed “backwards” from p to the root node 
which is a truncated stick breaking process with truncation level set to p. A thorough discussion
of the truncated stick breaking process is found in [10]. We further use a beta distributed latent
variable ωbi to combine the two stick breaking process together while ensuring each element of
i t = { ˆθp
i t} sums to one. Thus we have the following distribution over layers of a given path
θp
from which the layer allocation variables {li n : t(i  n) = t} for a selection at time t by individual i
are sampled:

i t  ˜θp

li n ∼ ωi t

ˆθi t(l)δl + (1 − ωi t)

˜θi t(l)δl  ωi t ∼ Beta(ωi t|aω  bω)

(3)

p(cid:88)

∞(cid:88)

l=1

l=p+1

3

5101520253035404550556000.10.20.30.40.5IndexStick Lenght  cpSBP  α=1cpSBP  α=5cpSBP  α=10SBP  α=1SBP  α=5SBP  α=10Note that the change point stick breaking process (cpSBP) can be treated as a generalization of the
stick breaking process for Dirichlet process  since when pi t = 0 the cpSBP corresponds to the
SBP. From the simulation studied in Figure 1  we observe that the change point  which is modeled
through the temporal covariate t as in (1)  corresponds to the layer with large stick weight and
thus at which topic draws are most probable. Also note that one may alternatively suggest simply
using pi t directly as the layer from which a topic is drawn  without the subsequent use of a cpSBP.
We examined this in the course of the experiments  and it did not work well  likely as a result of
the inﬂexibility of the single-parameter Poisson (with its equal mean and variance). The cpSBP
provided the additional necessary modeling ﬂexibility.

2.3 Sharing topics among different nodes

One problem with the nCRP-based topic model  implied by the tree structure  is that all descendent
sub-topics from parent node pa1 are distinct from the descendants of parent pa2  if pa1 (cid:54)= pa2.
Some of these distinct sets of children from different parents may be redundant  and this redundancy
can be removed if a child can have more than one parent [7  13  6]. In addition to the above problem 
in our application there are other potential problems brought by the cpSBP. Since we encourage the
later choice selections to be drawn from topics deeper in the tree  redundant topics at multiple layers
may be manifested if two types of people tend to make similar choices at different time points (e.g. 
at different stages of life). Thus it is likely that similar (redundant) topics may be learned on different
layers of the tree  and the inability of the original nCRP construction to share these topics misses
another opportunity to share statistical strength.
In [7  13  6] the authors addressed related challenges by replacing the tree structure with a directed
acyclic graph (DAG)  demonstrating success for document modeling. However  those solutions
don’t have the ﬂexibility of sharing topics on nodes among different layers. Here we propose a new
and simpler approach  so that the nCRP-based tree hierarchy is retained  while different nodes in the
whole tree may share the same topic  resolving the two problems discussed above. To achieve this
we draw a set of “global” topics { ˆφk}  and a stick-breaking process is employed to allocate one of
these global topics as φj  representing the jth node in the tree (this corresponds to drawing the {φj}
from a Dirichlet process [16]  with a Dirichlet distribution base). The SBP deﬁned over the global
topics is represented as follows:

∞(cid:88)

k−1(cid:89)

πk = δk

(1 − δi) 

δi ∼ Beta(δi|1  η) 

ˆφk ∼ Dir( ˆφk|β)  φj ∼

πkδ ˆφk

(4)

i=1

k=1

Within the generative process  let zi n denote the assignment of the nth choice of individual i to
global topic ˆφzi n; then the corresponding item chosen is drawn from Mult(1  ˆφzi n ).

3 Model Inference

In the proposed model  we sample the per-individual tree path indicator bi  the layer allocation of
choice topics in those paths li n  the change point pi t for each time interval  the parameters associ-
ated with the cpSBP construction γi t  ωi t  θp
i t  the stick breaking weight π over the global topics
ˆφk  and the global topic-assignment indicator zi n. Similar to [4]  the per-node topic parameters φn
are marginalized out. We provide update equations cycling through {li n  pi t  γi t  ωi t  θp
i t} that
are unique for this model. The update equations for bi and {π  zi n} are similar to the the ones in
[4] and [18]  respectively  which we do not reproduce here for brevity.

Sampling for change point pi t Due to the non-conjugacy between the Poisson and multinomial
distributions  the exact form of its posterior distribution is difﬁcult to compute. Additionally  in or-
der to sample pi t  we require imputation of an inﬁnite-dimensional process. The implementation of
the sampling algorithm either relies on ﬁnite approximations [10] which lead to straightforward up-
date equations  or requires an additional Metropolis-Hastings (M-H) step which allows us to obtain
samples from the exact posterior distribution of pi t with no approximation  e.g.  the retrospective
sampler [14] proposed for Dirichlet process hierarchical models. In this section we ﬁrst introduce
the ﬁnite approximation based sampler  and the retrospective sampling scheme based method will
be described in the supplemental material.

4

Denote P as the truncated maximum value of the change point  then given the samples of all other
latent variables  pi t can be sampled from the following equation:

q(pi t = p|θp

i t  λi t  ωi t  li t) ∝ p(pi t = p|λi t  P )p(li t|θp

(5)
where li t = {li n : t(i  n) = t} are all layer allocations of choices made by individual i at time
t. p(pi t = p|λi t  P ) =
is the Poisson density function truncated with p ≤ P   and
i t}) is the multinomial

i t  ωi t) = Mult(li t|{ωi t

CP = (cid:80)P

i t  ωi t)  0 ≤ p ≤ P

i t  (1 − ωi t) ˜θp
ˆθp

. p(li t|θp

−λi t
i te
p!

i te
p!CP

−λi t

p=1

λp

λp

density function over the layer allocations li t.

Sampling choice layer allocation li n Given all the other variables  now we sample the layer
allocation li n for the nth choice made by individual i. Denote ci n as the nth choice made by
individual i  Mzi n ci n = #[z−(i n) = zi n  c−(i n) = ci n] + β as the smoothed count of seeing
choice ci n allocated to global topic zi n  excluding the current choice. Parameter li n can be sampled
from the following equation:

p(li n = l|pi t = p  z  ωi t  θp

i t  c) ∝

ˆθp
i t(l)Mzi n ci n  

ωi t
(1 − ωi t)˜θp

i t(l)Mzi n ci n 

0 < l ≤ p
p < l ≤ P

(cid:40)

Sampling for product-of-gammas construction γi t From (1) note that the temporal dependent
intensity parameter λi t can be reconstructed from the gamma distributed variables γi t  which again
can be sampled directly from its posterior distribution given all other variables  due to the conjugacy
of product-gamma variable and Poisson construction. Denoting τ (t)

i l =(cid:81)l

j=1 j(cid:54)=t γi j  we have:

p(γi t|{pi t}T

t=1  ai t  bi t) = Ga

γi t

(cid:32)

(cid:12)(cid:12)(cid:12)ai t +

T(cid:88)

(cid:33)

T(cid:88)

pi l  bi t +

τ (t)
i l

l=t

l=t

Sampling for cpSBP parameters {ωi t  θp
cation li t = {li n : t(i  n) = t}  the cpSBP parameters θp
based on samples of Vh as deﬁned in (2). Speciﬁcally  we have

p(Vh|pi t = p  li t) =

(cid:16)
(cid:16)

 Beta
l=1 Nl t  1 +(cid:80)max li t

Beta

i t = { ˆθp

i t} Given the change points pi t and choice layer allo-
i t} can be reconstructed
(cid:17)

i t  ˜θp

(cid:17)

if h ≤ p
if h > p

l=1 Nl t
l=h+1 Nl t

Vh|ah + Nh t  bh +(cid:80)h−1
Vh|ah + Nh t  bh +(cid:80)max li t
(cid:17)

where Nl t = #[li n = l  t(i  n) = t] records the number of times a choice made by individ-
ual i in time interval t is allocated to path layer l. Given the samples of other variables  ωi t is
sampled from its full conditional posteior distribution: p(ωi t|pi t = p {li n : t(i  n) = t}) =
Beta

(cid:16)

(cid:12)(cid:12)(cid:12)1 +(cid:80)p

l=p+1 Nl t

ωi t

Sampling the Hyperparameters Concerning hyperparameters α  η  γ0  β  related to the stick
breaking process and hierarchical topic model construction  we sample them within the inference
process by placing prior distributions over them  similar to methods in [4]. One may also consider
other alternatives for learning the hyperparameters within topic models [19]. For the hyperparame-
ters ai l  bi l in the product-of-gamma construction  we sample them as proposed in [3]. Finally  we
ﬁx aw = 1 and sample bw by placing a gamma prior distribution on it. All these steps are done by a
M-H step between iterations of the Gibbs sampler.

4 Analysis of student course selection

4.1 Data description and computations

We demonstrate the proposed model on real data by considering selections of classes made by un-
dergraduate students at Duke University  for students in graduating classes 2009 to 2013; the data
consists of class selections of all students from Fall 2005 to Spring 2011. For computational reasons

5

the cpSBP and SBP employed over the tree-path depth are truncated to a maximum of 10 layers (be-
yond this depth the number of topics employed by the data was minimal)  while the number children
of each parent node is allowed to be unbounded. Within the sampler  we ran the model based on
the class selection records of students from class of 2009 and 2010 (total of 3382 students and 2756
unique classes)  and collected 200 samples after burn-in  taking every ﬁfth sample to approximate
the posterior distribution over the latent tree structure as well as the topic on each node of the tree.
We analyze the quality of the learned models using the remaining data (classes of 2011-2013)  char-
acterized by 5171 students and 2972 unique classes. Each topic is a probabilistic vector deﬁned over
3015 classes offered across all years. Within the MCMC inference procedure we trained our model
as follows: ﬁrst  we ﬁxed the change point pi t = t and then ran the sampler for 100 iterations  then
burned in the inference for 5000 iterations with pi t updated before drawing 5000 samples from the
full posterior.

4.2 Quantitative assessment

nCRP

cpSBP-nCRP

DP-nCRP
Full model

# Topics
492±11
973±37
318±26
367±32

# Nodes
492±11
973±37
521±41
961±44

Predictive LL (11)

-293226.8399
-290271.3576
-292311.3971
-288511.4298

Predictive LL (11-13)

-471736.8876
-469912.1120
-471951.3452
-468331.2990

Table 1: Predictive log-likelihood comparison on two datasets  given the mean of number of topics
and nodes learned with rounded standard deviation. nCRP is the model proposed in [4]. Compared
to nCRP  the cpSBP-nCRP replaced SBP with the proposed cpSBP  while in DP-nCRP the draw of
topic for each node is from Dirichlet process(DP) instead of Dirichlet distribution and retained the
SBP construction in nCRP. The full model used both cpSBP and DP. Results shown for class of
2011  and classes 2011-2013.

Figure 2: Histograms of class layer allocations according to their time covariates. Left: Stick break-
ing process  Right: Change point stick breaking process

In this section we examine the model’s ability to explain unseen data. For comparison consistency
we computed the predictive log-likelihood based on the samples collected in the same way as [4]
(alternatives means of evaluating topic models are discussed in [20]). We test the model using two
different compositions of the data  the ﬁrst is based on class selection history of students from class
of 2011 (1696 students)  where all 4 years of records are available. The second is based on class
selection history of students from class of 2011 to 2013 (3475 students)  where for the later two
years only partial course selection information is available  e.g.  for students from class of 2013
only class selection choices made in freshman year are available. Additionally  we compare the
different models with respect to the learned number of topics and the learned number of tree nodes.
This comparison is an indicator of the level of “parsimony” of the proposed model  introduced by
replacing independent draws of topics from a Dirichlet distribution by draws from a Dirichlet process
(with Dirichlet distribution base)  as explained in Section 2.3. Since the number of tree nodes grows
exponentially with the number of tree layers  from a practical viewpoint sharing topics among the
nodes saves memory used to store the topic vectors  whose dimension is typically large (here the
number of classes: 3015). In addition to the above insight  as the experimental results indicates 
sharing topics among different nodes can enhance the sharing of statistical strength  which leads to
better predictive performance. The results are summarized in Table 4.2.
We hypothesize that the enhanced performance of the proposed model to explain the unseen data is
also due to it’s improved ability to capture the latent predictive statistical structure  e.g.  to capture

6

1234567891001234x 104Layer  FreshmanSophomoreJuniorSenior1234567891001234x 104Layer  FreshmanSophomoreJuniorSeniorFigure 3: Change of the proportion of important majors along the layers of two paths which share the
nodes up to the second layer. These two paths correspond to the full versions (all 7 layers) of the top
two paths in Figure 4. BME: Biomedical Engineering  POLI: Political Science  ECON: Economics 
CS: Computer Science  BIO: Biology  PPS: Public Policy Science  ME: Mechanical Engineering 
OTHER: other 73 majors.

the latent temporal dynamics within the data by the change point stick breaking process (cpSBP).
To demonstrate this point  in Figure 2 we compare how cpSBP and SBP guided the class layer
allocations which have associated time covariates (e.g.  the academic year of each student). From
Figure 2 we observe that under spSBP  as the students’ academic career advances  they are more
probable to choose classes from topics deeper in the tree  while such pattern is less obvious in the
SBP case. Further  spSBP encouraged the data to utilize more layers in the tree than SBP.

4.3 Analyzing the learned tree

With incorporation of time covariates  we examine if the uncovered hierarchical structure is consis-
tent with the actual curriculum of students from their freshman to senior year. And we consider two
analyses here.
The ﬁrst is a visualization of a subtree learned from the class-selection history  based on students of
the class of 2009  as shown in Figure 4; shown are the most-probable classes in each topic  as well as
a histogram on the covariates (1 to 4  for freshman through senior) of the students who employed the
topic. For example  the topics on the top two layers correspond to the most popular classes selected
by mechanical engineering and computer science students  respectively  while topics located to the
right correspond to more advanced classes; to the left-most the root topic corresponds to classes
required for all students (e.g.  academic writing). The tree structured hierarchy captured the general
trend of class selection within/across different majors.
In Figure 4 we also highlight a topic in red  shared by two nodes. This topic corresponds to a set of
general introductory classes which are popular (high attendance) for two types of students: (i) young
students who take these classes early for preparation of future advanced studies  and (ii) students
who need to ﬁll elective requirements later in their academic career (“ideally" of an easy/elementary
nature  to not “distract" from required classes from the major). It is therefore deemed interesting
that these same classes seem to be preferred by young and old students  for apparently very different
reasons. Note that the sharing of topics between nodes of different layers is a unique aspect of this
model  not possible in [7  13  6].
In the second analysis we examine how the majors of students are distributed in the learned tree;
the ideal case would be that each tree path corresponds to an academic major  and the nodes shared
by paths manifest sharing of topics between different but related majors. In Figure 3 we show the
change of proportions of different majors among different layers of the top two paths in Figure 4
(this is a zoom-in of a much larger tree). For a clear illustration  we show the seven most popular
majors for these paths as a function of time (out of a total of 80 majors)  and the remaining 73 majors
are group together. We observe that the students with mechanical engineering (ME) majors share the
node on the second layer with students with a computer science (CS) major  and the layers deeper in
the tree begin to be exclusive to students with CS and ME majors  respectively. This phenomenon
corresponds to the process a student determining her major by choosing courses as she walks down
tree path. This also matches the fact that in this university  students declare their major during the
sophomore year.

7

00.10.20.30.40.50.60.70.80.911234567ProportionLayer  00.10.20.30.40.50.60.70.80.911234567ProportionLayer  BMEPOLIECONCSBIOPPSMEOTHERFigure 4: A subtree of topics learned from courses chosen by undergraduate students of class 2009;
the whole tree has 372 nodes and 252 topics  and a maximum of 7 layers. Each node shows two
aggregated statistics at that node: the eight most common classes of the topic on that node and a
histogram of the academic year the topic was selected by students (1-4  for freshman-senior). The
columns in each of the histogram correspond to freshman to senior year from left to right. The two
highlighted red nodes share the same topic. These results correspond to one (maximum-likelihood)
collection sample.

5 Discussion

We have extended hierarchical topic models to an important problem that has received limited at-
tention to date: the evolution of personal choices over time. The proposed approach builds upon the
nCRP [4]  but introduces novel modeling components to address the problem of interest. Specif-
ically  we develop a change-point stick-breaking process  coupled with a product of gammas and
Poisson construction  that encourages individuals to be represented by nodes deeper in the tree as
time evolves. The Dirichlet process has also been used to design the node-dependent topics  sharing
strength and inferring relationships between choices of different people over time. The framework
has been successfully demonstrated with a real-world data set: selection of courses over many years 
for students at Duke University.
Although we worked only on one speciﬁc real-world data set  there are many other examples for
which such a model may be of interest  especially when the data correspond to a sparse set of choices
over time. For example  it could be useful for companies attempting to understand the purchases
(choices) of customers  as a function of time (e.g.  the clothing choices of people as they advance
from teen years to adulthood). This may be of interest in marketing and targeted advertisement.

Acknowledgements
We would like to thank the anonymous reviewers for their insightful comments. The research re-
ported here was supported by AFOSR  ARO  DARPA  DOE  NGA and ONR.

8

INTRO	  TO	  SIGNALS	  AND	  SYSTEMS	  MICROELECT	  DEVICES	  &	  CIRCUITS	  ELECTRONIC	  MUSIC	  QUANTUM	  MECHANICS	  I	  TRNSPRT	  PHENOM	  BIOLOGCL	  SYS	  NONLINEAR	  DYNAMICS	  INTRO	  ELECTRIC 	  MAGNET	  TISSUE	  ENGINEERING	  MECHANICAL	  DESIGN	  AERODYNAMICS	  THERMO	  DYNAMICS	  MODELS	  CELL	  &	  MOL	  SYSTEMS	  COMPRESSIBLE	  FLUID	  FLOW	  SIGNALS	  AND	  SYSTEMS	  ELECTROMAGNET	  FIELDS	  FAILURE	  ANALY/PREVENTION	  CHEM/TECHNOL/SOCIETY	  DATA	  ANALY/STAT	  INFER	  THE	  DYNAMIC	  EARTH	  SOCIAL	  PSYCHOLOGY	  ABNORMAL	  PSYCHOLOGY	  POL	  ANALY	  PUB	  POL	  MAKING	  GLOBAL	  HEALTH	  ELEMENTARY	  SPANISH	  ACADEMIC	  WRITING	  ECONOMIC	  PRINCIPLES	  	  	  GENERAL	  CHEMISTRY	  I	  GENERAL	  CHEMISTRY	  II	  INTERMEDIATE	  CALCULUS	  INTERMEDIATE	  ECONOMICS	  I	  	  INTRODUCTORY	  PSYCHOLOGY	  LABORATORY	  CALCULUS	  I	  COMP	  METH	  IN	  ENGINEERING	  INTERMEDIATE	  CALCULUS	  INTRODUCTORY	  MECHANICS	  INTRO	  TO	  ENGINEERING	  LINEAR	  ALGEBRA	  GENERAL	  CHEMISTRY	  ENGINEERING	  INNOVATION	  ELECTRICITY	  &	  MAGNETISM	  THE	  DYNAMIC	  EARTH	  INTEGRATING	  ENV	  SCI/POL	  ENERGY	  AND	  ENVIRONMENT	  LIBERTY	  &	  AMER	  CONST	  GENERAL	  PHYSICS	  II	  INTERMEDIATE	  GERMAN	  I	  U	  S	  ENVIRONMENTAL	  POL	  ECONOMIC	  PRINCIPLES	  COMPUTER	  ORGANIZA/PROG	  SOFTWARE	  DESIGN/IMPLEMEN	  DISCRETE	  MATH	  FOR	  COMPSCI	  INTRO	  TO	  OPERATING	  SYSTM	  INTRO	  TO	  MATH	  LOGIC	  INTRO	  TO	  DATABASE	  SYSTEMS	  DESIGN/ANALY	  ALGORITHMS	  PROGRAM	  DESIGN/ANALY	  II	  MODERN	  TERRORISM	  LIBERTY/EQUALITY&AMER	  CONST	  CAMPAIGNS	  AND	  ELECTIONS	  JUNIOR-­‐SENIOR	  SEM	  SP	  TOP	  THE	  AMERICAN	  PRESIDENCY	  ERA	  OF	  THE	  AMERICAN	  REVOLU	  HISTORY	  OF	  WORLD	  WARS	  POLITICS	  AND	  LITERATURE	  THEATER	  IN	  LONDON:	  TEXT	  THEATER	  IN	  LONDON:	  PERFORM	  INDIVID	  DANCE	  PROG:	  SPECIAL	  INTRODUCTION	  TO	  ACTING	  DIRECTING	  THEATER	  PRODUCTION	  TENNESSEE	  WILLIAMS/CHEKHOV	  INTRODUCTION	  TO	  THEATER	  PROGRAM	  DESIGN/ANALY	  I	  INTRO	  ELECTRIC 	  MAGNET	  STRUCT	  DESIGN	  AND	  OPTMZATN	  ELEM	  DIFFERENTIAL	  EQUAT	  COMPUTER	  ARCHITECTURE	  PROBABIL/STATIS	  IN	  EGR	  MATRIX	  STRUCT	  ANALYSIS	  CONCRETE	  AND	  COMP	  STRUCT	  DEV	  CONGRESS	  AS	  INSTITUTION	  MODERN	  AMERICA	  INTERNATIONAL	  SECURITY	  POL	  DEV	  WESTERN	  EUROPE	  GLOBAL	  AND	  DOM	  POLITICS	  CRUSADES	  TO	  HOLY	  LAND	  SPECIAL	  TOPICS	  IN	  POLITICS	  THEOL/FICTION	  C	  S	  LEWIS	  ACOUSTICS	  AND	  MUSIC	  REPERTORY:	  MODERN	  DANCE	  COMPOSITION	  MEDIA	  INTERN	  LOS	  ANGELES	  U.S.	  CULTURE	  INDUSTRIES	  THE	  HOLLYWOOD	  CYBER	  JOUR	  REPERTORY:	  BALLET	  MODERN	  DANCE	  1890-­‐1950	  COMP	  NETWORK	  ARCHITEC	  ELECTROMAGNET	  FIELDS	  INTRO	  TO	  EMBEDDED	  SYSTEMS	  LINEAR	  CONTROL	  SYSTEMS	  ELECTRICITY	  &	  MAGNETISM	  COMPUTER	  ARCHITECTURE	  INTRO	  TO	  OPERATING	  SYSTM	  DIG	  IMAGE/MULTIDIM	  PROCESSING	  CHEM/TECHNOL/SOCIETY	  DATA	  ANALY/STAT	  INFER	  THE	  DYNAMIC	  EARTH	  SOCIAL	  PSYCHOLOGY	  ABNORMAL	  PSYCHOLOGY	  POL	  ANALY	  PUB	  POL	  MAKING	  GLOBAL	  HEALTH	  ELEMENTARY	  SPANISH	  LAW	  AND	  POLITICS	  LIBERTY/EQUALITY&AMER	  CONST	  CAMPAIGNS	  AND	  ELECTIONS	  JUNIOR-­‐SENIOR	  SEM	  SP	  TOP	  THE	  AMERICAN	  PRESIDENCY	  ERA	  OF	  THE	  AMERICAN	  REVOL	  HISTORY	  OF	  WORLD	  WARS	  POLITICS	  AND	  LITERATURE	  THEATER	  IN	  LONDON:	  TEXT	  THEATER	  IN	  LONDON:	  PERFORM	  INDIVID	  DANCE	  PROG:	  SPECIAL	  INTRODUCTION	  TO	  ACTING	  DIRECTING	  THEATER	  PRODUCTION	  TENNESSEE	  WILLIAMS/CHEKHOV	  INTRODUCTION	  TO	  THEATER	  References
[1] R. P. Adams  Z. Ghahramani  and M. I. Jordan. Tree-structured stick breaking for hierarchical

data. In Neural Information Processing Systems (NIPS)  2010.

[2] E. Bart  I. Porteous  P. Perona  and M. Welling. Unsupervised learning of visual taxonomies.

In CVPR  2008.

[3] A. Bhattacharya and D. B. Dunson. Sparse Bayesian inﬁnite factor models. Biometrika  2011.
[4] D. M. Blei  T. L. Grifﬁths  and M. I. Jordan. The nested Chinese restaurant process and

Bayesian nonparametric inference of topic hierarchies. Journal of the ACM  57(2)  2010.

[5] D. M. Blei  T. L. Grifﬁths  M. I. Jordan  and J. B. Tenenbaum. Hierarchical topic models
and the nested Chinese restaurant process. In Neural Information Processing Systems (NIPS).
2004.

[6] A. Chambers  P. Smyth  and M. Steyvers. Learning concept graphs from text with stick-

breaking priors. In Advances in Neural Information Processing Systems(NIPS). 2010.

[7] H. Chen  D.B. Dunson  and L. Carin. Topic modeling with nonparametric Markov tree. In

Proc. Int. Conf. Machine Learning (ICML)  2011.

[8] T. L. Grifﬁths  M. Steyvers  and J. B. Tenenbaum. Topics in semantic representation. Psycho-

logical Review  114(2):211–244  2007.

[9] C. Hans and D. B. Dunson. Bayesian inferences on umbrella orderings. BIOMETRICS 

61:1018–1026  2005.

[10] H. Ishwaran and L. F. James. Gibbs sampling methods for stick-breaking priors. Journal of

the American Statistical Association  96(453):161–173  2001.

[11] L. Li  C. Wang  Y. Lim  D. Blei  and L. Fei-Fei. Building and using a semantivisual image

hierarchy. In CVPR  2010.

[12] W. Li and A. McCallum. Pachinko allocation: Dag-structured mixture models of topic corre-

lations. In Proc. Int. Conf. Machine Learning (ICML)  2006.

[13] D. Mimno  W. Li  and A. McCallum. Mixtures of hierarchical topics with Pachinko allocation.

In Proc. Int. Conf. Machine Learning (ICML)  2007.

[14] O. Papaspiliopoulos and G. O. Roberts. Retrospective Markov chain Monte Carlo methods for

Dirichlet process hierarchiacal models. Biometrika  95(1):169–186  2008.

[15] R. Salakhutdinov  J. Tenenbaum  and A. Torralba. One-shot Learning with a Hierarchical

Nonparametric Bayesian Model. MIT Technical Report  2011.

[16] J. Sethuraman. A constructive deﬁnition of Dirichlet priors. Statistica Sinica  4:639–650 

1994.

[17] J. Sivic  B. C. Russell  A. Zisserman  W. T. Freeman  and A. A. Efros. Unsupervised discovery

of visual object class hierarchies. In CVPR  2008.

[18] Y. W. Teh  M. I. Jordan  Matthew J. Beal  and D. M. Blei. Hierarchical Dirichlet processes.

Journal of the American Statistical Association  101(476):1566–1581  2006.

[19] H. M. Wallach  D. Mimno  and A. McCallum. Rethinking LDA: Why priors matter. In Neural

Information Processing Systems (NIPS)  2009.

[20] H. M. Wallach  I. Murray  R. Salakhutdinov  and D. Mimno. Evaluation methods for topic

models. In Proc. Int. Conf. Machine Learning (ICML)  2009.

[21] C. Wang and D. M. Blei. Variational inference for the nested Chinese restaurant process. In

Neural Information Processing Systems (NIPS)  2009.

[22] XX. Zhang  D. B. Dunson  and L. Carin. Tree-structured inﬁnite sparse factor model. In Proc.

Int. Conf. Machine Learning (ICML)  2011.

9

,Ruoyu Sun
Yonghong Luo
Xiangrui Cai
Ying ZHANG
Jun Xu
Yuan xiaojie