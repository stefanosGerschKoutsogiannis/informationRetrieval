2011,Active Learning Ranking from Pairwise Preferences with Almost Optimal Query Complexity,Given a set $V$ of  $n$ elements we wish to linearly order them using pairwise preference labels  which may be non-transitive (due to irrationality or arbitrary noise).  The goal is to linearly order the elements while disagreeing with  as few pairwise preference labels as possible.  Our performance is measured by two parameters:  The number of disagreements (loss) and the query complexity (number of pairwise preference labels).  Our algorithm adaptively queries  at most $O(n\poly(\log n \eps^{-1}))$ preference labels for a regret of  $\eps$ times the optimal loss.  This is strictly better  and often significantly better than what  non-adaptive sampling could achieve.  Our main result helps settle an open problem posed by   learning-to-rank (from pairwise information) theoreticians and practitioners:  What is a provably correct way to sample preference labels?,Active Learning Ranking from Pairwise Preferences

with Almost Optimal Query Complexity

Technion  Haifa  Israel nailon@cs.technion.ac.il

Nir Ailon∗

Abstract

Given a set V of n elements we wish to linearly order them using pairwise
preference labels which may be non-transitive (due to irrationality or arbitrary
noise). The goal is to linearly order the elements while disagreeing with as
few pairwise preference labels as possible. Our performance is measured by
two parameters: The number of disagreements (loss) and the query complex-
ity (number of pairwise preference labels). Our algorithm adaptively queries at
most O(n poly(log n  ε−1)) preference labels for a regret of ε times the optimal
loss. This is strictly better  and often signiﬁcantly better than what non-adaptive
sampling could achieve. Our main result helps settle an open problem posed
by learning-to-rank (from pairwise information) theoreticians and practitioners:
What is a provably correct way to sample preference labels?

1

Introduction

problem  with a ﬁnite sample space of(cid:0)n

2

(cid:1) possibilities only (hence a transductive learning problem).

We study the problem of learning to rank from pairwise preferences  and solve an open problem
that has led to development of many heuristics but no provable results. The input is a set V of n
elements from some universe  and we wish to linearly order them given pairwise preference labels 
given as response to which is preferred  u or v? for pairs u  v ∈ V . The goal is to linearly order
the elements from the most preferred to the least preferred  while disagreeing with as few pairwise
preference labels as possible. Our performance is measured by two parameters: The loss (number of
disagreements) and query complexity (number of preference responses we need). This is a learning
The loss minimization problem given the entire n × n preference matrix is a well known NP-hard
problem called MFAST (minimum feedback arc-set in tournaments) [5]. Recently  Kenyon and
Schudy [23] have devised a PTAS for it  namely  a polynomial (in n) -time algorithm computing a
solution with loss at most (1 + ε) the optimal  for and ε > 0 (the degree of the polynomial there
may depend on ε). In our case each edge from the input graph is given for a unit cost  hence we seek
query efﬁciency. Our algorithm samples preference labels non-uniformly and adaptively  hence we
obtain an active learning algorithm. Our output is not a solution to MFAST  but rather a reduction of
the original learning problem to a simpler one decomposed into small instances in which the optimal
loss is high  consequently  uniform sampling of preferences can be shown to be sufﬁciently good.
Our Setting vs. The Usual “Learning to Rank” Problem. Our setting defers from much of
the learning to rank (LTR) literature. Usually  the labels used in LTR problems are responses to
individual elements  and not to pairs of elements. A typical example is the 1..5 scale rating for
restaurants  or 0  1 rating (irrelevant/relevant) for candidate documents retrieved for a query (known
as the binary ranking problem). The preference graph induced from these labels is transitive  hence
no combinatorial problems arise due to nontransitivity. We do not discuss this version of LTR. Some
LTR literature does consider the pairwise preference label approach  and there is much justiﬁcation
to it (see [11  22] and reference therein). Other works (e.g. [26]) discuss pairwise or higher order

∗Supported by a Marie Curie International Reintegration Grant PIRG07-GA-2010-268403

1

(listwise) approaches  but a close inspection reveals that they do not use pairwise (or listwise) labels 
only pairwise (or listwise) loss functions.
Using Kenyon and Schudy’s PTAS as a starting point. As mentioned above  our main algorithm
is derived from the PTAS of [23]  but with a signiﬁcant difference. We use their algorithm to obtain
a certain decomposition of the input. A key change to their algorithm  which is not query efﬁcient 
involves careful sampling followed by iterated sample refreshing steps.
Our work can be studied in various contexts  aside from LTR. Machine Learning Reductions: Our
main algorithm reduces a given instance to smaller subproblems decomposing it. We mention other
work in this vein: [6  3  9]. Active Learning: An important ﬁeld of statistical learning theory and
practice ([8  21  15  14  24  17  13  20  16  13]). In the most general setting  one wishes to improve
on standard statistical learning theoretical complexity bounds by actively choosing instances for
labels. Many heuristics have been developed  while algorithms with provable bounds (especially in
the agnostic case) are known for few problems  often toys. General bounds are difﬁcult to use: [8]
provides general purpose active learning bounds which are quite difﬁcult to use in actual speciﬁc
problems; The A2 algorithm [7]  analyzed in [21] using the disagreement coefﬁcient is not useful
here. It can be shown that the disagreement coefﬁcient here is trivial (omitted due to lack of space).
Noisy Sorting: There is much literature in theoretical computer science on sorting noisy data.
[10] work in a Bayesian setting; In [19]  the input preference graph is transitive  and labels are
nondeterministic. In other work  elements from the set of alternatives are assumed to have a latent
value. In this work the input is worst case and not Bayesian  query responses are deterministic and
elements do not necessarily have a latent value.
Paper Organization: Section 2 presents basic deﬁnitions and lemmata  and in particular deﬁnes
what a good decomposition is and how it can be used in learning permutations from pairwise pref-
erences. Section 3 presents our main active learning algorithm which is  in fact  an algorithm for
producing a good decomposition query efﬁciently. The main result is presented in Theorem 3.1.
Section 4 discusses future work and followup work appearing in the full version of this paper.

2 Notation and Basic Lemmata

Let V denote a ﬁnite set of size n that we wish to rank.1 We assume an unknown preference function
W on pairs of elements in V   which is unknown to us. For any pair u  v ∈ V   W (u  v) is 1 if u is
deemed preferred over v  and 0 otherwise. We enforce W (u  v) + W (v  u) = 1 (no abstentation)
hence  (V  W ) is a tournament. We assume that W is agnostic: it is not necessarily transitive and
may contain errors and inconsistencies. For convenience  for any two real numbers a  b we will let
[a  b] denote the interval {x : a ≤ x ≤ b} if a ≤ b and {x : b ≤ x ≤ a} otherwise.
We wish to predict W using a hypothesis h from concept class H = Π(V )  where Π(V ) is the
set of permutations π over V viewed equivalently as binary functions over V × V satisfying  for
all u  v  w ∈ V   π(u  v) = 1 − π(v  u) and π(u  w) = 1 whenever π(u  v) = π(v  w) = 1. For
π ∈ Π(V ) we also use notation: π(u  v) = 1 if and only if u ≺π v  namely  if u precedes v in π.
Abusing notation  we also view permutations as injective functions from [n] to V   so that the element
π(1) ∈ V is in the ﬁrst  most preferred position and π(n) is the least preferred one. We also deﬁne
the function ρπ inverse to π as the unique function satisfying π(ρπ(v)) = v for all v ∈ V . Hence 
u ≺π v is equivalent to ρπ(u) < ρπ(v). ) As in standard ERM  we deﬁne a risk function Cu v
penalizing the error of π with respect to the pair u  v  namely  Cu v(π  V  W ) = 1π(u v)(cid:54)=W (u v) .
The total loss  C(h  V  W ) is deﬁned as Cu v summed over all unordered u  v ∈ V . Our goal is to
devise an active learning algorithm for the purpose of minimizing this loss.
In this paper we show an improved  almost optimal statistical learning theoretical bound using recent
important breakthroughs in combinatorial optimization of a related problem called minimum feed-
back arc-set in tournaments (MFAST). The relation between this NP-Hard problem and our learning
problem has been noted before in (eg [12])  when these breakthroughs were yet to be known.
MFAST is more precisely deﬁned as follows: V and W are given in entirety (we pay no price for
reading W )  and we seek π ∈ Π(V ) minimizing the MFAST cost C(π  V  W ). A PTAS has been

1In a more general setting we are given a sequence V 1  V 2  . . . of sets  but there is enough structure and

interest in the single set case  which we focus on in this work.

2

discovered for this NP-Hard very recently in groundbreaking work by Kenyon and Schudy [23].
This PTAS is not useful however for the purpose of learning to rank from pairwise preferences
because it is not query efﬁcient. It may require to read all quadratically many entries in W . In this
work we ﬁx this drawback  and use the PTAS to obtain a certain useful decomposition.
Deﬁnition 2.1. Given a set V of size n  an ordered decomposition is a list of pairwise disjoint
subsets V1  . . .   Vk ⊆ V such that ∪k
i=1Vi = V . We let W|Vi denote the restriction of W to Vi × Vi
for i = 1  . . .   k. For a permutation π ∈ Π(v) we let π|Vi denote its restriction to the elements of Vi
(hence  π|Vi ∈ Π(Vi)). We say that π ∈ Π(V ) respects V1  . . .   Vk if for all u ∈ Vi  v ∈ Vj  i < j 
u ≺π v. We denote the set of permutations π ∈ Π(V ) respecting the decomposition V1  . . .   Vk by
Π(V1  . . .   Vk). We say that a subset U of V is small in V if |U| ≤ log n/ log log n  otherwise we
say that U is big in V . A decomposition V1  . . .   Vk is ε-good with respect to W if:2

(cid:88)

C(π|Vi  Vi  W|Vi) ≥ ε2 (cid:88)

(cid:18)ni

(cid:19)

.

2

(2.1)

(2.2)

Local Chaos:

min

π∈Π(V )

Approximate Optimality:

min

σ∈Π(V1 ... Vk)

C(σ  V  W ) ≤ (1 + ε) min
π∈Π(V )

C(π  V  W ) .

i:Vi big in V

i:Vi big in V

2

We will show how to use an ε-good decomposition  and how to obtain one query-efﬁciently.
Basic (suboptimal) results from statistical learning theory: Viewing pairs of V -elements as data
points  the loss C(π  V  W ) is  up to normalization  an expected cost over a random draw of a data
point. A sample E of unordered pairs gives rise to a partial cost  CE deﬁned as: CE(π  V  W ) =
W (v  u). (We assume throughout that E is chosen with repetitions and is hence
a multiset; the accounting of parallel edges is clear.) CE(· · ·) is an empirical unbiased estimator

(cid:1) is chosen uniformly at random among all (multi)subsets of a given size.

(cid:0)n
(cid:1)|E|−1(cid:80)
of C(π  V  W ) if E ⊆(cid:0)V

The basic question in statistical learning theory is  how good is the minimizer π of CE  in terms of
C? The notion of VC dimension [25] gives us a nontrivial (albeit suboptimal - see below) bound.
Lemma 2.2. The VC dimension of the set of permutations on V   viewed as binary classiﬁers on
pairs of elements  is n − 1.

(u v)∈E
u≺πv

2

2

(cid:18)(cid:113) n log m+log(1/δ)

satisfy: |CE(π  V  W ) − C(π  V  W )| = n2O

It is easy to show that the VC dimension is at most O(n log n)  which is the logarithm of the number
of permutations. See [4] for a linear bound. The implications are:
Proposition 2.3. If E is chosen uniformly at random (with repetitions) as a sample of m elements

from(cid:0)V
(cid:1)  where m > n  then with probability at least 1 − δ over the sample  all permutations π
(cid:1)
at least 1−δ  it sufﬁces to choose a sample E of m = O(µ−2(n log n+log δ−1)) elements from(cid:0)V
For two permutations π  σ  the Kendall-Tau metric dτ (π  σ) is deﬁned as dτ (π  σ) =(cid:80)
v)∧ (v ≺σ u)] . The Spearman Footrule metric dfoot(π  σ) is deﬁned as dfoot(π  σ) =(cid:80)

Hence  if we want to minimize C(π  V  W ) over π to within an additive error of µn2 with probability
uniformly at random (with repetitions)  and optimize CE(π  V  W ) instead.3 Assume δ ≥ e−n  so
that we get a more manageable sample bound of O(µ−2n log n). Is this bound at all interesting?
u(cid:54)=v 1[(u ≺π
u |ρπ(u)−

(cid:19)

m

.

2

ρσ(u)| . The following is well known [18]:

dτ (π  σ) ≤ dfoot(π  σ) ≤ 2dτ (π  σ) .

(2.3)
Clearly C(·  V ·) extends dτ (· ·) to distances between permutations and binary tournaments  with
the triangle inequality dτ (π  σ) ≤ C(π  V  W ) + C(σ  V  W ) satisﬁed for all W and π  σ ∈ Π(V ).
Assume we use Proposition 2.3 to ﬁnd π ∈ Π(V ) with an additive regret of O(µn2) with respect to
an optimal solution π∗ for some µ > 0. The triangle inequality implies dτ (π  π∗) = Ω(µn2). By
(2.3)  hence  dfoot(π  π∗) = Ω(µn2). By deﬁnition of dfoot  this means that the averege element v ∈
V is translated Ω(µn) positions away from its position in π∗. In some applications (e.g. IR)  one may
3(cid:0)V

(cid:1) denotes the set of unordered pairs of distinct elements in V .

2We will just say ε-good if W is clear from the context.

2

3

want elements to be at most a constant γ positions off. This translates to a sought regret of O(γn)
for constant γ  and using our notation  to µ = γ/n. Proposition 2.3 cannot guarantee less than a
quadratic sample size for such a regret  which is tantamount to querying all of W . We can do better:
For any ε > 0 we achieve an additive regret of O(εC(π∗  V  W )) using O(poly(log n  ε−1)) W -
queries  for arbitrarily small optimal loss C(π∗  V  W ). This is not achievable using Proposition 2.3.
One may argue that the VC bound may be too pessimistic  and other arguments may work for the
uniform sample case. A simple extremal case (omitted from this abstract) shows that this is false.
Proposition 2.4. Let V1  . . .   Vk be an ordered decomposition of V . Let B denote the set of indices
i ∈ [k] such that Vi is big in V . Assume E is chosen uniformly at random (with repetitions) as a
Deﬁne CE(π {V1  . . .   Vk}  W ) to be
i∈B

(cid:0)Vi
(cid:1).
(cid:1)  where m > n. For each i = 1  . . .   k  let Ei = E ∩(cid:0)Vi
sample of m elements from(cid:83)
(cid:1)−1|Ei|CEi(π|Vi  Vi  W|Vi) . (The nor-
(cid:0)ni
CE(π {V1  . . .   Vk}  W ) = (cid:0)(cid:80)
(cid:1)(cid:1)|E|−1(cid:80)
malization is deﬁned so that the expression is an unbiased estimator of(cid:80)
|Ei| = 0 for some i  formally deﬁne(cid:0)ni
(cid:1)−1|Ei|CEi(π|Vi  Vi  W|Vi) = 0.) Then with probability at
(cid:12)(cid:12)CE(π {V1  . . .   Vk}  W ) −(cid:80)
(cid:1)O
(cid:0)ni

(cid:0)ni
i∈B C(π|Vi  Vi  W|Vi)(cid:12)(cid:12) =(cid:80)

least 1 − e−n over the sample  all permutations π ∈ Π(V ) satisfy:

(cid:18)(cid:113) n log m+log(1/δ)

i∈B C(π|Vi  Vi  W|Vi). If

(cid:19)

i∈B

i∈B

i∈B

2

2

2

2

2

2

m

.

(cid:83)

The proof (omitted from this abstract) uses simple VC dimension arithmetic. Now  why is ε-
goodness good?
Lemma 2.5. Fix ε > 0 and assume we have an ε-good partition (Deﬁnition 2.1) V1  . . .   Vk
of V . Let B denote the set of i ∈ [k] such that Vi is big in V   and let ¯B = [k] \ B. Let
ni = |Vi| for i = 1  . . .   n  and let E denote a random sample of O(ε−6n log n) elements from
i∈B
CE(π {V1  . . .   Vk}  W ) be deﬁned as in Proposition 2.4. For any π ∈ Π(V1  . . .   Vk) deﬁne:
˜C(π) := CE(π {V1  . . .   Vk}  W ) +
1v≺πu .

(cid:1)  each element chosen uniformly at random with repetitions. Let Ei denote E ∩(cid:0)Vi

(cid:1). Let

C(π|Vi  Vi  W|Vi) +

(cid:88)

(cid:88)

(cid:88)

(cid:0)Vi

(2.4)

2

2

i∈ ¯B

1≤i<j≤k

(u v)∈Vi×Vj

Then the following event occurs with probability at least 1 − e−n: For any minimizer σ∗ of ˜C(·)
over Π(V1  . . .   Vk): C(σ∗  V  W ) ≤ (1 + 2ε) minπ∈Π(V ) C(π  V  W ).
(Proof omitted from abstract.) The consequence: Given an ε-good decomposition V1  . . .   Vk  op-
timizing ˜C(σ) over σ ∈ Π(V1  . . .   Vk)  would give a solution with relative regret of 2ε w.r.t. the
optimum. The ﬁrst and last terms in the RHS of (2.4) require no more than O(ε−6n log n) W -
queries to compute (by deﬁnition of E  and given the decomposition). The middle term runs over
small Vi’s  and can be computed from O(n log n/ log log n) W -queries. If we now assume that
a good decomposition can be efﬁciently computed using O(n polylog(n  ε−1)) W -queries (as we
indeed show)  then we would beat the VC bound whenever the optimal loss is at most O(n2−ν) for
some ν > 0.

3 A Query Efﬁcient Algorithm for ε-Good Decompositions

Theorem 3.1. Given a set V of size n  a preference oracle W and an error tolerance parameter
0 < ε < 1  there exists a poly(n  ε−1)-time algorithm returning  with constant probabiliy  an
ε-good partition of V   querying at most O(ε−6n log5 n) locations in W on expectation.

Before describing the algorithm and its analysis  we need some deﬁnitions:
Deﬁnition 3.2. Let π denote a permutation over V . Let v ∈ V and i ∈ [n]. We deﬁne πv→i to be
the permutation obtained by moving the rank of v to i in π  and leaving the rest of the elements in
the same order.4
Deﬁnition 3.3. Fix π ∈ Π(V )  v ∈ V and i ∈ [n]. We deﬁne TestMove(π  V  W  v  i) :=
C(π  V  W ) − C(πv→i  V  W ) . Equivalently  if i ≥ ρπ(v) then TestMove(π  V  W  v  i) :=
4For example  if V = {x  y  z} and (π(1)  π(2)  π(3)) = (x  y  z)  then (πx→3(1)  πx→3(2)  πx→3(3)) =

(y  z  x).

4

2

(cid:1)  deﬁne TestMoveE(π  V  W  v  i)  for i ≥ ρπ(v)  as TestMoveE(π  V  W  v  i) :=

(cid:80)
set E ⊆ (cid:0)V
u:ρπ(u)∈[ρπ(v)+1 i](Wuv − Wvu) . A similar expression can be written for i < ρπ(v). For a multi-
(cid:80)
|i−ρπ(v)|
u:(u v)∈ ˜E(W (u  v) − W (v  u)). where the multiset ˜E is deﬁned as {(u  v) ∈ E :
(cid:80)
ρπ(u) ∈ [ρπ(v) + 1  i]}. Similarly  for i < ρπ(v) we deﬁne TestMoveE(π  V  W  v  i) :=
|i−ρπ(v)|
u:(u v)∈ ˜E(W (v  u) − W (u  v)). where ˜E is now {(u  v) ∈ E : ρπ(u) ∈ [i  ρπ(v) − 1]}.

Lemma 3.4. Fix π ∈ Π(V )  v ∈ V   i ∈ [n] and an integer N. Let E ⊆(cid:0)V

(cid:1) be a random (multi)-

| ˜E|

| ˜E|

set of size N with elements (v  u1)  . . .   (v  uN )  drawn so that for each j ∈ [N ] the element uj
is chosen uniformly at random from among the elements lying between v (exclusive) and position i
(inclusive) in π. Then E[TestMoveE(π  V  W  v  i)] = TestMove(π  V  W  v  i). Additionally  for
any δ > 0  except with probability of failure δ 
| TestMoveE(π  V  W  v  i) − TestMove(π  V  W  v  i)| = O

|i − ρπ(v)|(cid:113) log δ−1

(cid:18)

(cid:19)

.

2

N

The lemma is easily proven using Hoeffding tail bounds  using the fact that |W (u  v)| ≤ 1 for all
u  v.
Our decomposition algorithm SampleAndRank is detailed in Algorithm 1  with
subroutines in Algorithms 2 and 3. It is a query efﬁcient improvement of the PTAS in [23] with
the following difference: here we are not interested in an approximation algorithm for MFAST 
but just in an ε-good decomposition. Whenever we reach a small block (line 3) or a big block
with a probably approximately sufﬁciently high cost (line 8) in our recursion of Algorithm 2)  we
simply output it as a block in our partition. Denote the resulting outputted partition by V1  . . .   Vk.
Denote by ˆπ the minimizer of C(·  V  W ) over Π(V1  . . .   Vk). We need to show that C(ˆπ  V  W ) ≤
(1 + ε) minπ∈Π(V ) C(π  V  W )  thus establishing (2.2). The analysis closely follows [23]. Due to
space limitations  we focus on the differences  and speciﬁcally on Procedure ApproxLocalImprove
(Algorithm 3)  replacing a greedy local improvement step in [23] which is not query efﬁcient.
SampleAndRank (Algorithm 1) takes the following arguments: The set V   the preference ma-
trix W and an accuracy argument ε.
It is implicitly understood that the argument W passed to
SampleAndRank is given as a query oracle  incurring a unit cost upon each access. The ﬁrst warm
start step in SampleAndRank computes an expected constant factor approximation π to MFAST
on V  W using QuickSort [2]. The query complexity of this step is O(n log n) on expectation (see
[3]). Before continuing  we make the following assumption  which holds with constant probability
using Markov probability bounds.
Assumption 3.5. The cost C(π  V  W ) of π computed in line 2 of SampleAndRank is O(1) times
that of the optimal π∗  and the query cost incurred in the computation is O(n log n).

Next  a recursive procedure SampleAndDecompose is called  running a divide-and-conquer algo-
rithm. Before branching  it executes the following: Lines 5 to 9 identify local chaos (2.1) (with
high probability). Line 10 calls ApproxLocalImprove (Algorithm 3)  responsible for performing
query-efﬁcient approximate greedy steps  as we now explain.
Approximate local improvement steps. ApproxLocalImprove takes a set V of size N  W   a
permutation π on V   two numbers C0  ε and an integer n.5 The number n is always the size of
the input in the root call to SampleAndDecompose  passed down in the recursion  and used for the
purpose of controlling success probabilities. The goal of is to repeatedly identify w.h.p. single vertex
moves that considerably decrease the cost. The procedure starts by creating a sample ensemble
S = {Ev i : v ∈ V  i ∈ [B  L]}  where B = log(cid:98)Θ(εN/ log n)(cid:99) and L = (cid:100)log N(cid:101). The size of each
Ev i ∈ S is Θ(ε−2 log2 n)  and each element (v  x) ∈ Ev i was added (with possible multiplicity)
by uniformly at random selecting  with repetitions  an element x ∈ V positioned at distance at most
2i from the position of v in π. Let Dπ denote the distribution space from which S was drawn  and
let PrX∼Dπ [X = S] denote the probability of obtaining a given sample ensemble S. S will enable
us to approximate the improvement in cost obtained by moving a single element u to position j.
Deﬁnition 3.6. Fix u ∈ V and j ∈ [n]  and assume log |j − ρπ(u)| ≥ B. Let (cid:96) = (cid:100)log |j −
ρπ(u)|(cid:101). We say that S is successful at u  j if |{x : (u  x) ∈ Eu (cid:96)} ∩ {x : ρπ(x) ∈ [ρπ(u)  j]}| =
Ω(ε−2 log2 n) .

5Notation abuse: V here is a subset of the original input.

5

Success of S at u  j means that sufﬁciently many samples x ∈ V such that ρπ(x) is between ρπ(u)
and j are represented in Eu (cid:96). Conditioned on S being successful at u  j  note that the denominator
from the deﬁnition of TestMoveE does not vanish  and we can thereby deﬁne:
Deﬁnition 3.7. S is a good approximation at u  j if (deﬁning (cid:96) as in Deﬁnition 3.6):

(cid:12)(cid:12)TestMoveEu (cid:96) (π  V  W  u  j) − TestMove(π  V  W  u  j)(cid:12)(cid:12) ≤ 1

2 ε|j − ρπ(u)|/ log n . S is a good

approximation if it is succesful and a good approximation at all u ∈ V   j ∈ [n] satisfying
(cid:100)log |j − ρπ(u)|(cid:101) ∈ [B  L].
Using Chernoff to ensure success and Hoeffding to ensure good approximation  union bounding:
Lemma 3.8. Except with probability 1 − O(n−4)  S is a good approximation.

Algorithm 1 SampleAndRank(V  W  ε)
1: n ← |V |
2: π ← Expected O(1)-approx solution to MFAST using O(n log n) W -queries on expectation

using QuickSort [2]

3: return SampleAndDecompose(V  W  ε  n  π)

(cid:1) (with repetitions)

(C is an additive O(ε2N 2) approximation of C w.p. ≥ 1 − n−4)

2

5: E ← random subset of O(ε−4 log n) elements from(cid:0)V

Algorithm 2 SampleAndDecompose(V  W  ε  n  π)
1: N ← |V |
2: if N ≤ log n/ log log n then
return trivial partition {V }
3:
4: end if
6: C ← CE(π  V  W )
7: if C = Ω(ε2N 2) then
8:
9: end if
10: π1 ← ApproxLocalImprove(V  W  π  ε  n)
11: k ← random integer in the range [N/3  2N/3]
12: VL ← {v ∈ V : ρπ(v) ≤ k}  πL ← restriction of π1 to VL
13: VR ← V \ VL 
14: return

πR ← restriction of π1 to VR

return trivial partition {V }

concatenation

of

SampleAndDecompose(VL  W  ε  n  πL) 

SampleAndDecompose(VR  W  ε  n  πR)

Mutating the Pair Sample To Reﬂect a Single Element Move. Line 16 in ApproxLocalImprove
requires elaboration. In lines 15-18 we sought (using S) an element u and position j  such that
moving u to j (giving rise to πu→j) would considerably improve the cost w.h.p. If such an element
u existed  we executed the exchange π ← πu→j. Unfortunately the sample ensemble S becomes
stale: even if S was a good approximation  it is no longer necessarily so w.r.t. the new value of π.
We refresh it in line 16 by applying a transformation ϕu→j on S  resulting in a new sample ensemble
ϕu→j(S) approximately distributed by Dπu→j . More precisely  ϕ (deﬁned below) is such that

ϕu→j(Dπ) = Dπu→j  

v i.

(3.1)
where the left hand side denotes the distribution obtained by drawing from Dπ and applying ϕu→j
to the result. We now deﬁne ϕu→j. Denoting ϕu→j(S) = S(cid:48) = {E(cid:48)
v i : v ∈ V  i ∈ [B  L]}  we
need to deﬁne each E(cid:48)
Deﬁnition 3.9. Ev i is interesting in the context of π and πu→j if the two sets T1  T2 deﬁned as
T1 = {x ∈ V : |ρπ(x) − ρπ(v)| ≤ 2i}  T2 = {x ∈ V : |ρπu→j (x) − ρπu→j (v)| ≤ 2i} differ.
We set E(cid:48)
v i = Ev i for all v  i for which Ev i is not interesting. Fix one interesting choice v  i. Let
T1  T2 be as in Deﬁntion 3.9. It can be easily shown that each of T1 and T2 contains O(1) elements
that are not contained in the other  and it can be assumed (using a simple clipping argument - omitted)
that this number is exactly 1  hence |T1| = |T2|. let X1 = T1 \ T2  and X2 = T2 \ T1. Fix any
injection α : X1 → X2  and extend α : T1 → T2 so that α(x) = x for all x ∈ T1 ∩ T2. Finally 

6

return

Algorithm 3 ApproxLocalImprove(V  W  π  ε  n) (Note: π used as both input and output)
1: N ← |V |  B ← (cid:100)log(Θ(εN/ log n)(cid:101)  L ← (cid:100)log N(cid:101)
2: if N = O(ε−3 log3 n) then
3:
4: end if
5: for v ∈ V do
r ← ρπ(v)
6:
for i = B . . . L do
7:
Ev i ← ∅
8:
for m = 1..Θ(ε−2 log2 n) do
9:
j ← integer uniformly at random chosen from [max{1  r − 2i}  min{n  r + 2i}]
10:
Ev i ← Ev i ∪ {(v  π(j))}
11:
12:
13:
14: end for
15: while ∃u ∈ V and j ∈ [n] s.t. (setting (cid:96) := (cid:100)log |j − ρπ(u)|(cid:101)):

(cid:96) ∈ [B  L] and TestMoveEu (cid:96) (π  V  W  u  j) > ε|j − ρπ(u)|/ log n do

For v ∈ V   i ∈ [B  L] refresh Ev i w.r.t. the move u → j using ϕu→j (Section 3)
π ← πu→j

end for

end for

16:
17:
18: end while

v i

u1→j1

u2→j2

uk→jk

  π2 = π1

(cid:12)(cid:12)(cid:12)(cid:83)

v i Ev i∆E(cid:48)

 ···   πk = πk−1

(cid:12)(cid:12)(cid:12) bounds the query

v i = {(v  α(x)) : (v  x) ∈ Ev i}. For v = u we create E(cid:48)

deﬁne E(cid:48)
v i from scratch by repeating the
loop in line 7 for that v. It is easy to see that (3.1) holds. By Lemma 3.8  the total variation distance
between (Dπ| good approximation) and Dπu→j is O(n−4). Using a simple chain rule argument:
Lemma 3.10. Fix π0 on V of size N  and ﬁx u1  . . .   uk ∈ V and j1  . . .   jk ∈ [n]. Draw
S 0 from Dπ0  and deﬁne S 1 = ϕu1→j1 (S 0) S 2 = ϕu2→j2 (S 1) ···  S k = ϕuk→jk (S k−1) 
. Consider the random variable Sk conditioned on
π1 = π0
S 0 S 1  . . .  S k−1 being good approximations for π0  . . .   πk−1  respectively. Then the total vari-
ation distance between the distribution of S k and the distribution (Dπk|πk) (corresponding to the
process of obtaning πk and drawing from Dπk ”from scratch”) is at most O(kn−4).
The difference between S and S(cid:48)  deﬁned as dist(S S(cid:48)) :=
complexity of computing mutations. The proof of the following has been omitted from this abstract.
Lemma 3.11. Assume S ∼ Dπ for some π  and S(cid:48) = ϕu→j. Then E[dist(S S(cid:48))] = O(ε−3 log3 n).
Analysis of SampleAndDecompose. Various high probability events must occur in order for the al-
gorithm guarantees to hold. Let E1 denote the event that the ﬁrst Θ(n4) sample ensembles S1 S2  . . .
ApproxLocalImprove  either in lines 5 and 14  or via mutations  are good approximations By Lem-
mas 3.8 and 3.10  using a union bound  with constant probability (say  0.99) this happens. Let E2
denote the event that the cost approximations obtained in line 5 of SampleAndDecompose are suc-
cessful at all recursive calls. By Hoeffding tail bounds  this happens with probability 1 − O(n−4)
for each call  there are O(n log n) calls  hence we can lower bound the probability of success of all
executions by 0.99. Concluding  the following holds with probability at least 0.97:
Assumption 3.12. Events E1 and E2 hold true.
We condition what follows on this assumption.6 Let π∗ denote the optimal permutation for the
root call to SampleAndDecompose with V  W  ε. The permutation π is  by Assumption 3.5  a
constant factor approximation for π∗. By the triangle inequality  dτ (π  π∗) ≤ C(π  V  W ) +
C(π∗  V  W )  hence  E[dτ (π  π∗)] = O(C(π∗  V  W )) . From this  using (2.3)  E[dfoot(π  π∗)] =
O(C(π∗  V  W )). Now consider the recursion tree T of SampleAndDecompose. Denote I
the set of internal nodes  and by L the set of leaves (i.e.
executions exiting from line 8).
For a call SampleAndDecompose corresponding to a node X  denote the input arguments by
(VX   W  ε  n  πX ). Let L[X]  R[X] denote the left and right children of X respectively. Let kX
6This may bias some expectation upper bounds derived earlier and in what follows. This bias can multiply

the estimates by at most 1/0.97  which can be absorbed in our O-notations.

7

2

X

X

(cid:17)

X

X

denote the integer k in 11 in the context of X ∈ I. Hence  by our deﬁnitions  VL[X]  VR[X]  πL[X]
and πR[X] are precisely VL  VR  πL  πR from lines 12-13 in the context of node X. Take  as
in line 1  NX = |VX|. Let π∗
X denote the optimal MFAST solution for instance (VX   W|VX ).
By E1 we conclude that the cost of πX u→j is always an actual improvement compared to πX
(for the current value of πX   u and j in iteration)  and the improvement in cost is of magni-
tude at least Ω(ε|ρπX (u) − j|/ log n)  which is Ω(ε2NX / log2 n) due to the use of B deﬁned in
line 1.7 But then the number of iterations of the while loop in line 15 of ApproxLocalImprove
is O(ε−2C(πX   VX   W|VX ) log2 n/NX ) (Otherwise the true cost of the running solution would

go below 0.) Since C(πX   VX   W|VX ) ≤ (cid:0)NX

(cid:1)  the number of iterations is hence at most

(u)) = O(ε|ρπ1X (u) − ρπ∗

X : (*) TestMove(π1X   VX   W|VX   u  ρπ∗

(u)| = O(εNX / log n)  and V long

tity as in [23]: TX := (cid:80)

O(ε−2NX log2 n). By Lemma 3.11 the expected query complexity incurred by the call to
ApproxLocalImprove is therefore O(ε−5NX log5 n). Summing over the recursion tree 
the
total query complexity incurred by calls to ApproxLocalImprove is  on expectation  at most
O(ε−5n log6 n). Now consider the moment at which the while loop of ApproxLocalImprove ter-
minates. Let π1X denote the permutation obtained at that point  returned to SampleAndDecompose
in line 10. We classify the elements v ∈ VX to two families: V short
denotes all u ∈ VX s.t.
|ρπ1X (u) − ρπ∗
denotes VX \ V short
. We know by assumption 
that the last sample ensemble S used in ApproxLocalImprove was a good approximation  hence
for all u ∈ V long
(u)|/ log n).
Following [23]  we say for u ∈ VX that u crosses kX if [ρπ1X (u)  ρπ∗
Let
denote the (random) set of elements u ∈ VX that cross kX. We deﬁne a key quan-
V cross
(u)). Following (*)  the
TestMove(π1X   VX   W|VX   u  ρπ∗
to TX.
u∈V long
X )/ log n) which is  using (2.3) at most
X  the last expres-
contribute to TX?
(u)|/NX ). Hence  the
. Under the constraints
(u)| = O(εNX / log n) 
this is O(dfoot(π1X   π∗
X )ε/ log n). Again using (2.3) and
the triangle inequality  the bound becomes O(εC(π1X   VX   W|VX )/ log n). Combining for V long
and V short  we conclude: (**) EkX [TX ] = O(εC(π∗
X   VX   W|VX )/ log n)  (the expectation is over
the choice of kX.) The bound (**) is the main improvement over [23]  and should be compared with
Lemma 3.2 there  stating (in our notation) TX = O(εC∗NX /(4n log n)). The latter bound is more
restrictive than ours in certain cases  and obtaining it relies on a procedure that cannot be performed
without having access W in its entirety. (**) however can be achieved using efﬁcient querying of
W   as we have shown. The remaineder of the arguments leading to proof of Theorem 3.1 closely
follow those in Section 4 of [23]. The details have been omitted from this abstract.

elements u ∈ V long
This latter bound is  by deﬁnition  O(εdfoot(π1X   π∗
X )/ log n). By the triangle inequality and the deﬁnition of π∗
O(εdτ (π1X   π∗
(cid:17)
sion is O(εC(π1X   VX   W|VX )/ log n). How much can elements in V short
The probability of each such element to cross k is O(|ρπ1X (u) − ρπ∗
(cid:80)
(u)|2/NX
total expected contribution is O
X ) and |ρπ1X (u) − ρπ∗

X )εNX /(NX log n)) = O(dfoot(π1X   π∗

(u)| ≤ dfoot(π1X   π∗

X

|ρπ1X (u) − ρπ∗

X

|ρπ1X (u) − ρπ∗

X

|ρπ1X (u) − ρπ∗

X

can contribute at most O

(cid:16)
ε(cid:80)

(u)] contains kX.

X

X

(cid:16)(cid:80)

X

(u)|/ log n

X

X

X

X

X

X

u∈V cross

X

X

u∈V short

X

u∈V short

4 Future Work
We presented a statistical learning theoretical active learning result for pairwise ranking. The main
vehicle was a query (and time) efﬁcient decomposition procedure  reducing the problem to smaller
ones in which the optimal loss is high and uniform sampling sufﬁces. The main drawback of our
result is the inability to use it in order to search in a limited subspace of permutations. A typical
example of such a subspace is the case in which each element v ∈ V has a corresponding feature
vector in a real vector space  and we only seek permutations induced by linear score functions. In
followup work  Ailon  Begleiter and Ezra [1] show a novel technique achieving a slightly better
query complexity than here with a simpler proof  while also admitting search in restricted spaces.
Acknowledgements The author gratefully acknowledges the help of Warren Schudy with derivation
of some of the bounds in this work. Special thanks to Ron Begleiter for helpful comments. Apolo-
gizes for omitting references to much relevant work that could not ﬁt in this version’s bibliography.

7This also bounds the number of times a sample ensemble is created by O(n4)  as required by E1.

8

References
[1] Nir Ailon  Ron Begleiter  and Esther Ezra  A new active learning scheme with applications to

learning to rank from pairwise preferences  arxiv.org/abs/1110.2136 (2011).

[2] Nir Ailon  Moses Charikar  and Alantha Newman  Aggregating inconsistent information:

Ranking and clustering  J. ACM 55 (2008)  no. 5.

[3] Nir Ailon and Mehryar Mohri  Preference based learning to rank  vol. 80  2010  pp. 189–212.
[4] Nir Ailon and Kira Radinsky  Ranking from pairs and triplets: Information quality  evaluation

methods and query complexity  WSDM  2011.

[5] Noga Alon  Ranking tournaments  SIAM J. Discret. Math. 20 (2006)  no. 1  137–142.
[6] M. F. Balcan  N. Bansal  A. Beygelzimer  D. Coppersmith  J. Langford  and G. B. Sorkin 
Robust reductions from ranking to classiﬁcation  Machine Learning 72 (2008)  no. 1-2  139–
153.

[7] Maria-Florina Balcan  Alina Beygelzimer  and John Langford  Agnostic active learning  J.

Comput. Syst. Sci. 75 (2009)  no. 1  78–89.

[8] Maria-Florina Balcan  Steve Hanneke  and Jennifer Vaughan  The true sample complexity of

active learning  Machine Learning 80 (2010)  111–139.

[9] A. Beygelzimer  J. Langford  and P. Ravikumar  Error-correcting tournaments  ALT  2009 

pp. 247–262.

[10] M. Braverman and E. Mossel  Noisy sorting without resampling  SODA: Proceedings of the

19th annual ACM-SIAM symposium on Discrete algorithms  2008  pp. 268–276.

[11] B. Carterette  P. N. Bennett  D. Maxwell Chickering  and S. T. Dumais  Here or there: Prefer-

ence judgments for relevance  ECIR  2008.

[12] William W. Cohen  Robert E. Schapire  and Yoram Singer  Learning to order things  NIPS ’97 

1998  pp. 451–457.

[13] D. Cohn  L. Atlas  and R. Ladner  Improving generalization with active learning  Machine

Learning 15 (1994)  no. 2  201–221.

[14] A. Culotta and A. McCallum  Reducing labeling effort for structured prediction tasks  AAAI:

Proceedings of the 20th national conference on Artiﬁcial intelligence  2005  pp. 746–751.

[15] S. Dasgupta  Coarse sample complexity bounds for active learning  Advances in Neural Infor-

mation Processing Systems 18  2005  pp. 235–242.

[16] S. Dasgupta  A. Tauman Kalai  and C. Monteleoni  Analysis of perceptron-based active learn-

ing  Journal of Machine Learning Research 10 (2009)  281–299.

[17] Sanjoy Dasgupta  Daniel Hsu  and Claire Monteleoni  A general agnostic active learning al-

gorithm  NIPS  2007.

[18] Persi Diaconis and R. L. Graham  Spearman’s footrule as a measure of disarray  Journal of

the Royal Statistical Society. Series B (Methodological) 39 (1977)  no. 2  pp. 262–268.

[19] U. Feige  D. Peleg  P. Raghavan  and E. Upfal  Computing with unreliable information  STOC:
Proceedings of the 22nd annual ACM symposium on Theory of computing  1990  pp. 128–137.
[20] Yoav Freund  H. Sebastian Seung  Eli Shamir  and Naftali Tishby  Selective sampling using the

query by committee algorithm  Mach. Learn. 28 (1997)  no. 2-3  133–168.

[21] Steve Hanneke  A bound on the label complexity of agnostic active learning  ICML  2007 

pp. 353–360.

[22] Eyke H¨ullermeier  Johannes F¨urnkranz  Weiwei Cheng  and Klaus Brinker  Label ranking by

learning pairwise preferences  Artif. Intell. 172 (2008)  no. 16-17  1897–1916.

[23] Claire Kenyon-Mathieu and Warren Schudy  How to rank with few errors  STOC  2007  pp. 95–

103.

[24] Dan Roth and Kevin Small  Margin-based active learning for structured output spaces  2006.
[25] V. N. Vapnik and A. Ya. Chervonenkis  On the uniform convergence of relative frequencies of
events to their probabilities  Theory of Prob. and its Applications 16 (1971)  no. 2  264–280.
[26] F. Xia  T-Y Liu  J. Wang  W. Zhang  and H. Li  Listwise approach to learning to rank: theory

and algorithm  ICML ’08  2008  pp. 1192–1199.

9

,Hang Gao
Zheng Shou
Alireza Zareian
Hanwang Zhang
Shih-Fu Chang