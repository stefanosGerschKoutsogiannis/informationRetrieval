2013,Predictive PAC Learning and Process Decompositions,We informally call a stochastic process learnable if it admits a generalization error approaching zero in probability for any concept class with finite VC-dimension (IID processes are the simplest example).  A mixture of learnable processes need not be learnable itself  and certainly its generalization error need not decay at the same rate. In this paper  we argue that it is natural in predictive PAC to condition not on the past observations but on the mixture component of the sample path. This definition not only matches what a realistic learner might demand  but also allows us to sidestep several otherwise grave problems in learning from dependent data. In particular  we give a novel PAC generalization bound for mixtures of learnable processes with a generalization error that is not worse than that of each mixture component.  We also provide a characterization of mixtures of absolutely regular ($\beta$-mixing) processes  of independent interest.,Predictive PAC Learning and Process Decompositions

Cosma Rohilla Shalizi
Statistics Department

Carnegie Mellon University
Pittsburgh  PA 15213 USA
cshalizi@cmu.edu

Aryeh Kontorovich

Computer Science Department

Ben Gurion University
Beer Sheva 84105 Israel

karyeh@cs.bgu.ac.il

Abstract

We informally call a stochastic process learnable if it admits a generalization error
approaching zero in probability for any concept class with ﬁnite VC-dimension
(IID processes are the simplest example). A mixture of learnable processes need
not be learnable itself  and certainly its generalization error need not decay at the
same rate. In this paper  we argue that it is natural in predictive PAC to condition
not on the past observations but on the mixture component of the sample path.
This deﬁnition not only matches what a realistic learner might demand  but also
allows us to sidestep several otherwise grave problems in learning from dependent
data.
In particular  we give a novel PAC generalization bound for mixtures of
learnable processes with a generalization error that is not worse than that of each
mixture component. We also provide a characterization of mixtures of absolutely
regular (β-mixing) processes  of independent probability-theoretic interest.

1

Introduction

Statistical learning theory  especially the theory of “probably approximately correct” (PAC) learn-
ing  has mostly developed under the assumption that data are independent and identically distributed
(IID) samples from a ﬁxed  though perhaps adversarially-chosen  distribution. As recently as 1997 
Vidyasagar [1] named extending learning theory to stochastic processes of dependent variables as a
major open problem. Since then  considerable progress has been made for speciﬁc classes of pro-
cesses  particularly strongly-mixing sequences and exchangeable sequences. (Especially relevant
contributions  for our purposes  came from [2  3] on exchangeability  from [4  5] on absolute regu-
larity1  and from [6  7] on ergodicity; others include [8  9  10  11  12  13  14  15  16  17].) Our goals
in this paper are to point out that many practically-important classes of stochastic processes possess
a special sort of structure  namely they are convex combinations of simpler  extremal processes.
This both demands something of a re-orientation of the goals of learning  and makes the new goals
vastly easier to attain than they might seem.

Main results Our main contribution is threefold: a conceptual deﬁnition of learning from non-IID
data (Deﬁnition 1) and a technical result establishing tight generalization bounds for mixtures of
learnable processes (Theorem 2)  with a direct corollary about exchangeable sequences (Corollary
1)  and an application to mixtures of absolutely regular sequences  for which we provide a new
characterization.

Notation X1  X2  . . . will be a sequence of dependent random variables taking values in a common
measurable space X   which we assume to be “standard” [18  ch. 3] to avoid technicalities  implying
1Absolutely regular processes are ones where the joint distribution of past and future events approaches
independence  in L1  as the separation between events goes to inﬁnity; see §4 below for a precise statement and
extensive discussion. Absolutely regular sequences are now more commonly called “β-mixing”  but we use the
older name to avoid confusion with the other sort of “mixing”.

1

that their σ-ﬁeld has a countable generating basis; the reader will lose little if they think of X as
Rd. (We believe our ideas apply to stochastic processes with multidimensional index sets as well 
but use sequences here.) X j
i will stand for the block (Xi  Xi+1  . . . Xj−1  Xj). Generic inﬁnite-
dimensional distributions  measures on X ∞  will be µ or ρ; these are probability laws for X∞
1 . Any
such stochastic process can be represented through the shift map τ : X ∞ (cid:55)→ X ∞ (which just drops
the ﬁrst coordinate  (τ x)t = xt+1)  and a suitable distribution of initial conditions. When we speak
of a set being invariant  we mean invariant under the shift. The collection of all such probability
measures is itself a measurable space  and a generic measure there will be π.

2 Process Decompositions

Since the time of de Finetti and von Neumann  an important theme of the theory of stochastic pro-
cesses has been ﬁnding ways of representing complicated but structured processes  obeying certain
symmetries  as mixtures of simpler processes with the same symmetries  as well as (typically) some
sort of 0-1 law. (See  for instance  the beautiful paper by Dynkin [19]  and the statistically-motivated
[20].) In von Neumann’s original ergodic decomposition [18  §7.9]  stationary processes  whose dis-
tributions are invariant over time  proved to be convex combinations of stationary ergodic measures 
ones where all invariant sets have either probability 0 or probability 1. In de Finetti’s theorem [21 
ch. 1]  exchangeable sequences  which are invariant under permutation  are expressed as mixtures of
IID sequences2. Similar results are now also known for asymptotically mean stationary sequences
[18  §8.4]  for partially-exchangeable sequences [22]  for stationary random ﬁelds  and even for
inﬁnite exchangeable arrays (including networks and graphs) [21  ch. 7].
The common structure shared by these decompositions is as follows.

1. The probability law ρ of the composite but symmetric process is a convex combination of
the simpler  extremal processes µ ∈ M with the same symmetry. The inﬁnite-dimensional
distribution of these extremal processes are  naturally  mutually singular.
2. Sample paths from the composite process are generated hierarchically  ﬁrst by picking an
extremal process µ from M according to a some measure π supported on M  and then
generating a sample path from µ. Symbolically 

µ ∼ π
| µ ∼ µ

X∞

1

3. Each realization of the composite process therefore gives information about only a single

extremal process  as this is an invariant along each sample path.

3 Predictive PAC

These points raise subtle but key issues for PAC learning theory. Recall the IID case: random
variables X1  X2  . . . are all generated from a common distribution µ(1)  leading to an inﬁnite-
dimensional process distribution µ. Against this  we have a class F of functions f. The goal in PAC
theory is to ﬁnd a sample complexity function3 s(  δ F  µ) such that  whenever n ≥ s 

f (Xt) − Eµ [f ]

≤ δ

(1)

That is  PAC theory seeks ﬁnite-sample uniform law of large numbers for F.
Because of its importance  it will be convenient to abbreviate the supremum 

(cid:32)

Pµ

sup
f∈F

n

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1

n

n(cid:88)

t=1

n(cid:88)

t=1

sup
f∈F

f (Xt) − Eµ [f ]

(cid:33)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≡ Γn

2This is actually a special case of the ergodic decomposition [21  pp. 25–26].
3Standard PAC is deﬁned as distribution-free  but here we maintain the dependence on µ for consistency

with future notation.

2

using the letter “Γ” as a reminder that when this goes to zero  F is a Glivenko-Cantelli class (for µ).
Γn is also a function of F and of µ  but we suppress this in the notation for brevity. We will also
pass over the important and intricate  but fundamentally technical  issue of establishing that Γn is
measurable (see [23] for a thorough treatment of this topic).
What one has in mind  of course  is that there is a space H of predictive models (classiﬁers  regres-
sions  . . . ) h  and that F is the image of H through an appropriate loss function (cid:96)  i.e.  each f ∈ F
can be written as

f (x) = (cid:96)(x  h(x))

(cid:104) ˆfn

minimization is reliable. That is  the function ˆfn which minimizes the empirical risk n−1(cid:80)
(cid:105)

for some h ∈ H.
If Γn → 0 in probability for this “loss function” class  then empirical risk
t f (Xt)
has an expected risk in the future which is close to the best attainable risk over all of F  R(F  µ) =
Indeed  since when n ≥ s  with high (≥ 1 − δ) probability all functions have
inf f∈F Eµ [f ].
empirical risks within  of their true risks  with high probability the true risk Eµ
is within 2
of R(F  µ). Although empirical risk minimization is not the only conceivable learning strategy 
it is  in a sense  a canonical one (computational considerations aside). The latter is an immediate
consequence of the VC-dimension characterization of PAC learnability:
Theorem 1 Suppose that the concept class H is PAC learnable from IID samples. Then H is learn-
able via empirical risk minimization.
PROOF: Since H is PAC-learnable  it must necessarily have a ﬁnite VC-dimension [24]. But for
ﬁnite-dimensional H and IID samples  Γn → 0 in probability (see [25] for a simple proof). This
implies that the empirical risk minimizer is a PAC learner for H. (cid:3)
In extending these ideas to non-IID processes  a subtle issue arises  concerning which expectation
value we would like empirical means to converge towards. In the IID case  because µ is simply the
inﬁnite product of µ(1) and f is a function on X   we can without trouble identify expectations under
the two measures with each other  and with expectations conditional on the ﬁrst n observations:

Eµ [f (X)] = Eµ(1) [f (X)] = Eµ [f (Xn+1) | X n
1 ]
Things are not so tidy when µ is the law of a dependent stochastic process.
In introducing a notion of “predictive PAC learning”  Pestov [3]  like Berti and Rigo [2] earlier 
proposes that the target should be the conditional expectation  in our notation Eµ [f (Xn+1) | X n
1 ].
This however presents two signiﬁcant problems. First  in general there is no single value for this —
it truly is a function of the past X n
1   or at least some part of it. (Consider even the case of a binary
Markov chain.) The other  and related  problem with this idea of predictive PAC is that it presents
learning with a perpetually moving target. Whether the function which minimizes the empirical risk
is going to do well by this criterion involves rather arbitrary details of the process. To truly pursue
this approach  one would have to actually learn the predictive dependence structure of the process 
a quite formidable undertaking  though perhaps not hopeless [26].
Both of these complications are exacerbated when the process producing the data is actually a mix-
ture over simpler processes  as we have seen is very common in interesting applied settings. This
is because  in addition to whatever dependence may be present within each extremal process  X n
gives (partial) information about what that process is. Finding Eρ [Xn+1 | X n
1
1 ] amounts to ﬁrst
ﬁnding all the individual conditional expectations  Eµ [Xn+1 | X n
1 ]  and then averaging them with
respect to the posterior distribution π(µ | X n
1 ). This averaging over the posterior produces ad-
ditional dependence between past and future. (See [27] on quantifying how much extra apparent
Shannon information this creates.) As we show in §4 below  continuous mixtures of absolutely reg-
ular processes are far from being absolutely regular themselves. This makes it exceedingly hard 
if not impossible  to use a single sample path  no matter how long  to learn anything about global
expectations.
These difﬁculties all simply dissolve if we change the target distribution. What a learner should care
about is not averaging over some hypothetical prior distribution of inaccessible alternative dynamical
systems  but rather what will happen in the future of the particular realization which provided the
training data  and must continue to provide the testing data. To get a sense of what this is means 

3

notice that for an ergodic µ 

m(cid:88)

i=1

1
m

Eµ [f ] = lim
m→∞

E [f (Xn+i) | X n
1 ]

(from [28  Cor. 4.4.1]). That is  matching expectations under the process measure µ means control-
ling the long-run average behavior  and not just the one-step-ahead expectation suggested in [3  2].
Empirical risk minimization now makes sense: it is attempting to ﬁnd a model which will work
well not just at the next step (which may be inherently unstable)  but will continue to work well  on
average  indeﬁnitely far into the future.
We are thus led to the following deﬁnition.
1 be a stochastic process with law µ  and let I be the σ-ﬁeld generated by all
Deﬁnition 1 Let X∞
the invariant events. We say that µ admits predictive PAC learning of a function class F when there
exists a sample-complexity function s(  δ F  µ) such that  if n ≥ s  then

(cid:32)

Pµ

sup
f∈F

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1

n

n(cid:88)

t=1

f (Xt) − Eµ [f|I]

≤ δ

(cid:33)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ 

A class of processes P admits of distribution-free predictive PAC learning if there exists a common
sample-complexity function for all µ ∈ P  in which case we write s(  δ F  µ) = s(  δ F P).
As is well-known  distribution-free predictive PAC learning  in this sense  is possible for IID pro-
cesses (F must have ﬁnite VC dimension). For an ergodic µ  [6] shows that s(  δ F  µ) exist and is
ﬁnite if and only  once again  F has a ﬁnite VC dimension; this implies predictive PAC learning  but
not distribution-free predictive PAC. Since ergodic processes can converge arbitrarily slowly  some
extra condition must be imposed on P to ensure that dependence decays fast enough for each µ. A
sufﬁcient restriction is that all processes in P be stationary and absolutely regular (β-mixing)  with
a common upper bound on the β dependence coefﬁcients  as [5  14] show how to turn algorithms
which are PAC on IID data into ones where are PAC on such sequences  with a penalty in extra sam-
ple complexity depending on µ only through the rate of decay of correlations4. We may apply these
familiar results straightforwardly  because  when µ is ergodic  all invariant sets have either measure
0 or measure 1  conditioning on I has no effect  and Eµ [f | I] = Eµ [f ].
Our central result is now almost obvious.

Theorem 2 Suppose that distribution-free prediction PAC learning is possible for a class of func-
tions F and a class of processes M  with sample-complexity function s(  δ F P). Then the class
of processes P formed by taking convex mixtures from M admits distribution-free PAC learning
with the same sample complexity function.
PROOF: Suppose that n ≥ s(  δ F). Then by the law of total expectation 

Pρ (Γn ≥ ) = Eρ [Pρ (Γn ≥  | µ)]

= Eρ [Pµ (Γn ≥ )]
≤ Eρ [δ] = δ

(2)
(3)
(4)

(cid:3)
In words  if the same bound holds for each component of the mixture  then it still holds after averag-
ing over the mixture. It is important here that we are only attempting to predict the long-run average
risk along the continuation of the same sample path as that which provided the training data; with
this as our goal  almost all sample paths looks like — indeed  are — realizations of single compo-
nents of the mixture  and so the bound for extremal processes applies directly to them5. By contrast 
there may be no distribution-free bounds at all if one does not condition on I.

4We suspect that similar results could be derived for many of the weak dependence conditions of [29].
5After formulating this idea  we came across a remarkable paper by Wiener [30]  where he presents a qual-
itative version of highly similar considerations  using the ergodic decomposition to argue that a full dynamical
model of the weather is neither necessary nor even helpful for meteorological forecasting. The same paper
also lays out the idea of sensitive dependence on initial conditions  and the kernel trick of turning nonlinear
problems into linear ones by projecting into inﬁnite-dimensional feature spaces.

4

A useful consequence of this innocent-looking result is that it lets us immediately apply PAC learning
results for extremal processes to composite processes  without any penalty in the sample complexity.
For instance  we have the following corollary:
Corollary 1 Let F have ﬁnite VC dimension  and have distribution-free sample complexity
s(  δ F M) for all IID measures µ ∈ P. Then the class M of exchangeable processes composed
from P admit distribution-free PAC learning with the same sample complexity 

s(  δ F P) = s(  δ F M)

This is in contrast with  for instance  the results obtained by [2  3]  which both go from IID se-
quences (laws in P) to exchangeable ones (laws in M) at the cost of considerably increased sample
complexity. The easiest point of comparison is with Theorem 4.2 of [3]  which  in our notation 
shows that
That we pay no such penalty in sample complexity because our target of learning is Eµ [f | I]  not
Eρ [f | X n
1 ]. This means we do not have to use data points to narrow the posterior distribution
π(µ | X n
1 )  and that we can give a much more direct argument.
In [3]  Pestov asks whether “one [can] maintain the initial sample complexity” when going from
IID to exchangeable sequences; the answer is yes  if one picks the right target. This holds whenever
the data-generating process is a mixture of extremal processes for which learning is possible. A
particularly important special case of this are the absolutely regular processes.

s(  δ M) ≤ s(/2  δ P)

4 Mixtures of Absolutely Regular Processes

Roughly speaking  an absolutely regular process is one which is asymptotically independent in
a particular sense  where the joint distribution between past and future events approaches  in L1 
the product of the marginal distributions as the time-lag between past and future grows. These are
particularly important for PAC learning  since much of the existing IID learning theory translates
directly to this setting.
To be precise  let X∞

−∞ be a two-sided6 stationary process. The β-dependence coefﬁcient at lag k is
(5)
where P−(1:k) is the joint distribution of X 0−∞ and X∞
k   the total variation distance between the
actual joint distribution of the past and future  and the product of their marginals. Equivalently
[31  32]

β(k) ≡(cid:13)(cid:13)P 0−∞ ⊗ P ∞
(cid:34)

k − P−(1:k)

(cid:13)(cid:13)TV
(cid:35)
P(cid:0)B | X 0−∞(cid:1) − P (B)

β(k) = E

sup

B∈σ(X∞
k )

(6)

which  roughly  is the expected total variation distance between the marginal distribution of the
future and its distribution conditional on the past.
As is well known  β(k) is non-increasing in k  and of course ≥ 0  so β(k) must have a limit as
k → ∞; it will be convenient to abbreviate this as β(∞). When β(∞) = 0  the process is said to
be beta mixing  or absolutely regular. All absolutely regular processes are also ergodic [32].
The importance of absolutely regular processes for learning comes essentially from a result due to
1 be a part of a sample path from an absolutely regular process µ  whose dependence
Yu [4]. Let X n
coefﬁcients are β(k). Fix integers m and a such that 2ma = n  so that the sequence is divided into
2m contiguous blocks of length a  and deﬁne µ(m a) to be distribution of m length-a blocks. (That
is  µ(m a) approximates µ by IID blocks.) Then |µ(C) − µ(m a)(C)| ≤ (m − 1)β(a) [4  Lemma
4.1]. Since in particular the event C could be taken to be {Γn > }  this approximation result allows
distribution-free learning bounds for IID processes to translate directly into distribution-free learning
bounds for absolutely regular processes with bounded β coefﬁcients.

6We have worked with one-sided processes so far  but the devices for moving between the two representa-

tions are standard  and this deﬁnition is more easily stated in its two-sided version.

5

If M contains only absolutely regular processes  then a measure π on M creates a ρ which is a
mixture of absolutely regular processes  or a MAR process. It is easy to see that absolute regularity
of the component processes (βµ(k) → 0) does not imply absolute regularity of the mixture processes
(βρ(k) (cid:54)→ 0). To see this  suppose that M consists of two processes µ0  which puts unit probability
mass on the sequence of all zeros  and µ1  which puts unit probability on the sequence of all ones;
and that π gives these two equal probability. Then βµi(k) = 0 for both i  but the past and the future
of ρ are not independent of each other.
More generally  suppose π is supported on just two absolutely regular processes  µ and µ(cid:48). For each
such µ  there exists a set of typical sequences Tµ ⊂ X ∞  in which the inﬁnite sample path of µ lies
almost surely7  and these sets do not overlap8  Tµ ∩ Tµ(cid:48) = ∅. This implies that ρ(Tµ) = π(µ)  but

(cid:26) 1 X 0−∞ ∈ Tµ

0

otherwise

ρ(Tµ | X 0−∞) =

Thus the change in probability of Tµ due to conditioning on the past is π(µ1) if the selected compo-
nent was µ2  and 1 − π(µ1) = π(µ2) if the selected component is µ1. We can reason in parallel for
Tµ2  and so the average change in probability is

π1(1 − π1) + π2(1 − π2) = 2π1(1 − π1)

and this must be βρ(∞). Similar reasoning when π is supported on q extremal processes shows

q(cid:88)

βρ(∞) =

πi(1 − πi)

(cid:90)

i=1

[1 − π({µ})]dπ(µ)

so that the general case is

βρ(∞) =

This implies that if π has no atoms  βρ(∞) = 1 always. Since βρ(k) is non-increasing  βρ(k) = 1
for all k  for a continuous mixture of absolutely regular processes. Conceptually  this arises because
of the use of inﬁnite-dimensional distributions for both past and future in the deﬁnition of the β-
dependence coefﬁcient. Having seen an inﬁnite past is sufﬁcient  for an ergodic process  to identify
the process  and of course the future must be a continuation of this past.
MARs thus display a rather odd separation between the properties of individual sample paths  which
approach independence asymptotically in time  and the ensemble-level behavior  where there is
ineradicable dependence  and indeed maximal dependence for continuous mixtures. Any one re-
alization of a MAR  no matter how long  is indistinguishable from a realization of an absolutely
regular process which is a component of the mixture. The distinction between a MAR and a single
absolutely regular process only becomes apparent at the level of ensembles of paths.
It is desirable to characterize MARs. They are stationary  but non-ergodic and have non-vanishing
β(∞). However  this is not sufﬁcient to characterize them. Bernoulli shifts are stationary and
ergodic  but not absolutely regular9. It follows that a mixture of Bernoulli shifts will be stationary 
and by the preceding argument will have positive β(∞)  but will not be a MAR.
Roughly speaking  given the inﬁnite past of a MAR  events in the future become asymptotically
independent as the separation between them increases10. A more precise statement needs to control
the approach to independence of the component processes in a MAR. We say that ρ is a ˜β-uniform
MAR when ρ is a MAR  and  for π-almost-all µ  βµ(k) ≤ ˜β(k)  with ˜β(k) → 0. Then if we con-
dition on ﬁnite histories X 0−n and let n grow  widely separated future events become asymptotically
independent.

7Since X is “standard”  so is X ∞  and the latter’s σ-ﬁeld σ(X∞

For each B ∈ B  the set Tµ B =(cid:8)x ∈ X ∞ :
is dynamically invariant  and  by Bikrhoff’s ergodic theorem  µ(Tµ B) = 1 [18  §7.9]. Then Tµ ≡(cid:84)

t=0 1B(τ tx) = µ(B)(cid:9) exists  is measurable 

also has µ-measure 1  because B is countable.

B∈B Tµ B
8Since µ (cid:54)= µ(cid:48)  there exists at least one set C with µ(C) (cid:54)= µ(cid:48)(C). The set Tµ C then cannot overlap at all

limn→∞ n−1(cid:80)n−1

−∞) has a countable generating basis  say B.

with the set Tµ(cid:48) C  and so Tµ cannot intersect Tµ(cid:48).

9They are  however  mixing in the sense of ergodic theory [28].
10ρ-almost-surely  X 0−∞ belongs to the typical set of a unique absolutely regular process  say µ  and so the
posterior concentrates on that µ  π(· | X 0−∞) = δµ. Hence ρ(X l
l+k)  which
tends to µ(X l−∞)µ(X∞

1  X∞
l+k) as k → ∞ because µ is absolutely regular.

l+k | X 0−∞) = µ(X l−∞  X∞

6

Theorem 3 A stationary process ρ is a ˜β-uniform MAR if and only if

(cid:34)

(cid:35)
1  X 0−n) − ρ(B | X 0−n)

ρ(B | X l

lim
k→∞ lim

n→∞ E

sup

l

sup
B∈σ(X∞

k+l)

= 0

(7)

Before proceeding to the proof  it is worth remarking on the order of the limits: for ﬁnite n  condi-
tioning on X 0−n still gives a MAR  not a single (albeit random) absolutely-regular process. Hence
the k → ∞ limit for ﬁxed n would always be positive  and indeed 1 for a continuous π.
PROOF “Only if”: Re-write Eq. 7  expressing ρ in terms of π and the extremal processes:

(cid:90) (cid:0)µ(B | X l

1  X 0−n) − µ(B | X 0−n)(cid:1) dπ(µ | X 0−n)

(cid:35)

(cid:34)

lim
k→∞ lim

n→∞ E

sup

l

sup
B∈σ(X∞

k+l)

As n → ∞  µ(B | X 0−n) → µ(B | X 0−∞)  and µ(B | X l
1  X 0−n) → µ(B | X l−∞). But 
in expectation  both of these are within ˜β(k) of µ(B)  and so within 2 ˜β(k). “If”: Consider the
contrapositive. If ρ is not a uniform MAR  either it is a non-uniform MAR  or it is not a MAR at
all. If it is not a uniform MAR  then no matter what function ˜β(k) tending to zero we propose 
the set of µ with βµ ≥ ˜β must have positive π measure  i.e.  a positive-measure set of processes
must converge arbitrarily slowly. Therefore there must exist a set B (or a sequence of such sets)
witnessing this arbitrarily slow convergence  and hence the limit in Eq. 7 will be strictly positive. If
ρ is not a MAR at all  we know from the ergodic decomposition of stationary processes that it must
be a mixture of ergodic processes  and so it must give positive π weight to processes which are not
absolutely regular at all  i.e.  µ for which βµ(∞) > 0. The witnessing events B for these processes
a fortiori drive the limit in Eq. 7 above zero. (cid:3)

5 Discussion and future work

We have shown that with the right conditioning  a natural and useful notion of predictive PAC
emerges. This notion is natural in the sense that for a learner sampling from a mixture of ergodic
processes  the only thing that matters is the future behavior of the component he is “stuck” in — and
certainly not the process average over all the components. This insight enables us to adapt the recent
PAC bounds for mixing processes to mixtures of such processes. An interesting question then is to
characterize those processes that are convex mixtures of a given kind of ergodic process (de Finetti’s
theorem was the ﬁrst such characterization).
In this paper  we have addressed this question for
mixtures of uniformly absolutely regular processes. Another fascinating question is how to extend
predictive PAC to real-valued functions [33  34].

References
[1] Mathukumalli Vidyasagar. A Theory of Learning and Generalization: With Applications to

Neural Networks and Control Systems. Springer-Verlag  Berlin  1997.

[2] Patrizia Berti and Pietro Rigo. A Glivenko-Cantelli theorem for exchangeable random vari-

ables. Statistics and Probability Letters  32:385–391  1997.

[3] Vladimir Pestov. Predictive PAC learnability: A paradigm for learning from exchangeable
input data. In Proceedings of the 2010 IEEE International Conference on Granular Computing
(GrC 2010)  pages 387–391  Los Alamitos  California  2010. IEEE Computer Society. URL
http://arxiv.org/abs/1006.1129.

[4] Bin Yu. Rates of convergence for empirical processes of stationary mixing sequences. Annals
of Probability  22:94–116  1994. URL http://projecteuclid.org/euclid.aop/
1176988849.
[5] M. Vidyasagar.

Learning and Generalization: With Applications to Neural Networks.

Springer-Verlag  Berlin  second edition  2003.

[6] Terrence M. Adams and Andrew B. Nobel. Uniform convergence of Vapnik-Chervonenkis
classes under ergodic sampling. Annals of Probability  38:1345–1367  2010. URL http:
//arxiv.org/abs/1010.3162.

7

[7] Ramon van Handel. The universal Glivenko-Cantelli property. Probability Theory and Related
Fields  155:911–934  2013. doi: 10.1007/s00440-012-0416-5. URL http://arxiv.org/
abs/1009.4434.

[8] Dharmendra S. Modha and Elias Masry. Memory-universal prediction of stationary random
processes. IEEE Transactions on Information Theory  44:117–133  1998. doi: 10.1109/18.
650998.

[9] Ron Meir. Nonparametric time series prediction through adaptive model selection. Ma-
chine Learning  39:5–34  2000. URL http://www.ee.technion.ac.il/˜rmeir/
Publications/MeirTimeSeries00.pdf.

[10] Rajeeva L. Karandikar and Mathukumalli Vidyasagar. Rates of uniform convergence of empir-
ical means with mixing processes. Statistics and Probability Letters  58:297–307  2002. doi:
10.1016/S0167-7152(02)00124-4.

[11] David Gamarnik. Extension of the PAC framework to ﬁnite and countable Markov chains.
IEEE Transactions on Information Theory  49:338–345  2003. doi: 10.1145/307400.307478.
[12] Ingo Steinwart and Andreas Christmann. Fast learning from non-i.i.d. observations. In Y. Ben-
gio  D. Schuurmans  John Lafferty  C. K. I. Williams  and A. Culotta  editors  Advances
in Neural Information Processing Systems 22 [NIPS 2009]  pages 1768–1776. MIT Press 
Cambridge  Massachusetts  2009. URL http://books.nips.cc/papers/files/
nips22/NIPS2009_1061.pdf.

[13] Mehryar Mohri and Afshin Rostamizadeh. Stability bounds for stationary φ-mixing and β-
mixing processes. Journal of Machine Learning Research  11  2010. URL http://www.
jmlr.org/papers/v11/mohri10a.html.

[14] Mehryar Mohri and Afshin Rostamizadeh. Rademacher complexity bounds for non-I.I.D. pro-
In Daphne Koller  D. Schuurmans  Y. Bengio  and L´eon Bottou  editors  Advances
cesses.
in Neural Information Processing Systems 21 [NIPS 2008]  pages 1097–1104  2009. URL
http://books.nips.cc/papers/files/nips21/NIPS2008_0419.pdf.

[15] Pierre Alquier and Olivier Wintenberger. Model selection for weakly dependent time series
forecasting. Bernoulli  18:883–913  2012. doi: 10.3150/11-BEJ359. URL http://arxiv.
org/abs/0902.2924.

[16] Ben London  Bert Huang  and Lise Getoor.

Improved generalization bounds for large-
In NIPS Workshop on Algorithmic and Statistical Approaches
scale structured prediction.
for Large Social Networks  2012. URL http://linqs.cs.umd.edu/basilic/web/
Publications/2012/london:nips12asalsn/.

[17] Ben London  Bert Huang  Benjamin Taskar  and Lise Getoor. Collective stability in structured
prediction: Generalization from one example.
In Sanjoy Dasgupta and David McAllester 
editors  Proceedings of the 30th International Conference on Machine Learning [ICML-13] 
volume 28  pages 828–836  2013. URL http://jmlr.org/proceedings/papers/
v28/london13.html.

[18] Robert M. Gray. Probability  Random Processes  and Ergodic Properties. Springer-Verlag 
New York  second edition  2009. URL http://ee.stanford.edu/˜gray/arp.
html.

[19] E. B. Dynkin. Sufﬁcient statistics and extreme points. Annals of Probability  6:705–730  1978.

URL http://projecteuclid.org/euclid.aop/1176995424.

[20] Steffen L. Lauritzen. Extreme point models in statistics. Scandinavian Journal of Statistics 
11:65–91  1984. URL http://www.jstor.org/pss/4615945. With discussion and
response.

[21] Olav Kallenberg. Probabilistic Symmetries and Invariance Principles. Springer-Verlag  New

York  2005.

[22] Persi Diaconis and David Freedman. De Finetti’s theorem for Markov chains. Annals of Proba-
bility  8:115–130  1980. doi: 10.1214/aop/1176994828. URL http://projecteuclid.
org/euclid.aop/1176994828.

[23] R. M. Dudley. A course on empirical processes. In ´Ecole d’´et´e de probabilit´es de Saint-Flour 
XII–1982  volume 1097 of Lecture Notes in Mathematics  pages 1–142. Springer  Berlin  1984.

8

[24] Anselm Blumer  Andrzej Ehrenfeucht  David Haussler  and Manfred K. Warmuth. Learnability
and the Vapnik-Chervonenkis dimension. Journal of the Association for Computing Machin-
ery  36:929–965  1989. doi: 10.1145/76359.76371. URL http://users.soe.ucsc.
edu/˜manfred/pubs/J14.pdf.

[25] St´ephane Boucheron  Olivier Bousquet  and G´abor Lugosi. Theory of classiﬁcation: A survey
of recent advances. ESAIM: Probabability and Statistics  9:323–375  2005. URL http:
//www.numdam.org/item?id=PS_2005__9__323_0.

[26] Frank B. Knight. A predictive view of continuous time processes. Annals of Probability  3:

573–596  1975. URL http://projecteuclid.org/euclid.aop/1176996302.

[27] William Bialek  Ilya Nemenman  and Naftali Tishby. Predictability  complexity and learning.
Neural Computation  13:2409–2463  2001. URL http://arxiv.org/abs/physics/
0007070.

[28] Andrzej Lasota and Michael C. Mackey. Chaos  Fractals  and Noise: Stochastic Aspects of Dy-
namics. Springer-Verlag  Berlin  1994. First edition  Probabilistic Properties of Deterministic
Systems  Cambridge University Press  1985.

[29] J´erˆome Dedecker  Paul Doukhan  Gabriel Lang  Jos´e Rafael Le´on R.  Sana Louhichi  and
Cl´ementine Prieur. Weak Dependence: With Examples and Applications. Springer  New York 
2007.

[30] Norbert Wiener. Nonlinear prediction and dynamics. In Jerzy Neyman  editor  Proceedings
of the Third Berkeley Symposium on Mathematical Statistics and Probability  volume 3  pages
247–252  Berkeley  1956. University of California Press. URL http://projecteuclid.
org/euclid.bsmsp/1200502197.

[31] Paul Doukhan. Mixing: Properties and Examples. Springer-Verlag  New York  1995.
[32] Richard C. Bradley. Basic properties of strong mixing conditions. A survey and some open
questions. Probability Surveys  2:107–144  2005. URL http://arxiv.org/abs/math/
0511078.

[33] Noga Alon  Shai Ben-David  Nicol`o Cesa-Bianchi  and David Haussler. Scale-sensitive di-
mensions  uniform convergence  and learnability. Journal of the ACM  44:615–631  1997. doi:
10.1145/263867.263927. URL http://tau.ac.il/˜nogaa/PDFS/learn3.pdf.

[34] Peter L. Bartlett and Philip M. Long.

learning  uniform convergence  and
scale-sensitive dimensions. Journal of Computer and Systems Science  56:174–190  1998.
doi: 10.1006/jcss.1997.1557. URL http://www.phillong.info/publications/
more_theorems.pdf.

Prediction 

9

,Cosma Shalizi
Aryeh Kontorovich