2018,Identification and Estimation of Causal Effects from Dependent Data,The assumption that data samples are independent and identically distributed (iid) is standard in many areas of statistics and machine learning. Nevertheless  in some settings  such as social networks  infectious disease modeling  and reasoning with spatial and temporal data  this assumption is false. An extensive literature exists on making causal inferences under the iid assumption [12  8  21  16]  but  as pointed out in [14]  causal inference in non-iid contexts is challenging due to the combination of unobserved confounding bias and data dependence. In this paper we develop a general theory describing when causal inferences are possible in such scenarios. We use segregated graphs [15]  a generalization of latent projection mixed graphs [23]  to represent causal models of this type and provide a complete algorithm for non-parametric identification in these models. We then demonstrate how statistical inferences may be performed on causal parameters identified by this algorithm  even in cases where parts of the model exhibit full interference  meaning only a single sample is available for parts of the model [19]. We apply these techniques to a synthetic data set which considers the adoption of fake news articles given the social network structure  articles read by each person  and baseline demographics and socioeconomic covariates.,Identiﬁcation and Estimation Of Causal Effects from

Dependent Data

Eli Sherman

Department of Computer Science

Johns Hopkins University

Baltimore  MD 21218
esherman@jhu.edu

Ilya Shpitser

Department of Computer Science

Johns Hopkins University

Baltimore  MD 21218
ilyas@cs.jhu.edu

Abstract

The assumption that data samples are independent and identically distributed (iid)
is standard in many areas of statistics and machine learning. Nevertheless  in
some settings  such as social networks  infectious disease modeling  and reasoning
with spatial and temporal data  this assumption is false. An extensive literature
exists on making causal inferences under the iid assumption [17  11  26  21]  even
when unobserved confounding bias may be present. But  as pointed out in [19] 
causal inference in non-iid contexts is challenging due to the presence of both
unobserved confounding and data dependence. In this paper we develop a general
theory describing when causal inferences are possible in such scenarios. We use
segregated graphs [20]  a generalization of latent projection mixed graphs [28] 
to represent causal models of this type and provide a complete algorithm for non-
parametric identiﬁcation in these models. We then demonstrate how statistical
inference may be performed on causal parameters identiﬁed by this algorithm.
In particular  we consider cases where only a single sample is available for parts
of the model due to full interference  i.e.  all units are pathwise dependent and
neighbors’ treatments affect each others’ outcomes [24]. We apply these techniques
to a synthetic data set which considers users sharing fake news articles given the
structure of their social network  user activity levels  and baseline demographics
and socioeconomic covariates.

1

Introduction

The assumption of independent and identically distributed (iid) samples is ubiquitous in data analysis.
In many research areas  however  this assumption simply does not hold. For instance  social media
data often exhibits dependence due to homophily and contagion [19]. Similarly  in epidemiology 
data exhibiting herd immunity is likely dependent across units. Likewise  signal processing and
sequence learning often consider data that are spatially [8] or temporally [23] dependent.
In causal inference  dependence in data often manifests as interference wherein some units’ treatments
may causally affect other units’ outcomes [3  9]. Herd immunity is a canonical example of interfer-
ence since other subjects’ vaccination status causally affects the likelihood of a particular subject
contracting a disease. Even under the iid assumption  making causal inferences from observed data is
difﬁcult due to the presence of unobserved confounding. This difﬁculty is worsened when interference
is present  as described in detail in [19]. In general  these difﬁculties prevent identiﬁcation of causal
parameters of interest  making estimation of these parameters from data an ill-posed problem. An
extensive literature on identiﬁcation of causal parameters (under the iid assumption) has been devel-
oped. The g-formula [17] identiﬁes any interventional distribution in directed acylcic graph-based
(DAG) causal models without latent variables. Pearl showed that in certain cases identiﬁcation is

32nd Conference on Neural Information Processing Systems (NeurIPS 2018)  Montréal  Canada.

possible even in the presence of unobserved confounding via the front-door criterion [11]. These
results were generalized into a complete identiﬁcation theory in hidden variable causal DAG models
via the ID algorithm [26  21]. An extensive theory of estimation of identiﬁed causal parameters has
been developed. Some approaches are described in [17  18]  although this is far from an exhaustive
list. While work on identiﬁcation and estimation of causal parameters under interference exists
[3  25  9  14  13  7  1]  no general theory has been developed up to now. In this paper  we aim to
provide this theory for a general class of causal models that permit interference.

2 A Motivating Example

To motivate subsequent developments  we introduce the following example application. Consider
a large group of internet users  belonging to a set of online communities  perhaps based on shared
hobbies or political views. For each user i  their time spent online Ai is inﬂuenced by their observed
vector of baseline factors Ci  and unobserved factors Ui. In addition  each user maintains a set of
friendship ties with other users via an online social network. The user’s activity level in the network 
Mi  is potentially dependent on the user’s friends’ activities  meaning that for users j and k  Mj
and Mk are potentially dependent. The dependence between M variables is modeled as a stable
symmetric relationship that has reached an equilibrium state. Furthermore  activity level Mi for user
i is inﬂuenced by observed factors Ci  time spent online Ai  and the time spent online Aj of any unit
j who is a friend of i. Finally  we denote user i’s sharing behavior by Yi. This behavior is inﬂuenced
by the social network activity of the unit  and possibly the unit friends’ time spent online.
A crucial assumption in our example is that for each user i  purchasing behavior Yi is causally
inﬂuenced by baseline characteristics Ci  social network activity Mi  and unobserved characteristics
Ui  but time spent online Ai does not directly inﬂuence sharing Yi  except as mediated by social
network activity of the users. While this might seem like a rather strong assumption  it is more
reasonable than standard “front-door” assumptions [12] in the literature  since we allow the entire
social network structure to mediate the inﬂuence Ai on Yi for every user.
We are interested in predicting how a counterfactual change in a set of users’ time spent online
inﬂuences their purchasing behavior. Note that solving this problem from observed data on users
as we described is made challenging both by the fact that unobserved variables causally affect both
community membership and sharing  creating spurious correlations  and because social network
membership introduces dependence among users. In particular  for realistic social networks  every
user’s activity potentially depends on every other user’s activity (even if indirectly). This implies that
a part of the data for this problem may effectively consist of a single dependent sample [24].
In the remainder of the paper we formally describe how causal inference may be performed in
examples like above  where both unobserved confounding and data dependence are present. In
section 3 we review relevant terminology and notation  give factorizations deﬁning graphical models 
describe causal inference in models without hidden variables  and give identiﬁcation theory for such
models in terms of a modiﬁed factorization. We also introduce the dependent data setting we will
consider. In section 4 we describe more general nested factorizations [16] applicable to marginals
obtained from hidden variable DAG models  and describe identiﬁcation theory in causal models with
hidden variables in terms of a modiﬁed nested factorization. In section 5  we introduce causal chain
graph models [6] as a way of modeling causal problems with interference and data dependence  and
pose the identiﬁcation problem for interventional distributions in such models. In section 6 we give a
sound and complete identiﬁcation algorithm for interventional distributions in a large class of causal
chain graph models with hidden variables  which includes the above example  but also many others.
We describe our experiments  which illustrate how identiﬁed functionals given by our algorithm may
be estimated in practice  even in full interference settings where all units are mutually dependent  in
section 7. Our concluding remarks are found in section 8.

3 Background on Causal Inference And Interference Problems

3.1 Graph Theory
We will consider causal models represented by mixed graphs containing directed (→)  bidirected
(↔) and undirected (−) edges. Vertices in these graphs and their corresponding random variables
will be used interchangeably  denoted by capital letters  e.g. V ; values  or realizations  of vertices

2

C1

C2

C1

C2

C1

C2

C1

C2

A1

A2

U1

U2

A1

A2

U1

M1

M2

U2

A1

A2

M1

M2

M1

M2

A1

A2

m1

m2

Y1

Y2

Y1

Y2

Y1

Y2

Y2

Y1

Y2

(a)

(b)

(c)

(d)

(e)

Figure 1: (a) A causal model representing the effect of community membership on article sharing 
mediated by social network structure. (b) A causal model on dyads which is a variation of causal
models of interference considered in [9]. (c) A latent projection of the CG in (a) onto observed
variables. (d) The graph representing GY∗ for the intervention operation do(a1) applied to (c). (e)
The ADMG obtained by ﬁxing M1  M2 in (c).

instance for a set S  paG(S) =(cid:83)

and variables will be denoted by lowercase letters  e.g. v; bold letters will denote sets of variables
or values e.g. V or v. We will denote the state space of a variable V or a set of variables V as
XV   and XV. Unless stated otherwise  all graphs will be assumed to have a vertex set denoted by
V. For a mixed graph G of the above type  we denote the standard genealogic sets for a variable
V ∈ V as follows: parents paG(V ) ≡ {W ∈ V|W → V }  children chG(V ) ≡ {W ∈ V|V → W} 
siblings sibG(V ) ≡ {W ∈ V|W ↔ V }  neighbors nbG(V ) ≡ {W ∈ V|W − V }  ancestors
anG(V ) ≡ {W ∈ V|W → ··· → V }  descendants deG(V ) ≡ {W ∈ V|V → ··· → W}  and
non-descendants ndG(V ) ≡ V \ deG(V ). We deﬁne the anterior of V   or antG(V )  to be the set of
all vertices with a partially directed path (a path containing only → and − edges such that no − edge
can be oriented to induce a directed cycle) into V . These relations generalize disjunctively to sets  for
S∈S paG(S). We also deﬁne the set pasG(S) as paG(S) \ S. Given
a graph G and a subset S of V  deﬁne the induced subgraph GS to be a graph with a vertex set S and
all edges in G between elements in S.
Given a mixed graph G  we deﬁne a district D to be a maximal set of vertices  where every vertex
pair in GD is connected by a bidirected path (a path containing only ↔ edges). Similarly we deﬁne a
block B to be a maximal set of vertices  where every vertex pair in GB is connected by an undirected
path (a path containing only − edges). Any block of size at least 2 is called a non-trivial block. We
deﬁne a maximal clique as a maximal set of vertices pairwise connected by undirected edges. The set
of districts in G is denoted by D(G)  the set of blocks is denoted by B(G)  the set non-trivial blocks
is denoted by Bnt(G)  and the set of cliques is denoted by C(G). The district of V is denoted by
disG(V ). By convention  for any V   disG(V ) ∩ deG(V ) ∩ anG(V ) ∩ antG(V ) = {V }.
A mixed graph is called segregated (SG) if it contains no partially directed cycles  and no vertex has
both neighbors and siblings  Fig. 1 (c) is an example. In a SG G  D(G) and Bnt(G) partition V. A SG
without bidirected edges is called a chain graph (CG) [5]. A SG without undirected edges is called an
acyclic directed mixed graph (ADMG) [15]. A CG without undirected edges or an ADMG without
bidirected edges is a directed acyclic graph (DAG) [10]. A CG without directed edges is called an
undirected graph (UG). Given a CG G  the augmented graph Ga is the UG where any adjacent vertices
in G or any elements in paG(B) for any B ∈ B(G) are connected by an undirected edge.

3.2 Graphical Models

p(V) =(cid:81)
ciated with a UG G that can be written in terms of a UG factorization: p(V) = Z−1(cid:81)

A graphical model is a set of distributions with conditional independences represented by structures
in a graph. The following (standard) deﬁnitions appear in [5]. A DAG model  or a Bayesian network 
is a set of distributions associated with a DAG G that can be written in terms of a DAG factorization:
V ∈V p(V | paG(V )). A UG model  or a Markov random ﬁeld  is a set of distributions asso-
C∈C(G) ψC(C) 
where Z is a normalizing constant. A CG model is a set of distributions associated with a CG G that

3

can be written in terms of the following two level factorization: p(V) =(cid:81)
where for each B ∈ B(G)  p(B| paG(B)) = Z(paG(B))−1(cid:81)

B∈B(G) p(B| paG(B)) 
C∈C((GB∪paG (B))a);C(cid:54)⊆paG (B) ψC(C).

3.3 Causal Inference and Causal Models

model  the distribution p({V |V ∈ V}) is assumed to factorize as(cid:81)

A causal model of a DAG is also a set of distributions  but on counterfactual random variables.
Given Y ∈ V and A ⊆ V \ {Y }  a counterfactual variable  or ‘potential outcome’  written as Y (a) 
represents the value of Y in a hypothetical situation where a set of treatments A is set to values a
by an intervention operation [12]. Given a set Y  deﬁne Y(a) ≡ {Y}(a) ≡ {Y (a) | Y ∈ Y}. The
distribution p(Y(a)) is sometimes written as p(Y|do(a)) [12].
Causal models of a DAG G consist of distributions deﬁned on counterfactual random variables of
the form V (a) where a are values of paG(V ). In this paper we assume Pearl’s functional model for
a DAG G with vertices V  where V (a) are determined by structural equations fV (a  V )  which
remain invariant under any possible intervention on a  with V an exogenous disturbance variable
which introduces randomness into V even after all elements of paG(V ) are ﬁxed. Under Pearl’s
V ∈V p(V ). This implies that
the sets of variables {{V (aV ) | aV ∈ XpaG (V )} | V ∈ V} are mutually independent [12]. The
atomic counterfactuals in the above set model the relationship between paG(V )  representing direct
causes of V   and V itself. From these  all other counterfactuals may be deﬁned using recursive
substitution. For any A ⊆ V \ {V }  V (a) ≡ V (apaG (V )∩A {paG(V ) \ A}(a)). For example  in
the DAG in Fig. 1 (b)  Y1(a1) is deﬁned to be Y1(a1  U1  A2(U2)). Counterfactual responses to
interventions are often compared on the mean difference scale for two values a  a(cid:48)  representing cases
and controls: E[Y (a)] − E[Y (a(cid:48))]. This quantity is known as the average causal effect (ACE).
A causal parameter is said to be identiﬁed in a causal model if it is a function of the observed data
distribution p(V). Otherwise the parameter is said to be non-identiﬁed. In any causal model of a
DAG G  all interventional distributions p(V \ A|do(a)) are identiﬁed by the g-formula [17]:

(1)

(cid:89)

p(V | paG(V ))(cid:12)(cid:12)A=a

p(V \ A|do(a)) =

V ∈V\A

Note that the g-formula may be viewed as a modiﬁed (or truncated) DAG factorization  with terms
corresponding to elements in A missing.

3.4 Modeling Dependent Data

1   . . .   Y j

So far  the causal and statistical models we have introduced assumed data generating process that
produce independent samples. To capture examples of the sort we introduced in section 2  we must
generalize these models. Suppose we analyze data with M blocks with N units each. It is not
necessary to assume that blocks are equally sized for the kinds of problems we consider  but we make
this assumption to simplify our notation. Denote the variable Y for the i’th unit in block j as Y j
i . For
each block j  let Yj ≡ (Y j
N )  and let Y ≡ (Y1  . . .   YM ). In some cases we will not be
concerned with units’ block memberships. In these cases we will accordingly omit the superscript
and the subscript will index the unit with respect to all units in the network.
We are interested in counterfactual responses to interventions on A  treatments on all units in
all blocks. For any a ∈ XA  deﬁne Y j
i (a) to be the potential response of unit i in block j to a
hypothetical treatment assignment of a to A. We deﬁne Yj(a) and Y(a) in the natural way as
vectors of responses  given a hypothetical treatment assignment to a  either for units in block j or for
all units  respectively. Let a(j) be a vector of values of A  where values assigned to units in block j
are free variables  and other values are bound variables. Furthermore  for any ˜aj ∈ XAj   let a(j)[˜aj]
be a vector of values which agrees on all bound values with a(j)  but which assigns ˜aj to all units in
block j (e.g. which binds free variables in a(j) to ˜aj).
A commonly made assumption is interblock non-interference  also known as partial interference in
[22  25]  where for any block j  treatments assigned to units in a block other than j do not affect
the responses of any unit in block j. Formally  this is stated as (∀j  a(j)  a(cid:48)(j)  ˜aj)  Yj(a(j)[˜aj]) =
Yj(a(cid:48)(j)[˜aj]). Counterfactuals under this assumption are written in a way that emphasizes they only
depend on treatments assigned within that block. That is  for any a(j)  Yj(a(j)[˜aj]) ≡ Yj(˜aj).

4

In this paper we largely follow the convention of [9]  where variables corresponding to distinct units
within a block are shown as distinct vertices in a graph. As an example  Fig. 1 (b) represents a causal
model with observed data on multiple realizations of dyads or blocks of two dependent units [4]. Note
that the arrow from A2 to Y1 in this model indicates that the treatment of unit 2 in a block inﬂuences
the outcome of unit 1  and similarly for treatment of unit 1 and outcome of unit 2. In this model  a
variation of models considered in [9]  the interventional distributions p(Y2|do(a1)) = p(Y2|a1) and
p(Y1|do(a2)) = p(Y1|a2) even if U1  U2 are unobserved.

4 Causal Inference with Hidden Variables

If a causal model contains hidden variables  only data on the observed marginal distribution is avail-
able. In this case  not every interventional distribution is identiﬁed  and identiﬁcation theory becomes
more complex. However  just as identiﬁed interventional distributions were expressible as a truncated
DAG factorization via the g-formula (1) in fully observed causal models  identiﬁed interventional
distributions are expressible as a truncated nested factorization [16] of a latent projection ADMG
[28] that represents a class of hidden variable DAGs that share identiﬁcation theory. In this section
we deﬁne latent projection ADMGs  introduce the nested factorization with respect to an ADMG in
terms of a ﬁxing operator  and re-express the ID algorithm [27  21] as a truncated nested factorization.

4.1 Latent Projection ADMGs
Given a DAG G(V ∪ H)  where V are observed and H are hidden variables  a latent projection G(V)
is the following ADMG with a vertex set V. An edge A → B exists in G(V) if there exists a directed
path from A to B in G(V ∪ H) with all intermediate vertices in H. Similarly  an edge A ↔ B exists
in G(V) if there exists a path without consecutive edges → ◦ ← from A to B with the ﬁrst edge on
the path of the form A ← and the last edge on the path of the form → B  and all intermediate vertices
on the path in H. As an example of this operation  the graph in Fig. 1 (c) is the latent projection of
Fig. 1 (a). Note that a variable pair in a latent projection G(V) may be connected by both a directed
and a bidirected edge  and that multiple distinct hidden variable DAGs G1(V ∪ H1) and G2(V ∪ H2)
may share the same latent projection ADMG.

4.2 The Nested Factorization
The nested factorization of p(V) with respect to an ADMG G(V) is deﬁned on kernel objects derived
from p(V) and conditional ADMGs derived from G(V). The derivations are via a ﬁxing operation 
which can be causally interpreted as a single application of the g-formula on a single variable (to
either a graph or a kernel) to obtain another graph or another kernel.

4.2.1 Conditional Graphs And Kernels
A kernel qV(V|W) is a mapping from values in W to normalized densities over V [5]. In other
v∈V qV(v|w) = 1 ∀w ∈ W.
Conditioning and marginalization in kernels are deﬁned in the usual way. For A ⊆ V  we deﬁne

words  kernels act like conditional distributions in the sense that(cid:80)
q(A|W) ≡(cid:80)

V\A q(V|W) and q(V \ A|A  W) ≡ q(V|W)/q(A|W).

A conditional acyclic directed mixed graph (CADMG) G(V  W) is an ADMG in which the nodes are
partitioned into W  representing ﬁxed variables  and V  representing random variables. Variables
in W have the property that only outgoing directed edges may be adjacent to them. Genealogic
relationships generalize from ADMGs to CADMGs without change. Districts are deﬁned to be
subsets of V in a CADMG G  e.g. no element of W is in any element of D(G).

4.2.2 Fixability and Fixing
A variable V ∈ V in a CADMG G is ﬁxable if deG(V ) ∩ disG(V ) = ∅. In other words  V is ﬁxable
if paths V ↔ ··· ↔ B and V → ··· → B do not both exist in G for any B ∈ V \ {V }. Given
a CADMG G(V  W) and V ∈ V ﬁxable in G  the ﬁxing operator φV (G) yields a new CADMG
G(cid:48)(V \ {V }|W ∪ {V })  where all edges with arrowheads into V are removed  and all other edges
in G are kept. Similarly  given a CADMG G(V  W)  a kernel qV(V|W)  and V ∈ V ﬁxable in G 
the ﬁxing operator φV (qV;G) yields a new kernel q(cid:48)
qV(V | ndG (V ) W).

V\{V }(V \ {V }|W ∪ {V }) ≡

qV(V|W)

5

Note that ﬁxing is a probabilistic operation in which we divide a kernel by a conditional kernel. In
some cases this operates as a conditioning operation  in other cases as a marginalization operation 
and in yet other cases  as neither  depending on the structure of the kernel being divided.
For a set S ⊆ V in a CADMG G  if all vertices in S can be ordered into a sequence σS = (cid:104)S1  S2  . . .(cid:105)
such that S1 is ﬁxable in G  S2 in φS1(G)  etc.  S is said to be ﬁxable in G  V\S is said to be reachable
in G  and σS is said to be valid. A reachable set C is said to be intrinsic if GC has a single district.
We will deﬁne φσS(G) and φσS(q;G) via the usual function composition to yield operators that ﬁx
all elements in S in the order given by σS.
The distribution p(V) is said to obey the nested factorization for an ADMG G if there exists a set
of kernels {qC(C | paG(C)) | C is intrinsic in G} such that for every ﬁxable S  and any valid σS 
D∈D(φσS (G)) qD(D| pasG(D)). All valid ﬁxing sequences for S yield the same
CADMG G(V \ S  S)  and if p(V) obeys the nested factorization for G  all valid ﬁxing sequences
for S yield the same kernel. As a result  for any valid sequence σ for S  we will redeﬁne the operator
φσ  for both graphs and kernels  to be φS. In addition  it can be shown [16] that the above kernel set
is characterized as:

φσS(p(V);G) =(cid:81)

{qC(C | paG(C)) | C is intrinsic in G} = {φV\C(p(V);G) | C is intrinsic in G}.

Thus  we can re-express the above nested factorization as stating that for any ﬁxable set S  we have
D∈D(φS(G)) φV\D(p(V);G). Since ﬁxing is deﬁned on CADMGs and kernels 
the deﬁnition of nested Markov models generalizes in a straightforward way to a kernel q(V|W)
being in the nested Markov model for a CADMG G(V  W). This holds if for every S ﬁxable in

φS(p(V);G) =(cid:81)
G(V  W)  φS(q(V|W);G) =(cid:81)

D∈D(φS(G)) φV\D(q(V|W);G).

An important result in [16] states that if p(V ∪ H) obeys the factorization for a DAG G with vertex
set V ∪ H  then p(V) obeys the nested factorization for the latent projection ADMG G(V).

Identiﬁcation in Hidden Variable Causal DAGs

4.3
For any disjoint subsets Y  A of V in a latent projection G(V) representing a causal DAG G(V∪ H) 
deﬁne Y∗ ≡ anG(V)V\A (Y). Then p(Y|do(a)) is identiﬁed in G if and only if every set D ∈
D(G(V)Y∗ ) is reachable (in fact  intrinsic). Moreover  if identiﬁcation holds  we have [16]:

p(Y|do(a)) =

φV\D(p(V);G(V))|A=a.

(2)

(cid:88)

(cid:89)

Y∗\Y

D∈D(G(V)Y∗ )

In other words  p(Y|do(a)) is only identiﬁed if it can be expressed as a factorization  where every
piece corresponds to a kernel associated with a set intrinsic in G(V). Moreover  no piece in this
factorization contains elements of A as random variables  just as was the case in (1). In fact  (2)
provides a concise formulation of the ID algorithm [27  21] in terms of the nested Markov model in
which the observed distribution in the causal problem lies. For a full proof  see [16].

5 Chain Graphs For Causal Inference With Dependent Data

We generalize causal models to represent settings with data dependence  speciﬁcally to cases where
variables may exhibit stable but symmetric relationships. These may correspond to friendship ties in
a social network  physical proximity  or rules of infectious disease spread. These stand in contrast to
causal relationships which are also stable  but asymmetric. We represent settings with both of these
kinds of relationships using causal CG models under the Lauritzen-Wermuth-Freydenburg (LWF)
interpretation. Though there are alternative conceptions of chain graphs [2]  we concentrate on LWF
CGs here. This is because LWF CGs yield observed data distributions with smooth parameterizations.
In addition  LWF CGs yield Markov properties where each unit’s friends (and direct causes) screen
the unit from other units in the network. This sort of independence is intuitively appealing in many
network settings. Extensions of our results to other CG models are likely possible  but we leave them
to future work.
LWF CGs were given a causal interpretation in [6]. In a causal CG  the distribution p(B| paG(B)) for
each block B is determined via a computer program that implements a Gibbs sampler on variables
B ∈ B  where the conditional distribution p(B|B \ {B}  paG(B)) is determined via a structural
equation of the form fB(B \ {B}  paG(B)  B). This interpretation of p(B| paG(B)) allows the

6

implementation of a simple intervention operation do(b). The operation sets B to b by replacing the
line of the Gibbs sampler program that assigns B to the value returned by fB(B \ {B}  paG(B)  B)
(given a new realization of B)  with an assignment of B to the value b. It was shown [6] that in a
causal CG model  for any disjoint Y  A  p(Y|do(a)) is identiﬁed by the CG version of the g-formula

(1): p(Y|do(a)) =(cid:81)

B∈B(G) p(B \ A| pa(B)  B ∩ A)|A=a.

In our example above  stable symmetric relationships inducing data dependence  represented by
undirected edges  coexist with hidden variables. To represent causal inference in this setting  we
generalize earlier developments for hidden variable causal DAG models to hidden variable causal CG
models. Speciﬁcally  we ﬁrst deﬁne a latent projection analogue called the segregated projection for a
large class of hidden variable CGs using segregated graphs (SGs). We then deﬁne a factorization for
SGs that generalizes the nested factorization and the CG factorization  and show that if a distribution
p(V ∪ H) factorizes given a CG G(V ∪ H) in the class  then p(V) factorizes according to the
segregated projection G(V). Finally  we derive identiﬁcation theory for hidden variable CGs as a
generalization of (2) that can be viewed as a truncated SG factorization.

5.1 Segregated Projections Of Latent Variable Chain Graphs
Fix a chain graph CG G and a vertex set H such that for all H ∈ H  H does not lie in B ∪ paG(B) 
for any B ∈ Bnt(G). We call such a set H block-safe.
Deﬁnition 1 Given a CG G(V ∪ H) and a block-safe set H  deﬁne a segregated projection graph
G(V) with a vertex set V. Moreover  for any collider-free path from any two elements V1  V2 in V 
where all intermediate vertices are in H  G(V) contains an edge with end points matching the path.
That is  we have V1 ← ◦ . . .◦ → V2 leads to the edge V1 ↔ V2  V1 → ◦ . . .◦ → V2 leads to the
edge V1 → V2  and in G(V).

As an example  the SG in Fig. 1 (c) is a segregated projection of the hidden variable CG in Fig. 1 (a).
While segregated graphs preserve conditional independence structure on the observed marginal of a
CG for any H [20]  we chose to further restrict the set H in order to ensure that the directed edges in
the segregated projection retain an intuitive causal interpretation of edges in a latent projection [28].
That is  whenever A → B in a segregated projection  A is a causal ancestor of B in the underlying
causal CG. SGs represent latent variable CGs  meaning that they allow causal systems that model
feedback that leads to network structures  of the sort considered in [6]  but simultaneously allow
certain forms of unobserved confounding in such causal systems.

5.2 Segregated Factorization

The segregated factorization of an SG can be deﬁned as a product of two kernels which themselves
factorize  one in terms of a CADMG (a conditional graph with only directed and bidirected arrows) 
and another in terms of a conditional chain graph (CCG) G(V  W)  a CG with the property that the
only type of edge adjacent to any element W of W is a directed edge out of W . A kernel q(V|W) is
said to be Markov relative to the CCG G(V  W) if q(V|W) = Z(W)
B∈B(G) q(B| paG(B)) 

−1(cid:81)

C∈C((GB∪paG (B))a);C(cid:54)⊆paG (B) ψC(C)  for each B ∈ B(G).

and q(B| paG(B)) = Z(paG(B))−1(cid:81)
and the two corresponding kernels. Given a SG G  let district variables D∗ be deﬁned as(cid:83)
and let block variables B∗ be deﬁned as(cid:83)

We now show  given p(V) and an SG G(V)  how to construct the appropriate CADMG and CCG 
D∈D(G) D 
B∈Bnt(G) B. Since D(G) and Bnt(G) partition V in a SG 
B∗ and D∗ partition V as well. Let the induced CADMG Gd of a SG G be the graph containing
the vertex sets D∗ as V and pasG(D∗) as W  and which inherits all edges in G between D∗  and
all directed edges from pasG(D∗) to D∗ in G. Similarly  let the induced CCG Gb of G be the graph
containing the vertex set B∗ as V and pasG(B∗) as W  and which inherits all edges in G between
B∗  and all directed edges from paG(B∗) to B∗. We say that p(V) obeys the factorization of a SG
G(V) if p(V) = q(D∗| pasG(D∗))q(B∗| paG(B∗))  q(B∗| paG(B∗)) is Markov relative to the CCG
Gb  and q(D∗| pasG(D∗)) is in the nested Markov model of the CADMG Gd.
The following theorem gives the relationship between a joint distribution that factorizes given a
hidden variable CG G  its marginal distribution  and the corresponding segregated factorization. This

7

theorem is a generalization of the result proven in [16] relating hidden variable DAGs and latent
projection ADMGs. The proof is deferred to the appendix.
Theorem 1 If p(V ∪ H) obeys the CG factorization relative to G(V ∪ H)  and H is block-safe then
p(V) obeys the segregated factorization relative to the segregated projection G(V).

6 A Complete Identiﬁcation Algorithm for Latent Variable Chain Graphs

Y∗\Y

φD∗\D(q(D

∗| paG(V)(D

∗

));Gd)

D∈D((cid:101)Gd)

 (cid:89)

 (cid:89)

With Theorem 1 in hand  we are ready to characterize general non-parametric identiﬁcation of
interventional distributions in hidden variable causal chain graph models  where hidden variables
form a block-safe set. This result can be viewed on the one hand as a generalization of the CG
g-formula derived in [6]  and on the other hand as a generalization of the ID algorithm (2).
Theorem 2 Assume G(V ∪ H) is a causal CG  where H is block-safe. Fix disjoint subsets Y  A of
in D((cid:101)Gd) is reachable in Gd  where (cid:101)Gd is the induced CADMG of G(V)Y∗.
V. Let Y∗ = antG(V)V\A Y. Then p(Y|do(a)) is identiﬁed from p(V) if and only if every element
Moreover  if p(Y|do(a)) is identiﬁed  it is equal to
(cid:88)
where q(D∗| paG(V)(D∗)) = p(V)/((cid:81)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)A=a
B∈Bnt(G(V)) p(B| paG(V)(B))  and (cid:101)Gb is the induced CCG

p(B \ A| paG(V)Y∗ (B)  B ∩ A)

of G(V)Y∗.
To illustrate the application of this theorem  consider the SG G in Fig. 1 (c)  where we are interested
in p(Y2|do(a1  a2)). It is easy to see that Y∗ = {C1  C2  M1  M2  Y2} (see GY∗ in Fig. 1 (d))
with B(GY∗ ) = {{M1  M2}} and D(GY∗ ) = {{C1} {C2} {Y2}}. The chain graph factor of the
factorization in Theorem 2 is p(M1  M2|A1 = a1  A2  C1  C2). Note that this expression further
factorizes according to the (second level) undirected factorization of blocks in a CCG. For the
three district factors {C1} {C2} {Y2} in Fig. 1 (d)  we must ﬁx variables in three different sets
{C2  A1  A2  Y1  Y2}  {C1  A1  A2  Y1  Y2}  {C1  C2  A1  Y1  A2} in Gd  shown in Fig. 1 (e). We
defer the full derivation involving the ﬁxing operator to the supplementary material. The resulting
identifying functional for p(Y2|do(a1  a2)) is:
p(M1  M2|a1  a2  C1  C2)

p(Y2|a1  A2  M2  C2)p(A2|C2)p(C1)p(C2)

B∈B((cid:101)Gb)

(3)

(cid:88)

{C1 C2 M1 M2}

(cid:88)

A2

7 Experiments

We now illustrate how identiﬁed functionals given by Theorem 2 may be estimated from data.
Speciﬁcally we consider network average effects (N.E.)  the network analogue of the average causal
effect (ACE)  as deﬁned in [3]:
1
N

E[Yi(Ai = 1  A−1 = 1)] − E[Yi(Ai = 0  A−i = 0)]

NEi(a−i) =

(cid:88)

i

in our article sharing example described in section 2  and shown in simpliﬁed form (for two units) in
Fig. 1 (a). The experiments and results we present here generalize easily to other network effects
such as direct and spillover effects [3]  although we do not consider this here in the interests of
space. For purposes of illustration we consider a simple setting where the social network is a 3-
regular graph  with networks of size N = [400  800  1000  2000]. Under the hidden variable CG
model we described in section 2  the above effect is identiﬁed by a functional which generalizes
(3) from a network of size 2 to a larger network. Importantly  since we assume a single connected
network of M variables  we are in the full interference setting where only a single sample from
p(M1  . . . MN|A1  . . .   AN   C1  . . .   CN ) is available. This means that while the standard maximum
likelihood plug-in estimation strategy is possible for models for Yi and Ai in (3)  the strategy does
not work for the model for M. Instead  we adapt the auto-g-computation approach based on the
pseudo-likelihood and coding estimators proposed in [24]  which is appropriate for full interference

8

settings with a Markov property given by a CG  as part of our estimation procedure. Note that
the approach in [24] was applied for a special case of the set of causal models considered here  in
particular those with no unmeasured confounding. Here we use the same approach for estimating
general functionals in models that may include unobserved confounders between treatments and
outcomes. In fact  our example model is analogous to the model in [24]  in the same way that the
front-door criterion is to the backdoor criterion in causal inference under the assumption of iid data
[12].
Our detailed estimation strategy  along with a more detailed description of our results  is described in
the appendix. We performed 1000 bootstrap samples of the 4 different networks. Since calculating
the true causal effects is intractable even if true model parameters are known  we calculate the
approximate ‘ground truth’ for each intervention by sampling from our data generating process under
the intervention 5 times and averaging the relevant effect. We calculated the (approximation of) the
bias of each effect by subtracting the estimate from the ‘ground truth.’ The ‘ground truth’ network
average effects range from −.453 to −.456. As shown in Tables 1 and 2  both estimators recover the
ground truth effect with relatively small bias. Estimators for effects which used the pseudo-likelihood
estimator for M generally have lower variance than those that used the coding estimator for M 
which is expected due to the greater efﬁciency of the former. This behavior was also observed in
[24]. In both estimators  bias decreases with network size. This is also expected intuitively  although
detailed asymptotic theory for statistical inference in networks is currently an open problem  due to
dependence of samples.

95% Conﬁdence Intervals of Bias of Network Average Effects
N
Coding
Pseudo

1000
(-.100  .065)
(-.116  .074)

400
(-.157  .103)
(-.133  .080)

800
(-.129  .106)
(-.099  .089)

2000
(-.086  .051)
(-.070  .041)

Estimator

Table 1: 95% conﬁdence intervals for the bias of each estimating method for the network average
effects. All intervals cover the approximated ground truth since they include 0

Estimator

N
Coding
Pseudo

Bias of Network Average Effects

400
-.000 (.060)
.006 (.052)

800
-.020 (.051)
-.023 (.042)

1000
-.024 (.052)
-.023 (.042)

2000
-.022 (.034)
-.021 (.026)

Table 2: The biases of each estimating method for the network average effects. Standard deviation of
the bias of each estimate is given in parentheses.

8 Conclusion

In this paper  we generalized existing non-parametric identiﬁcation theory for hidden variable
causal DAG models to hidden variable causal chain graph models  which can represent both causal
relationships  and stable symmetric relationships that induce data dependence. Speciﬁcally  we gave a
representation of all identiﬁed interventional distributions in such models as a truncated factorization
associated with segregated graphs  mixed graphs containing directed  undirected  and bidirected
edges which represent marginals of chain graphs.
We also demonstrated how statistical inference may be performed on identiﬁable causal parameters 
by adapting a combination of maximum likelihood plug in estimation  and methods based on coding
and pseudo-likelihood estimators that were adapted for full interference problems in [24]. We
illustrated our approach with an example of calculating the effect of community membership on
article sharing if the effect of the former on the latter is mediated by a complex social network of
units inducing full dependence.

9 Acknowledgements

The second author would like to thank the American Institute of Mathematics for supporting this
research via the SQuaRE program. This project is sponsored in part by the National Institutes of

9

Health grant R01 AI127271-01 A1  the Ofﬁce of Naval Research grant N00014-18-1-2760 and the
Defense Advanced Research Projects Agency (DARPA) under contract HR0011-18-C-0049. The
content of the information does not necessarily reﬂect the position or the policy of the Government 
and no ofﬁcial endorsement should be inferred.

10

References
[1] D. Arbour  D. Garant  and D. Jensen. Inferring network effects from observational data. In
Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and
Data Mining  pages 715–724. ACM  2016.

[2] M. Drton. Discrete chain graph models. Bernoulli  15(3):736–753  2009.

[3] M. Hudgens and M. Halloran. Toward causal inference with interference. Journal of the

American Statistical Association  103(482):832–842  2008.

[4] D. A. Kenny  D. A. Kashy  and W. L. Cook. Dyadic Data Analysis. Guilford Press New York 

2006.

[5] S. L. Lauritzen. Graphical Models. Oxford  U.K.: Clarendon  1996.

[6] S. L. Lauritzen and T. S. Richardson. Chain graph models and their causal interpretations (with

discussion). Journal of the Royal Statistical Society: Series B  64:321–361  2002.

[7] M. Maier  K. Marazopoulou  and D. Jensen. Reasoning about independence in probabilistic

models of relational data. arXiv preprint arXiv:1302.4381  2013.

[8] V. Mnih  K. Kavukcuoglu  D. Silver  A. A. Rusu  J. Veness  M. G. Bellemare  A. Graves 
M. Riedmiller  A. K. Fidjeland  G. Ostrovski  et al. Human-level control through deep rein-
forcement learning. Nature  518(7540):529  2015.

[9] E. L. Ogburn and T. J. VanderWeele. Causal diagrams for interference. Statistical Science 

29(4):559–578  2014.

[10] J. Pearl. Probabilistic Reasoning in Intelligent Systems. Morgan and Kaufmann  San Mateo 

1988.

[11] J. Pearl. Causal diagrams for empirical research. Biometrika  82(4):669–709  1995.

[12] J. Pearl. Causality: Models  Reasoning  and Inference. Cambridge University Press  2 edition 

2009.

[13] J. M. Peña. Learning acyclic directed mixed graphs from observations and interventions. In

Conference on Probabilistic Graphical Models  pages 392–402  2016.

[14] J. M. Peña. Reasoning with alternative acyclic directed mixed graphs. Behaviormetrika  pages

1–34  2018.

[15] T. S. Richardson. Markov properties for acyclic directed mixed graphs. Scandinavial Journal

of Statistics  30(1):145–157  2003.

[16] T. S. Richardson  R. J. Evans  J. M. Robins  and I. Shpitser. Nested Markov properties for

acyclic directed mixed graphs  2017. Working paper.

[17] J. M. Robins. A new approach to causal inference in mortality studies with sustained exposure
periods – application to control of the healthy worker survivor effect. Mathematical Modeling 
7:1393–1512  1986.

[18] J. M. Robins. Marginal structural models versus structural nested models as tools for causal
inference. In Statistical Models in Epidemiology: The Environment and Clinical Trials. NY:
Springer-Verlag  1999.

[19] C. R. Shalizi and A. C. Thomas. Homophily and contagion are generically confounded in
observational social network studies. Sociological methods & research  40(2):211–239  2011.

[20] I. Shpitser. Segregated graphs and marginals of chain graph models. In Advances in Neural

Information Processing Systems 28. Curran Associates  Inc.  2015.

[21] I. Shpitser and J. Pearl. Identiﬁcation of joint interventional distributions in recursive semi-
Markovian causal models. In Proceedings of the Twenty-First National Conference on Artiﬁcial
Intelligence (AAAI-06). AAAI Press  Palo Alto  2006.

11

[22] M. E. Sobel. What do randomized studies of housing mobility demonstrate? causal inference in
the face of interference. Journal of the American Statistical Association  101.476:1398–1407 
2006.

[23] I. Sutskever  O. Vinyals  and Q. V. Le. Sequence to sequence learning with neural networks. In

Advances in neural information processing systems  pages 3104–3112  2014.

[24] E. J. Tchetgen Tchetgen  I. Fulcher  and I. Shpitser. Auto-g-computation of causal effects on a

network. hhttps://arxiv.org/abs/1709.01577  2017. Working paper.

[25] E. J. Tchetgen Tchetgen and T. J. VanderWeele. On causal inference in the presence of

interference. Statistical Methods in Medical Research  21(1):55–75  2012.

[26] J. Tian and J. Pearl. On the identiﬁcation of causal effects. Technical Report R-290-L 

Department of Computer Science  University of California  Los Angeles  2002.

[27] J. Tian and J. Pearl. On the testable implications of causal models with hidden variables. In
Proceedings of the Eighteenth Conference on Uncertainty in Artiﬁcial Intelligence (UAI-02) 
volume 18  pages 519–527. AUAI Press  Corvallis  Oregon  2002.

[28] T. S. Verma and J. Pearl. Equivalence and synthesis of causal models. Technical Report R-150 

Department of Computer Science  University of California  Los Angeles  1990.

12

,Eli Sherman
Ilya Shpitser