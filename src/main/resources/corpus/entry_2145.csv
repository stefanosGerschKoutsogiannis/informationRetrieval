2016,Following the Leader and Fast Rates in Linear Prediction: Curved Constraint Sets and Other Regularities,The follow the leader (FTL) algorithm  perhaps the simplest of all online learning algorithms  is known to perform well when the loss functions it is used on are positively curved. In this paper we ask whether there are other "lucky" settings when FTL achieves sublinear  "small" regret. In particular  we study the fundamental problem of linear prediction over a non-empty convex  compact domain. Amongst other results  we prove that the curvature of  the boundary of the domain can act as if the losses were curved: In this case  we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero  FTL enjoys a logarithmic growth rate of regret  while  e.g.  for polyhedral domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm  we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL.,Following the Leader and Fast Rates in Linear
Prediction: Curved Constraint Sets and Other

Regularities

Ruitong Huang

Department of Computing Science
University of Alberta  AB  Canada

ruitong@ualberta.ca

Tor Lattimore

School of Informatics and Computing

Indiana University  IN  USA
tor.lattimore@gmail.com

András György

Dept. of Electrical & Electronic Engineering

Imperial College London  UK
a.gyorgy@imperial.ac.uk

Csaba Szepesvári

Department of Computing Science
University of Alberta  AB  Canada

szepesva@ualberta.ca

Abstract

The follow the leader (FTL) algorithm  perhaps the simplest of all online learning
algorithms  is known to perform well when the loss functions it is used on are posi-
tively curved. In this paper we ask whether there are other “lucky” settings when
FTL achieves sublinear  “small” regret. In particular  we study the fundamental
problem of linear prediction over a non-empty convex  compact domain. Amongst
other results  we prove that the curvature of the boundary of the domain can act as
if the losses were curved: In this case  we prove that as long as the mean of the loss
vectors have positive lengths bounded away from zero  FTL enjoys a logarithmic
growth rate of regret  while  e.g.  for polyhedral domains and stochastic data it
enjoys ﬁnite expected regret. Building on a previously known meta-algorithm  we
also get an algorithm that simultaneously enjoys the worst-case guarantees and the
bound available for FTL.

1

Introduction

Learning theory traditionally has been studied in a statistical framework  discussed at length  for
example  by Shalev-Shwartz and Ben-David [2014]. The issue with this approach is that the analysis
of the performance of learning methods seems to critically depend on whether the data generating
mechanism satisﬁes some probabilistic assumptions. Realizing that these assumptions are not
necessarily critical  much work has been devoted recently to studying learning algorithms in the so-
called online learning framework [Cesa-Bianchi and Lugosi  2006]. The online learning framework
makes minimal assumptions about the data generating mechanism  while allowing one to replicate
results of the statistical framework through online-to-batch conversions [Cesa-Bianchi et al.  2004].
By following a minimax approach  however  results proven in the online learning setting  at least
initially  led to rather conservative results and algorithm designs  failing to capture how more regular 
“easier” data  may give rise to faster learning speed. This is problematic as it may suggest overly
conservative learning strategies  missing opportunities to extract more information when the data is
nicer. Also  it is hard to argue that data resulting from passive data collection  such as weather data 
would ever be adversarially generated (though it is equally hard to defend that such data satisﬁes
precise stochastic assumptions). Realizing this issue  during recent years much work has been devoted
to understanding what regularities and how can lead to faster learning speed. For example  much
work has been devoted to showing that faster learning speed (smaller “regret”) can be achieved in

30th Conference on Neural Information Processing Systems (NIPS 2016)  Barcelona  Spain.

the online convex optimization setting when the loss functions are “curved”  such as when the loss
functions are strongly convex or exp-concave  or when the losses show small variations  or the best
prediction in hindsight has a small total loss  and that these properties can be exploited in an adaptive
manner (e.g.  Merhav and Feder 1992  Freund and Schapire 1997  Gaivoronski and Stella 2000 
Cesa-Bianchi and Lugosi 2006  Hazan et al. 2007  Bartlett et al. 2007  Kakade and Shalev-Shwartz
2009  Orabona et al. 2012  Rakhlin and Sridharan 2013  van Erven et al. 2015  Foster et al. 2015).
In this paper we contribute to this growing literature by studying online linear prediction and the
follow the leader (FTL) algorithm. Online linear prediction is arguably the simplest of all the learning
settings  and lies at the heart of online convex optimization  while it also serves as an abstraction of
core learning problems such as prediction with expert advice. FTL  the online analogue of empirical
risk minimization of statistical learning  is the simplest learning strategy  one can think of. Although
the linear setting of course removes the possibility of exploiting the curvature of losses  as we will
see  there are multiple ways online learning problems can present data that allows for small regret 
even for FTL. As is it well known  in the worst case  FTL suffers a linear regret (e.g.  Example 2.2 of
Shalev-Shwartz [2012]). However  for “curved” losses (e.g.  exp-concave losses)  FTL was shown
to achieve small (logarithmic) regret (see  e.g.  Merhav and Feder [1992]  Cesa-Bianchi and Lugosi
[2006]  Gaivoronski and Stella [2000]  Hazan et al. [2007]).
In this paper we take a thorough look at FTL in the case when the losses are linear  but the problem
perhaps exhibits other regularities. The motivation comes from the simple observation that  for
prediction over the simplex  when the loss vectors are selected independently of each other from
a distribution with a bounded support with a nonzero mean  FTL quickly locks onto selecting the
loss-minimizing vertex of the simplex  achieving ﬁnite expected regret. In this case  FTL is arguably
an excellent algorithm. In fact  FTL is shown to be the minimax optimizer for the binary losses in the
stochastic expert setting in the paper of Kotłowski [2016]. Thus  we ask the question of whether there
are other regularities that allow FTL to achieve nontrivial performance guarantees. Our main result
shows that when the decision set (or constraint set) has a sufﬁciently “curved” boundary and the
linear loss is bounded away from 0  FTL is able to achieve logarithmic regret even in the adversarial
setting  thus opening up a new way to prove fast rates based on not on the curvature of losses  but on
that of the boundary of the constraint set and non-singularity of the linear loss. In a matching lower
bound we show that this regret bound is essentially unimprovable. We also show an alternate bound
for polyhedral constraint sets  which allows us to prove that (under certain technical conditions) for
stochastic problems the expected regret of FTL will be ﬁnite. To ﬁnish  we use (A  B)-prod of Sani
√
et al. [2014] to design an algorithm that adaptively interpolates between the worst case O(
n) regret
and the smaller regret bounds  which we prove here for “easy data.” Simulation results on artiﬁcial
data to illustrate the theory complement the theoretical ﬁndings  though due to lack of space these are
presented only in the long version of the paper [Huang et al.  2016].
While we believe that we are the ﬁrst to point out that the curvature of the constraint set W can help
in speeding up learning  this effect is known in convex optimization since at least the work of Levitin
and Polyak [1966]  who showed that exponential rates are attainable for strongly convex constraint
sets if the norm of the gradients of the objective function admit a uniform lower bound. More recently 
Garber and Hazan [2015] proved an O(1/n2) optimization error bound (with problem-dependent
constants) for the Frank-Wolfe algorithm for strongly convex and smooth objectives and strongly
√
convex constraint sets. The effect of the shape of the constraint set was also discussed by Abbasi-
Yadkori [2010] who demonstrated O(
n) regret in the linear bandit setting. While these results at a
high level are similar to ours  our proof technique is rather different than that used there.

2 Preliminaries  online learning and the follow the leader algorithm

We consider the standard framework of online convex optimization  where a learner and an envi-
ronment interact in a sequential manner in n rounds: In round every round t = 1  . . .   n  ﬁrst the
learner predicts wt ∈ W. Then the environment picks a loss function (cid:96)t ∈ L  and the learner suffers
loss (cid:96)t(wt) and observes (cid:96)t. Here  W is a non-empty  compact convex subset of Rd and L is a set
of convex functions  mapping W to the reals. The elements of L are called loss functions. The
performance of the learner is measured in terms of its regret 

Rn =

(cid:96)t(w) .

n(cid:88)

t=1

n(cid:88)

t=1

(cid:96)t(wt) − min
w∈W

2

The simplest possible case  which will be the focus of this paper  is when the losses are linear  i.e. 
when (cid:96)t(w) = (cid:104)ft  w(cid:105) for some ft ∈ F ⊂ Rd. In fact  the linear case is not only simple  but is also
fundamental since the case of nonlinear loss functions can be reduced to it: Indeed  even if the losses
are nonlinear  deﬁning ft ∈ ∂(cid:96)t(wt) to be a subgradient1 of (cid:96)t at wt and letting ˜(cid:96)t(u) = (cid:104)ft  u(cid:105)  by
the deﬁnition of subgradients  (cid:96)t(wt) − (cid:96)t(u) ≤ (cid:96)t(wt) − ((cid:96)t(wt) + (cid:104)ft  u − wt(cid:105)) = ˜(cid:96)t(wt) − ˜(cid:96)t(u) 

hence for any u ∈ W  (cid:88)

(cid:96)t(wt) −(cid:88)

(cid:96)t(u) ≤(cid:88)

˜(cid:96)t(wt) −(cid:88)

˜(cid:96)t(u) .

t

t

t

t

In particular  if an algorithm keeps the regret small no matter how the linear losses are selected (even
when allowing the environment to pick losses based on the choices of the learner)  the algorithm can
also be used to keep the regret small in the nonlinear case. Hence  in what follows we will study the
linear case (cid:96)t(w) = (cid:104)ft  w(cid:105) and  in particular  we will study the regret of the so-called “Follow The
Leader” (FTL) learner  which  in round t ≥ 2 picks

t−1(cid:88)

i=1

wt = argmin
w∈W

(cid:96)i(w) .

minw∈W(cid:80)t−1

For the ﬁrst round  w1 ∈ W is picked in an arbitrary manner. When W is compact  the optimal w of
i=1(cid:104)w  ft(cid:105) is attainable  which we will assume henceforth. If multiple minimizers exist 
we simply ﬁx one of them as wt. We will also assume that F is non-empty  compact and convex.
(cid:80)t

i=1 fi be the negative average of the ﬁrst t vectors in (ft)n

t=1  ft ∈ F. For

2.1 Support functions
Let Θt = − 1
convenience  we deﬁne Θ0 := 0. Thus  for t ≥ 2 
(cid:104)w  fi(cid:105) = argmin
w∈W

wt = argmin
w∈W

t−1(cid:88)

t

i=1

(cid:104)w −Θt−1(cid:105) = argmax
w∈W

(cid:104)w  Θt−1(cid:105) .

(cid:8)(θ  z)| z ≥ Φ(θ)  z ∈ R  θ ∈ Rd(cid:9) of Φ is a cone  since for any (θ  z) ∈ epi(Φ) and a ≥ 0  az ≥

Denote by Φ(Θ) = maxw∈W(cid:104)w  Θ(cid:105) the so-called support function of W. The support function 
being the maximum of linear and hence convex functions  is itself convex. Further Φ is positive
homogenous: for a ≥ 0 and θ ∈ Rd  Φ(aθ) = aΦ(θ). It follows then that the epigraph epi(Φ) =
aΦ(θ) = Φ(aθ)  (aθ  az) ∈ epi(Φ) also holds.
The differentiability of the support function is closely tied to whether in the FTL algorithm the choice
of wt is uniquely determined:
Proposition 2.1. Let W (cid:54)= ∅ be convex and closed. Fix Θ and let Z := {w ∈ W |(cid:104)w  Θ(cid:105) = Φ(Θ)}.
Then  ∂Φ(Θ) = Z and  in particular  Φ(Θ) is differentiable at Θ if and only if maxw∈W(cid:104)w  Θ(cid:105) has
a unique optimizer. In this case  ∇Φ(Θ) = argmaxw∈W(cid:104)w  Θ(cid:105).
The proposition follows from Danskin’s theorem when W is compact (e.g.  Proposition B.25 of
Bertsekas 1999)  but a simple direct argument can also be used to show that it also remains true even
when W is unbounded.2 By Proposition 2.1  when Φ is differentiable at Θt−1  wt = ∇Φ(Θt−1).

3 Non-stochastic analysis of FTL

We start by rewriting the regret of FTL in an equivalent form  which shows that we can expect FTL
to enjoy a small regret when successive weight vectors move little. A noteworthy feature of the next
proposition is that rather than bounding the regret from above  it gives an equivalent expression for it.
Proposition 3.1. The regret Rn of FTL satisﬁes

n(cid:88)

Rn =

t(cid:104)wt+1 − wt  Θt(cid:105) .

(cid:8)θ ∈ Rd | g(x(cid:48)) ≥ g(x) + (cid:104)θ  x(cid:48) − x(cid:105) ∀x(cid:48) ∈ dom(g)(cid:9)  where dom(g) ⊂ Rd is the domain of g.

1 We let ∂g(x) denote the subdifferential of a convex function g : dom(g) → R at x  i.e.  ∂g(x) =

t=1

2 The proofs not given in the main text can be found in the long version of the paper [Huang et al.  2016].

3

(cid:80)n
The result is a direct corollary of Lemma 9 of McMahan [2010]  which holds for any sequence of
losses  even in the lack of convexity. It is also a tightening of the well-known inequality Rn ≤
t=1 (cid:96)t(wt) − (cid:96)t(wt+1)  which again holds for arbitrary loss sequences (e.g.  Lemma 2.1 of Shalev-
Shwartz [2012]). To keep the paper self-contained  we give an elegant  short direct proof  based on
the summation by parts formula:
(cid:80)n
t=1 ut (vt+1 − vt) = (ut+1vt+1 − u1v1) −(cid:80)n
inition of regret with ut := wt · and vt+1 := tΘt  we get Rn = −(cid:80)n
(cid:104)wn+1  nΘn(cid:105) = −{hhhhhh

Proof. The summation by parts formula states that for any u1  v1  . . .   un+1  vn+1 reals 
t=1(ut+1 − ut) vt+1. Applying this to the def-
t=1(cid:104)wt  tΘt − (t − 1)Θt−1(cid:105) +
hhhhhh
(cid:104)wn+1  nΘn(cid:105).

(cid:104)wn+1  nΘn(cid:105) − 0 −(cid:80)n

t=1(cid:104)wt+1 − wt  tΘt(cid:105)} +

Our next proposition gives another formula that is equal to the regret. As opposed to the previous
result  this formula is appealing as it is independent of wt; but it directly connects the sequence
(Θt)t to the geometric properties of W through the support function Φ. For this proposition we will
momentarily assume that Φ is differentiable at (Θt)t≥1; a more general statement will follow later.
Proposition 3.2. If Φ is differentiable at Θ1  . . .   Θn 

Rn =

t DΦ(Θt  Θt−1)  

(1)

n(cid:88)

t=1

where DΦ(θ(cid:48)  θ) = Φ(θ(cid:48)) − Φ(θ) − (cid:104)∇Φ(θ)  θ(cid:48) − θ(cid:105) is the Bregman divergence of Φ and we use the
convention that ∇Φ(0) = w1.
Proof. Let v = argmaxw∈W(cid:104)w  θ(cid:105)  v(cid:48) = argmaxw∈W(cid:104)w  θ(cid:48)(cid:105). When Φ is differentiable at θ 
DΦ(θ(cid:48)  θ) = Φ(θ(cid:48)) − Φ(θ) − (cid:104)∇Φ(θ)  θ(cid:48)− θ(cid:105) = (cid:104)v(cid:48)  θ(cid:48)(cid:105)− (cid:104)v  θ(cid:105) − (cid:104)v  θ(cid:48)− θ(cid:105) = (cid:104)v(cid:48)− v  θ(cid:48)(cid:105) . (2)

Therefore  by Proposition 3.1  Rn =(cid:80)n

t=1 t(cid:104)wt+1 − wt  Θt(cid:105) =(cid:80)n

t=1 t DΦ(Θt  Θt−1).

When Φ is non-differentiable at some of the points Θ1  . . .   Θn  the equality in the above propo-
sition can be replaced with inequalities. Deﬁning the upper Bregman divergence DΦ(θ(cid:48)  θ) =
supw∈∂Φ(θ) Φ(θ(cid:48)) − Φ(θ) − (cid:104)w  θ(cid:48) − θ(cid:105) and the lower Bregman divergence DΦ(θ(cid:48)  θ) similarly with
inf instead of sup  similarly to Proposition 3.2  we obtain

n(cid:88)

t DΦ(Θt  Θt−1) ≤ Rn ≤ n(cid:88)

t DΦ(Θt  Θt−1) .

(3)

t=1

t=1

3.1 Constraint sets with positive curvature
The previous results shows in an implicit fashion that the curvature of W controls the regret. We now
present our ﬁrst main result that makes this connection explicit. Denote the boundary of W by bd(W).
For this result  we shall assume that W is C 2  that is  bd(W) is a twice continuously differentiable
submanifold of Rd. Recall that in this case the principal curvatures of W at w ∈ bd(W) are the
eigenvalues of ∇uW (w)  where uW : bd(W) → Sd−1  the so-called Gauss map  maps a boundary
point w ∈ bd(W) to the unique outer normal vector to W at w.3 As it is well known  ∇uW (w) is a
self-adjoint operator  with nonnegative eigenvalues  thus the principal curvatures are nonnegative.
Perhaps a more intuitive  yet equivalent deﬁnition  is that the principal eigenvalues are the eigenvalues
of the Hessian of f = fw in the parameterization t (cid:55)→ w + t− fw(t)uW (w) of bd(W) which is valid
in a small open neighborhood of w  where fw : TwW → [0 ∞) is a suitable convex  nonnegative
valued function that also satisﬁes fw(0) = 0 and where TwW  a hyperplane of Rd  denotes the
tangent space of W at w  obtained by taking the support plane H of W at w and shifting it by −w.
Thus  the principal curvatures at some point w ∈ bd(W) describe the local shape of bd(W) up to
the second order.
A related concept that has been used in convex optimization to show fast rates is that of a strongly
convex constraint set [Levitin and Polyak  1966  Garber and Hazan  2015]: W is λ-strongly convex

3Sd−1 =(cid:8)x ∈ Rd |(cid:107)x(cid:107)2 = 1(cid:9) denotes the unit sphere in d-dimensions. All differential geometry concept

and results that we need can be found in Section 2.5 of [Schneider  2014].

4

with respect to the norm (cid:107)·(cid:107) if  for any x  y ∈ W and γ ∈ [0  1]  the (cid:107)·(cid:107)-ball with origin γx+(1−γ)y
and radius γ(1 − γ)λ(cid:107)x − y(cid:107)2 /2 is included in W. One can show that a closed convex set W is
λ-strongly convex with respect to (cid:107)·(cid:107)2 if and only if the principal curvatures of the surface bdW are
all at least λ.
Our next result connects the principal curvatures of bd(W) to the regret of FTL and shows that FTL
enjoys logarithmic regret for highly curved surfaces  as long as (cid:107)Θt(cid:107)2 is bounded away from zero.
Theorem 3.3. Let W ⊂ Rd be a C 2 convex body with d ≥ 2.4 Let M = maxf∈F (cid:107)f(cid:107)2 and assume
that Φ is differentiable at (Θt)t. Assume that the principal curvatures of the surface bd(W) are all
at least λ0 for some constant λ0 > 0 and Ln := min1≤t≤n (cid:107)Θt(cid:107)2 > 0. Choose w1 ∈ bd(W). Then

Rn ≤ 2M 2
λ0Ln

(1 + log(n)) .

(cid:16) 2M 2
λ0L (1 + log(n)) + LW (cid:80)n

As we will show later in an essentially matching lower
bound  this bound is tight  showing that the forte of FTL is
when Ln is bounded away from zero and λ0 is large. Note
√
that the bound is vacuous as soon as Ln = O(log(n)/n)
√
and is worse than the minimax bound of O(
n) when
n). One possibility to reduce the
Ln = o(log(n)/
bound’s sensitivity to Ln is to use the trivial bound
(cid:104)wt+1 − wt  Θt(cid:105) ≤ LW = L supw w(cid:48)∈W (cid:107)w − w(cid:48)(cid:107)2 for
(cid:17)
indices t when (cid:107)Θt(cid:107) ≤ L. Then  by optimizing the bound
over L  one gets a data-dependent bound of the form
t=1 t I ((cid:107)Θt(cid:107) ≤ L)
 
inf L>0
which is more complex  but is free of Ln and thus reﬂects
the nature of FTL better. Note that in the case of stochastic
problems  where f1  . . .   fn are independent and identically
distributed (i.i.d.) with µ := −E [Θt] (cid:54)= 0  the probability
that (cid:107)Θt(cid:107)2 < (cid:107)µ(cid:107)2 /2 is exponentially small in t. Thus  selecting L = (cid:107)µ(cid:107)2 /2 in the previous
bound  the contribution of the expectation of the second term is O((cid:107)µ(cid:107)2 W )  giving an overall bound
log(n) + (cid:107)µ(cid:107)2 W ). After the proof we will provide some simple examples
of the form O( M 2
λ0(cid:107)µ(cid:107)2
that should make it more intuitive how the curvature of W helps keeping the regret of FTL small.
Proof. Fix θ1  θ2 ∈ Rd and let w(1) = argmaxw∈W(cid:104)w  θ1(cid:105)  w(2) = argmaxw∈W(cid:104)w  θ2(cid:105). Note that
if θ1  θ2 (cid:54)= 0 then w(1)  w(2) ∈ bd(W). Below we will show that

Figure 1: Illustration of the con-
struction used in the proof of (4).

(cid:104)w(1) − w(2)  θ1(cid:105) ≤ 1
2λ0

(4)
Proposition 3.1 suggests that it sufﬁces to bound (cid:104)wt+1 − wt  Θt(cid:105). By (4)  we see that it sufﬁces to
bound how much Θt moves. A straightforward calculation shows that Θt cannot move much:
Lemma 3.4. For any norm (cid:107)·(cid:107) on F  we have (cid:107)Θt − Θt−1(cid:107) ≤ 2
t M   where M = maxf∈F (cid:107)f(cid:107) is a
constant that depends on F and the norm (cid:107)·(cid:107).

(cid:107)θ2(cid:107)2

2

.

(cid:107)θ2 − θ1(cid:107)2

Combining inequality (4) with Proposition 3.1 and Lemma 3.4  we get
(cid:107)Θt − Θt−1(cid:107)2

2

Rn =

n(cid:88)

t=1

t(cid:104)wt+1 − wt  Θt(cid:105) ≤ n(cid:88)
n(cid:88)

t=1

1

≤ 2M 2
λ0Ln

≤ 2M 2
λ0

t(cid:107)Θt−1(cid:107)2

t=1

t
2λ0

n(cid:88)

t=1

(cid:107)Θt−1(cid:107)2
≤ 2M 2
λ0Ln

1
t

(1 + log(n)) .

To ﬁnish the proof  it thus remains to show (4).
The following elementary lemma relates the cosine of the angle between two vectors θ1 and θ2 to the
squared normalized distance between the two vectors  thereby reducing our problem to bounding the
cosine of this angle. For brevity  we denote by cos(θ1  θ2) the cosine of the angle between θ1 and θ2.

4Following Schneider [2014]  a convex body of Rd is any non-empty  compact  convex subset of Rd.

5

w(1)(cid:102)θ1w(2)(cid:102)θ2(cid:99)θ2Pγ(s)Lemma 3.5. For any non-zero vectors θ1  θ2 ∈ Rd 
1 − cos(θ1  θ2) ≤ 1
2

(cid:107)θ1 − θ2(cid:107)2
(cid:107)θ1(cid:107)2(cid:107)θ2(cid:107)2

2

.

(5)

(cid:105).
With this result  we see that it sufﬁces to upper bound cos(θ1  θ2) by 1 − λ0(cid:104)w(1) − w(2) 
θ1(cid:107)θ1(cid:107)2
To develop this bound  let ˜θi = θi(cid:107)θi(cid:107)2
for i = 1  2. The angle between θ1 and θ2 is the same as the
angle between the normalized vectors ˜θ1 and ˜θ2. To calculate the cosine of the angle between ˜θ1
and ˜θ2  let P be a plane spanned by ˜θ1 and w(1) − w(2) and passing through w(1) (P is uniquely
determined if ˜θ1 is not parallel to w(1) − w(2); if there are multiple planes  just pick any of them).
Further  let ˆθ2 ∈ Sd−1 be the unit vector along the projection of ˜θ2 onto the plane P   as indicated in
Fig. 1. Clearly  cos(˜θ1  ˜θ2) ≤ cos(˜θ1  ˆθ2).
Consider a curve γ(s) on bd(W) connecting w(1) and w(2) that is deﬁned by the intersection of
bd(W) and P and is parametrized by its curve length s so that γ(0) = w(1) and γ(l) = w(2)  where
l is the length of the curve γ between w(1) and w(2). Let uW (w) denote the outer normal vector to W
at w as before  and let uγ : [0  l] → Sd−1 be such that uγ(s) = ˆθ where ˆθ is the unit vector parallel
to the projection of uW (γ(s)) on the plane P . By deﬁnition  uγ(0) = ˜θ1 and uγ(l) = ˆθ2. Note that
in fact γ exists in two versions since W is a compact convex body  hence the intersection of P and
bd(W) is a closed curve. Of these two versions we choose the one that satisﬁes that (cid:104)γ(cid:48)(s)  ˜θ1(cid:105) ≤ 0
for s ∈ [0  l].5 Given the above  we have
cos(˜θ1  ˆθ2) = (cid:104)ˆθ2  ˜θ1(cid:105) = 1+ (cid:104)ˆθ2 − ˜θ1  ˜θ1(cid:105) = 1+
(cid:104)u(cid:48)
γ(s)  ˜θ1(cid:105) ds. (6)
Note that γ is a planar curve on bd(W)  thus its curvature λ(s) satisﬁes λ(s) ≥ λ0 for s ∈ [0  l].
Also  for any w on the curve γ  γ(cid:48)(s) is a unit vector parallel to P . Moreover  u(cid:48)
γ(s) is parallel to
γ(cid:48)(s) and λ(s) = (cid:107)u(cid:48)

u(cid:48)
γ(s) ds  ˜θ1

(cid:68)(cid:90) l

(cid:90) l

= 1+

(cid:69)

0

0

γ(s)(cid:107)2(cid:104)γ(cid:48)(s)  ˜θ1(cid:105) ≤ λ0(cid:104)γ(cid:48)(s)  ˜θ1(cid:105) 

where the last inequality holds because (cid:104)γ(cid:48)(s)  ˜θ1(cid:105) ≤ 0. Plugging this into (6)  we get the desired
cos(˜θ1  ˆθ2) ≤ 1 + λ0
= 1 − λ0(cid:104)w(1) − w(2)  ˜θ1(cid:105) .

(cid:104)γ(cid:48)(s)  ˜θ1(cid:105) ds = 1 + λ0

γ(cid:48)(s) ds  ˜θ1

(cid:69)

γ(s)(cid:107)2. Therefore 
γ(s)  ˜θ1(cid:105) = (cid:107)u(cid:48)
(cid:104)u(cid:48)
(cid:90) l

(cid:68)(cid:90) l
(cid:17) ≤ 1

0

λ0

Reordering and combining with (5) we obtain
1 − cos(˜θ1  ˆθ2)

(cid:104)w(1) − w(2)  ˜θ1(cid:105) ≤ 1
λ0

0

(cid:16)

(1 − cos(θ1  θ2)) ≤ 1
2λ0

(cid:107)θ1 − θ2(cid:107)2
(cid:107)θ1(cid:107)2(cid:107)θ2(cid:107)2

2

.

Multiplying both sides by (cid:107)θ1(cid:107)2 gives (4)  thus  ﬁnishing the proof.
Example 3.6. The smallest principal curvature of some common convex bodies are as follows:

• The smallest principal curvature λ0 of the Euclidean ball W = {w |(cid:107)w(cid:107)2 ≤ r} of radius r

• Let Q be a positive deﬁnite matrix. If W =(cid:8)w | w(cid:62)Qw ≤ 1(cid:9) then λ0 = λmin/

satisﬁes λ0 = 1
r .

λmax 

√

where λmin and λmax are the minimal  respectively  maximal eigenvalues of Q.

• In general  let φ : Rd → R be a C 2 convex function. Then  for W = {w | φ(w) ≤ 1} 

λ0 = minw∈bd(W) minv : (cid:107)v(cid:107)2=1 v⊥φ(cid:48)(w)

v(cid:62)∇2φ(w)v
(cid:107)φ(cid:48)(w)(cid:107)2

.

√
In the stochastic i.i.d. case  when E [Θt] = −µ  we have (cid:107)Θt + µ(cid:107)2 = O(1/
t) with high probability.
Thus say  for W being the unit ball of Rd  one has wt = Θt/(cid:107)Θt(cid:107)2; therefore  a crude bound suggests
that (cid:107)wt − w∗(cid:107)2 = O(1/
n)  while the previous result
predicts that Rn is much smaller. In the next example we look at the unit ball  to explain geometrically 
what “causes” the smaller regret.

t)  overall predicting that E [Rn] = O(

√

√

5γ(cid:48) and u(cid:48)

γ denote the derivatives of γ and u  respectively  which exist since W is C 2.

6

Example 3.7. Let W = {w |(cid:107)w(cid:107)2 ≤ 1} and consider a stochastic setting where the fi are i.i.d.
samples from some underlying distribution with expectation E [fi] = µ = (−1  0  . . .   0) and
(cid:107)fi(cid:107)∞ ≤ M. It is straightforward to see that w∗ = (1  0  . . .   0)  and thus (cid:104)w∗  µ(cid:105) = −1. Let
E = {−θ |(cid:107)θ − µ(cid:107)2 ≤ }. As suggested beforehand  we expect −µt ∈ E with high probability. As
OD(cid:105) − 1 = | ˜BD|. Similarly  the excess
shown in Fig. 2  the excess loss of an estimate # »
OA(cid:48) in the ﬁgure is |CD|. Therefore  for an estimate −µt ∈ E  the point A is
loss of an estimate # »
where the largest excess loss is incurred. The triangle OAD is similar to the triangle ADB. Thus
|BD|
|AD|
|OD| . Therefore  |BD| = 2 and since | ˜BD| ≤ |BD|  if (cid:107)µt − µ(cid:107)2 ≤   the excess error is
|AD| =
at most 2 = O(1/t)  making the regret Rn = O(log n).

OA is (cid:104) # »
O ˜A 

# »

Our last result in this section is an asymptotic lower bound for
the linear game  showing that FTL achieves the optimal rate
under the condition that mint (cid:107)Θt(cid:107)2 ≥ L > 0.
Theorem 3.8. Let h  L
(0  1).
that {(1 −L)  (−1 −L)}

(cid:8)(x  y) : x2 + y2/h2 ≤ 1(cid:9) be an ellipsoid with princi-

Assume
F and let W =

pal curvature h. Then  for any learning strategy  there exists a
sequence of losses in F such that Rn = Ω (log(n)/(Lh)) and
(cid:107)Θt(cid:107)2 ≥ L for all t.

⊂

∈

3.2 Other regularities

So far we have looked at the case when FTL achieves a low
regret due to the curvature of bd(W). The next result char-
acterizes the regret of FTL when W is a polyhedron  which
has a ﬂat  non-smooth boundary and thus Theorem 3.3 is not
applicable. For this statement recall that given some norm (cid:107) · (cid:107) 
its dual norm is deﬁned by (cid:107)w(cid:107)∗ = sup(cid:107)v(cid:107)≤1(cid:104)v  w(cid:105).
Theorem 3.9. Assume that W is a polyhedron and that Φ is differentiable at Θi  i = 1  . . .   n.
Let wt = argmaxw∈W(cid:104)w  Θt−1(cid:105)  W = supw1 w2∈W (cid:107)w1 − w2(cid:107)∗ and F = supf1 f2∈F (cid:107)f1 − f2(cid:107).
Then the regret of FTL is
Rn ≤ W

Figure 2: Illustration of how
curvature helps to keep the re-
gret small.

t I(wt+1 (cid:54)= wt)(cid:107)Θt − Θt−1(cid:107) ≤ F W

I(wt+1 (cid:54)= wt) .

n(cid:88)

n(cid:88)

t=1

t=1

Note that when W is a polyhedron  wt is expected to “snap” to some vertex of W. Hence  we expect
the regret bound to be non-vacuous  if  e.g.  Θt “stabilizes” around some value. Some examples after
the proof will illustrate this.
Proof. Let v = argmaxw∈W(cid:104)w  θ(cid:105)  v(cid:48) = argmaxw∈W(cid:104)w  θ(cid:48)(cid:105). Similarly to the proof of Theorem 3.3 

(cid:104)v(cid:48) − v  θ(cid:48)(cid:105) = (cid:104)v(cid:48)  θ(cid:48)(cid:105) − (cid:104)v(cid:48)  θ(cid:105) + (cid:104)v(cid:48)  θ(cid:105) − (cid:104)v  θ(cid:105) + (cid:104)v  θ(cid:105) − (cid:104)v  θ(cid:48)(cid:105)

≤ (cid:104)v(cid:48)  θ(cid:48)(cid:105) − (cid:104)v(cid:48)  θ(cid:105) + (cid:104)v  θ(cid:105) − (cid:104)v  θ(cid:48)(cid:105) = (cid:104)v(cid:48) − v  θ(cid:48) − θ(cid:105) ≤ W I(v(cid:48) (cid:54)= v)(cid:107)θ(cid:48) − θ(cid:107) 

where the ﬁrst inequality holds because (cid:104)v(cid:48)  θ(cid:105) ≤ (cid:104)v  θ(cid:105). Therefore  by Lemma 3.4 

n(cid:88)

n(cid:88)

n(cid:88)

Rn =

t(cid:104)wt+1 − wt  Θt(cid:105) ≤ W

t I(wt+1(cid:54)= wt)(cid:107)Θt − Θt−1(cid:107) ≤ F W

I(wt+1(cid:54)= wt) .

t=1

t=1

t=1

As noted before  since W is a polyhedron  wt is (generally) attained at the vertices. In this case  the
epigraph of Φ is a polyhedral cone. Then  the event when wt+1 (cid:54)= wt  i.e.  when the “leader” switches
corresponds to when Θt and Θt−1 belong to different linear regions corresponding to different linear
pieces of the graph of Φ.
We now spell out a corollary for the stochastic setting. In particular  in this case FTL will often enjoy
a constant regret:

7

OD=w∗A=−µtB˜B˜A=(cid:100)wtCA(cid:48)˜A(cid:48)=−µCorollary 3.10 (Stochastic setting). Assume that (ft)1≤t≤n is an i.i.d. sequence of random variables
such that E [fi] = µ and (cid:107)fi(cid:107)∞ ≤ M. Let W = supw1 w2∈W (cid:107)w1 − w2(cid:107)1. Further assume that
there exists a constant r > 0 such that Φ is differentiable for any ν such that (cid:107)ν − µ(cid:107)∞ ≤ r. Then 

E [Rn] ≤ 2M W (1 + 4dM 2/r2) .

Proof. Let V = {ν |(cid:107)ν − µ(cid:107)∞ ≤ r}. Note that the epigraph of the function Φ is a polyhedral cone.
Since Φ is differentiable in V   {(θ  Φ(θ))| θ ∈ V } is a subset of a linear subspace. Therefore  for
−Θt −Θt−1 ∈ V   wt+1 = wt. Hence  by Theorem 3.9 

(cid:32)

n(cid:88)

(cid:33)

On the other hand  note that (cid:107)fi(cid:107)∞ ≤ M. Then

t=1

E [Rn] ≤ 2M W

n(cid:88)
(cid:32)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) 1
t=1 exp(−αt) ≤(cid:82) n
(cid:80)n

Pr(−Θt /∈ V ) = Pr

t

t(cid:88)

i=1

Pr(−Θt −Θt−1 /∈ V ) ≤ 4M W

1 +

Pr(−Θt /∈ V )

.

(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)∞

(cid:33)

≤ d(cid:88)

j=1

Pr

(cid:32)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) 1

t

t(cid:88)

i=1

t=1

fi j − µj

(cid:33)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≥ r

≤ 2de

− tr2

2M 2  

fi − µ

≥ r

where the last inequality is due to Hoeffding’s inequality. Now  using that for α > 0 

0 exp(−αt)dt ≤ 1

α  we get E [Rn] ≤ 2M W (1 + 4dM 2/r2).

The condition that Φ is differentiable for any ν such that (cid:107)ν − µ(cid:107)∞ ≤ r is equivalent to that Φ is
differentiable at µ. By Proposition 2.1  this condition requires that at µ  maxw∈W(cid:104)w  θ(cid:105) has a unique
optimizer. Note that the volume of the set of vectors θ with multiple optimizers is zero.

4 An adaptive algorithm for the linear game

While as shown in Theorem 3.3  FTL can exploit the curvature of the surface of the constraint set
to achieve O(log n) regret  it requires the curvature condition and mint (cid:107)Θt(cid:107)2 ≥ L being bounded
√
away from zero  or it may suffer even linear regret. On the other hand  many algorithms  such as the
"Follow the regularized leader" (FTRL) algorithm  are known to achieve a regret guarantee of O(
n)
even for the worst-case data in the linear setting. This raises the question whether one can have an
algorithm that can achieve constant or O(log n) regret in the respective settings of Corollary 3.10
or Theorem 3.3  while it still maintains O(
n) regret for worst-case data. One way to design an
adaptive algorithm is to use the (A  B)-prod algorithm of Sani et al. [2014]  leading to the following
result:
Proposition 4.1. Consider (A  B)-prod of Sani et al. [2014]  where algorithm A is chosen to be
FTRL with an appropriate regularization term  while B is chosen to be FTL. Then the regret of the
resulting hybrid algorithm H enjoys the following guarantees:

√

• If FTL achieves constant regret as in the setting of Corollary 3.10  then the regret of H is

also constant.

• If FTL achieves a regret of O(log n) as in the setting of Theorem 3.3  then the regret of H is

also O(log n).

√
• Otherwise  the regret of H is at most O(

n log n).

5 Conclusion

FTL is a simple method that is known to perform well in many settings  while existing worst-case
results fail to explain its good performance. While taking a thorough look at why and when FTL can
be expected to achieve small regret  we discovered that the curvature of the boundary of the constraint
and having average loss vectors bounded away from zero help keep the regret of FTL small. These
conditions are signiﬁcantly different from previous conditions on the curvature of the loss functions
which have been considered extensively in the literature. It would be interesting to further investigate
this phenomenon for other algorithms or in other learning settings.

8

Acknowledgements

This work was supported in part by the Alberta Innovates Technology Futures through the Alberta
Ingenuity Centre for Machine Learning and by NSERC. During part of this work  T. Lattimore was
with the Department of Computing Science  University of Alberta.

References
Y. Abbasi-Yadkori. Forced-exploration based algorithms for playing in bandits with large action sets. Library

and Archives Canada  2010.

J. Abernethy  P.L. Bartlett  A. Rakhlin  and A. Tewari. Optimal strategies and minimax lower bounds for online

convex games. In 21st Annual Conference on Learning Theory (COLT)  2008.

P.L. Bartlett  E. Hazan  and A. Rakhlin. Adaptive online gradient descent. In Advances in Neural Information

Processing Systems (NIPS)  pages 65–72  2007.

D. Bertsekas. Nonlinear Programming. Athena Scientiﬁc  Belmont  MA  1999.
N. Cesa-Bianchi and G. Lugosi. Prediction  Learning  and Games. Cambridge University Press  New York  NY 

USA  2006.

N. Cesa-Bianchi  A. Conconi  and C. Gentile. On the generalization ability of on-line learning algorithms. IEEE

Trans. Information Theory  50(9):2050–2057  2004.

D.J. Foster  A. Rakhlin  and K. Sridharan. Adaptive online learning. In Advances in Neural Information

Processing Systems (NIPS)  pages 3357–3365  2015.

Y. Freund and R. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting.

Journal of Computer and System Sciences  55:119–139  1997.

A.A. Gaivoronski and F. Stella. Stochastic nonstationary optimization for ﬁnding universal portfolios. Annals of

Operations Research  100(1–4):165–188  2000.

D. Garber and E. Hazan. Faster rates for the frank-wolfe method over strongly-convex sets. In Proceedings of

the 32nd International Conference on Machine Learning (ICML)  volume 951  pages 541–549  2015.

E. Hazan  A. Agarwal  and S. Kale. Logarithmic regret algorithms for online convex optimization. Machine

Learning  69(2-3):169–192  2007.

R. Huang  T. Lattimore  A. György  and Cs. Szepesvári. Following the leader and fast rates in linear prediction:

Curved constraint sets and other regularities. arXiv  2016.

S. M. Kakade and S. Shalev-Shwartz. Mind the duality gap: Logarithmic regret algorithms for online optimization.

In Advances in Neural Information Processing Systems (NIPS)  pages 1457–1464  2009.

W. Kotłowski. Minimax strategy for prediction with expert advice under stochastic assumptions. Algorithmic

Learning Theory (ALT)  2016.

E.S. Levitin and B.T. Polyak. Constrained minimization methods. USSR Computational Mathematics and

Mathematical Physics  6(5):1–50  1966.

H.B. McMahan. Follow-the-regularized-leader and mirror descent: Equivalence theorems and implicit updates.

arXiv  2010. URL http://arxiv.org/abs/1009.3240.

N. Merhav and M. Feder. Universal sequential learning and decision from individual data sequences. In 5th

Annual ACM Workshop on Computational Learning Theory (COLT)  pages 413—427. ACM Press  1992.

F. Orabona  N. Cesa-Bianchi  and C. Gentile. Beyond logarithmic bounds in online learning. In Proceedings of
the Fifteenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS)  pages 823–831 
2012.

A. Rakhlin and K. Sridharan. Online learning with predictable sequences. In 26th Annual Conference on

Learning Theory (COLT)  pages 993–1019  2013.

A. Sani  G. Neu  and A. Lazaric. Exploiting easy data in online optimization. In Advances in Neural Information

Processing Systems (NIPS)  pages 810–818  2014.

R. Schneider. Convex Bodies: The Brunn–Minkowski Theory. Encyclopedia of Mathematics and its Applications.

Cambridge Univ. Press  2nd edition  2014.

S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and trends in Machine

Learning  4(2):107–194  2012.

S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge

University Press  New York  NY  USA  2014.

T. van Erven  P. Grünwald  N. Mehta  M. Reid  and R. Williamson. Fast rates in statistical and online learning.
Journal of Machine Learning Research (JMLR)  16:1793–1861  2015. Special issue in Memory of Alexey
Chervonenkis.

9

,Ruitong Huang
Tor Lattimore
András György
Csaba Szepesvari
Charles Marx
Richard Phillips
Sorelle Friedler
Carlos Scheidegger
Suresh Venkatasubramanian