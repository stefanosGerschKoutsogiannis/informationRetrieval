2008,On the Efficient Minimization of Classification Calibrated Surrogates,Bartlett et al (2006) recently proved that a ground condition for convex surrogates  classification calibration  ties up the minimization of the surrogates and classification risks  and left as an important problem the algorithmic questions about the minimization of these surrogates. In this paper  we propose an algorithm which provably minimizes any classification calibrated surrogate strictly convex and differentiable --- a set whose losses span the exponential  logistic and squared losses ---  with boosting-type guaranteed convergence rates under a weak learning assumption. A particular subclass of these surrogates  that we call balanced convex surrogates  has a key rationale that ties it to maximum likelihood estimation  zero-sum games and the set of losses that satisfy some of the most common requirements for losses in supervised learning. We report experiments on more than 50 readily available domains of 11 flavors of the algorithm  that shed light on new surrogates  and the potential of data dependent strategies to tune surrogates.,On the Efﬁcient Minimization of Classiﬁcation

Calibrated Surrogates

Richard Nock

CEREGMIA — Univ. Antilles-Guyane

97275 Schoelcher Cedex  Martinique  France

Frank Nielsen

LIX - Ecole Polytechnique

91128 Palaiseau Cedex  France

rnock@martinique.univ-ag.fr

nielsen@lix.polytechnique.fr

Abstract

Bartlett et al (2006) recently proved that a ground condition for convex surrogates 
classiﬁcation calibration  ties up the minimization of the surrogates and classiﬁ-
cation risks  and left as an important problem the algorithmic questions about the
minimization of these surrogates. In this paper  we propose an algorithm which
provably minimizes any classiﬁcation calibrated surrogate strictly convex and dif-
ferentiable — a set whose losses span the exponential  logistic and squared losses
—  with boosting-type guaranteed convergence rates under a weak learning as-
sumption. A particular subclass of these surrogates  that we call balanced convex
surrogates  has a key rationale that ties it to maximum likelihood estimation  zero-
sum games and the set of losses that satisfy some of the most common require-
ments for losses in supervised learning. We report experiments on more than 50
readily available domains of 11 ﬂavors of the algorithm  that shed light on new
surrogates  and the potential of data dependent strategies to tune surrogates.

1 Introduction

A very active supervised learning trend has been ﬂourishing over the last decade: it studies functions
known as surrogates — upperbounds of the empirical risk  generally with particular convexity prop-
erties —  whose minimization remarkably impacts on empirical / true risks minimization [3  4  10].
Surrogates play fundamental roles in some of the most successful supervised learning algorithms 
including AdaBoost  additive logistic regression  decision tree induction  Support Vector Machines
[13  7  10]. As their popularity has been rapidly spreading  authors have begun to stress the need to
set in order the huge set of surrogates  and better understand their properties. Statistical consistency
properties have been shown for a wide set containing most of the surrogates relevant to learning 
classiﬁcation calibrated surrogates (CCS) [3]; other important properties  like the algorithmic ques-
tions about minimization  have been explicitly left as important problems to settle [3].

In this paper  we address and solve this problem for all strictly convex differentiable CCS  a set
referred to as strictly convex surrogates (SCS). We propose a minimization algorithm  ULS  which
outputs linear separators  with two key properties: it provably achieves the optimum of the surrogate 
and meets Boosting-type convergence under a weak learning assumption. There is more  as we
show that SCS strictly contains another set of surrogates of important rationale  balanced convex
surrogates (BCS). This set  which contains the logistic and squared losses but not the exponential
loss  coincides with the set of losses satisfying three common requirements about losses in learning.
In fact  BCS spans a large subset of the expected losses for zero-sum games of [9]  by which ULS may
also be viewed as an efﬁcient learner for decision making (in simple environments  though).

Section 2 gives preliminary deﬁnitions; section 3 presents surrogates losses and risks; sections 4 and
5 present ULS and its properties; section 6 discusses experiments with ULS; section 7 concludes.

2 Preliminary deﬁnitions

Unless otherwise stated  bold-faced variables like w denote vectors (components are wi  i =
1  2  ...)  calligraphic upper-cases like S denote sets  and blackboard faces like O denote subsets
of R  the set of real numbers. We let set O denote a domain (Rn  [0  1]n  etc.  where n is the
number of description variables)  whose elements are observations. An example is an ordered pair
(o  c) ∈ O × {c−  c+}  where {c−  c+} denotes the set of classes (or labels)  and c+ (resp. c−) is
the positive class (resp. negative class). Classes are abstracted by a bijective mapping to one of two
other sets:

c ∈ {c−  c+} (cid:11) y∗ ∈ {−1  +1} (cid:11) y ∈ {0  1} .

(1)
The convention is c+ (cid:10) +1 (cid:10) 1 and c− (cid:10) −1 (cid:10) 0. We thus have three distinct notations for an
example: (o  c)  (o  y∗)  (o  y)  that shall be used without ambiguity. We suppose given a set of m
examples  S = {(oi  ci)  i = 1  2  ...  m}. We wish to build a classiﬁer H  which can either be a
function H : O → O ⊆ R (hereafter  O is assumed to be symmetric with respect to 0)  or a function
H : O → [0  1]. Following a convention of [6]  we compute to which extent the outputs of H and
the labels in S disagree  ε(S  H)  by summing a loss which quantiﬁes pointwise disagreements:

ε(S  H)

.= (cid:88)

i

(cid:96)(ci  H(oi)) .

(2)

The fundamental loss is the 0/1 loss  (cid:96)0/1(c  H) (to ease readability  the second argument is written
H instead of H(o)). It takes on two forms depending on im(H):

[0 1](y  H) .= 1y(cid:54)=τ ◦H if im(H) = [0  1] .

R (y∗  H) .= 1y∗(cid:54)=σ◦H if im(H) = O   or (cid:96)0/1
(cid:96)0/1

(3)
The following notations are introduced in (3): for a clear distinction of the output of H  we put in
index to (cid:96) and ε an indication of the loss’ domain of parameters: R  meaning it is actually some
O ⊆ R  or [0  1]. The exponent to (cid:96) gives the indication of the loss name. Finally  1π is the indicator
variable that takes value 1 iff predicate π is true  and 0 otherwise; σ : R → {−1  +1} is +1 iff
x ≥ 0 and −1 otherwise; τ : [0  1] → {0  1} is 1 iff x ≥ 1/2  and 0 otherwise.
Both losses (cid:96)R and (cid:96)[0 1] are deﬁned simultaneously via popular transforms on H  such as the logit
transform logit(p) .= log(p/(1 − p)) ∀p ∈ [0  1] [7]. We have indeed (cid:96)0/1
R (y∗  logit(H))
and (cid:96)0/1
[0 1](y  logit−1(H)). We have implicitly closed the domain of the logit  adding
two symbols ±∞ to ensure that the eventual inﬁnite values for H can be mapped back to [0  1].
In supervised learning  the objective is to carry out the minimization of the expectation of the 0/1
loss in generalization  the so-called true risk. Very often however  this task can be relaxed to the
minimization of the empirical risk of H  which is (2) with the 0/1 loss [6]:

[0 1](y  H) = (cid:96)0/1

R (y∗  H) = (cid:96)0/1

ε0/1(S  H)

.= (cid:88)

(cid:96)0/1(ci  H(oi)) .

i

(4)

The main classiﬁers we investigate are linear separators (LS). In this case  H(o) .= (cid:80)t αtht(o) for
features ht with im(ht) ⊆ R and leveraging coefﬁcients αt ∈ R.
3 Losses and surrogates

A serious alternative to directly minimizing (4) is to rather focus on the minimization of a sur-
rogate risk [3]. This is a function ε(S  H) as in (2) whose surrogate loss (cid:96)(c  H(o)) satisﬁes
(cid:96)0/1(c  H(o)) ≤ (cid:96)(c  H(o)). Four are particularly important in supervised learning  deﬁned via
the following surrogate losses:
(5)
(6)
(7)
(8)

.= exp(−y∗H)  
.= log(1 + exp(−y∗H))  
.= (1 − y∗H)2  
.= max{0  1 − y∗H} .

(cid:96)exp
R (y∗  H)
(cid:96)log
R (y∗  H)
(cid:96)sqr
R (y∗  H)
(cid:96)hinge
R (y∗  H)

(5) is the exponential loss  (6) is the logistic loss  (7) is the squared loss and (8) is hinge loss.
Deﬁnition 1 A Strictly Convex Loss (SCL) is a strictly convex function ψ : X → R+ differentiable
on int(X) with X symmetric interval with respect to zero  s. t. ∇ψ(0) < 0.

aφ im(∇φ)

⊇ im(H) = (φ

(cid:63)

Fφ(y∗H)
(−y∗H) − aφ)/bφ
−y∗H+√(1−µ)2+(y∗H)2

φ

(H)

ˆPr[c = c+|H; o]

= ∇−1
1
2√(1−µ)2+H 2
2 +
1
2 +

H

H

R

φµ µ∈(0 1)(x) .= µ + (1 − µ)px(1 − x) µ
φM(x) .= px(1 − x)
0
φQ(x) .= −x log x − (1 − x) log(1 − x) 0
φB(x) .= x(1 − x)
0
Table 1: permissible functions  their corresponding BCLs and the matching [0  1] predictions.

−y∗H + p1 + (y∗H)2
log(1 + exp(−y ∗H))

(1 − y ∗H)2

2√1+H 2

[−1  1]

2 + H

1+exp(H)

exp(H)

1−µ

R

R

1

2

∇. is the gradient notation (here  the derivative). Any surrogate risk built from a SCL is called a
Strictly Convex Surrogate (SCS). From Theorem 4 in [3]  it comes that SCL contains all classiﬁcation
calibrated losses (CCL) that are strictly convex and differentiable  such as (5)  (6)  (7).
.= supx(cid:48)∈int(X){xx(cid:48) − ψ(x(cid:48))}. Be-
Fix ψ ∈ SCL. The Legendre conjugate ψ(cid:63) of ψ is ψ(cid:63)(x)
cause of the strict convexity of ψ  the analytic expression of the Legendre conjugate becomes
ψ (x)). ψ(cid:63) is also strictly convex and differentiable. A function
ψ(cid:63)(x)
φ : [0  1] → R+ is called permissible iff it is differentiable on (0  1)  strictly concave  symmet-
.= φ(1/2) − aφ > 0. Permissible
ric about x = 1/2  and with φ(0) = φ(1) = aφ ≥ 0. We let bφ
functions with aφ = 0 span a very large subset of generalized entropies [9]. Permissible func-
tions are useful to deﬁne the following subclass of SCL  of particular interest (here  φ .= −φ).

ψ (x) − ψ(∇−1

.= x∇−1

φ(x)

 12

 10

 8

 6

 4

 2

 0

(f = f
B)
(f = f
M)
m = 1/3 )
(f = f
Q)

(f = f

Deﬁnition 2 Let φ permissible.
(BCL) with signature φ  Fφ  is:
.= (φ

Fφ(x)

(cid:63)

The Balanced Convex Loss

(−x) − aφ)/bφ .

(9)

-3

-2

-1

 0

 1

 2

 3

Balanced Convex Surrogates (BCS) are deﬁned accordingly. All
(x) satisﬁes the following
BCL share a common shape. Indeed  φ
relationships:

(cid:63)

(cid:63)
φ
(cid:63)
φ

(x) = φ

(cid:63)

(10)
(11)

(−x) + x  

(cid:63)

φ

lim

x→infim(∇φ)

(x) = aφ .

Figure 1: Bold curves depict plots
of φ
(−x) for the φ in Table 1; thin
dotted half-lines are its asymptotes.
Noting that Fφ(0) = 1 and ∇Fφ (0) = −(1/bφ)∇−1
(0) < 0  it follows that BCS ⊂ SCS 
It also follows
where the strict inequality comes from the fact that (5) is a SCL but not a BCL.
limx→supim(∇φ) Fφ(x) = 0 from (11)  and limx→infim(∇φ) Fφ(x) = −x/bφ from (10). We get that
the asymptotes of any BCL can be summarized as (cid:96)(x) .= x(σ(x) − 1)/(2bφ). When bφ = 1  this is
the linear hinge loss [8]  a generalization of (8) for which x .= y∗H − 1. Thus  while hinge loss is
not a BCL  it is the limit behavior of any BCL (see Figure 1).
Table 1 (left column) gives some examples of permissible φ. When scaled so that φ(1/2) = 1 
some confound with popular choices: φB with Gini index  φQ with the Bit-entropy  and φM with
Matsushita’s error [10  11]. Table 1 also gives the expressions of Fφ along with the im(H) = O ⊆ R
allowed by the BCL  for the corresponding permissible function. It is interesting to note the constraint
on im(H) for the squared loss to be a BCL  which makes it monotonous in the interval  but implies
to rescale the outputs of classiﬁers like linear separators to remain in [−1  1].
4 ULS: the efﬁcient minimization of any SCS

For any strictly convex function ψ : X → R differentiable on int(X)  the Bregman Loss Function
(BLF) Dψ with generator ψ is [5]:
Dψ(x||x(cid:48))
(12)

.= ψ(x) − ψ(x(cid:48)) − (x − x(cid:48))∇ψ(x(cid:48)) .

The following Lemma states some relationships that are easy to check using ψ (cid:63)(cid:63) = ψ. They are
particularly interesting when im(H) = O ⊆ R.

Algorithm 1: Algorithm ULS(M  ψ)
Input: M ∈ Rm×T   SCL ψ with dom(ψ) = R;
Let α1 ← 0; Let w0 ← ∇−1
for j = 1  2  ...J do

(0)1;

˜ψ

[WU] (weight update) wj ← (M αj) (cid:5) w0 ;
Let Tj ⊆ {1  2  ...  T}; let δj ← 0;
[LC] (leveraging coefﬁcients) ∀t ∈ Tj  pick δj t such that: (cid:80)m
Let αj+1 ← αj + δj;

Output: H(x) .= (cid:80)T

t=1 αJ+1 tht(x) ∈ LS

i=1 mit((M δj) (cid:5) wj)i = 0 ;

φ

(H)) = bφFφ(y∗H) and Dφ(y||∇−1

ψ(cid:63) (y∗H))− ψ(cid:63)(0). Furthermore  for any BCL Fφ 
(H)) = Dφ(1||∇−1

Lemma 1 For any SCL ψ  ψ(y∗H) = Dψ(cid:63) (0||∇−1
Dφ(y||∇−1
The second equality is important because it ties real predictions (right) with [0  1] predictions (left).
It also separates SCL and BCL  as for any ψ in SCL  it can be shown that there exists a functions ϕ
ϕ (H)) = ψ(y∗H) iff ψ ∈ BCL. We now focus on the minimization of any SCS.
such that Dϕ(y||∇−1
We show that there exists an algorithm  ULS  which ﬁts a linear separator H to the minimization
of any SCS εψ
i H(oi)) for any SCL ψ with dom(ψ) = R  in order not to restrict the LS
built. To simplify notations  we let:

.= (cid:80)i ψ(y∗

(y∗H)).

φ

φ

R

.= ψ(cid:63)(−x) .
With this notation  the ﬁrst equality in Lemma 1 becomes:

˜ψ(x)

(13)

˜ψ

ψ (−x).

(−y∗H)) − ˜ψ(0) .

ψ(y∗H) = D ˜ψ(0||∇−1

(14)
.= dom(∇ ˜ψ) = −im(∇ψ)  where this latter equality comes from ∇ ˜ψ(x) =
We let W
−∇ψ(cid:63) (−x) = −∇−1
It also comes im(∇ ˜ψ) = R. Because any BLF is strictly convex
in its ﬁrst argument  we can compute its Legendre conjugate. In fact  we shall essentially need the
argument that realizes the supremum: for any x ∈ R  for any p ∈ W  we let:

(15)
We do not make reference to ˜ψ in the (cid:5) notation  as it shall be clear from context. We name x (cid:5) p
the Legendre dual of the ordered pair (x  p)  closely following a notation by [6]. The Legendre dual
is unique and satisﬁes:

.= argp(cid:48)∈W sup{xp(cid:48) − D ˜ψ(p(cid:48)||p)} .

x (cid:5) p

∇ ˜ψ(x (cid:5) p) = x + ∇ ˜ψ(p)  
∀x  x(cid:48) ∈ R ∀p ∈ W  x (cid:5) (x(cid:48) (cid:5) p) = (x + x(cid:48)) (cid:5) p .

(16)
(17)
To state ULS  we follow the setting of [6] and suppose that we have T features ht (t = 1  2  ...  T )
known in advance  the problem thus reducing to the computation of the leveraging coefﬁcients. We
deﬁne m × T matrix M with:

.= −y∗
Given leveraging coefﬁcients vector α ∈ RT   we get:

mit

i ht(oi) .

−y∗

i H(oi) = (M α)i .

(18)

(19)

We can specialize this setting to classical greedy induction frameworks for LS: in classical boosting 
at step j  we would ﬁt a single αt [6]; in totally corrective boosting  we would rather ﬁt {αt  1 ≤ t ≤
j} [14]. Intermediate schemes may be used as well forTj  provided they ensure that  at each step j of
the algorithm and for any feature ht  it may be chosen at some j(cid:48) > j. ULS is displayed in Algorithm
1. In Algorithm 1  notations are vector-based: the Legendre duals are computed component-wise;
furthermore  Tj may be chosen according to whichever scheme underlined above. The following
Theorem provides a ﬁrst general convergence property for ULS.

Theorem 1 ULS(M  ψ) converges to a classiﬁer H realizing the minimum of εψ
R.

Proof sketch:
In step [WU] in ULS  (17) brings wj+1 = (M αj+1) (cid:5) w0 = (M δj) (cid:5) wj. After
few derivations involving the choice of δj and step [LC] in ULS  we obtain (with vector notations 
BLFs are the sum of the component-wise BLFs):

D ˜ψ(0||wj+1) − D ˜ψ(0||wj) = −D ˜ψ(wj+1||wj)

(20)
Let A ˜ψ(wj+1  wj) .= −D ˜ψ(wj+1||wj)  which is just  from (20) and (14)  the difference between
two successive SCL in Algorithm 1. Thus  A ˜ψ(wj+1  wj) < 0 whenever wj+1 (cid:54)= wj. Should we
be able to prove that when ULS has converged  w. ∈ KerM (cid:62)  this would make A ˜ψ(wj+1  wj) an
auxiliary function for ULS  which is enough to prove the convergence of ULS towards the optimum
[6]. Thus  suppose that wj+1 = wj (ULS has converged). Suppose that Tj is a singleton (e.g.
classical boosting scheme). In this case  δj = 0 and so ∀t = 1  2  ...  T  (cid:80)m
i=1 mit(0 (cid:5) wj)i =
(cid:80)m
j+1M = 0(cid:62)  and wj  wj+1 ∈ KerM (cid:62). The case of totally
corrective boosting is simpler  as after the last iteration we would have wJ+1 ∈ KerM (cid:62). Interme-
diate choices for Tj ⊂ {1  2  ...  T} are handled in the same way.
We emphasize the fact that Theorem 1 proves the convergence towards the global optimum of εψ
R 
regardless of ψ. The optimum is deﬁned by the LS with features in M that realizes the smallest
εψ
R. Notice that in practice  it may be a tedious task to satisfy exactly (20)  in particular for totally
corrective boosting [14].

i=1 mitwj i = 0  i.e. w(cid:62)

j M = w(cid:62)

ULS has the ﬂavor of boosting algorithms  repeatedly modifying a set of weights w over the exam-
ples. In fact  this similarity is more than syntactical  as ULS satisﬁes two ﬁrst popular algorithmic
boosting properties  the ﬁrst of which being that step [LC] in ULS is equivalent to saying that this
LS has zero edge on wj+1 [14]. The following Lemma shows that this edge conditions is sound.
Lemma 2 Suppose that there does not exist some ht with all mit of the same sign  ∀i = 1  2  ...  m.
Then  for any choice of Tj  step [LC] in ULS has always a ﬁnite solution.
Proof: Let:

Z .= D ˜ψ(0||(M αj+1) (cid:5) w0) .
(21)
˜ψ(−(M (δj + αj))i) from (14)  a function convex in all leveraging
We have Z = m ˜ψ(0) + (cid:80)m
.= ∂2Z/(∂δj uδj v) (for the sake of simplicity 
coefﬁcients. Deﬁne |Tj| × |Tj| matrix E with euv
Tj = {1  2  ... |Tj|}  where |.| denotes the cardinal). We have euv = (cid:80)m
i=1 miumiv/ϕ(((M δj) (cid:5)
wj)i)  with ϕ(x) .= d2 ˜ψ(x)/dx2 a function strictly positive in int(W) since ˜ψ is strictly convex.
.= 1/ϕ(((M δj)(cid:5)wj)i) > 0. It is easy to show that x(cid:62)Ex = (cid:80)m
Let qi j
i=1 qi j(cid:104)x  ˜mi(cid:105)2 ≥ 0 ∀x ∈
.= mit. Thus  E is positive semideﬁnite; as such  step
R|Tj |  with ˜mi ∈ R|Tj | the vector with ˜mit
[LC] in ULS  which is the same as solving ∂Z/∂δj u = 0  ∀u ∈ Tj (i.e. minimizing Z) has always
a solution.
The condition for the Lemma to work is absolutely not restrictive  as if such an ht were to exist  we
would not need to run ULS: indeed  we would have either ε0/1(S  ht) = 0  or ε0/1(S −ht) = 0. The
second property met by ULS is illustrated in the second example below.

i=1

We give two examples of specializations of ULS. Take for exam-
ple ψ(x) = exp(−x) (5). In this case  W = R+  w0 = 1 and it is
not hard to see that ULS matches real AdaBoost with unnormal-
ized weights [13]. The difference is syntactical: the LS output
by ULS and real AdaBoost are the same. Now  take any BCL. In
this case  ˜ψ = φ  W = [0  1] (scaling issues underlined for the
logit in Section 2 make it desirable to close W)  and w0 = 1/21.
In all these cases  where W ⊆ R+  wj is always a distribution
up to a normalization factor  and this would also be the case for
any strictly monotonous SCS ψ. The BCL case brings an appeal-
ing display of how the weights behave. Figure 2 displays a typ-
ical Legendre dual for a BCL. Consider example (oi  yi)  and its
i H(oi)) (cid:5) w0 i for
weight update  wj i ← (M αj)i (cid:5) w0 i = (−y∗
i H(oi) in Fig-
the current classiﬁer H. Fix p = w0 i and x = −y∗
ure 2. We see that the new weight of the example gets larger iff
x > 0  i.e. iff the example is given the wrong class by H  which

x

1
x (cid:5) p

1/2

p

0

∇

φ

Figure 2: A typical ∇φ (red:
strictly increasing  symmetric wrt
point (1/2  0))  with Legendre dual
x (cid:5) p computed from x and p.
is the second boosting property met by ULS.

ULS turns out to meet a third boosting property  and the most important as it contributes to root the
algorithm in the seminal boosting theory of the early nineties: we have guarantees on its convergence
rate under a generalization of the well-known “Weak Learning Assumption” (WLA) [13]. To state
the WLA  we plug the iteration in the index of the distribution normalization coefﬁcient in (21)  and
deﬁne Zj

.= ||wj||1 (||.||k is the Lk norm). The WLA is:

(WLA)∀j ∃γj > 0 : |(1/|Tj|) (cid:88)

t∈Tj

(1/Zj)

m

(cid:88)

i=1

mitwj i| ≥ γj .

(22)

This is indeed a generalization of the usual WLA for boosting algorithms  that we obtain taking
|Tj| = 1  ht ∈ {−1  +1} [12]. Few algorithms are known that formally boost WLA in the sense that
requiring only WLA implies guaranteed rates for the minimization of εψ
R. We show that ULS meets
this property ∀ψ ∈ SCL. To state this  we need few more deﬁnitions. Let mt denote the tth column
.= minj Zj. Let aγ denote the average of γj (∀j)  and
vector of M  am
aϕ

.= minx∈int(W) ϕ(x) (ϕ deﬁned in the proof of Lemma 2).

.= maxt ||mt||2 and aZ

Theorem 2 Under the WLA  ULS terminates in at most J = O(ma2
Proof sketch: We use Taylor expansions with Lagrange remainder for ˜ψ  and then the mean-value
theorem  and obtain that ∀w  w + ∆ ∈ W ∃w(cid:63) ∈ [min{w + ∆  w}  max{w + ∆  w}] such that
D ˜ψ(w + ∆||w) = ∆2ϕ(w(cid:63))/2 ≥ (∆2/2)aϕ ≥ 0. We use m times this inequality with w = wj i
and ∆ = (wj+1 i − wj i)  sum the inequalities  combine with Cauchy - Schwartz and Jensen’s
inequalities  and obtain:

γ)) iterations.

m/(aϕa2

Za2

D ˜ψ(wj+1||wj) ≥ aϕ(aZγj/(2am))2 .

(23)

Using (20)  we obtain that D ˜ψ(0||wJ+1) − m ˜ψ(0) equals:

−m ˜ψ(0) + D ˜ψ(0||w1) +

J

(cid:88)

j=1

(D ˜ψ(0||wj+1) − D ˜ψ(0||wj)) = mψ(0) −

J

(cid:88)

j=1

D ˜ψ(wj+1||wj) .(24)

But  (14) together with the deﬁnition of wj in [WU] (see ULS) yields D ˜ψ(0||wJ+1 i) = ˜ψ(0) +
i H(oi)) ∀i = 1  2  ...  m  which ties up the SCS to (24); the guaranteed decrease in the rhs
ψ(y∗
of (24) by (23) makes that there remains to check when the rhs becomes negative to conclude that
ULS has terminated. This gives the bound of the Theorem.
The bound in Theorem 2 is mainly useful to prove that the WLA guarantees a convergence rate of
order O(m/a2
5 ULS  BCL  maximum likelihood and zero-sum games

γ) for ULS  but not the best possible as it is in some cases far from being optimal.

BCL matches through the second equality in Lemma 1 the set of losses that satisfy the main re-
quirements about losses used in machine learning. This is a strong rationale for its use. Suppose
im(H) ⊆ [0  1]  and consider the following requirements about some loss (cid:96)[0 1](y  H):

(R1) The loss is lower-bounded. ∃z ∈ R such that inf y H (cid:96)[0 1](y  H) = z.
(R2) The loss is a proper scoring rule. Consider a singleton domain O = {o}. Then  the best
(constant) prediction is arg minx∈[0 1] ε[0 1](S  x) = p .= ˆPr[c = c+|o] ∈ [0  1]  where p is
the relative proportion of positive examples with observation o.

(R3) The loss is symmetric in the following sense: (cid:96)[0 1](y  H) = (cid:96)[0 1](1 − y  1 − H).

R1 is standard. For R2  we can write ε[0 1](S  x) = p(cid:96)[0 1](1  x) + (1 − p)(cid:96)[0 1](0  x) = L(p  x) 
which is just the expected loss of zero-sum games used in [9] (eq. (8)) with Nature states reduced
to the class labels. The fact that the minimum is achieved at x = p makes the loss a proper scoring
rule. R3 implies (cid:96)[0 1](1  1) = (cid:96)[0 1](0  0)  which is virtually assumed for any domain; otherwise  it
scales to H ∈ [0  1] a well-known symmetry in the cost matrix that holds for domains without class
dependent misclassiﬁcation costs. For these domains indeed  it is assumed (cid:96)[0 1](1  0) = (cid:96)[0 1](0  1).

Finally  we say that loss (cid:96)[0 1] is properly deﬁned iff dom((cid:96)[0 1]) = [0  1]2 and it is twice differentiable
on (0  1)2. This is only a technical convenience: even the 0/1 loss coincides on {0  1} with properly
deﬁned losses. In addition  the differentiability condition would be satisﬁed by many popular losses.
The proof of the following Lemma involves Theorem 3 in [1] and additional facts to handle R3.
Lemma 3 Assume im(H) ⊆ [0  1]. Loss (cid:96)[0 1](.  .) is properly deﬁned and meets requirements R1 
R2  R3 iff (cid:96)[0 1](y  H) = z + Dφ(y||H) for some permissible φ.
Thus  φ maybe viewed as the “signature” of the loss. The second equality in Lemma 1 makes a tight
connection between the predictions of H in [0  1] and R. Let it be more formal: the matching [0  1]
prediction for some H with im(H) = O is:

ˆPrφ[c = c+|H; o]

.= ∇−1

φ

(H(o))  

(25)

With this deﬁnition  illustrated in Table 1  Lemma 3 and the second equality in Lemma 1 show that
BCL matches the set of losses of Lemma 3. This deﬁnition also brings the true nature of the mini-
mization of any BCS with real valued hypotheses like linear separators (in ULS). From Lemma 3 and
[2]  there exists a bijection between BCL and a subclass of the exponential families whose members’
pdfs may be written as: Prφ[y|θ] = exp(−Dφ(y||∇−1
(θ)) + φ(y) − ν(y))  where θ ∈ R is the
natural parameter and ν(.) is used for normalization. Plugging θ = H(o)  using (25) and the second
equality in Lemma 1  we obtain that any BCS can be rewritten as εφ
R = U +(cid:80)i − log Prφ[yi|H(oi)] 
where U does not play a role in its minimization. We obtain the following Lemma  in which we sup-
pose im(H) = O.

φ

Lemma 4 Minimizing any BCS with classiﬁer H yields the maximum likelihood estimation  for each
observation  of the natural parameter θ = H(o) of an exponential family deﬁned by signature φ.
.=
In fact  one exponential family is concerned in ﬁne. To see this  we can factor the pdf as Pr[y|θ]
(cid:63) the cumulant function  λ(y) the sufﬁcient statistic and z the
exp (θλ(y) − ψ(θ)) /z  with ψ = φ
normalization function. Since y ∈ {0  1}  we easily end up with Prφ[y|θ] = 1/(1 + exp(−θ))  the
logistic prediction for a Bernoulli prior. To summarize  minimizing any loss that meets R1  R2 and
R3 (i.e. any BCL) amounts to the same ultimate goal; Since ULS works for any of the corresponding
surrogate risks  the crux of the choice of the BCL relies on data-dependent considerations.
Finally  we can go further in the parallel with game theory developed above for R2: using notations
in [9]  the loss function of the decision maker can be written L(X  q) = Dφ(1||q(X)). R3 makes it
easy to recover losses like the log loss or the Brier score [9] respectively from φQ and φB (Table 1).
In this sense  ULS is also a sound learner for decision making in the zero-sum game of [9]. Notice
however that  to work  it requires that Nature has a restricted sample space size ({0  1}).
6 Experiments
We have compared against each other 11 ﬂavors of ULS  including real AdaBoost [13]  on a bench-
mark of 52 domains (49 from the UCI repository). True risks are estimated via stratiﬁed 10-fold
cross validation; ULS is ran for r (ﬁxed) features ht  each of which is a Boolean rule: If Mono-
mial then Class= ±1 else Class = ∓1  with at most l (ﬁxed) literals  induced following the greedy
minimization of the BCS at hand. Leveraging coefﬁcients ([LC] in ULS) are approximated up to
10−10 precision. Figure 3 summarizes the results for two values of the couple (l  r). Histograms
are ordered from left to right in increasing average true risk over all domains (shown below his-
tograms). The italic numbers give  for each algorithm  the number of algorithms it beats accord-
ing to a Student paired t-test over all domains with .1 threshold probability. Out of the 10 ﬂa-
vors of ULS  the ﬁrst four ﬂavors pick φ in Table 1. The ﬁfth uses another permissible function:
φυ(x) .= (x(1 − x))υ  ∀υ ∈ (0  1). The last ﬁve adaptively tune the BCS at hand out-of-a-bag
of BCS. The ﬁrst four ﬁt the BCS at each stage of the inner loop (for j ...) of ULS. Two (noted
“F.”) pick the BCS which minimizes the empirical risk in the bag; two others (noted “E.”) pick the
BCS which maximizes the current edge. There are two different bags corresponding to four permis-
sible functions each: the ﬁrst (index “1”) contains the φ in Table 1  the second (index “2”) replaces
φB by φυ. We wanted to evaluate φB because it forces to renormalize the leveraging coefﬁcients in
H each time it is selected  to ensure that the output of H lies in [−1  1]. The last adaptive ﬂavor 
F ∗  “externalizes” the choice of the BCS: it selects for each fold the BCS which yields the smallest
empirical risk in a bag corresponding to ﬁve φ: those of Table 1 plus φυ.

 25

 20

 15

 10

 5

 0

 25

 20

 15

 10

 5

 0

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

F∗

14.18 (10)

φM

14.70 (5)

φυ

14.71 (3)

φµ

14.83 (2)

F2

15.03 (1)

φQ

15.06 (1)

E1

15.22 (1)

φB

15.25 (1)

AdaBoost
15.35 (1)

E2

15.36 (1)

F1

17.37 (0)

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

987654321

10

11

F∗

12.15 (10)

φQ

12.39 (3)

AdaBoost
12.56 (3)

φM

12.59 (3)

φB

12.62 (3)

E2

12.63 (3)

φυ

12.74 (2)

φµ

12.79 (2)

F2

13.10 (2)

F1

17.57 (1)

E1

23.60 (0)

Figure 3: Summary of our results over the 52 domains for the 11 algorithms (top: l = 2  r = 10;
bottom: l = 3  r = 100). Vertical (red) bars show the average rank over all domains (see text).

Three main conclusions emerge from Figure 3. First  F ∗ appears to be superior to all other ap-
proaches  but slightly more sophisticated choices for the SCS (i.e. E.  F.) fail at improving the
results; this is a strong advocacy for a particular treatment of this surrogate tuning problem. Second 
Matsushita’s BCL  built from φM  appears to be a serious alternative to the logistic loss. Third and
last  a remark previously made by [10] for decision trees seems to hold as well for linear separators 
as stronger concave regimes for φ in BCLs tend to improve performances at least for small r.
Conclusion
In this paper  we have shown the existence of a supervised learning algorithm which minimizes
any strictly convex  differentiable classiﬁcation calibrated surrogate [3]  inducing linear separators.
Since the surrogate is now in the input of the algorithm  along with the learning sample  it opens
the interesting problem of the tuning of this surrogate to the data at hand to further reduce the true
risk. While the strategies we have experimentally tested are  with this respect  a simple primer for
eventual solutions  they probably display the potential and the non triviality of these solutions.
References
[1] A. Banerjee  X. Guo  and H. Wang. On the optimality of conditional expectation as a bregman predictor.

IEEE Trans. on Information Theory  51:2664–2669  2005.

[2] A. Banerjee  S. Merugu  I. Dhillon  and J. Ghosh. Clustering with Bregman divergences. Journal of

Machine Learning Research  6:1705–1749  2005.

[3] P. Bartlett  M. Jordan  and J. D. McAuliffe. Convexity  classiﬁcation  and risk bounds. Journal of the Am.

Stat. Assoc.  101:138–156  2006.

[4] P. Bartlett and M. Traskin. Adaboost is consistent. In NIPS*19  2006.
[5] L. M. Bregman. The relaxation method of ﬁnding the common point of convex sets and its application to
the solution of problems in convex programming. USSR Comp. Math. and Math. Phys.  7:200–217  1967.
[6] M. Collins  R. Schapire  and Y. Singer. Logistic regression  adaboost and Bregman distances. In COLT’00 

pages 158–169  2000.

[7] J. Friedman  T. Hastie  and R. Tibshirani. Additive Logistic Regression : a Statistical View of Boosting.

Ann. of Stat.  28:337–374  2000.

[8] C. Gentile and M. Warmuth. Linear hinge loss and average margin. In NIPS*11  pages 225–231  1998.
[9] P. Gr¨unwald and P. Dawid. Game theory  maximum entropy  minimum discrepancy and robust Bayesian

decision theory. Ann. of Statistics  32:1367–1433  2004.

[10] M.J. Kearns and Y. Mansour. On the boosting ability of top-down decision tree learning algorithms.

Journal of Comp. Syst. Sci.  58:109–128  1999.

[11] K. Matsushita. Decision rule  based on distance  for the classiﬁcation problem. Ann. of the Inst. for Stat.

Math.  8:67–77  1956.

[12] R. Nock and F. Nielsen. A Real Generalization of discrete AdaBoost. Artif. Intell.  171:25–41  2007.
[13] R. E. Schapire and Y. Singer.
Improved boosting algorithms using conﬁdence-rated predictions.
COLT’98  pages 80–91  1998.

In

[14] M. Warmuth  J. Liao  and G. R¨atsch. Totally corrective boosting algorithms that maximize the margin. In

ICML’06  pages 1001–1008  2006.

,Shai Shalev-Shwartz
Tong Zhang
Jiasen Lu
Jianwei Yang
Devi Parikh