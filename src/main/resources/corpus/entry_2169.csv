2019,From deep learning to mechanistic understanding in neuroscience: the structure of retinal prediction,Recently  deep feedforward neural networks have achieved considerable success in modeling biological sensory processing  in terms of reproducing the input-output map of sensory neurons. However  such models raise profound questions about the very nature of explanation in neuroscience. Are we simply replacing one complex system (a biological circuit) with another (a deep network)  without understanding either? Moreover  beyond neural representations  are the deep network's computational mechanisms for generating neural responses the same as those in the brain? Without a systematic approach to extracting and understanding computational mechanisms from deep neural network models  it can be difficult both to assess the degree of utility of deep learning approaches in neuroscience  and to extract experimentally testable hypotheses from deep networks. We develop such a systematic approach by combining dimensionality reduction and modern attribution methods for determining the relative importance of interneurons for specific visual computations. We apply this approach to deep network models of the retina  revealing a conceptual understanding of how the retina acts as a predictive feature extractor that signals deviations from expectations for diverse spatiotemporal stimuli. For each stimulus  our extracted computational mechanisms are consistent with prior scientific literature  and in one case yields a new mechanistic hypothesis. Thus overall  this work not only yields insights into the computational mechanisms underlying the striking predictive capabilities of the retina  but also places the framework of deep networks as neuroscientific models on firmer theoretical foundations  by providing a new roadmap to go beyond comparing neural representations to extracting and understand computational mechanisms.,From deep learning to mechanistic understanding in

neuroscience: the structure of retinal prediction

Hidenori Tanaka1 2 †  Aran Nayebi3  Niru Maheswaranathan3 5  Lane McIntosh3  Stephen A.

Baccus4  and Surya Ganguli2 5 †

1Physics & Informatics Laboratories  NTT Research  Inc.  East Palo Alto  CA  USA

2Department of Applied Physics  Stanford University  Stanford  CA  USA
3Neurosciences PhD Program  Stanford University  Stanford  CA  USA
4Department of Neurobiology  Stanford University  Stanford  CA  USA

5Google Brain  Google  Inc.  Mountain View  CA  USA

†{tanaka8 sganguli}@stanford.edu

Abstract

Recently  deep feedforward neural networks have achieved considerable success in
modeling biological sensory processing  in terms of reproducing the input-output
map of sensory neurons. However  such models raise profound questions about the
very nature of explanation in neuroscience. Are we simply replacing one complex
system (a biological circuit) with another (a deep network)  without understanding
either? Moreover  beyond neural representations  are the deep network’s computa-
tional mechanisms for generating neural responses the same as those in the brain?
Without a systematic approach to extracting and understanding computational
mechanisms from deep neural network models  it can be difﬁcult both to assess the
degree of utility of deep learning approaches in neuroscience  and to extract experi-
mentally testable hypotheses from deep networks. We develop such a systematic
approach by combining dimensionality reduction and modern attribution methods
for determining the relative importance of interneurons for speciﬁc visual computa-
tions. We apply this approach to deep network models of the retina  revealing a
conceptual understanding of how the retina acts as a predictive feature extractor
that signals deviations from expectations for diverse spatiotemporal stimuli. For
each stimulus  our extracted computational mechanisms are consistent with prior
scientiﬁc literature  and in one case yields a new mechanistic hypothesis. Thus
overall  this work not only yields insights into the computational mechanisms
underlying the striking predictive capabilities of the retina  but also places the
framework of deep networks as neuroscientiﬁc models on ﬁrmer theoretical founda-
tions  by providing a new roadmap to go beyond comparing neural representations
to extracting and understand computational mechanisms.

1

Introduction

Deep convolutional neural networks (CNNs) have emerged as state of the art models of a variety
of visual brain regions in sensory neuroscience  including the retina [1  2]  primary visual cortex
(V1)  [3  4  5  6]  area V4 [3]  and inferotemporal cortex (IT) [3  4]. Their success has so far been
primarily evaluated by their ability to explain reasonably large fractions of variance in biological
neural responses across diverse visual stimuli. However  fraction of variance explained is not of
course the same thing as scientiﬁc explanation  as we may simply be replacing one inscrutable black
box (the brain)  with another (a potentially overparameterized deep network).

33rd Conference on Neural Information Processing Systems (NeurIPS 2019)  Vancouver  Canada.

Figure 1: Deep learning models
of the retina trained only on nat-
ural scenes reproduce an array
of retinal phenomena with artiﬁ-
cial stimuli (reproduced from ref.
[2]).
(A) Training procedure: We ana-
lyzed a three-layer convolutional
neural network (CNN) model of the
retina which takes as input a spa-
tiotemporal natural scene movie and
outputs a nonnegative ﬁring rate 
corresponding to a retinal ganglion
cell response. The ﬁrst layer con-
sists of eight spatiotemporal convo-
lutional ﬁlters (i.e.  cell types) with
the size of (15×15×40)  the second
layer of eight convolutional ﬁlters
(8×11×11)  and the fully connected
layer predicting the ganglion cells’
response. As previously reported
in [2]  the deep learning model re-
produces (B) an omitted stimulus re-
sponse  (C) latency coding  (D) the
motion reversal response  and (E)
motion anticipation.

Indeed  any successful scientiﬁc model of a biological circuit should succeed along three fundamental
axes  each of which goes above and beyond the simple metric of mimicking the circuit’s input-
output map. First  the intermediate computational mechanisms used by the hidden layers to generate
responses should ideally match the intermediate computations in the brain. Second  we should be able
to extract conceptual insight into how the neural circuit generates nontrivial responses to interesting
stimuli (for example responses to stimuli that cannot be generated by a linear receptive ﬁeld). And
third  such insights should suggest new experimentally testable hypotheses that can drive the next
generation of neuroscience experiments.
However  it has been traditionally difﬁcult to systematically extract computational mechanisms  and
consequently conceptual insights  from deep CNN models due to their considerable complexity
[7  8]. Here we provide a method to do so based on the idea of model reduction  whose goal is to
systematically extract a simple  reduced  minimal subnetwork that is most important in generating
a complex CNN’s response to any given stimulus. Such subnetworks then both summarize compu-
tational mechanisms and yield conceptual insights. We build on ideas from interpretable machine
learning  notably methods of input attribution that can decompose a neural response into a sum of
contributions either from individual pixels [9] or hidden neurons [10]. To achieve considerable model
reduction for responses to spatiotemporal stimuli  we augment and combine such input attribution
methods with dimensionality reduction  which  for carefully designed artiﬁcial stimuli employed in
neurophysiology experiments  often involves simple spatiotemporal averages over stimulus space.
We demonstrate the power of our systematic model reduction procedure to attain mechanistic insights
into deep CNNs by applying them to state of the art deep CNN models of the retina [1  2]. The retina
constitutes an ideal ﬁrst application of our methods because the considerable knowledge (see e.g. [11])
about retinal mechanisms for transducing spatiotemporal light patterns into neural responses enables
us to assess whether deep CNNs successfully learn the same computational structure. In particular 
we obtain deep CNN models from [2] which were trained speciﬁcally to mimic the input-output
transformation from natural movies to retinal ganglion cell outputs measured in the salamander retina.
The model architecture involved a three-layer CNN model of the retina with ReLU nonlinearities
(Fig. 1A). This network was previously shown [1  2] to: (i) yield state of the art models of the retina’s
response to natural scenes that are almost as accurate as possible given intrinsic retinal stochasticity;
(ii) possess internal subunits with similar response properties to those of retinal interneurons  such as

2

ΔtxyΔtxMotion reversalt [s]Schwartz et al. (2007)Rate [Hz]xLatency codingGollisch & Meister (2008)Figure 1Training input Natural scene movieTraining output Ganglion cells’ responseExperimental dataOmitted stimulus responseModel outputSchwartz et al. (2007)sRate [Hz]t [s]Training procedure: natural scenesTesting procedure: structured stimulusMotion anticipationBerry et al. (1999)Position(A)(B)(C)(D)(E)N. Maheswaranathan et al. (2018)bipolar and amacrine cell types; (iii) generalize from natural movies  to a wide range of eight different
classes of artiﬁcially structured stimuli used over decades of neurophysiology experiments to probe
retinal response properties. This latter generalization capacity from natural movies to artiﬁcially
structured stimuli (that were never present in the training data) is intriguing given the vastly different
spatiotemporal statistics of the artiﬁcial stimuli versus natural stimuli  suggesting the artiﬁcial stimuli
were indeed well chosen to engage the same retinal mechanisms engaged under natural vision [2].
Here  we focus on understanding the computational mechanisms underlying the deep CNN’s ability
to reproduce the neural responses to four classes of artiﬁcial stimuli (Fig. 1B-E)  each of which 
through painstaking experiments and theory  have revealed striking nonlinear retinal computations
that advanced our scientiﬁc understanding of the retina. The ﬁrst is the omitted stimulus response
(OSR) [12  13] (Fig. 1B)  in which a periodic sequence of full ﬁeld ﬂashes entrains a retinal ganglion
cell to respond periodically  but when a single ﬂash is omitted  the ganglion cell produces an even
larger response at the expected time of the response to the omitted ﬂash. Moreover  the timing of this
omitted stimulus response occurs at the expected time over a range of frequencies of the periodic
ﬂash train  suggesting the retina is somehow retaining a memory trace of the period of the train of
ﬂashes. The second is latency encoding [14]  in which stronger stimuli yield earlier responses (Fig.
1C). The third is motion reversal [15]  in which a bar suddenly reversing its motion near a ganglion
cell receptive ﬁeld generates a much larger response after the motion reversal (Fig. 1D). The fourth
is motion anticipation [16]  where the neural population responding to a moving bar is advanced in
the direction of motion to compensate for propagation delays through the retina (Fig. 1E). These
responses are striking because they imply the retina has implicitly built into it a predictive world
model codifying simple principles like temporal periodicity  and the velocity based extrapolation of
future position. The retina can then use these predictions to improve visual processing (e.g. in motion
anticipation)  or when these predictions are violated  the retina can generate a large response to signal
that deviation (e.g. in the OSR and motion reversal).
While experimentally motivated prior theoretical models have been employed to explain the OSR
[17  18]  latency encoding [14  19]  motion reversal [20  21]  and motion anticipation [16]  to date 
no single model other than the deep CNN found in [2] has been able to simultaneously account for
retinal ganglion cell responses to both natural scenes and all four of these classes of stimuli  as well
as several other classes of artiﬁcial stimuli. However  it is difﬁcult to explain the computational
mechanisms underlying the deep CNN’s ability to generate these responses simply by examining the
complex network in Fig. 1A. For example  why does the deep CNN ﬁre more when a stimulus is
omitted  or when a bar reverses? How can it anticipate motion to compensate for propagation delays?
And why do stronger responses cause earlier ﬁring?
These are foundational scientiﬁc questions about the retina whose answers require conceptual insights
that are not afforded by the existence of a complex but highly predictive CNN alone. And even more
importantly  if we could extract conceptual insights into the computational mechanisms underlying
CNN responses  would these mechanisms match those used in the biological retina? Or is the
deep CNN only accurate at the level of modelling the input-output map of the retina  while being
fundamentally inaccurate at the level of underlying mechanisms? Adjudicating between these two
possibilities is essential for validating whether the deep learning approach to modelling in sensory
neuroscience can indeed succeed in elucidating biological neural mechanisms  which has traditionally
been the gold-standard of circuit based understanding in systems neuroscience [11  22  23  24].
In the following we will show how a combination of dimensionality reduction and hidden neuron or
stimulus attribution can yield simpliﬁed subnetwork models of the deep CNNs response to stimuli 
ﬁnding models that are consistent with prior mechanistic models with experimental support in the
case of latency encoding  motion reversal  and motion anticipation. In addition  our analysis yields a
new model that cures the inadequacies of previous models of the OSR. Thus our overall approach
provides a new roadmap to extract mechanistic insights into deep CNN function  conﬁrms in the
case of the retina that deep CNNs do indeed learn computational mechanisms that are similar to
those used in biological circuits  and yields a new experimentally testable hypothesis about retinal
computation. Moreover  our results in the retina yield hope (to be tested in future combined theory
and experiments) that more complex deep CNN models of higher visual cortical regions  may not only
yield accurate black box models of input-output transformations  but may also yield veridical and
testable hypotheses about intermediate computational mechanisms underlying these transformations 
thereby potentially placing deep CNN models of sensory brain regions on ﬁrmer epistemological
foundations.

3

2 From deep CNNs to neural mechanisms through model reduction

To extract understandable reduced models from the millions of parameters comprising the deep CNN
in Fig. 1A and [2]  we ﬁrst reduce dimensionality by exploiting spatial invariance present in the
artiﬁcial stimuli carefully designed to speciﬁcally probe retinal physiology (Fig.1B-E)  and then carve
out important sub-circuits using modern attribution methods [9  10]. We proceed in 3 steps:
Step (1): Quantify the importance of a model unit with integrated gradients. The nonlinear
input-output map of our deep CNN can be expressed as r(t) = F[s(t)]  where r(t) ∈ R+ denotes
the nonnegative ﬁring rate of a ganglion cell at time bin t and s(t) ∈ R50×50×40 denotes the recent
spatiotemporal history of the visual stimulus spanning two dimensions of space (x  y) (with 50
spatial bins in each dimension) as well as 40 preceding time bins parameterized by ∆t. Thus
a single component of the vector s(t) is given by sxy∆t(t)  which denotes the stimulus contrast
at position (x  y) at time t − ∆t. We assume a zero contrast stimulus yields no response (i.e.
F[0] = 0). We can decompose  or attribute the response r(t) to each preceding spacetime point by
considering a straight path in spatiotemporal stimulus space from the zero stimulus to s(t) given
by s(t; α) = αs(t) where the path parameter α ranges from 0 to 1 [9]. Using the line integral
F[s(t; 1)] =(cid:82) 1

∂α   we obtain

∂s(cid:12)(cid:12)s(t α) · ∂s(t α)
0 dα ∂F
50(cid:88)x=1
40(cid:88)∆t=1

50(cid:88)y=1

r(t) = F[s(t)] =

sxy∆t(t)(cid:90) 1

0

dα

∂F

∂sxy∆t(t)(cid:12)(cid:12)(cid:12)(cid:12)αs(t) ≡

50(cid:88)x=1

50(cid:88)y=1

40(cid:88)∆t=1

Axy∆t.

(1)

∂s(t)(cid:12)(cid:12)s=0 · s(t) is only approximate. The coefﬁcient vector ∂F

This equation represents an exact decomposition of the response r(t) into attributions Axy∆t from
each preceding spacetime stimulus pixel (x  y  ∆t). Intuitively  the magnitude of Axy∆t tells us
how important each pixel is in generating the response  and the sign tells us whether or not turning
on each pixel from 0 to sxy∆t(t) yields a net positive or negative contribution to r(t). When F
is linear  this decomposition reduces to a Taylor expansion of F about s(t) = 0. However  in
the nonlinear case  this decomposition has the advantage that it is exact  while the linear Taylor
expansion r(t) ≈ ∂F
of this Taylor
expansion is often thought of as the linear spacetime receptive ﬁeld (RF) of the model ganglion cell 
a concept that dominates sensory neuroscience. Thus choosing to employ this attribution method
enables us to go beyond the dominant but imperfect notion of an RF  in order to understand nonlinear
neural responses to arbitrary spatiotemporal stimuli. In supplementary material  we discuss how this
theoretical framework of attribution to input space can be temporally extended to answer different
questions about how deep networks process spatiotemporal inputs.
However  since our main focus here is model reduction  we consider instead attributing the ganglion
cell response back to the ﬁrst layer of hidden units  to quantify their importance. We denote by
cxy(t) = W [1]
z[1]
cxy (cid:126) s(t) + bcxy the pre-nonlinearity activation of the layer 1 hidden units  where
Wcxy and bcxy are the convolutional ﬁlters and biases of a unit in channel c (c = 1  . . .   8) at
convolutional position (x  y) (with x  y = 1  . . .   36). Now computing the line integral F[s(t; 1)] =
(cid:82) 1
0 dα ∂F

∂α over the same stimulus path employed in (1) yields

∂s(t)(cid:12)(cid:12)s=0

∂z[1](cid:12)(cid:12)s(t α) · ∂z[1]
r(t) = (cid:88)x y c(cid:34)(cid:90) 1

dα

0

∂F
∂z[1]

cxy(cid:12)(cid:12)(cid:12)(cid:12)s(t α)(cid:35) (W [1]

cxy (cid:126) s) = (cid:88)x y c

[Gcxy(s)] (W [1]

cxy (cid:126) s) = (cid:88)x y c

Acxy.

(2)

This represents an exact decomposition of the response r(t) into attributions Acxy from each subunit
at the same time t (since all CNN ﬁlters beyond the ﬁrst layer are purely spatial). This attribution
further splits into a product of W [1]
cxy (cid:126) s  reﬂecting the activity of that subunit originating from
spatiotemporal ﬁltering of the preceding stimulus history  and an effective stimulus dependent weight
Gcxy(s) from each subunit to the ganglion cell  reﬂecting how variations in subunit activity z[1]
cxy
as the stimulus is turned on from 0 to s(t) yield a net impact on the response r(t). A positive
(negative) effective weight indicates that increasing subunit activity along the stimulus path yields a
net excitatory (inhibitory) effect on r(t).
Step (2): Exploiting stimulus invariances to reduce dimensionality. The attribution of the re-
sponse r(t) to ﬁrst layer subunits in (2) still involves 8 × 36 × 36 = 10  368 attributions. We can 
however  leverage the spatial uniformity of artiﬁcial stimuli used in neurophysiology experiments to

4

reduce this dimensionality. For example  in the OSR and latency coding  stimuli are spatially uniform 
implying W [1]
cxy (cid:126) s is independent of spatial indices (x  y). Thus  we can reduce the
number of attributions to the number of channels via

c (cid:126) s ≡ W [1]

r(t) =

8(cid:88)c=1(cid:18) 36(cid:88)x=1

36(cid:88)y=1

Gcxy(s)(cid:19) · (W [1]

c (cid:126) s) ≡

8(cid:88)c=1

Gc(s) · (W [1]

c (cid:126) s) ≡

8(cid:88)c=1

Ac.

(3)

For the moving bar in both motion reversal and motion anticipation  W [1]
independent of the y index and we can reduce the dimensionality from 10 368 down to 288 by

cxy (cid:126) s is

r(t) =

8(cid:88)c=1

36(cid:88)x=1(cid:18) 36(cid:88)y=1

Gcxy(s)(cid:19) · (W [1]

cx (cid:126) s) ≡

8(cid:88)c=1

36(cid:88)x=1

cx (cid:126) s ≡ W [1]
36(cid:88)x=1

8(cid:88)c=1

Gcx(s) · (W [1]

cx (cid:126) s) ≡

(4)

Acx.

More generally for other stimuli with no obvious spatial invariances  one could still attempt to reduce
dimensionality by performing PCA or other dimensionality reduction methods on the space of hidden
unit pre-activations or attributions over time. We leave this intriguing direction for future work.
Step (3): Building reduced models from important subunits. Finally  we can construct minimal
circuit models by ﬁrst identifying “important” units deﬁned as those with large magnitude attributions
A. We then construct our reduced model as a one hidden layer neural network composed of only
the important hidden units  with effective connectivity from each hidden unit to the ganglion cell
determined by the effective weights G in (2)  (3)  or (4).
3 Results: the computational structure of retinal prediction

We now apply the systematic model reduction steps described in the previous section to each of
the retinal stimuli in Fig. 1B-E. We show that in each case the reduced model yields scientiﬁc
hypotheses to explain the response  often consistent with prior experimental and theoretical work 
thereby validating deep CNNs as a method for veridical scientiﬁc hypothesis generation in this setting.
Moreover  our approach yields integrative conceptual insights into how these diverse computations
can all be simultaneously produced by the same set of hidden units.

3.1 Omitted stimulus response

As shown in Fig. 1B  periodic stimulus ﬂashes trigger delayed periodic retinal responses. However 
when this periodicity is violated by omitting a ﬂash  the ganglion cell signals the violation with a
large burst of ﬁring [25  26]. This OSR phenomenon is observed across several species including
salamander [12  13]. Interestingly  for periodic ﬂashes in the range of 6-12Hz  the latency between
the last ﬂash before the omitted one  and the burst peak in the response  is proportional to the period
of the train of ﬂashes [12  13]  indicating the retina retains a short memory trace of this period.
Moreover  pharmacological experiments suggest ON bipolar cells are required to produce the OSR
[13  17]  which have been shown to correspond to the ﬁrst layer hidden units in the deep CNN [1  2].
These phenomena raise two fundamental questions: what computational mechanism causes the large
amplitude burst  and how is the timing of the peak sensitive to the period of the ﬂashes? There are
two theoretical models in the literature that aim to answer these questions. One proposes that the
bipolar cell activity responds to each individual ﬂash with an oscillatory response whose period
adapts to the period of the ﬂash train [18]. However  recent direct recordings of bipolar cells suggest
that such period adaptation is not present [27]. The other model claims that having dual pathways of
ON and OFF bipolar cells are enough to reproduce most of the aspects of the phenomena observed in
experiments [17]. However  the model only reproduces the shift of the onset of the burst  and not a
shift in the peak of the burst  which has the critical predictive latency [18].
Direct model reduction (Fig. 2) of the deep CNN in Fig. 1A using the methods of section 2 yields a
more sophisticated model than any prior model  comprised of three important pathways that combine
one OFF temporal ﬁlter with two ON temporal ﬁlters. Unlike prior models  the reduced model
exhibits a shift in the peak of the OSR burst as a function of the frequency of input ﬂashes.

5

Figure 2: Omitted stimulus response. (A-1 2) Schematics of the model reduction procedure by
only leaving three (1 OFF  2 ON) highly contributing units. (B) Attribution for each of the cell types
Ac over time. (C) Effective stimulus dependent weight for each of the cell types Gc over time. (D)
The combination of the two pathways of ﬁlter 2 and 6 reproduces the period dependent latency. (E)
Two ON bipolar cells are necessary to capture the predictive latency. Cell 2 with earlier peak is
only active in a high-frequency regime  while the cell 6 with later peak is active independent of the
frequency.

Fig. 2A presents a schematics of the model reduction steps described in (3). We ﬁrst attribute a
ganglion cell’s response to 8 individual channels and then average across both spatial dimensions
(Fig. 2A-1) as in steps (1) and (2). Then we build a reduced model from the identiﬁed important
subunits that capture essential features of the omitted stimulus response phenomenon (Fig. 2A-2).
In Fig. 2B  we present the time dependence of the attribution Ac(s(t)) in (3) for the eight channels 
or cell-types. Red (blue) traces reﬂect positive (negative) attributions. Channel temporal ﬁlters are
to the left of each attribution row and the total output response r(t) is on the top row. The stimulus
consists of three ﬂashes  yielding three small responses  and then one large response after the end of
the three ﬂashes (grey line). Quantitatively  we identify that cell-type 3 dominantly explains the small
responses to preceding ﬂashes  while cell types 2 and 6 are necessary to explain the large burst after
the ﬂash train ends. The ﬁnal set of units included in the reduced model should be the minimal set
required to capture the deﬁning features of the phenomena of interest. In the case of omitted stimulus
response  the deﬁning feature is the existence of the large amplitude burst whose peak location is
sensitive to the period of the applied ﬂashes. Once we identify the set of essential temporal ﬁlters 
we then proceed to determine the sign and magnitude of contribution (excitatory or inhibitory) of
the cell types. In Fig. 2C  we present the time-dependent effective weights from Gc(s(t)) in (3) for
the eight cell types  or channels. Red (blue) reﬂects positive (negative) weights. Given the product
of the temporal ﬁlters and the weights  cell-types 2 and 6 are effectively ON cells  which cause
positive ganglion cell responses to contrast increments  while cell-type 3 is an OFF cell  which is a
cell type that causes positive responses to contrast decrements. Following the prescribed procedures 
carving out the 3 important cell-types and effective weights yields a novel  mechanistic three pathway
model of the OSR  with 1 OFF and 2 ON pathways. Unlike prior models  the reduced model exhibits
a shift in the peak of the OSR burst as a function of the frequency of input ﬂashes (with dark to
light blue indicating high to low frequency variation in the ﬂash train) as in Fig. 2D. Furthermore 
the reduced model is consistent across the frequency range that produces the phenomena. Finally 
model reduction yields conceptual insights into how cell-types 2 and 6 enable the timing of the burst
peak to remember the period of the ﬂash train (Fig. 2E). The top row depicts the decomposition
of the overall burst response r(t) (grey) into time dependent attributions A2 (red) and A6 (blue) 
obeying the relation r(t) ≈ A2 + A6. Cell-type 2  which has an earlier peak in its temporal ﬁlter 
preferentially causes ganglion cell responses in high-frequency ﬂash trains (left) compared to low
frequency trains (right)  while cell-type 6 is equally important in both. The middle row shows the
temporal ﬁlter Wc=2(∆t)  which has an earlier peak with a long tail  enabling it to integrate across
not only the last ﬂash  but also preceding ﬂashes (yellow bars). Time increases into the past from
left to right. Thus  the activation of this cell type 2 decreases as the ﬂash train frequency decreases 
explaining the decrease in attribution in the top row. The bottom row shows that the temporal ﬁlter
Wc=6(∆t) of cell type 6  in contrast  has a later peak with a rapidly decaying tail. Thus the temporal
convolution Wc=6(∆t) (cid:126) s(∆t) of this ﬁlter with the ﬂash train is sensitive only to the last ﬂash  and

6

(A-2)Ac=6(t)timeintensityFigure 2: Omitted Stimulus Response(A-1)(B)(C)~(D)s(t)(E)12345678Ac=Gc·(W[1]c~s)r(t)=8Xc=1AcGcGc(s)W[1]c32612345678high freqlow freq26Ac=2(t)r(t)⇡+tttW[1]c=2~sW[1]c=6~shigh
freqlow
freqPositive Negativeis therefore independent of ﬂash train frequency. The late peak and rapid tail explain why it supports
the response at late times independent of frequency in the top row.
Thus  our systematic model reduction approach yields a new model of the OSR that cures important
inadequacies of prior models. Moreover  it yields a new  experimentally testable scientiﬁc hypothesis
that the OSR is an emergent property of three bipolar cell pathways with speciﬁc and diverse temporal
ﬁltering properties.

3.2 Latency coding

Rapid changes in contrast (which often occur
for example right after saccades) elicit a burst
of ﬁring in retinal ganglion cells with a latency
that is shorter for larger contrast changes [14]
(Fig. 1C). Moreover  pharmacological studies
demonstrate that both ON and OFF bipolar cells
(corresponding to ﬁrst layer hidden neurons in
the deep CNN [1  2]) are necessary to produce
this phenomenon [19].
Model reduction via (3) in section 2 reveals that
a single pair of slow ON and fast OFF pathways
can explain the shift in the latency Fig. 3. First 
under a contrast decrement  there is a strong  fast
excitatory contribution from the OFF pathway.
Second  as the magnitude of the contrast decre-
ment increases  delayed inhibition from the slow
ON pathway becomes stronger. This negative
delayed contribution truncates excitation from
the OFF pathway at late times  thereby causing a
shift in the location of the total peak response to
earlier times (Fig. 3). The dual pathway mech-
anism formed by slow ON and fast OFF bipolar
cells is consistent with all existing experimental
facts. Moreover  it has been previously proposed
as a theory of latency coding [14  19]. Thus this
example illustrates the power of a general nat-
ural scene based deep CNN training approach 
followed by model reduction  to automatically
generate veridical scientiﬁc hypotheses that were previously discovered only through specialized
experiments and analyses requiring signiﬁcant effort [14  19].

Figure 3: Latency coding (A) The decomposition
of the overall response r(t) (grey) into dominant
attributions A3(t) (blue) from an OFF pathway 
and A2(t) (red) from an ON pathway  obeying the
relation r(t) ≈ A3 + A2. Under a contrast decre-
ment  the OFF pathway activated ﬁrst  followed by
delayed inhibitory input from the ON pathway. (B)
As the amount of contrast decrement increases (yel-
low bars)  delayed inhibition from the ON pathway
(red) strengthens  which cuts off the total response
in r(t) at late times more strongly  thereby shifting
the location of the peak of r(t) to earlier times.

3.3 Motion reversal

As shown in Fig. 1D and [15]  when a moving bar suddenly reverses its direction of motion  ganglion
cells near the reversal location exhibit a sharp burst of ﬁring. While a ganglion cell classically
responds as the bar moves through its receptive ﬁeld (RF) center from left to right before the motion
reversal  the sharp burst after the motion reversal does not necessarily coincide with the spatial
re-entry of the bar into the center of the RF as it moves back from right to left. Instead  the motion
reversal burst response occurs at a ﬁxed temporal latency relative to the time of motion reversal 
for a variety of reversal locations within 110 µm of the RF center. These observations raise two
fundamental questions: why does the burst even occur and why does it occur at a ﬁxed latency?
The classical linear-nonlinear model cannot reproduce the reversal response; it only correctly re-
produces the initial peak associated with the initial entry of a bar into the RF center [15]. Thus a
nonlinear mechanism is required. Model reduction of the deep CNN obtained via (4) reveals that
two input channels arrayed across 1D x space can explain this response through a speciﬁc nonlinear
mechanism (Fig. 4). Moreover  the second important channel revealed by model reduction yields a
cross cell-type inhibition that explains the ﬁxed latency (Fig. 4D). Intriguingly  this reduced model is

7

Figure 3: Latency Coding23inputoutputLow intensity(A)(B)High intensityA2A3r(t)⇡+Figure 4: Motion reversal of a moving bar.
(A) Schematics of (x  t) spatiotemporal model
reduction obtained via (4). By averaging over y we obtain 8 cell types at 36 different x positions
yielding 288 units. Attribution values reveal that only cell types 2 and 3 play a dominant role in
motion reversal. (B) The properties of cell-type 3 explains the existence of the burst. On the left are
time-series of pre-nonlinearity activations W [1]
c=3 x (cid:126) s of hidden units whose RF center is at spatial
position x. Time t = 0 indicates the time of motion reversal. The boxed region indicates the spatial
and temporal extent of the retinal burst in response to motion reversal. The offset of the box from
time t = 0 indicates the ﬁxed latency. A ﬁxed linear combination with constant coefﬁcents of this
activation cannot explain the existence of the burst due to cancellations along the vertical x-axis in the
boxed region. However  due to downstream nonlinearities  the effective weight coefﬁcients Gc=3 x
from subunits to ganglion cell responses rapidly ﬂip in sign (middle)  and generating a burst of motion
reversal response (right). (C) Schematics of the reduced model keeping only important subunits. (D)
Attribution contributions from the two dominant cell types A2 (in pink) and A3 (in blue)  where
Ac =(cid:80)36
x=1 Acx. With only cell-type 3  the further the reversal location is from a ganglion cell’s RF
center  the longer we would expect it to take to generate a reversal response. However  the inhibition
coming from cell type 2 increases the further away the reversal occurs  truncating the late response
and thus ﬁxing the latency of the motion reversal response.

qualitatively consistent with a recently proposed and experimentally motivated model [20] that points
out the crucial role of dual pathways of ON and OFF bipolar cells.

3.4 Motion anticipation

As shown in Fig. 1E and [16] the retina already
starts to compensate for propagation delays by
advancing the retinal image of a moving bar
along the direction of motion  so that the retinal
image does not lag behind the instantaneous
location as one might naively expect.
Model reduction of our deep CNN reveals a
mechanism for this predictive tracking. First 
since ganglion cell RFs have some spatial extent 
a moving bar naturally triggers some ganglion
cells before entering their RF center  yielding
a leading edge of a retinal wave. What is then
required for motion anticipation is some addi-
tional motion direction sensitive inhibition that
cuts off the lagging edge of the wave so its peak
activity shifts towards the leading edge. Indeed 
model reduction reveals a computational mech-
anism in which one cell type feeds an excitatory
signal to a ganglion cell while the other provides
direction sensitive inhibition that truncates the lagging edge. This model is qualitatively consistent
with prior theoretical models that employ such direction selective inhibition to anticipate motion [16].

Figure 5: Motion anticipation of a moving bar.
Contributions from the two dominant cell types.
A2 in pink  A3 in blue  r(t) ≈ A2 + A3 in grey 
where Ac =(cid:80)36
x=1 Acx. Depending on the direc-
tion of motion of a bar  activity that lags behind
the leading edge gets asymmetrically truncated by
the inhibition from the cell type 2 (pink). (A) The
bar is moving to the right and the inhibition (pink)
is slightly stronger on the left side. (B) the bar
is moving to the left and the inhibition (pink) is
stronger on the right side.

8

Figure 4: Motion Reversal(A)(B)(D)(C)txW[1]cx~sGcxr(t)=8Xc=136Xx=1AcxW[1]c=3 x~sGc=3 xAc=3 x=Gc=3 x·(W[1]c=3 x~s)Ac=3 x=Gc=3 x·(W[1]c=3 x~s)xA2A3r(t)⇡+32Figure 5: Motion Anticipation(A)(B)A2A3r(t)⇡+4 Discussion

Figure 6: A uniﬁed framework
to reveal computational structure
in the brain. We outlined an auto-
mated procedure to go from large-
scale neural recordings to mechanis-
tic insights and scientiﬁc hypotheses
through deep learning and model re-
duction. We validate our approach
on the retina  demonstrating how
only three cell-types with different
ON/OFF and fast/slow spatiotempo-
ral ﬁltering properties can nonlin-
early interact to simultaneously gen-
erate diverse retinal responses.

In summary  in the case of the retina  we have shown that complex CNN models obtained via machine
learning can not only mimic sensory responses to rich natural scene stimuli  but also can serve as a
powerful and automatic mechanism for generating valid scientiﬁc hypotheses about computational
mechanisms in the brain  when combined with our proposed model reduction methods (Fig. 6).
Applying this approach to the retina yields conceptual insights into how a single model consisting
of multiple nonlinear pathways with diverse spatiotemporal ﬁltering properties can explain decades
of painstaking physiological studies of the retina. This suggests in some sense an inverse roadmap
for experimental design in sensory neuroscience. Rather than carefully designing special artiﬁcial
stimuli to probe speciﬁc sensory neural responses  and generating individual models tailored to each
stimulus  one could instead ﬁt a complex neural network model to neural responses to a rich set of
ethologically relevant natural stimuli  and then apply model reduction methods to understand how
different parts of a single model can simultaneously account for responses to artiﬁcial stimuli across
many experiments. The interpretable mechanisms extracted from model reduction then constitute
speciﬁc hypotheses that can be tested in future experiments. Moreover  the complex model itself can
be used to design new stimuli  for example by searching for stimuli that yield divergent responses
in the complex model  versus a simpler model of the same sensory region. Such stimulus searches
could potentially elucidate functional reasons for the existence of model complexity.
In future studies  it will be interesting to conduct a systematic exploration of universality and
individuality [28] in the outcome of model reduction procedures applied to deep learning models
which recapitulate desired phenomena  but are obtained from different initializations  architectures 
and experimental recordings. An intriguing hypothesis is that the reduced models required to explain
speciﬁc neurobiological phenomena arise as universal computational invariants across the ensemble
of deep learning models parameterized by these various design choices  while many other aspects of
such deep learning models may individually vary across these choices  reﬂecting mere accidents of
history in initialization  architecture and training.
It would also be extremely interesting to stack this model reduction procedure to obtain multilayer
reduced models that extract computational mechanisms and conceptual insights into deeper CNN
models of higher cortical regions. The validation of such extracted computational mechanisms would
require further experimental probes of higher responses with carefully chosen stimuli  perhaps even
stimuli chosen to maximize responses in the deep CNN model itself [29  30]. Overall the success of
this combined deep learning and model reduction approach to scientiﬁc inquiry in the retina  which
was itself not at all a priori obvious before this work  sets a foundation for future studies to explore
this combined approach deeper in the brain.

Acknowledgments

We thank Daniel Fisher for insightful discussions and support. We thank the Masason foundation
(HT)  grants from the NEI (R01EY022933  R01EY025087  P30-EY026877) (SAB)  and the Simons 
James S. McDonnell foundations  and NSF Career 1845166 (SG) for funding.

9

1. High-throughput neural recordings2. Train deep-learning model and perform neurophysiology experiments in silico3. Identify important sub-circuits
and derive an array of interpretable models236Figure 6 FinalReferences
[1] Lane McIntosh  Niru Maheswaranathan  Aran Nayebi  Surya Ganguli  and Stephen Baccus. Deep learning
models of the retinal response to natural scenes. Advances in neural information processing systems  pages
1369–1377  2016.

[2] Niru Maheswaranathan  Lane T. McIntosh  Hidenori Tanaka  Satchel Grant  David B. Kastner  Josh
Melander  Luke Brezovec  Aran Nayebi  Julia Wang  Surya Ganguli  and Stephen A. Baccus. The dynamic
neural code of the retina for natural scenes. bioRxiv  2019. doi: 10.1101/340943.

[3] Daniel L. K. Yamins  Ha Hong  Charles F. Cadieu  Ethan A. Solomon  Darren Seibert  and James J. DiCarlo.
Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proceedings
of the National Academy of Sciences  111(23):8619–8624  2014. doi: 10.1073/pnas.1403112111.

[4] Seyed-Mahdi Khaligh-Razavi and Nikolaus Kriegeskorte. Deep supervised  but not unsupervised  models

may explain it cortical representation. PLoS computational biology  10(11):e1003915  2014.

[5] Umut Güçlü and Marcel AJ van Gerven. Deep neural networks reveal a gradient in the complexity of
neural representations across the ventral stream. The Journal of Neuroscience  35(27):10005–10014  2015.

[6] Santiago A Cadena  George H Denﬁeld  Edgar Y Walker  Leon A Gatys  Andreas S Tolias  Matthias
Bethge  and Alexander S Ecker. Deep convolutional models improve predictions of macaque v1 responses
to natural images. bioRxiv  page 201764  2017.

[7] David GT Barrett  Ari S Morcos  and Jakob H Macke. Analyzing biological and artiﬁcial neural networks:

challenges with opportunities for synergy? Current opinion in neurobiology  55:55–64  2019.

[8] Joshua I Glaser  Ari S Benjamin  Roozbeh Farhoodi  and Konrad P Kording. The roles of supervised

machine learning in systems neuroscience. Progress in neurobiology  2019.

[9] Mukund Sundararajan  Ankur Taly  and Qiqi Yan. Axiomatic attribution for deep networks. In Proceedings

of the 34th International Conference on Machine Learning  pages 3319–3328  2017.

[10] Kedar Dhamdhere  Mukund Sundararajan  and Qiqi Yan. How important is a neuron. In International

Conference on Learning Representations  2019.

[11] Tim Gollisch and Markus Meister. Eye smarter than scientists believed: neural computations in circuits of

the retina. Neuron  65(2):150–164  2010.

[12] Greg Schwartz  Rob Harris  David Shrom  and Michael J Berry II. Detection and prediction of periodic

patterns by the retina. Nature neuroscience  10(5):552  2007.

[13] Greg Schwartz and Michael J Berry 2nd. Sophisticated temporal pattern recognition in retinal ganglion

cells. Journal of neurophysiology  99(4):1787–1798  2008.

[14] Tim Gollisch and Markus Meister. Rapid neural coding in the retina with relative spike latencies. Science 

319(5866):1108–1111  2008.

[15] Greg Schwartz  Sam Taylor  Clark Fisher  Rob Harris  and Michael J Berry II. Synchronized ﬁring among

retinal ganglion cells signals motion reversal. Neuron  55(6):958–969  2007.

[16] Michael J Berry II  Iman H Brivanlou  Thomas A Jordan  and Markus Meister. Anticipation of moving

stimuli by the retina. Nature  398(6725):334  1999.

[17] Birgit Werner  Paul B Cook  and Christopher L Passaglia. Complex temporal response patterns with a

simple retinal circuit. Journal of neurophysiology  100(2):1087–1097  2008.

[18] Juan Gao  Greg Schwartz  Michael J Berry  and Philip Holmes. An oscillatory circuit underlying the
detection of disruptions in temporally-periodic patterns. Network: Computation in Neural Systems  20(2):
106–135  2009.

[19] Tim Gollisch and Markus Meister. Modeling convergent on and off pathways in the early visual system.

Biological cybernetics  99(4-5):263–278  2008.

[20] Eric Y Chen  Janice Chou  Jeongsook Park  Greg Schwartz  and Michael J Berry. The neural circuit
mechanisms underlying the retinal response to motion reversal. Journal of Neuroscience  34(47):15557–
15575  2014.

10

[21] Eric Y Chen  Olivier Marre  Clark Fisher  Greg Schwartz  Joshua Levy  Rava Azeredo da Silveira  and
Michael J Berry. Alert response to motion onset in the retina. Journal of Neuroscience  33(1):120–132 
2013.

[22] David I Vaney  Benjamin Sivyer  and W Rowland Taylor. Direction selectivity in the retina: symmetry and

asymmetry in structure and function. Nature Reviews Neuroscience  13(3):194  2012.

[23] Masakazu Konishi. Coding of auditory space. Annual review of neuroscience  26(1):31–55  2003.

[24] Eve Marder and Dirk Bucher. Understanding circuit dynamics using the stomatogastric nervous system of

lobsters and crabs. Annu. Rev. Physiol.  69:291–316  2007.

[25] Theodore H Bullock  Michael H Hofmann  Frederick K Nahm  John G New  and James C Prechtl. Event-
related potentials in the retina and optic tectum of ﬁsh. Journal of Neurophysiology  64(3):903–914 
1990.

[26] Theodore H Bullock  Sacit Karamürsel  Jerzy Z Achimowicz  Michael C McClune  and Canan Ba¸sar-
Eroglu. Dynamic properties of human visual evoked and omitted stimulus potentials. Electroencephalog-
raphy and clinical neurophysiology  91(1):42–53  1994.

[27] Nikhil Rajiv Deshmukh. Complex computation in the retina. PhD thesis  Princeton University  2015.

[28] Niru Maheswaranathan  Alex H Williams  Matthew D Golub  Surya Ganguli  and David Sussillo. Univer-
sality and individuality in neural dynamics across large populations of recurrent networks. Advances in
neural information processing systems  2019.

[29] Pouya Bashivan  Kohitij Kar  and James J DiCarlo. Neural population control via deep image synthesis.

Science  364(6439):eaav9436  2019.

[30] Edgar Y Walker  Fabian H Sinz  Erick Cobos  Taliah Muhammad  Emmanouil Froudarakis  Paul G Fahey 
Alexander S Ecker  Jacob Reimer  Xaq Pitkow  and Andreas S Tolias. Inception loops discover what
excites neurons most using deep predictive models. Nature neuroscience  22(12):2060–2065  2019.

11

,Hidenori Tanaka
Aran Nayebi
Niru Maheswaranathan
Lane McIntosh
Stephen Baccus
Surya Ganguli