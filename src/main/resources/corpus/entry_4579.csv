2007,Receptive Fields without Spike-Triggering,Stimulus selectivity of sensory neurons is often characterized by estimating their receptive field properties such as orientation selectivity. Receptive fields are usually derived from the mean (or covariance) of the spike-triggered stimulus ensemble. This approach treats each spike as an independent message but does not take into account that information might be conveyed through patterns of neural activity that are distributed across space or time. Can we find a concise description for the processing of a whole population of neurons analogous to the receptive field for single neurons? Here  we present a generalization of the linear receptive field which is not bound to be triggered on individual spikes but can be meaningfully linked to distributed response patterns. More precisely  we seek to identify those stimulus features and the corresponding patterns of neural activity that are most reliably coupled. We use an extension of reverse-correlation methods based on canonical correlation analysis. The resulting population receptive fields span the subspace of stimuli that is most informative about the population response. We evaluate our approach using both neuronal models and multi-electrode recordings from rabbit retinal ganglion cells. We show how the model can be extended to capture nonlinear stimulus-response relationships using kernel canonical correlation analysis  which makes it possible to test different coding mechanisms. Our technique can also be used to calculate receptive fields from multi-dimensional neural measurements such as those obtained from dynamic imaging methods.,Receptive Fields without Spike- Triggering

Jakob H Macke

j a k o b@ t u e bi n g e n . mpg . de

G ¨unther Zeck

z e c k @ n e u r o . mpg . de

Max Planck Ins titute for B iological Cybernetics

Max Planck Ins titute of Neurobiology

S pemanns tras s e 41

72076 T ¨ubingen  Germany

Am Klopfers pitze 1 8

8 21 5 2 Martins ried  Germany

Matthias Bethge

mbe t h g e @ t u e bi n g e n . mp g . de

Max Planck Ins titute for B iological Cybernetics

S pemanns tras s e 41

72076 T ¨ubingen  Germany

Abstract

S timulus s electivity of s ens ory neurons is often characterized by es timating their
receptive ﬁeld properties s uch as orientation s electivity. Receptive ﬁelds are us u-
ally derived from the mean (or covariance) of the s pike-triggered s timulus ens em-
ble. This approach treats each s pike as an independent mes s age but does not take
into account that information might be conveyed through patterns of neural activ-
ity that are dis tributed acros s s pace or time. Can we ﬁnd a concis e des cription for
the proces s ing of a whole population of neurons analogous to the receptive ﬁeld
for s ingle neurons ? Here  we pres ent a generalization of the linear receptive ﬁeld
which is not bound to be triggered on individual s pikes but can be meaningfully
linked to dis tributed res pons e patterns . More precis ely  we s eek to identify thos e
s timulus features and the corres ponding patterns of neural activity that are mos t
reliably coupled. We us e an extens ion of revers e-correlation methods bas ed on
canonical correlation analys is . The res ulting population receptive ﬁelds s pan the
s ubs pace of s timuli that is mos t informative about the population res pons e. We
evaluate our approach us ing both neuronal models and multi-electrode recordings
from rabbit retinal ganglion cells . We s how how the model can be extended to
capture nonlinear s timulus -res pons e relations hips us ing kernel canonical correla-
tion analys is   which makes it pos s ible to tes t different coding mechanis ms . Our
technique can als o be us ed to calculate receptive ﬁelds from multi-dimens ional
neural meas urements s uch as thos e obtained from dynamic imaging methods .

1

Introduction

Vis ual input to the retina cons is ts of complex light intens ity patterns . The interpretation of thes e
patterns cons titutes a challenging problem: for computational tas ks like object recognition  it is not
clear what information about the image s hould be extracted and in which format it s hould be repre-
s ented. S imilarly  it is difﬁcult to as s es s what information is conveyed by the multitude of neurons
in the vis ual pathway. Right from the ﬁrs t s ynaps e  the information of an individual photoreceptor
is s ignaled to many different cells with different temporal ﬁltering properties   each of which is only
a s mall unit within a complex neural network [ 20] . Even if we leave the difﬁculties impos ed by
nonlinearities and feedback as ide  it is hard to judge what the contribution of any particular neuron
is to the information trans mitted.

1

The prevalent tool for characterizing the behavior of s ens ory neurons   the s pike triggered average 
is bas ed on a quas i-linear model of neural res pons es [ 1 5 ] . For the s ake of clarity  we cons ider an
idealized model of the s ignaling channel

.

.

.

.

.

.

y = W x + ξ  

(1 )
  yN ) T denotes the vector of neural res pons es   x the s timulus parameters   W =
where y = ( y1  
  wN ) T the ﬁlter matrix with row ‘ k ’ containing the receptive ﬁeld wk of neuron k   and ξ
( w1  
is the nois e. The s pike-triggered average only allows des cription of the s timulus -res pons e function
(i. e.
In order to unders tand the collective behavior of a
neuronal population  we rather have to unders tand the behavior of the matrix W  and the s tructure
of the nois e correlations Σ ξ : B oth of them inﬂuence the feature s electivity of the population.

the wk ) of one s ingle neuron at a time.

Can we ﬁnd a compact des cription of the features that a neural ens emble is mos t s ens itive to? In
the cas e of a s ingle cell  the receptive ﬁeld provides s uch a des cription: It can be interpreted as the
“favorite s timulus ” of the neuron  in the s ens e that the more s imilar an input is to the receptive ﬁeld 
the higher is the s piking probability  and thus the ﬁring rate of the neuron. In addition  the receptive
ﬁeld can eas ily be es timated us ing a s pike-triggered average  which  under certain as s umptions  
yields the optimal es timate of the receptive ﬁeld in a linear-nonlinear cas cade model [ 1 1 ] .

If we are cons idering an ens emble of neurons rather than a s ingle neuron  it is not obvious what to
trigger on: This requires as s umptions about what patterns of s pikes or modulations in ﬁring rates
acros s the population carry information about the s timulus . Rather than addres s ing the ques tion
“what features of the s timulus are correlated with the occurence of s pikes ”  the ques tion now is :
“What s timulus features are correlated with what patterns of s piking activity? ” [ 1 4] . Phras ed in the
language of information theory  we are s earching for the s ubs pace that contains mos t of the mu-
tual information between s ens ory inputs and neuronal res pons es . B y this dimens ionality reduction
technique  we can ﬁnd a compact des cription of the proces s ing of the population.

As an efﬁcient implementation of this s trategy  we pres ent an extens ion of revers e-correlation meth-
ods bas ed on canonical correlation analys is . The res ulting population receptive ﬁelds (PRFs ) are not
bound to be triggered on individual s pikes but are linked to res pons e patterns that are s imultaneous ly
determined by the algorithm.

We calculate the PRF for a population cons is ting of uniformly s paced cells with center-s urround
receptive ﬁelds and nois e correlations   and es timate the PRF of a population of rabbit retinal ganglion
cells from multi-electrode recordings .
In addition  we s how how our method can be extended to
explore different hypothes es about the neural code  s uch as s pike latencies or interval coding  which
require nonlinear read out mechanis ms .

2 From reverse correlation to canonical correlation

m .
We regard the s timulus at time t as a random variable Xt ∈ R
For s implicity  we as s ume that the s timulus cons is ts of Gaus s ian white nois e  i. e. E( X) = 0 and
Cov( X) = I.

n   and the neural res pons e as Yt ∈ R

The s pike-triggered average a of a neuron can be motivated by the fact that it is the direction in
s timulus -s pace maximizing the correlation-coefﬁcient

ρ =

�

Cov( aT X  Y1 )
Var( aT X) Var( Y1 )

.

(2)

between the ﬁltered s timulus aT X and a univariate neural res pons e Y1 .
In the cas e of a neural
population  we are not only looking for the s timulus feature a  but als o need to determine what
pattern of s piking activity b it is coupled with. The natural extens ion is to s earch for thos e vectors
a1 and b 1 that maximize

.

(3 )

�

ρ1 =

Cov( aT
Var( aT

1 X  b T
1 Y)
1 X) Var( b T

1 Y)

We interpret a1 as the s timulus ﬁlter whos e output is maximally correlated with the output of the
“res pons e ﬁlter” b 1 . Thus   we are s imultaneous ly s earching for features of the s timulus that the
neural s ys tem is s elective for  and the patterns of activity that it us es to s ignal the pres ence or abs ence

2

of this feature. We refer to the vector a1 as the (ﬁrs t) population receptive ﬁeld of the population 
and b 1 is the response feature corres ponding to a1 . If a hypothetical neuron receives input from the
population  and wants to decode the pres ence of the s timulus a1   the weights of the optimal linear
readout [ 1 6] could be derived from b 1 .

Canonical Correlation Analys is (CCA) [ 9]
that
maximize (3 ): We denote the covariances of X and Y by Σ x   Σ y   the cros s -covariance by Σ x y   and
the whitened cros s -covariance by

is an algorithm that ﬁnds the vectors a1 and b 1

C = Σ ( − 1 / 2 )

x

Σ x y Σ ( − 1 / 2 )

y

.

(4)

Let C = UDV T denote the s ingular value decompos ition of C  where the entries of the diagonal
matrix D are non-negative and decreas ing along the diagonal. Then  the k -th pair of canonical
variables is given by ak = Σ
vk   where uk and vk are the k -th column
the k -th diagonal
vectors of U and V   res pectively. Furthermore  the k -th s ingular value of C  i. e.
entry of D is the correlation-coefﬁcient ρk of aT
j X
are uncorrelated for i �= j.

k Y. The random variables aT

uk and b k = Σ

i X and aT

k Xand b T

( − 1 / 2 )
x

( − 1 / 2 )
y

Importantly  the s olution for the optimization problem in CCA is unique and can be computed ef-
ﬁciently via a s ingle eigenvalue problem. The population receptive ﬁelds and the characteris tic
patterns are found by a joint optimization in s timulus and res pons e s pace. Therefore  one does
not need to know—or as s ume—a priori what features the population is s ens itive to  or what s pike
patterns convey the information.

The ﬁrs t K PRFs form a bas is for the s ubs pace of s timuli that the neural population is mos t s ens itive
to  and the individual bas is vectors ak are s orted according to their “informativenes s ” [ 1 3   1 7] .

The mutual information between two one-dimens ional Gaus s ian Variables with correlation ρ is given
by MIG a us s = − 1
2 log( 1 − ρ2 )   s o maximizing correlation coefﬁcients is equivalent to maximizing
mutual information [ 3 ] . As s uming the neural res pons e Y to be Gaus s ian  the s ubs pace s panned by
the ﬁrs t K vectors BK = ( b 1  
  b K ) is als o the K-s ubs pace of s timuli that contains the maximal
amount of mutual information between s timuli and neural res pons e. That is

.

.

.

`

´

“

“

det

T

B

Σ y B

”

”

BK = argmax

B ∈ R n × k

det

B T

Σ y − Σ T

x y Σ

( − 1 )
x

Σ x y

B

.

(5 )

Thus  
in terms of dimens ionality reduction  CCA optimizes the s ame objective as oriented PCA
[ 5 ] .
In contras t to oriented PCA  however  CCA does not require one to know explicitly how the
res pons e covariance Σ y = Σ s + Σ ξ s plits into s ignal Σ s and nois e Σ ξ covariance. Ins tead  it us es the
cros s -covariance Σ x y which is directly available from revers e correlation experiments . In addition 
CCA not only returns the mos t predictable res pons e features b 1  
. b K but als o the mos t predictive
s timulus components AK = ( a1  
For general Y and for s timuli X with elliptically contoured dis tribution  MIG a us s − J( AT X) pro-
vides a lower bound to the mutual information between AT X and B T Y  where

. aK ) .

.

.

.

.

T

J( A

X) =

1
2

log( det( 2 πeA

T

Σ x A) ) − h( A

T

X)

(6)

is the Negentropy of AT X  and h( AT X)
its differential entropy. S ince for elliptically contoured
dis tributions J( AT X) does not depend on A  the PRFs can be s een as the s olution of a variational
approach  maximizing a lower bound to the mutual information. Maximizing mutual information
directly is hard  requires extens ive amounts of data  and us ually multiple repetitions of the s ame
s timulus s equence.

3 The receptive ﬁeld of a population of neurons

3.1 The effect of tuning functions and noise correlations

To illus trate the relations hip between the tuning-functions of individual neurons and the PRFs [ 22]  
we calculate the ﬁrs t PRF of a s imple one-dimens ional population model cons is ting of center-

3

s urround neurons . Each tuning function is modeled by a “Difference of Gaus s ians ” (DOG)

„

“

«

”

 

„

!

«

f ( x) = exp

−

1
2

x − c

σ

2

− A exp

−

2

1
2

x − c

η

(7)

whos e centers c are uniformly dis tributed over the real axis . The width η of the negative Gaus s ian is
s et to be twice as large as the width σ of the pos itive Gaus s ian. If the area of both Gaus s ians is the
s ame ( A = 1 )   the DC component of the DOG-ﬁllter is zero  i. e.
the neuron is not s ens itive to the
mean luminance of the s timulus . If the ratio between both areas becomes s ubs tantially unbalanced 
the DC component will become the larges t s ignal ( A ≈ 0) .

In addition to the parameter A  we will s tudy the length s cale of nois e correlations λ [ 1 8 ] . S peciﬁ-
cally  we as s ume exponentially decaying nois e correlation with Σ ξ ( s ) = exp( − | s | / λ) .

As this model is invariant under s patial s hifts   the ﬁrs t PRF can be calculated by ﬁnding the s patial
frequency at which the S NR is maximal. That is   the ﬁrs t PRF can be us ed to es timate the pas s band
of the population trans fer function. The S NR is given by

„

„

««

S NR( ω) =

2

ω

2

1 + λ
2 λ

− ω 2 σ 2

e

+ A

2

e

− η 2 ω 2

− 2 Ae

σ 2 + η 2

2

ω 2

−

2

.

(8 )

The pas s band of the ﬁrs t population ﬁlter moves as a function of both parameters A and λ. It equals
large imbalance) and s mall λ (i. e. s hort correlation length). In
the DC component for s mall A (i. e.
this cas e  the mean intens ity is the s timulus property that is mos t faithfully s ignaled by the ens emble.

A

1

0.8

0.6

0.4

0.2

 

 

0.5

1
λ

1.5

2

1

0.8

0.6

0.4

0.2

0

Figure 1 : S patial frequency of the ﬁrs t PRF for the model des cribed above. λ is the length-s cale of
the nois e correlations   A is the weight of the negative Gaus s ian in the DOG-model. The region in
the bottom left corner (bounded by the white line) is the part of the parameter-s pace in which the
PRF equals the DC component.

3.2 The receptive ﬁeld of an ensemble of retinal ganglion cells

We mapped the population receptive ﬁelds of rabbit retinal ganglion cells recorded with a whole-
mount preparation. We are not primarily interes ted in prediction performance [ 1 2]   but rather in
dimens ionality reduction: We want to characterize the ﬁltering properties of the population.

The neurons were s timulated with a 1 6 × 1 6 checkerboard cons is ting of binary white nois e which
was updated every 20ms . The experimental procedures are des cribed in detail in [ 21 ] . After s pike-
s orting  s pike trains from 32 neurons were binned at 2 0ms res olution  and the res pons e of a neuron
to a s timulus at time t was deﬁned to cons is t of the the s pike-counts in the 1 0 bins between 40ms
and 240ms after t. Thus   each population res pons e Yt is a 3 20 dimens ional vector.

Figure 3 . 2 A) dis plays the ﬁrs t 6 PRFs   the corres ponding patterns of neural activity (B ) and their
correlation coefﬁcients ρk (which were calculated us ing a cros s -validation procedure). It can be s een
that the PRFs look very different to the us ual center-s urrond s tructure of retinal ganglion. However 
one s hould keep in mind that it is really the s pace s panned by the PRFs that is relevant  and thus be
careful when interpreting the actual ﬁlter s hapes [ 1 5 ] .

For comparis on  we als o plotted the s ingle-cell receptive ﬁelds in Figure 3 . 2 C)  and their projections
into the s paced s panned by the ﬁrs t 6 PRFs . Thes e plots s ugges t that a s mall number of PRFs might

4

�

be s ufﬁcient to approximate each of the receptive ﬁelds . To determine the dimens ionality of the
relevant s ubs pace  we analyzed the correlation-coefﬁcients ρk . The Gaus s ian Mutual Information
MIG a us s = − 1
is an es timate of the information contained in the s ubs pace
2
s panned by the ﬁrs t K PRFs . B as ed on this meas ure  a 1 2 dimens ional s ubs pace accounts for 90%
of the total information.

K
k = 1 log( 1 − ρ2
k )

In order to link the empirically es timated PRFs with the theoretical analys is in s ection 3 . 1   we
calculated the s pectral properties of the ﬁrs t PRF. Our analys is revealed that mos t of the power is in
the low frequencies   s ugges ting that the population is in the parameter-regime where the s ingle-cell
receptive ﬁelds have power in the DC-component and the nois e-correlations have s hort range  which
is certainly reas onable for retinal ganglion cells [ 4] .

0.51

0.44

0.38

0.35

0.29

0.27

A)

B )

x
e
d
n

i
 

n
o
r
u
e
N

5
10
15
20
25
30

5
10
15
20
25
30

5
10
15
20
25
30

5
10
15
20
25
30

5
10
15
20
25
30

 

0.2

0

−0.2

160

220

5
10
15
20
25
30
220

 
40

40

160

Time →

220

40

160

220

40

160

220

40

160

220

40

160

 
 
 
 
 

C)
F
R

 
 
 
 
 

F
R

 
.
j
o
r
P

 
 
 
 
 

F
R

 
 
 
 
 

F
R

 
.
j

o
r
P

Figure 2: The population receptive ﬁelds of a group of 32 retinal ganglion cells : A) the ﬁrs t 6 PRFs  
as s orted by the correlation coefﬁcient ρk B ) the res pons e features bk coupled with the PRFs . Each
row of each image corres ponds to one neuron  and each column to one time-bin. B lue color denotes
enhanced activity  red s uppres s ed. It can be s een that only a s ubs et of neurons contributed to the ﬁrs t
6 PRFs . C) The s ingle-cell receptive ﬁelds of 2 4 neurons from our population  and their projections
into the s pace s panned by the 6 PRFs .

5

A)

k

ρ
 
s
t

i

n
e
c
i
f
f

e
o
c
 
s
n
o

i
t

l

a
e
r
r
o
C

0.6
0.5
0.4
0.3
0.2
0.1
0
−0.1

1

5

10 15 20

30
PRF index

40

50

B )

I

M

 
f

 

o
e
g
a

t

n
e
c
r
e
P

100
90
80

60

40

20

0

1

5

10

15

20

Dimensionality of subspace

30

40

50

Figure 3 : A) Correlation coefﬁcients ρk for the PRFs . Es timates and error-bars are calculated us ing
a cros s -validation procedure. B ) Gaus s ian-MI of the s ubs pace s panned by the ﬁrs t K PRFs .

4 Nonlinear extensions using Kernel Canonical Correlation Analysis

Thus far  our model is completely linear: We as s ume that the s timulus is linearly related to the
neural res pons es   and we als o as s ume a linear readout of the res pons e.
In this s ection  we will
explore generalizations of the CCA model us ing Kernel CCA: B y embedding the s timulus -s pace
nonlinearly in a feature s pace  nonlinear codes can be des cribed.

Kernel methods provide a framework for extending linear algorithms to the nonlinear cas e [ 8 ] . After
projecting the data into a feature s pace via a feature maps φ and ψ  a s olution is found us ing linear
In the cas e of Kernel CCA [ 1   1 0  2  7] one s eeks to ﬁnd a linear
methods in the feature s pace.
ˆX = φ( X) and ˆY = ψ( Y)   rather than between X and
relations hip between the random variables
Y. If an algorithm is purely deﬁned in terms of dot-products   and if the dot-product in feature s pace
k( s   t) = � ψ( s )   ψ( t) � can be computed efﬁciently  then the algorithm does not require explicit
calculation of the feature maps φ and ψ. This “kernel-trick” makes it pos s ible to work in high-
It is worth mentioning that the s pace of patterns Y its elf
(or inﬁnite)-dimens ional feature s paces .
does not have to be a vector s pace. Given a data-s et x 1 .
. x n   it s ufﬁces to know the dot-products
between any pair of training points   Ki j : = � ψ( yi )   ψ( yj ) � .

.

The kernel function k( s   t) can be s een as a s imiliarity meas ure.
It incorporates our as s umptions
about which s pike-patterns s hould be regarded as s imilar “mes s ages ”. Therefore  the choice of the
kernel-function is clos ely related to s peciﬁng what the s earch-s pace of potential neural codes is . A
number of dis tance- and kernel-functions [ 6  1 9] have been propos ed to compute dis tances between
s pike-trains . They can be des igned to take into account precis ely timed pattern of s pikes   or to be
invariant to certain trans formations s uch as temporal jitter.

We illus trate the concept on s imulated data: We will us e a s imilarity meas ure bas ed on the metric
D interval
[ 1 9] to es timate the receptive ﬁeld of a neuron which does not us e its ﬁring rate  but rather
the occurrence of s peciﬁc inters pike intervals to convey information about the s timulus . The metric
D interval
between two s pike-trains is es s entially the cos t of matching their intervals by s hifting  adding
or deleting s pikes .
In theory  this function is not guaranteed
to be pos itive deﬁnite  which could lead to numerical problems   but we did not encounter any in
our s imulation. ) If we cons ider coding-s chemes that are bas ed on patterns of s pikes   the methods
des cribed here become us eful even for the analys is of s ingle neurons . We will here concentrate on a
s ingle neuron  but the analys is can be extended to patterns dis tributed acros s s everal neurons .

(We s et k( s   t) = exp( − D( s   t) .

Our hypothetical neuron encodes information in a pattern cons is ting of three s pikes : The relative
timing of the s econd s pike is informative about the s timulus : The bigger the correlation between
receptive ﬁeld and s timulus � r  s t �   the s horter is the interval. If the receptive ﬁeld is very dis s imilar
to the s timulus   the interval is long. While the timing of the s pikes relative to each other is precis e 
there is jitter in the timing of the pattern relative to the s timulus . Figure 4 A) is a ras ter plot of
s imulated s pike-trains from this model  ordered by � r  s t � . We als o included nois e s pikes at random
times .

6

A)

C)

D)

B )

i

s
n
a
r
t
 

i

e
k
p
S

0

50

100

Time →

150

200

Figure 4: Coding by s pike patterns : A) Receptive ﬁeld of neuron des cribed in S ection 4. B ) A
s ubs et of the s imulated s pike-trains   s orted with res pect to the s imilarity between the s hown s timulus
and the receptive ﬁeld of the model. The interval between the ﬁrs t two informative s pikes in each
trial is highlighted in red. C) Receptive ﬁeld recovered by Kernel CCA  the correlation coefﬁcient
between real and es timated receptive ﬁeld is 0. 93 . D) Receptive ﬁeld derived us ing linear decoding 
correlation coefﬁcient is 0. 02 .

Us ing thes e s pike-trains   we tried to recover the receptive ﬁeld r without telling the algorithm what
the indicating pattern was . Each s timulus was s hown only once  and therefore  that every s pike-
pattern occurred only once. We s imulated 5 000 s timulus pres entations for this model  and applied
Kernel CCA with a linear kernel on the s timuli  and the alignment-s core on the s pike-trains . B y
us ing incomplete Choles ky decompos itions [ 2]   one can compute Kernel CCA without having to
calculate the full kernel matrix. As many kernels on s pike trains are computationally expens ive  this
trick can res ult in s ubs tantial s peed-ups of the computation. The receptive ﬁeld was recovered (s ee
Figure 4)  des pite the highly nonlinear encoding mechanis m of the neuron. For comparis on  we als o
s how what receptive ﬁeld would be obtained us ing linear decoding on the indicated bins .

Although this neuron model may s eem s lightly contrived 
in
principle  receptive ﬁelds can be es timated even if the ﬁring rate gives no information at all about
the s timulus   and the encoding is highly nonlinear. Our algorithm does not only look at patterns that
occur more often than expected by chance  but als o takes into account to what extent their occurrence
is correlated to the s ens ory input.

it is a good proof of concept that 

5 Conclusions

We s et out to ﬁnd a us eful des cription of the s timulus -res pons e relations hip of an ens emble of
neurons akin to the concept of receptive ﬁeld for s ingle neurons . The population receptive ﬁelds are
found by a joint optimization over s timuli and s pike-patterns   and are thus not bound to be triggered
by s ingle s pikes .

We es timated the PRFs of a group of retinal ganglion cells   and found that the ﬁrs t PRF had mos t
s pectral power in the low-frequency bands   cons is tent with our theoretical analys is . The s timulus
we us ed was a white-nois e s equence—it will be interes ting to s ee how the informative s ubs pace and
its s pectral properties change for different s timuli s uch as colored nois e. The ganglion cell layer of
the retina is a s ys tem that is relatively well unders tood at the level of s ingle neurons . Therefore 
our res ults can readily be compared and connected to thos e obtained us ing conventional analys is
techniques . However  our approach has the potential to be es pecially us eful in s ys tems in which the
functional s igniﬁcance of s ingle cell receptive ﬁelds is difﬁcult to interpret.

7

We us ually as s umed that each dimens ion of the res pons e vector Y repres ents an electrode-recording
from a s ingle neuron. However  the vector Y could als o repres ent any other multi-dimens ional mea-
s urement of brain activity: For example  imaging modalities s uch as voltage-s ens itive dye imaging
yield meas urements at multiple pixels s imultaneous ly. Data from electro-phys iological data  e. g. lo-
cal ﬁeld potentials   are often analyzed in frequency s pace  i. e. by looking at the energy of the s ignal
in different frequency bands . This als o res ults in a multi-dimens ional repres entation of the s ignal.
Us ing CCA  receptive ﬁelds can readily be es timated from thes e kinds of repres entations without
limiting attention to s ingle channels or extracting neural events .

Acknowledgments

We would like to thank A Gretton and J Eichhorn for us eful dis cus s ions   and F J¨akel  J B utler and S Liebe for
comments on the manus cript.

References

[ 1 ] S . Akaho. A kernel method for canonical correlation analys is . In International Meeting ofPsychometric

Society  Osaka  2001 .

[ 2] F. R. B ach and M. I. Jordan. Kernel independent component analys is . Journal ofMachine Learning

Research  3 : 1 : 48   2002.

[ 3 ] G. Chechik  A. Globers on  N. Tis hby  and Y. Weis s . Information B ottleneck for Gaus s ian Variables . The

Journal ofMachine Learning Research  6: 1 65 –1 8 8   2005 .

[ 4] S . Devries and D. B aylor. Mos aic Arrangement of Ganglion Cell Receptive Fields in Rabbit Retina.

Journal ofNeurophysiology  78 (4): 2048 –2060  1 997.

[ 5 ] K. Diamantaras and S . Kung. Cros s -correlation neural network models . Signal Processing  IEEE Trans-

actions on  42(1 1 ): 3 21 8 –3 223   1 994.

[ 6] J. Eichhorn  A. Tolias   A. Zien  M. Kus s   C. E. Ras mus s en  J. Wes ton  N. Logothetis   and B . S ch ¨olkopf.
Prediction on s pike data us ing kernel algorithms . In S . Thrun  L. S aul  and B . S ch ¨olkopf  editors   Advances
in Neural Information Processing Systems 1 6. MIT Pres s   Cambridge  MA  2004.

[ 7] K. Fukumizu  F. R. B ach  and A. Gretton. S tatis tical cons is tency of kernel canonical correlation analys is .

Journal ofMachine Learning Research  2007.

[ 8 ] T. Hofmann  B . S ch ¨olkopf  and A. S mola. Kernel methods in machine learning. Annals ofStatistics (in

press)  2007.

[ 9] H. Hotelling. Relations between two s ets of variates . Biometrika  28 : 3 21 –3 77  1 93 6.

[ 1 0] T. Melzer  M. Reiter  and H. B is chof. Nonlinear feature extraction us ing generalized canonical correlation
analys is . In Proc. ofInternational Conference on Artiﬁcial Neural Networks (ICANN)  pages 3 5 3 –3 60  8
2001 .

[ 1 1 ] L. Panins ki. Convergence properties of three s pike-triggered analys is techniques . Network  1 4(3 ): 43 7–64 

Aug 2003 .

[ 1 2] J. W. Pillow  L. Panins ki  V. J. Uzzell  E. P. S imoncelli  and E. J. Chichilnis ky. Prediction and decoding
of retinal ganglion cell res pons es with a probabilis tic s piking model. J Neurosci  25 (47): 1 1 003 –1 3   2005 .
[ 1 3 ] J. W. Pillow and E. P. S imoncelli. Dimens ionality reduction in neural models : an information-theoretic

generalization of s pike-triggered average and covariance analys is . J Vis  6(4): 41 4–28   2006.

[ 1 4] M. J. S chnitzer and M. Meis ter. Multineuronal ﬁring patterns in the s ignal from eye to brain. Neuron 

3 7(3 ): 499–5 1 1   2003 .

[ 1 5 ] O. S chwartz  J. W. Pillow  N. C. Rus t  and E. P. S imoncelli. S pike-triggered neural characterization. J

Vis  6(4): 48 4–5 07  2006.

[ 1 6] H. S . S eung and H. S ompolins ky. S imple models for reading neuronal population codes . Proc Natl Acad

Sci U S A  90(22): 1 0749–5 3   1 993 .

[ 1 7] T. S harpee  N. Rus t  and W. B ialek. Analyzing neural res pons es to natural s ignals : maximally informative

dimens ions . Neural Comput  1 6(2): 223 –5 0  2004.

[ 1 8 ] H. S ompolins ky  H. Yoon  K. Kang  and M. S hamir. Population coding in neuronal s ys tems with corre-

lated nois e. Phys Rev E Stat Nonlin Soft Matter Phys  64(5 Pt 1 ): 05 1 904  2001 .

[ 1 9] J. Victor. S pike train metrics . Curr Opin Neurobiol  1 5 (5 ): 5 8 5 –92  2005 .
[ 20] H. W¨as s le. Parallel proces s ing in the mammalian retina. Nat Rev Neurosci  5 (1 0): 747–5 7  2004.
[ 21 ] G. M. Zeck  Q. Xiao  and R. H. Mas land. The s patial ﬁltering properties of local edge detectors and

bris k-s us tained retinal ganglion cells . Eur J Neurosci  22(8 ): 201 6–26  2005 .

[ 22] K. Zhang and T. S ejnows ki. Neuronal Tuning: To S harpen or B roaden?   1 999.

8

,Oswin Krause
Dídac Rodríguez Arbonès
Christian Igel