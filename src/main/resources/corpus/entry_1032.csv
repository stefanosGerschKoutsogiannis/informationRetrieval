2011,Comparative Analysis of Viterbi Training and Maximum Likelihood Estimation for HMMs,We present an asymptotic analysis of Viterbi Training (VT) and contrast it with a more conventional Maximum Likelihood (ML) approach to parameter estimation in Hidden Markov Models. While ML estimator works by (locally) maximizing the likelihood of the observed data  VT seeks to maximize the probability of the most likely hidden state sequence. We develop an analytical framework based on a generating function formalism and illustrate it on an exactly solvable model of HMM with one unambiguous symbol. For this particular model the ML objective function is continuously degenerate. VT objective  in contrast  is shown to have only finite degeneracy. Furthermore  VT converges faster and results in sparser (simpler) models  thus realizing an automatic Occam's razor for HMM learning. For more general scenario VT can be worse compared to ML but still capable of correctly recovering most of the parameters.,Comparative Analysis of Viterbi Training and
Maximum Likelihood Estimation for HMMs

Armen Allahverdyan∗
Yerevan Physics Institute

Yerevan  Armenia

aarmen@yerphi.am

Aram Galstyan

USC Information Sciences Institute

Marina del Rey  CA  USA
galstyan@isi.edu

Abstract

We present an asymptotic analysis of Viterbi Training (VT) and contrast it with a
more conventional Maximum Likelihood (ML) approach to parameter estimation
in Hidden Markov Models. While ML estimator works by (locally) maximizing
the likelihood of the observed data  VT seeks to maximize the probability of the
most likely hidden state sequence. We develop an analytical framework based on
a generating function formalism and illustrate it on an exactly solvable model of
HMM with one unambiguous symbol. For this particular model the ML objective
function is continuously degenerate. VT objective  in contrast  is shown to have
only ﬁnite degeneracy. Furthermore  VT converges faster and results in sparser
(simpler) models  thus realizing an automatic Occam’s razor for HMM learning.
For more general scenario VT can be worse compared to ML but still capable of
correctly recovering most of the parameters.

1

Introduction

Hidden Markov Models (HMM) provide one of the simplest examples of structured data observed
through a noisy channel. The inference problems of HMM naturally divide into two classes [20  9]:
i) recovering the hidden sequence of states given the observed sequence  and ii) estimating the model
parameters (transition probabilities of the hidden Markov chain and/or conditional probabilities of
observations) from the observed sequence. The ﬁrst class of problems is usually solved via the max-
imum a posteriori (MAP) method and its computational implementation known as Viterbi algorithm
[20  9]. For the parameter estimation problem  the prevailing method is maximum likelihood (ML)
estimation  which ﬁnds the parameters by maximizing the likelihood of the observed data. Since
global optimization is generally intractable  in practice it is implemented through an expectation–
maximization (EM) procedure known as Baum–Welch algorithm [20  9].
An alternative approach to parameter learning is Viterbi Training (VT)  also known in the literature
as segmental K-means  Baum–Viterbi algorithm  classiﬁcation EM  hard EM  etc. Instead of maxi-
mizing the likelihood of the observed data  VT seeks to maximize the probability of the most likely
hidden state sequence. Maximizing VT objective function is hard [8]  so in practice it is imple-
mented via an EM-style iterations between calculating the MAP sequence and adjusting the model
parameters based on the sequence statistics. It is known that VT lacks some of the desired features
of ML estimation such as consistency [17]  and in fact  can produce biased estimates [9]. However 
it has been shown to perform well in practice  which explains its widespread use in applications
such as speech recognition [16]  unsupervised dependency parsing [24]  grammar induction [6]  ion
channel modeling [19]. It is generally assumed that VT is more robust and faster but usually less
accurate  although for certain tasks it outperforms conventional EM [24].

∗Currently at: Laboratoire de Physique Statistique et Systemes Complexes  ISMANS  Le Mans  France.

1

The current understanding of when and under what circumstances one method should be preferred
over the other is not well–established. For HMMs with continuos observations  Ref. [18] established
an upper bound on the difference between the ML and VT objective functions  and showed that both
approaches produce asymptotically similar estimates when the dimensionality of the observation
space is very large. Note  however  that this asymptotic limit is not very interesting as it makes
the structure imposed by the Markovian process irrelevant. A similar attempt to compare both ap-
proaches on discrete models (for stochastic context free grammars) was presented in [23]. However 
the established bound was very loose.
Our goal here is to understand  both qualitatively and quantitatively  the difference between the two
estimation methods. We develop an analytical approach based on generating functions for exam-
ining the asymptotic properties of both approaches. Previously  a similar approach was used for
calculating entropy rate of a hidden Markov process [1]. Here we provide a non-trivial extension of
the methods that allows to perform comparative asymptotic analysis of ML and VT estimation. It is
shown that both estimation methods correspond to certain free-energy minimization problem at dif-
ferent temperatures. Furthermore  we demonstrate the approach on a particular class of HMM with
one unambiguous symbol and obtain a closed–form solution to the estimation problem. This class
of HMMs is sufﬁciently rich so as to include models where not all parameters can be determined
from the observations  i.e.  the model is not identiﬁable [7  14  9].
We ﬁnd that for the considered model VT is a better option if the ML objective is degenerate (i.e.  not
all parameters can be obtained from observations). Namely  not only VT recovers the identiﬁable
parameters but it also provides a simple (in the sense that non-identiﬁable parameters are set to
zero) and optimal (in the sense of the MAP performance) solution. Hence  VT realizes an automatic
Occam’s razor for the HMM learning. In addition  we show that the VT algorithm for this model
converges faster than the conventional EM approach. Whenever the ML objective is not degenerate 
VT leads generally to inferior results that  nevertheless  may be partially correct in the sense of
recovering certain (not all) parameters.

Pr[Sk+l = sk|Sk−1+l = sk−1] = p(sk|sk−1) 

that S is mixing: it has a unique stationary distribution pst(s) (cid:80)L

2 Hidden Markov Process
Let S = {S0 S1 S2  ...} be a discrete-time  stationary  Markov process with conditional probability
(1)
where l is an integer. Each realization sk of the random variable Sk takes values 1  ...  L. We assume
r=1p(s|r)pst(r) = pst(s)  that is
established from any initial probability in the long time limit.
Let random variables Xi  with realizations xi = 1  ..  M  be noisy observations of Si: the (time-
invariant) conditional probability of observing Xi = xi given the realization Si = si of the Markov
process is π(xk|sk). Deﬁning x ≡ (xN   ...  x1)  s ≡ (sN   ...  s0)  the joint probability of S X reads
(2)

P (s  x) = TsN sN−1(xN )...Ts1 s0(x1) pst(s0) 

where the L × L transfer-matrix T (x) with matrix elements Tsi si−1(x) is deﬁned as

(3)
X = {X1 X2  ...} is called a hidden Markov process. Generally  it is not Markov  but it inherits
stationarity and mixing from S [9]. The probabilities for X can be represented as follows:

Tsi si−1(x) = π(x|si) p(si|si−1).

P (x) =(cid:88)

ss(cid:48) [T(x)]ss(cid:48) pst(s(cid:48))  T(x) ≡ T (xN )T (xN−1) . . . T (x1) 

(4)

where T(x) is a product of transfer matrices.

3 Parameter Estimation

3.1 Maximum Likelihood Estimation
The unknown parameters of an HMM are the transition probabilities p(s|s(cid:48)) of the Markov process
and the observation probabilities π(x|s); see (2). They have to be estimated from the observed

2

sequence x. This is standardly done via the maximum-likelihood approach: one starts with some
trial values ˆp(s|s(cid:48))  ˆπ(x|s) of the parameters and calculates the (log)-likelihood ln ˆP (x)  where ˆP
means the probability (4) calculated at the trial values of the parameters. Next  one maximizes
ln ˆP (x) over ˆp(s|s(cid:48)) and ˆπ(x|s) for the given observed sequence x (in practice this is done via the
Baum-Welch algorithm [20  9]). The rationale of this approach is as follows. Provided that the
length N of the observed sequence is long  and recaling that X is mixing (due to the analogous
feature of S) we get probability-one convergence (law of large numbers) [9]:

ln ˆP (x) →(cid:88)
xP (x) ln[P (x)/ ˆP (x)] ≥ 0  the global maximum of(cid:80)

P (y) ln ˆP (y) 

y

entropy is non-negative (cid:80)

where the average is taken over the true probability P (...) that generated x. Since the relative
xP (x) ln ˆP (x)
as a function of ˆp(s|s(cid:48)) and ˆπ(x|s) is reached for ˆp(s|s(cid:48)) = p(s|s(cid:48)) and ˆπ(x|s) = π(x|s). This
argument is silent on how unique this global maximum is and how difﬁcult to reach it.

(5)

3.2 Viterbi Training

An alternative approach to the parameter learning employs the maximal a posteriori (MAP) estima-
tion and proceeds as follows: Instead of maximizing the likelihood of observed data (5) one tries to
maximize the probability of the most likely sequence [20  9]. Given the joint probability ˆP (s  x) at
trial values of parameters  and given the observed sequence x  one estimates the generating state-
sequence s via maximizing the a posteriori probability

ˆP (s|x) = ˆP (s  x)/ ˆP (x)

(6)
over s. Since ˆP (x) does not depend on s  one can maximize ln ˆP (s  x). If the number of obser-
vations is sufﬁciently large N → ∞  one can substitute maxs ln ˆP (s  x) by its average over P (...)
[see (5)] and instead maximize (over model parameters)

P (x) maxs ln ˆP (s  x).

(7)

(cid:104)(cid:88)

(cid:105)

To relate (7) to the free energy concept (see e.g. [2  4])  we deﬁne an auxiliary (Gibbsian) probability

ˆρβ(s|x) = ˆP β(s  x)/

ˆP β(s(cid:48)  x)

(8)
where β > 0 is a parameter. As a function of s (and for a ﬁxed x)  ˆρβ→∞(s|x) concentrates on
those s that maximize ln ˆP (s  x):

s(cid:48)

 

where δ(s  s(cid:48)) is the Kronecker delta (cid:101)s[j](x) are equivalent outcomes of the maximization  and N

j

is the number of such outcomes. Further  deﬁne

(9)

ˆρβ→∞(s|x) → 1
N

δ[s (cid:101)s[j](x)] 

(cid:88)
P (x) ln(cid:88)

x

s

(cid:88)

Fβ ≡ − 1
β

(cid:88)

x

ˆP β(s  x).

(10)

Within statistical mechanics Eqs. 8 and 10 refer to  respectively  the Gibbs distribution and free
energy of a physical system with Hamiltonian H = − ln P (s  x) coupled to a thermal bath at
inverse temperature β = 1/T [2  4].
It is then clear that ML and Viterbi Training correspond
to minimizing the free energy Eq. 10 at β = 1 and β = ∞  respectively. Note that β2∂βF =

sρβ(s|x) ln ρβ(s|x) ≥ 0  which yields F1 ≤ F∞.

−(cid:80)
xP (x)(cid:80)

3.3 Local Optimization

As we mentioned  global maximization of neither objective is feasible in the general case. Instead 
in practice this maximization is locally implemented via an EM-type algorithm [20  9]: for a given
observed sequence x  and for some initial values of the parameters  one calculates the expected value
of the objective function under the trial parameters (E-step)  and adjusts the parameters to maximize
this expectation (M-step). The resulting estimates of the parameters are now employed as new trial
parameters and the previous step is repeated. This recursion continues till convergence.

3

eβγPN

i=1δ(si+1 a)δ(si b) and deﬁne

For our purposes  this procedure can be understood as calculating certain statistics of the hid-
Indeed  let us introduce fγ(s) ≡
den sequence averaged over the Gibbs distribution Eqs. 8.

P (x) ln(cid:88)

βFβ(γ) ≡ −(cid:88)
(cid:101)P (Sk+1 = a  Sk = b) = −∂γ[F∞(γ)]|γ→0.

(11)
Then  for instance  the (iterative) Viterbi estimate of the transition probabilities are given as follows:
(12)
Conditional probabilities for observations are calculated similarly via a different indicator function.

ˆP β(s  x)fγ(s).

x

s

4 Generating Function

1
N

P (y) ln λ[T(y)] 

ln||T(x)|| → 1
N

Note from (4) that both P (x) and ˆP (x) are obtained as matrix-products. For a large number of
multipliers the behavior of such products is governed by the multiplicative law of large numbers.
We now recall its formulation from [10]: for N → ∞ and x generated by the mixing process X
there is a probability-one convergence:

(cid:88)
(13)
where ||...|| is a matrix norm in the linear space of L × L matrices  and λ[T(x)] is the maximal
pears for N → ∞ [10]. Eqs. (4  13) also imply(cid:80)
eigenvalue of T(x). Note that (13) does not depend on the speciﬁc norm chosen  because all norms
in the ﬁnite-dimensional linear space are equivalent; they differ by a multiplicative factor that disap-
xλ[T(x)] → 1. Altogether  we calculate (5) via
(cid:88)

(14)
Note that the multiplicative law of large numbers is normally formulated for the maximal singular
value. Its reformulation in terms of the maximal eigenvalue needs additional arguments [1].
Introducing the generating function

its probability-one limit
1
N

P (x) ln ˆP (x) → 1
N

λ[T(x)] ln λ[ˆT(x)].

(cid:88)

x

y

x

(15)
where n is a non-negative number  and where ΛN (n  N) means Λ(n  N) in degree of N  one repre-
sents (14) as

x

 

λ[T(x)]λn(cid:104)ˆT(x)
(cid:105)

ΛN (n  N) =(cid:88)
(cid:88)

1
N

x

λ[T(x)] ln λ[ˆT(x)] = ∂nΛ(n  N)|n=0 

(16)

(cid:20)
−(cid:88)∞

zm
m

(cid:21)

where we took into account Λ(0  N) = 1  as follows from (15).
The behavior of ΛN (n  N) is better understood after expressing it via the zeta-function ξ(z  n) [1]

(17)
where Λm(n  m) ≥ 0 is given by (15). Since for a large N  ΛN (n  N) → ΛN (n) [this is the content
of (13)]  the zeta-function ξ(z  n) has a zero at z = 1

ξ(z  n) = exp

Λm(n  m)

m=1

 

(18)
Indeed for z close (but smaller than)
almost
diverges and one has ξ(z  n) → 1 − zΛ(n). Recalling that Λ(0) = 1 and taking n → 0 in 0 =
dn ξ( 1

Λ(n)   n)  we get from (16)

[zΛ(n)]m

m=1

m=1

zm

m

d

Λ(n):
ξ(1/Λ(n)  n) = 0.
1

Λ(n)  the series(cid:80)∞

m Λm(n  m) →(cid:80)∞

(cid:88)

(19)

(20)

For calculating −βFβ in (10) we have instead of (19)

1
N

λ[T(x)] ln λ[ˆT(x)] = ∂nξ(1  0)
∂zξ(1  0) .

x

− βFβ
N

= ∂nξ[β](1  0)
∂zξ[β](1  0)  

where ξ[β](z  n) employs ˆT β
Though in this paper we restricted ourselves to the limit N → ∞  we stress that the knowledge of
the generating function ΛN (n  N) allows to analyze the learning algorithms for any ﬁnite N.

si si−1(x) = ˆπβ(x|si) ˆpβ(si|si−1) instead of ˆTsi si−1(x) in (19).

4

Figure 1: The hidden Markov process (21–22) for  = 0. Gray circles and arrows indicate on the
realization and transitions of the internal Markov process; see (21). The light circles and black
arrows indicate on the realizations of the observed process.

5 Hidden Markov Model with One Unambiguous Symbol

5.1 Deﬁnition
Given a L-state Markov process S  the observed process X has two states 1 and 2; see Fig. 1. All
internal states besides one are observed as 2  while the internal state 1 produces  respectively  1 and
2 with probabilities 1 −  and . For L = 3 we obtain from (1) π(1|1) = 1 − π(2|1) = 1 −  
π(1|2) = π(1|3) = π(2|1) = 0  π(2|2) = π(2|3) = 1. Hence 1 is unambiguous: if it is observed 
the unobserved process S was certainly in 1; see Fig. 1. The simplest example of such HMM exists
already for L = 2; see [12] for analytical features of entropy for this case. We  however  describe
in detail the L = 3 situation  since this case will be seen to be generic (in contrast to L = 2) and
it allows straightforward generalizations to L > 3. The transition matrix (1) of a general L = 3
Markov process reads

(cid:32) p0

(cid:33)

=

q0
r0

(cid:33)

(cid:32) 1 − p1 − p2

1 − r1 − r2
1 − r1 − r2

(21)

P ≡ { p(s|s(cid:48))}3

s s(cid:48)=1 =

(cid:33)

 

(cid:33)

(cid:32) p0

p1
p2

(cid:32) p0

q1
q0
q2

r1
r2
r0

q1
0
0

r1
0
0

0
0

where  e.g.  q1 = p(1|2) is the transition probability 2 → 1; see Fig. 1. The corresponding transfer
matrices read from (3)

T (1) = (1 − )

  T (2) = P − T (1).

(22)

Eq. (22) makes straightforward the reconstruction of the transfer-matrices for L ≥ 4. It should also
be obvious that for all L only the ﬁrst row of T (1) consists of non-zero elements.
For  = 0 we get from (22) the simplest example of an aggregated HMM  where several Markov
states are mapped into one observed state. This model plays a special role for the HMM theory 
since it was employed in the pioneering study of the non-identiﬁability problem [7].

5.2 Solution of the Model

For this model ξ(z  n) can be calculated exactly  because T (1) has only one non-zero row. Using
the method outlined in the supplementary material (see also [1  3]) we get
k−2tk−2 − ˆtn
where τ and ˆτ are the largest eigenvalues of T (2) and ˆT (2)  respectively

0 ) +(cid:88)∞

ξ(z  n) = 1 − z(t0ˆtn

k−1tk−1]zk

0 + τ0ˆτ n

[τ ˆτ nˆtn

(23)

k=2

tk ≡ (cid:104)1|T (1)T (2)k|1(cid:105) =(cid:88)L

(24)
(25)
Here |Rα(cid:105) and (cid:104)Lα| are  respectively right and left eigenvalues of T (2)  while τ1  . . .   τL (τL ≡ τ)
are the eigenvalues of T (2). Eqs. (24  25) obviously extend to hatted quantities.

ψα ≡ (cid:104)1|T (1)|Rα(cid:105)(cid:104)Lα|1(cid:105) 

(cid:104)1| ≡ (1  0  . . .   0).

τ k
αψα 

α=1

5

12312q2r2p2q1r1p1We get from (23  19):

(cid:17)

 

ˆtn
k tk

(cid:16)
1 −(cid:88)∞
(cid:80)∞
(cid:80)∞

k=0tk ln[ˆtk]
k=0(k + 1)tk

k=0

.

ξ(1  n) = (1 − ˆτ nτ)

∂nξ(1  0)
∂zξ(1  0)

=

(26)

(27)

(33)

(34)

(35)

 > 0 this interpretation does not hold  but tk still has a meaning of probability as(cid:80)∞

Note that for  = 0  tk are return probabilities to the state 1 of the L-state Markov process. For

k=0tk = 1.

Turning to equations (19  27) for the free energy  we note that as a function of trial values it depends
on the following 2L parameters:

(ˆτ1  . . .   ˆτL  ˆψ1  . . .   ˆψL).

(28)
As a function of the true values  the free energy depends on the same 2L parameters (28) [without
hats]  though concrete dependencies are different. For the studied class of HMM there are at most
L(L − 1) + 1 unknown parameters: L(L − 1) transition probabilities of the unobserved Markov
chain  and one parameter  coming from observations. We checked numerically that the Jacobian
of the transformation from the unknown parameters to the parameters (28) has rank 2L − 1. Any
2L − 1 parameters among (28) can be taken as independent ones.
For L > 2 the number of effective independent parameters that affect the free energy is smaller than
the number of parameters. So if the number of unknown parameters is larger than 2L − 1  neither
of them can be found explicitly. One can only determine the values of the effective parameters.

6 The Simplest Non-Trivial Scenario

The following example allows the full analytical treatment  but is generic in the sense that it contains
all the key features of the more general situation given above (21). Assume that L = 3 and

q0 = ˆq0 = r0 = ˆr0 = 0 

 = ˆ = 0.

(29)

Note the following explicit expressions

(30)
(31)
(32)
Eqs. (30–32) with obvious changes si → ˆsi for every symbol si hold for ˆtk  ˆτk and ˆψk. Note a

t0 = p0  t1 = p1q1 + p2r1  t2 = p1r1q2 + p2q1r2 
τ1 = 0 
ψ3 − ψ2 = t1/τ  ψ3 + ψ2 = t2/τ 2 

τ2 = −τ 

τ = τ3 =

q2r2 

√

consequence of(cid:80)2

k=0pk =(cid:80)2

k=0qk =(cid:80)2

k=0rk = 1:

τ 2(1 − t0) = 1 − t0 − t1 − t2.

6.1 Optimization of F1

Eqs. (27) and (30–32) imply(cid:80)∞

k=0(k + 1)tk = µ

1−τ 2  

µ ≡ 1 − τ 2 + t2 + (1 − t0)(1 + τ 2) > 0 
− µF1
N

= t1 ln ˆt1 + t2 ln ˆt2 + (1 − τ 2)t0 ln ˆt0 + (1 − t0)τ 2 ln ˆτ 2 .

The free energy F1 depends on three independent parameters ˆt0  ˆt1  ˆt2 [recall (33)]. Hence  minimiz-
ing F1 we get ˆti = ti (i = 0  1  2)  but we do not obtain a deﬁnite solution for the unknown parame-
ters: any four numbers ˆp1  ˆp2  ˆq1  ˆr1 satisfying three equations t0 = 1 − ˆp1 − ˆp2  t1 = ˆp1 ˆq1 + ˆp2ˆr1 
t2 = ˆp1ˆr1(1 − ˆq1) + ˆp2 ˆq1(1 − ˆr1)  minimize F1.

6.2 Optimization of F∞
In deriving (35) we used no particular feature of {ˆpk}2
(20)  the free energy at β > 0 is recovered from (35) by equating its LHS to − βFβ

k=1  {ˆrk}2

k=0  {ˆqk}2

k=1. Hence  as seen from
N and by taking in

6

0   ˆτ 2 → ˆqβ
its RHS: ˆt0 → ˆpβ
free energy reads from (35)

2   ˆt1 → ˆpβ

2 ˆrβ

1 ˆqβ

1 + ˆpβ

2 ˆrβ

1   ˆt2 → ˆpβ

1 ˆrβ

1 ˆqβ

2 + ˆpβ

2 ˆqβ

1 ˆrβ

2 . The zero-temperature

− µF∞
N

= (1 − τ 2)t0 ln ˆt0 + (1 − t0)τ 2 ln ˆτ 2 + t1 ln max[ˆp1 ˆq1  ˆp2ˆr1]

{ˆσi}4

(36)
We now minimize F∞ over the trial parameters ˆp1  ˆp2  ˆq1  ˆr1. This is not what is done by the VT
algorithm; see the discussion after (12). But at any rate both procedures aim to minimize the same
target. VT recursion for this models will be studied in section 6.3 — it leads to the same result.
Minimizing F∞ over the trial parameters produces four distinct solutions:

+ t2 ln max[ˆp2 ˆq1ˆr2  ˆp1ˆr1 ˆq2].

i=1 = {ˆp1 = 0  ˆp2 = 0  ˆq1 = 0  ˆr1 = 0}.

(37)
For each of these four solutions: ˆti = ti (i = 0  1  2) and F1 = F∞. The easiest way to get these
results is to minimize F∞ under conditions ˆti = ti (for i = 0  1  2)  obtain F1 = F∞ and then to
conclude that due to the inequality F1 ≤ F∞ the conditional minimization led to the global mini-
mization. The logics of (37) is that the unambiguous state tends to get detached from the ambiguous
ones  since the probabilities nullifying in (37) refer to transitions from or to the unambiguous state.
Note that although minimizing either F∞ and F1 produces correct values of the independent vari-
ables t0  t1  t2  in the present situation minimizing F∞ is preferable  because it leads to the four-fold
degenerate set of solutions (37) instead of the continuously degenerate set. For instance  if the solu-
tion with ˆp1 = 0 is chosen we get for other parameters

ˆp2 = 1 − t0  ˆq1 =

t2

1 − t0 − t1

  ˆr1 = t1
1 − t0

.

(38)

Furthermore  a more elaborate analysis reveals that for each ﬁxed set of correct parameters only one
among the four solutions Eq. 37 provides the best value for the quality of the MAP reconstruction 
i.e. for the overlap between the original and MAP-decoded sequences.
Finally  we note that minimizing F∞ allows one to get the correct values t0  t1  t2 of the independent
variables ˆt0  ˆt1 and ˆt2 only if their number is less than the number of unknown parameters. This
is not a drawback  since once the number of unknown parameters is sufﬁciently small [less than
four for the present case (29)] their exact values are obtained by minimizing F1. Even then  the
minimization of F∞ can provide partially correct answers. Assume in (36) that the parameter ˆr1 is
known  ˆr1 = r1. Now F∞ has three local minima given by ˆp1 = 0  ˆp2 = 0 and ˆq1 = 0; cf. with
(37). The minimum with ˆp2 = 0 is the global one and it allows to obtain the exact values of the
two effective parameters: ˆt0 = 1 − ˆp1 = t0 and ˆt1 = ˆp1 ˆq1 = t1. These effective parameters are
recovered  because they do not depend on the known parameter ˆr1 = r1. Two other minima have
greater values of F∞  and they allow to recover only one effective parameter: ˆt0 = 1 − ˆp1 = t0.
If in addition to ˆr1 also ˆq1 is known  the two local minimia of F∞ (ˆp1 = 0 and ˆp2 = 0) allow to
recover ˆt0 = t0 only. In contrast  if ˆp1 = p1 (or ˆp2 = p2) is known exactly  there are three local
minima again—ˆp2 = 0  ˆq1 = 0  ˆr1 = 0—but now none of effective parameters is equal to its true
value: ˆti (cid:54)= ti (i = 0  1  2).

6.3 Viterbi EM

Recall the description of the VT algorithm given after (12). For calculating (cid:101)P (Sk+1 = a  Sk = b)

via (11  12) we modify the transfer matrix element in (15  17) as ˆTab(k) → ˆTab(k)eγ  which
produces from (11  12) for the MAP-estimates of the transition probabilities

t1 ˆχ1 + t2 ˆχ2

t1 + t2 + t0(1 − τ 2)   (cid:101)p2 = 1 − t0 −(cid:101)p1 
(cid:101)p1 =
(cid:101)q1 = t1 ˆχ1 + t2(1 − ˆχ2)
t1 ˆχ1 + t2 + (1 − t0)τ 2   (cid:101)q2 = 1 −(cid:101)q1
t2 + t1(1 − ˆχ1) + (1 − t0)τ 2 (cid:101)r2 = 1 −(cid:101)r1 
(cid:101)r1 =

t1(1 − ˆχ1) + t2 ˆχ2

(39)

(40)

(41)

where ˆχ1 ≡
of them is equal to 0 or 1 depending on the ratios ˆp1 ˆq1
ˆp2 ˆr1

ˆpβ
1 ˆrβ
1 ˆqβ
2
1 ˆqβ
2 + ˆpβ
2 ˆrβ

ˆpβ
1 ˆqβ
1
1 + ˆpβ
ˆpβ
1 ˆqβ

. The β → ∞ limit of ˆχ1 and ˆχ2 is obvious: each
. The EM approach amounts to

and ˆp1 ˆr1 ˆq2
ˆp2 ˆr2 ˆq1

  ˆχ2 ≡

ˆpβ
1 ˆrβ

2 ˆqβ
1

2 ˆrβ
1

7

starting with some trial values ˆp1  ˆp2  ˆq1  ˆr1 and using(cid:101)p1  (cid:101)p2 (cid:101)q1 (cid:101)r1 as new trial parameters (and

so on). We see from (39–41) that the algorithm converges just in one step: (39–41) are equal to
the parameters given by one of four solutions (37)—which one among the solutions (37) is selected
depends on the on initial trial parameters in (39–41)—recovering the correct effective parameters
(30–32); e.g. cf. (38) with (39  41) under ˆχ1 = ˆχ2 = 0. Hence  VT converges in one step in
contrast to the Baum-Welch algorithm (that uses EM to locally minimize F1) which  for the present
model  obviously does not converge in one step. There is possibly a deeper point in the one-step
convergence that can explain why in practice VT converges faster than the Baum-Welch algorithm
[9  21]: recall that  e.g. the Newton method for local optimization works precisely in one step for
quadratic functions  but generally there is a class of functions  where it performs faster than (say)
the steepest descent method. Further research should show whether our situation is similar: the VT
works just in one step for this exactly solvable HMM model that belongs to a class of models  where
VT generally performs faster than ML.
We conclude this section by noting that the solvable case (29) is generic: its key results extend to
the general situation deﬁned above (21). We checked this fact numerically for several values of L.
In particular  the minimization of F∞ nulliﬁes as many trial parameters as necessary to express the
remaining parameters via independent effective parameters t0  t1  . . .. Hence for L = 3 and  = 0
two such trial parameters are nulliﬁed; cf. with discussion around (28). If the true error probability
 (cid:54)= 0  the trial value ˆ is among the nulliﬁed parameters. Again  there is a discrete degeneracy in
solutions provided by minimizing F∞.

7 Summary

We presented a method for analyzing two basic techniques for parameter estimation in HMMs  and
illustrated it on a speciﬁc class of HMMs with one unambiguous symbol. The virtue of this class
of models is that it is exactly solvable  hence the sought quantities can be obtained in a closed
form via generating functions. This is a rare occasion  because characteristics of HMM such as
likelihood or entropy are notoriously difﬁcult to calculate explicitly [1]. An important feature of the
example considered here is that the set of unknown parameters is not completely identiﬁable in the
maximum likelihood sense [7  14]. This corresponds to the zero eigenvalue of the Hessian for the
ML (maximum-likelihood) objective function. In practice  one can have weaker degeneracy of the
objective function resulting in very small values for the Hessian eigenvalues. This scenario occurs
often in various models of physics and computational biology [11]. Hence  it is a drawback that the
theory of HMM learning was developed assuming complete identiﬁably [5].
One of our main result is that in contrast to the ML approach that produces continuously degener-
ate solutions  VT results in ﬁnitely degenerate solution that is sparse  i.e.  some [non-identiﬁable]
parameters are set to zero  and  furthermore  converges faster. Note that sparsity might be a desired
feature in many practical applications. For instance  imposing sparsity on conventional EM-type
learning has been shown to produce better results part of speech tagging applications [25]. Whereas
[25] had to impose sparsity via an additional penalty term in the objective function  in our case spar-
sity is a natural outcome of maximizing the likelihood of the best sequence. While our results were
obtained on a class of exactly-solvable model  it is plausible that they hold more generally.
The fact that VT provides simpler and more deﬁnite solutions—among all choices of the parameters
compatible with the observed data—can be viewed as a type of the Occam’s razor for the parameter
learning. Note ﬁnally that statistical mechanics intuition behind these results is that the aposteriori
likelihood is (negative) zero-temperature free energy of a certain physical system. Minimizing this
free energy makes physical sense: this is the premise of the second law of thermodynamics that
ensures relaxation towards a more equilibrium state.
In that zero-temperature equilibrium state
certain types of motion are frozen  which means nullifying the corresponding transition probabilities.
In that way the second law relates to the Occam’s razor. Other connections of this type are discussed
in [15].

Acknowledgments

This research was supported in part by the US ARO MURI grant No. W911NF0610094 and US
DTRA grant HDTRA1-10-1-0086.

8

References
[1] A. E. Allahverdyan  Entropy of Hidden Markov Processes via Cycle Expansion  J. Stat. Phys. 133  535

(2008).

[2] A.E. Allahverdyan and A. Galstyan  On Maximum a Posteriori Estimation of Hidden Markov Processes 

Proc. of UAI  (2009).

[3] R. Artuso. E. Aurell and P. Cvitanovic  Recycling of strange sets  Nonlinearity 3  325 (1990).
[4] P. Baldi and S. Brunak  Bioinformatics  MIT Press  Cambridge  USA (2001).
[5] L. E. Baum and T. Petrie  Statistical inference for probabilistic functions of ﬁnite state Markov chains 

Ann. Math. Stat. 37  1554 (1966).

[6] J.M. Benedi  J.A. Sanchez  Estimation of stochastic context-free grammars and their use as language

models  Comp. Speech and Lang. 19  pp. 249-274 (2005).

[7] D. Blackwell and L. Koopmans  On the identiﬁability problem for functions of ﬁnite Markov chains  Ann.

Math. Statist. 28  1011 (1957).

[8] S. B. Cohen and N. A. Smith  Viterbi training for PCFGs: Hardness results and competitiveness of

uniform initialization  Procs. of ACL (2010).

[9] Y. Ephraim and N. Merhav  Hidden Markov processes  IEEE Trans. Inf. Th.  48  1518-1569  (2002).
[10] L.Y. Goldsheid and G.A. Margulis  Lyapunov indices of a product of random matrices  Russ. Math. Sur-

veys 44  11 (1989).

[11] R. N. Gutenkunst et al.  Universally Sloppy Parameter Sensitivities in Systems Biology Models  PLoS

Computational Biology  3  1871 (2007).

[12] G. Han and B. Marcus  Analyticity of entropy rate of hidden Markov chains  IEEE Trans. Inf. Th.  52 

5251 (2006).

[13] R. A. Horn and C. R. Johnson  Matrix Analysis (Cambridge University Press  New Jersey  USA  1985).
[14] H. Ito  S. Amari  and K. Kobayashi  Identiﬁability of Hidden Markov Information Sources  IEEE Trans.

Inf. Th.  38  324 (1992).

[15] D. Janzing  On causally asymmetric versions of Occam’s Razor and their relation to thermodynamics 

arXiv:0708.3411 (2007).

[16] B. H. Juang and L. R. Rabiner  The segmental k-means algorithm for estimating parameters of hidden
Markov models  IEEE Trans. Acoustics  Speech  and Signal Processing  ASSP-38  no.9  pp.1639-1641 
(1990).

[17] B. G. Leroux  Maximum-Likelihood Estimation for Hidden Markov Models  Stochastic Processes and

Their Applications  40  127 (1992).

[18] N. Merhav and Y. Ephraim  Maximum likelihood hidden Markov modeling using a dominant sequence of

states  IEEE Transactions on Signal Processing  vol.39  no.9  pp.2111-2115 (1991).

[19] F. Qin  Restoration of single-channel currents using the segmental k-means method based on hidden

Markov modeling  Biophys J 86  14881501 (2004).

[20] L. R. Rabiner  A tutorial on hidden Markov models and selected applications in speech recognition  Proc.

IEEE  77  257 (1989).

[21] L. J. Rodriguez and I. Torres  Comparative Study of the Baum-Welch and Viterbi Training Algorithms 

Pattern Recognition and Image Analysis  Lecture Notes in Computer Science  2652/2003  847 (2003).
[22] D. Ruelle  Statistical Mechanics  Thermodynamic Formalism  (Reading  MA: Addison-Wesley  1978).
[23] J. Sanchez  J. Benedi  F. Casacuberta  Comparison between the inside-outside algorithm and the Viterbi
algorithm for stochastic context-free grammars  in Adv. in Struct. and Synt. Pattern Recognition (1996).
[24] V. I. Spitkovsky  H. Alshawi  D. Jurafsky  and C. D. Manning  Viterbi Training Improves Unsupervised
Dependency Parsing  in Proc. of the 14th Conference on Computational Natural Language Learning
(2010).

[25] A. Vaswani  A. Pauls  and D. Chiang  Efﬁcient optimization of an MDL-inspired objective function for

unsupervised part-of-speech tagging  in Proc. ACL (2010).

9

,Sorathan Chaturapruek
John Duchi